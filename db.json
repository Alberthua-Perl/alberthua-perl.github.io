{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/img/avatar.jpg","path":"img/avatar.jpg","modified":1,"renderable":0},{"_id":"source/img/favicon.ico","path":"img/favicon.ico","modified":1,"renderable":0},{"_id":"source/img/icon_wechat.png","path":"img/icon_wechat.png","modified":1,"renderable":0},{"_id":"source/img/tag-bg.jpg","path":"img/tag-bg.jpg","modified":1,"renderable":0},{"_id":"source/img/tag-bg.svg","path":"img/tag-bg.svg","modified":1,"renderable":0},{"_id":"source/img/404-bg.jpg","path":"img/404-bg.jpg","modified":1,"renderable":0},{"_id":"themes/huxblog/source/css/highlight.styl","path":"css/highlight.styl","modified":1,"renderable":1},{"_id":"themes/huxblog/source/css/hux-blog.css","path":"css/hux-blog.css","modified":1,"renderable":1},{"_id":"themes/huxblog/source/css/hux-blog.min.css","path":"css/hux-blog.min.css","modified":1,"renderable":1},{"_id":"themes/huxblog/source/fonts/glyphicons-halflings-regular.eot","path":"fonts/glyphicons-halflings-regular.eot","modified":1,"renderable":1},{"_id":"themes/huxblog/source/fonts/glyphicons-halflings-regular.ttf","path":"fonts/glyphicons-halflings-regular.ttf","modified":1,"renderable":1},{"_id":"themes/huxblog/source/fonts/glyphicons-halflings-regular.woff2","path":"fonts/glyphicons-halflings-regular.woff2","modified":1,"renderable":1},{"_id":"themes/huxblog/source/fonts/glyphicons-halflings-regular.woff","path":"fonts/glyphicons-halflings-regular.woff","modified":1,"renderable":1},{"_id":"themes/huxblog/source/js/bootstrap.min.js","path":"js/bootstrap.min.js","modified":1,"renderable":1},{"_id":"themes/huxblog/source/js/hux-blog.js","path":"js/hux-blog.js","modified":1,"renderable":1},{"_id":"themes/huxblog/source/js/hux-blog.min.js","path":"js/hux-blog.min.js","modified":1,"renderable":1},{"_id":"themes/huxblog/source/js/jquery.nav.js","path":"js/jquery.nav.js","modified":1,"renderable":1},{"_id":"themes/huxblog/source/js/jquery.tagcloud.js","path":"js/jquery.tagcloud.js","modified":1,"renderable":1},{"_id":"themes/huxblog/source/fonts/glyphicons-halflings-regular.svg","path":"fonts/glyphicons-halflings-regular.svg","modified":1,"renderable":1},{"_id":"themes/huxblog/source/js/bootstrap.js","path":"js/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/huxblog/source/js/jquery.min.js","path":"js/jquery.min.js","modified":1,"renderable":1},{"_id":"themes/huxblog/source/css/bootstrap.min.css","path":"css/bootstrap.min.css","modified":1,"renderable":1},{"_id":"themes/huxblog/source/css/bootstrap.css","path":"css/bootstrap.css","modified":1,"renderable":1},{"_id":"source/img/contact-bg.jpg","path":"img/contact-bg.jpg","modified":1,"renderable":0},{"_id":"themes/huxblog/source/js/jquery.js","path":"js/jquery.js","modified":1,"renderable":1},{"_id":"source/img/about-bg.svg","path":"img/about-bg.svg","modified":1,"renderable":0},{"_id":"source/img/about-bg.jpg","path":"img/about-bg.jpg","modified":1,"renderable":0},{"_id":"source/img/home-bg.jpg","path":"img/home-bg.jpg","modified":1,"renderable":0},{"_id":"source/img/home-bg.svg","path":"img/home-bg.svg","modified":1,"renderable":0}],"Cache":[{"_id":"themes/huxblog/README.md","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1669631581114},{"_id":"source/404.md","hash":"83c2c6d587beaa967a976e5969d60fa97fcdbe55","modified":1669631580973},{"_id":"themes/huxblog/_config.yml","hash":"5d235aa7716657282795ee86d9c9db2374197a66","modified":1669631581114},{"_id":"themes/huxblog/LICENSE","hash":"2b209f06bebeb2a8c2b7e187e436f3e1e1fbc8a7","modified":1669631581114},{"_id":"source/_posts/fcos-rhcos-basic-usage.md","hash":"f1174c8ab75d2847d92c1d67e30e05b97ecd9ade","modified":1669650365854},{"_id":"source/_posts/golang-code-server.md","hash":"31eff2c3a6d11606a03763a6826e58b69c4c5b94","modified":1670293121438},{"_id":"source/_posts/golang-environment-deploy.md","hash":"c83469cfb2d3786a34dfec54b7b1b3366dd73640","modified":1669631580973},{"_id":"source/_posts/kubeadm-update-k8s-certs.md","hash":"d62c1df7cea61260d1051c932a994d2cbb5adaf1","modified":1672286910460},{"_id":"source/_posts/k8s-cluster-resource-basic.md","hash":"67aec40f46f22f8099904d7ed61a90fecfdb7465","modified":1669643244090},{"_id":"source/_posts/linux-process-uid.md","hash":"a3179bf21b9fb47f0781fedd88e2df652739fe28","modified":1674893996875},{"_id":"source/_posts/https-handshake-authentication.md","hash":"52665a5108b8c228e15a4240f46a7b8de5e164d2","modified":1674194552409},{"_id":"source/_posts/kani-deploy-k8s.md","hash":"ce83148ac1f71ff6e46922755cd006169a282418","modified":1670295048521},{"_id":"source/_posts/loganalyzer-rsyslog-mysql.md","hash":"73ff6b3659d120756f748093957b10c07f9212bf","modified":1670230769210},{"_id":"source/_posts/podman-arch-usage.md","hash":"209eab2506e3d4ced73c25702edfdccdb59a2537","modified":1670224298946},{"_id":"source/_posts/redhat-quay-v3-registry.md","hash":"0dcd4796edce9b455f90e7ef01e947b5eb3486ad","modified":1670232703745},{"_id":"source/_posts/rocketchat-mongodb-on-k8s.md","hash":"67f9efb98f4f2d08ffc9bc02ad6b3eca7ac35d9b","modified":1671783016791},{"_id":"source/about/index.md","hash":"cfe017eb3ac922ddfe7b4088215717aa61afc44a","modified":1671971996003},{"_id":"source/archives/index.md","hash":"26f32f263feefefdf7b04af63d326113e4166e8f","modified":1671762674566},{"_id":"source/_posts/skopeo-basic-usage.md","hash":"fbbce0f085f2a69b089da0512c7c68292e77c026","modified":1670304797881},{"_id":"source/_posts/podman-usage-practice.md","hash":"78879b8fe8ceded9aa5a26308e81c5dfb35579f1","modified":1670295361829},{"_id":"source/img/avatar.jpg","hash":"341c4110b9f5e20a8e8a312ce842fc5c4a456b21","modified":1669631581024},{"_id":"source/img/favicon.ico","hash":"9987b24caac594aa54615ca089f4dc7f8de47b46","modified":1672836864010},{"_id":"source/img/icon_wechat.png","hash":"7fdb00c9017236e05c1b3e6da38a2cc382fd69fa","modified":1669631581106},{"_id":"source/tags/index.md","hash":"21c5eee4c1fe877025234e5b1a1a62c4fb7896d6","modified":1671763205742},{"_id":"themes/huxblog/languages_to_be_added/de.yml","hash":"424a9c1e6ab69334d7873f6574da02ca960aa572","modified":1669631581114},{"_id":"themes/huxblog/languages_to_be_added/default.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1669631581114},{"_id":"themes/huxblog/languages_to_be_added/en.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1669631581114},{"_id":"themes/huxblog/languages_to_be_added/es.yml","hash":"cb4eeca0ed3768a77e0cd216300f2b2549628b1b","modified":1669631581114},{"_id":"themes/huxblog/languages_to_be_added/zh-CN.yml","hash":"7bfcb0b8e97d7e5edcfca8ab26d55d9da2573c1c","modified":1669631581115},{"_id":"themes/huxblog/languages_to_be_added/ru.yml","hash":"42df7afeb7a35dc46d272b7f4fb880a9d9ebcaa5","modified":1669631581115},{"_id":"themes/huxblog/languages_to_be_added/pl.yml","hash":"de7eb5850ae65ba7638e907c805fea90617a988c","modified":1669631581115},{"_id":"themes/huxblog/languages_to_be_added/no.yml","hash":"8ca475a3b4f8efe6603030f0013aae39668230e1","modified":1669631581114},{"_id":"themes/huxblog/languages_to_be_added/zh-TW.yml","hash":"9acac6cc4f8002c3fa53ff69fb8cf66c915bd016","modified":1669631581115},{"_id":"themes/huxblog/layout/404.ejs","hash":"a4d73541a53e56b7dd46249c6d27cb59f4d97422","modified":1669631581115},{"_id":"themes/huxblog/layout/index.ejs","hash":"70ac58c46625300a70791e210daf446afa6d1cd4","modified":1669631581117},{"_id":"themes/huxblog/layout/layout.ejs","hash":"03e278a3b8bc4503183276b6130ac04a8d5b9865","modified":1669631581118},{"_id":"themes/huxblog/layout/page.ejs","hash":"3fde0787e883274563f9de5aaeb8130b667e132a","modified":1669631581118},{"_id":"themes/huxblog/layout/keynote.ejs","hash":"f5689862281e34dbe8402b0e72f632902e53e88b","modified":1669631581117},{"_id":"themes/huxblog/layout/post.ejs","hash":"fd68124c3de2bbe7d870cecadcf684df7cf82519","modified":1669631581119},{"_id":"themes/huxblog/layout/archives.ejs","hash":"f0046e58cc1dd876133be2bf927aed2b1821cb3e","modified":1669631581117},{"_id":"themes/huxblog/layout/archive.ejs","hash":"6c3ed5d914379319efe835a4aa505abbc616c328","modified":1669631581117},{"_id":"themes/huxblog/layout/about.ejs","hash":"7f56c71383ef6c156b56d79b3984e07cc466606a","modified":1669631581117},{"_id":"themes/huxblog/layout/tags.ejs","hash":"a51bf2828af20939d702de1fdae067439a1153c0","modified":1669631581119},{"_id":"source/img/tag-bg.jpg","hash":"8538e566a5ed1a2d26afce936b67dd5e345bc3c7","modified":1669631581106},{"_id":"source/img/tag-bg.svg","hash":"8ee7e619fc2795472cc28e347b537f27a2aed93a","modified":1669631581112},{"_id":"source/_posts/fcos-rhcos-basic-usage/login-fedora-coreos-live.png","hash":"ee4269d4c6b48fb7fa449b80b12002376ee4980e","modified":1666622177000},{"_id":"source/_posts/fcos-rhcos-basic-usage/coreos-installer-customized-install.png","hash":"1f358024c5e1e6fce42cfbcd5cbded16ef75fc0e","modified":1666574017000},{"_id":"source/_posts/fcos-rhcos-basic-usage/use-fedora-coreos-live-to-install.png","hash":"ae18558cd189e927cc5b7ffc00010ee1e90becfc","modified":1666573832000},{"_id":"source/_posts/golang-code-server/code-server-bg.png","hash":"30b21602c05f178fd07051a7295b5e91f3181c10","modified":1669557877000},{"_id":"source/_posts/golang-environment-deploy/golang-develop-bg.png","hash":"30b21602c05f178fd07051a7295b5e91f3181c10","modified":1669631580973},{"_id":"source/_posts/golang-environment-deploy/golang-develop-bg.svg","hash":"c8bf17e5157e364cd4c51b7591d3be08a63b237b","modified":1669631580973},{"_id":"source/_posts/golang-environment-deploy/sublime-text-golang-3.png","hash":"9d18a6368181e7e37b4e3eeda2ff0f44c5e57248","modified":1669631580975},{"_id":"source/_posts/golang-environment-deploy/sublime-text-golang-2.png","hash":"7e6dc5f6ff602c40490a175a9955957b31f993d5","modified":1669631580975},{"_id":"source/_posts/golang-environment-deploy/sublime-text-golang-1.png","hash":"0aa7f92c7b20b5dea18c4ba26f1c7ad896bac1c7","modified":1669631580975},{"_id":"source/_posts/golang-environment-deploy/sublime-text-golang-5.png","hash":"d0c1361f2d46c8eb777d3e4c7ef8e25f417e5a4e","modified":1669631580975},{"_id":"source/_posts/golang-environment-deploy/sublime-text-golang-4.png","hash":"1fcb1d245a7ff2bbcb680017a92df4b6cd687d37","modified":1669631580975},{"_id":"source/_posts/golang-environment-deploy/sublime-text-golang-8.png","hash":"e976c3789e5446c4c6252586bf00d2ae30e99809","modified":1669631580977},{"_id":"source/_posts/golang-environment-deploy/sublime-text-golang-7.png","hash":"cbc6bf92b7efe68095731c319695d5b1b09343ef","modified":1669631580977},{"_id":"source/_posts/golang-environment-deploy/vim-error.jpg","hash":"a4ec5edff095e15d89a78d624fff231a397be50b","modified":1669631580977},{"_id":"source/_posts/golang-environment-deploy/sublime-text-golang-6.png","hash":"138889becb1f55475bbb8d10c89c9e70679ee816","modified":1669631580977},{"_id":"source/_posts/https-handshake-authentication/firefox-import-pc12-certs-2.png","hash":"bc5a512c597acd0c6d1a3aa6a57e5bb2370830fa","modified":1674049594000},{"_id":"source/_posts/https-handshake-authentication/firefox-import-pc12-certs-5.png","hash":"4aeaf2a7d43142ee9e43eba28aa98c9ec1836851","modified":1674037574000},{"_id":"source/_posts/https-handshake-authentication/firefox-import-pc12-certs-4.png","hash":"a883421f80b62c0decaa5b59574aa058516ba130","modified":1674049707000},{"_id":"source/_posts/https-handshake-authentication/firefox-import-pc12-certs-3.png","hash":"8c695e350f469eaea95daab3be4f5ef255e9b991","modified":1674049679000},{"_id":"source/_posts/https-handshake-authentication/https-mutual-no-client-cert-error-1.png","hash":"6a7dc2b7d8bc178c5b9c96bcfd14b2cf5eedf689","modified":1674037456000},{"_id":"source/_posts/https-handshake-authentication/https-single-auth-chrome-error-1.png","hash":"78d1f9fa2c889c9ae3c369fd30bfc1e40ebe8c9b","modified":1674049812000},{"_id":"source/_posts/https-handshake-authentication/server-hello-done.jpg","hash":"98cd326b6c5b21c847e84491086c0cc7f3cdfcff","modified":1672416044000},{"_id":"source/_posts/https-handshake-authentication/server-response-to-client-4-phase.png","hash":"9e0b681fd8328a0b22611285d473aa421240b49a","modified":1672798801000},{"_id":"source/_posts/https-handshake-authentication/ssl-tls-authentication.png","hash":"698f575770bc44b399829acd04bb9fe33909eac6","modified":1672389160000},{"_id":"source/_posts/https-handshake-authentication/server-key-exchange.png","hash":"cac522267a729317cbd32cc9374ad8d0435bd00f","modified":1672415367000},{"_id":"source/_posts/https-handshake-authentication/ssl-tls-handshake-end.png","hash":"73d2904ecd2120a1814e936f32261baaf325e801","modified":1672811743000},{"_id":"source/_posts/https-handshake-authentication/ssl-tls-in-network-stack.png","hash":"7b0fe89054b4cce3a2ae17e97df22bb3dffc1fc1","modified":1672385533000},{"_id":"source/_posts/k8s-cluster-resource-basic/k8s-resource-basic.png","hash":"2b188ce6115bb6c59227dc4b09eb7d9bff083e7d","modified":1669631580979},{"_id":"source/_posts/k8s-cluster-resource-basic/k8s-resource-basic.svg","hash":"ddb7e0af613e904e9936bf091ae4a442bf00ca2b","modified":1669631580979},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-mysql-rsyslogserver.jpg","hash":"a4f34333ca86d9599f487596194f50272ea00091","modified":1620026986000},{"_id":"source/_posts/kubeadm-update-k8s-certs/kubeadm-certs-bg.jpg","hash":"a102d05e95270ebbf1701d310e75e38b39b71215","modified":1672285039000},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/quay-push-error-2.jpg","hash":"c5b1d5135d9d64b9703d1decf207255671161f48","modified":1620047374000},{"_id":"source/_posts/podman-arch-usage/podman-bg.webp","hash":"e8ccc3aae0be1dd0f0410fcc46783fd6561471eb","modified":1670224105000},{"_id":"source/_posts/podman-arch-usage/podman-version-compare.png","hash":"08a461e9cadddd2f72297e631ee0dcf8aaab9403","modified":1670220986000},{"_id":"source/_posts/podman-usage-practice/podman-bg.webp","hash":"e8ccc3aae0be1dd0f0410fcc46783fd6561471eb","modified":1670224105000},{"_id":"source/_posts/redhat-quay-v3-registry/config-quay-1.png","hash":"7f050839b16bd27f3ec73ee942d42a7928e37196","modified":1620892250000},{"_id":"source/_posts/redhat-quay-v3-registry/config-quay-4.png","hash":"7c27372682ce2e84b290ae1f3e82538375504fa7","modified":1620892330000},{"_id":"source/_posts/redhat-quay-v3-registry/config-quay-2.png","hash":"f80fc9e45653655e5972ef3e49d4d10ca13aa215","modified":1620892299000},{"_id":"source/_posts/redhat-quay-v3-registry/config-quay-3.png","hash":"5ecaa17ec3d5c227276e58a6955909914097a04e","modified":1620892315000},{"_id":"source/_posts/redhat-quay-v3-registry/config-quay-6.png","hash":"f12a386341c3f7b5c962ef34e15eaf1de6654815","modified":1620892357000},{"_id":"source/_posts/redhat-quay-v3-registry/config-quay-5.png","hash":"3edac8fed196a3cfe705f8d17221b2c1d3485978","modified":1620892344000},{"_id":"source/_posts/redhat-quay-v3-registry/config-quay-8.png","hash":"f9183cb80918e44bb65bccc0b045c98aba1798d6","modified":1620892384000},{"_id":"source/_posts/redhat-quay-v3-registry/first-login-config-quay.png","hash":"6023ac2e3c02c61f50b8a79d1b35803fef5db6b9","modified":1620892168000},{"_id":"source/_posts/redhat-quay-v3-registry/normal-login-quay.png","hash":"f041e5307900a4fe083c939473e71a51d69021f9","modified":1620892695000},{"_id":"source/_posts/redhat-quay-v3-registry/podman-push-quay-permission-denied-1001-1.jpg","hash":"d2fe6cb532048f4c48e938a5b55a8df41ce44ef3","modified":1639990888000},{"_id":"source/_posts/rocketchat-mongodb-on-k8s/rocketchat-login.png","hash":"eced4ff9473ea0eb5fab367e49ee07fc5067775d","modified":1670297524000},{"_id":"source/_posts/skopeo-basic-usage/skopeo-bg.jpg","hash":"6face4bc90a8f5bfc53d329961238b9367cfc3da","modified":1670304575000},{"_id":"source/_posts/skopeo-basic-usage/skopeo-copy-dir-2.jpg","hash":"7f0af9bde8e375efbae82be8f9e68dcd4b90db29","modified":1644413689000},{"_id":"source/img/404-bg.jpg","hash":"68f7d525269a94287e0ad18713ae232fb59dcf71","modified":1669631581016},{"_id":"themes/huxblog/layout/_partial/head.ejs","hash":"87c544a64ea49b835330135a616deb2e9fd39bbb","modified":1669631581116},{"_id":"themes/huxblog/layout/_partial/footer.ejs","hash":"e325a9953abc1a3751aa1a927bc3ecbdd627803a","modified":1669631581116},{"_id":"themes/huxblog/layout/_partial/nav.ejs","hash":"4c905166c960852e9b9a3c9d5c680091e37b481f","modified":1669631581116},{"_id":"themes/huxblog/source/css/highlight.styl","hash":"e842080e6d580f0f70a7df71fbde3c4e49463c19","modified":1669631581122},{"_id":"themes/huxblog/source/css/hux-blog.css","hash":"c1b0a32ad8075ac09d99fb4d64a9fbc84163abf8","modified":1669631581122},{"_id":"themes/huxblog/source/css/hux-blog.min.css","hash":"1baef04de262aeb7023d835429b49a805ac4ab40","modified":1669631581122},{"_id":"themes/huxblog/source/fonts/glyphicons-halflings-regular.eot","hash":"86b6f62b7853e67d3e635f6512a5a5efc58ea3c3","modified":1669631581122},{"_id":"themes/huxblog/source/fonts/glyphicons-halflings-regular.ttf","hash":"44bc1850f570972267b169ae18f1cb06b611ffa2","modified":1669631581124},{"_id":"themes/huxblog/source/fonts/glyphicons-halflings-regular.woff2","hash":"ca35b697d99cae4d1b60f2d60fcd37771987eb07","modified":1669631581125},{"_id":"themes/huxblog/source/fonts/glyphicons-halflings-regular.woff","hash":"278e49a86e634da6f2a02f3b47dd9d2a8f26210f","modified":1669631581125},{"_id":"themes/huxblog/source/js/bootstrap.min.js","hash":"b3f2ef9f985e7906c9360756b73cd64bf7733647","modified":1669631581127},{"_id":"themes/huxblog/source/js/hux-blog.js","hash":"4b4d3c557405d04c3087d36c13e2834fe05c0f73","modified":1669631581127},{"_id":"themes/huxblog/source/js/hux-blog.min.js","hash":"1563e7f70550ac6b30803d6f449719b853200e35","modified":1669631581128},{"_id":"themes/huxblog/source/js/jquery.nav.js","hash":"ef2160a456176a4d09cc0b95d52b27dfbbadf2d8","modified":1669631581133},{"_id":"themes/huxblog/source/js/jquery.tagcloud.js","hash":"4e5fd0b07f3bd935f2e603710447e039e3677211","modified":1669631581133},{"_id":"source/_posts/fcos-rhcos-basic-usage/fedora-coreos-release-version.png","hash":"5231f0d165037ec52e197c4cb28184aad14907ad","modified":1665064528000},{"_id":"source/_posts/https-handshake-authentication/client-hello-body-2.png","hash":"0e53e97db1050924044428350184451e35a84db7","modified":1672413706000},{"_id":"source/_posts/https-handshake-authentication/client-response-to-server-ssl.jpg","hash":"e5536e0c40e9ed1ef2e640be37140f2a26805722","modified":1672416311000},{"_id":"source/_posts/https-handshake-authentication/firefox-import-pc12-certs-1.png","hash":"58eb8f8e26448302d2a3f81617189234a3108217","modified":1674049549000},{"_id":"source/_posts/https-handshake-authentication/ca-signed-certification-verify.jpg","hash":"b1cdec87f1ea61a96e0b3e9a9314c3dcbf561061","modified":1672384725000},{"_id":"source/_posts/https-handshake-authentication/server-response-to-client-ssl.png","hash":"a7b0c63faa202a50a0947ae04e24e4d8f8b0a8e2","modified":1672414139000},{"_id":"source/_posts/k8s-cluster-resource-basic/kubectl-get-raw-json.jpg","hash":"2a37464350ad172cc4889f3bd7a55d0c0d6856a3","modified":1669631580981},{"_id":"source/_posts/k8s-cluster-resource-basic/kubernetes-interface-2.jpg","hash":"dd94eb544f19060264be58a95dfd6659dad0cfe9","modified":1669631580995},{"_id":"source/_posts/k8s-cluster-resource-basic/pod-name.jpg","hash":"efad7d57d1b7fd090260a9faa7a415c50ee2466b","modified":1669631580999},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-1.jpg","hash":"219813cbdf5326472e5d4175a0dce10d39e1a994","modified":1620056513000},{"_id":"themes/huxblog/layout/_partial/pagination.ejs","hash":"557d6bb069a1d48af49ae912994653f44b32a570","modified":1669631581116},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-2.jpg","hash":"09bf12b8bb0de7750f7f06429941e2dcd9900da6","modified":1620056539000},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-9.jpg","hash":"bda92ea5e61b37ae8a67081f806a287d2146971e","modified":1617608135000},{"_id":"source/_posts/podman-arch-usage/container-access-external-iptables.jpg","hash":"0a5b385ecba903eab3223979a77cb51aa1d95474","modified":1637377863000},{"_id":"source/_posts/podman-arch-usage/gogs-git-repository.jpg","hash":"77b39edaa1f5d430e067d4d71b7e228b2e0c8fa8","modified":1636819922000},{"_id":"source/_posts/podman-arch-usage/minio-server-cloud-native-object-storage-demo-1.jpg","hash":"42f2be9c7c2bb6b6c2597b1a1c369090c1cc386f","modified":1630469787000},{"_id":"source/_posts/podman-arch-usage/minio-server-cloud-native-object-storage-demo-3.jpg","hash":"c3a64c0141e40b595925f26175050fd0484f6d48","modified":1630470097000},{"_id":"source/_posts/podman-arch-usage/podman-busybox-capability.jpg","hash":"8990f8c6a51ace7796ceed5712fa4146a769488b","modified":1637651221000},{"_id":"source/_posts/podman-arch-usage/podman-commit-warning.jpg","hash":"1f00e86ac6489590310efa3dee45503655b0df28","modified":1637645750000},{"_id":"source/_posts/podman-arch-usage/podman-login-token.jpg","hash":"a2288cdcae2f4b9bf988e64c1f4688bca2333f08","modified":1644250290000},{"_id":"source/_posts/podman-arch-usage/podman-push-quay.jpg","hash":"9b1ab1dc61c042038bd7806f9f719f52bf7b374e","modified":1636551815000},{"_id":"source/_posts/podman-arch-usage/podman-run-pod-create.jpg","hash":"5a50b2f67dad8fd06a5146b63934fd21a7532df5","modified":1637648163000},{"_id":"source/_posts/podman-arch-usage/podman-rmi-error-no-container-use.jpg","hash":"4a17ca0766d17379cf1fd15a2522887dded056b0","modified":1636550872000},{"_id":"source/_posts/podman-arch-usage/user-namespace-subuid-mapping-2.jpg","hash":"a0def5fdf57cc9c4d7a803300015639d836ba47f","modified":1637771691000},{"_id":"source/_posts/podman-usage-practice/container-access-external-iptables.jpg","hash":"0a5b385ecba903eab3223979a77cb51aa1d95474","modified":1637377863000},{"_id":"source/_posts/podman-usage-practice/minio-server-cloud-native-object-storage-demo-1.jpg","hash":"42f2be9c7c2bb6b6c2597b1a1c369090c1cc386f","modified":1630469787000},{"_id":"source/_posts/podman-usage-practice/gogs-git-repository.jpg","hash":"77b39edaa1f5d430e067d4d71b7e228b2e0c8fa8","modified":1636819922000},{"_id":"source/_posts/podman-usage-practice/podman-busybox-capability.jpg","hash":"8990f8c6a51ace7796ceed5712fa4146a769488b","modified":1637651221000},{"_id":"source/_posts/podman-usage-practice/minio-server-cloud-native-object-storage-demo-3.jpg","hash":"c3a64c0141e40b595925f26175050fd0484f6d48","modified":1630470097000},{"_id":"source/_posts/podman-usage-practice/podman-login-token.jpg","hash":"a2288cdcae2f4b9bf988e64c1f4688bca2333f08","modified":1644250290000},{"_id":"source/_posts/podman-usage-practice/podman-push-quay.jpg","hash":"9b1ab1dc61c042038bd7806f9f719f52bf7b374e","modified":1636551815000},{"_id":"source/_posts/podman-usage-practice/podman-commit-warning.jpg","hash":"1f00e86ac6489590310efa3dee45503655b0df28","modified":1637645750000},{"_id":"source/_posts/podman-usage-practice/podman-rmi-error-no-container-use.jpg","hash":"4a17ca0766d17379cf1fd15a2522887dded056b0","modified":1636550872000},{"_id":"source/_posts/podman-usage-practice/podman-run-pod-create.jpg","hash":"5a50b2f67dad8fd06a5146b63934fd21a7532df5","modified":1637648163000},{"_id":"source/_posts/podman-usage-practice/user-namespace-subuid-mapping-2.jpg","hash":"a0def5fdf57cc9c4d7a803300015639d836ba47f","modified":1637771691000},{"_id":"source/_posts/redhat-quay-v3-registry/catalog-health-index.jpg","hash":"d4201bd4a61a4d969173aca2351156c96b161e9d","modified":1643292823000},{"_id":"source/_posts/redhat-quay-v3-registry/config-quay-7.png","hash":"7cc6cb2439650e33401891f76b12a931490c7264","modified":1620892370000},{"_id":"source/_posts/redhat-quay-v3-registry/go-toolset-catalog.jpg","hash":"e8f08e57a7bd0dadd47b5d3d6e7378c9b86e7ed2","modified":1643278660000},{"_id":"source/_posts/redhat-quay-v3-registry/docker-client-login-quay-registry.jpg","hash":"55d78f296219e61490b1dcbffb7680a8ff3b84f8","modified":1639991740000},{"_id":"source/_posts/skopeo-basic-usage/podman-load-dir-from-skopeo-copy.jpg","hash":"3ea789e8147a5823dc5a81b9e311a8dadc7eb90b","modified":1646380908000},{"_id":"source/_posts/skopeo-basic-usage/skopeo-copy-dest-creds.jpg","hash":"45476fa26b5e9abcb78f4e9a46fba63c6dac48ac","modified":1644308465000},{"_id":"source/_posts/skopeo-basic-usage/skopeo-docker-image-format-digest-2.jpg","hash":"58124f703d6f38a4b11181068602fe35461628f6","modified":1649520415000},{"_id":"source/_posts/skopeo-basic-usage/skopeo-delete-2.jpg","hash":"7ad8615297b0ca28d13c1486709e6cadb2a2cd4e","modified":1646708694000},{"_id":"source/_posts/skopeo-basic-usage/skopeo-sync-demo.jpg","hash":"09adc47d47a909749b1d870e52235756fe840fd0","modified":1646570433000},{"_id":"source/_posts/skopeo-basic-usage/skopeo-sync-help.jpg","hash":"a82aad52c6bc77f317e382afe98d5f5a1c686869","modified":1646570666000},{"_id":"themes/huxblog/source/fonts/glyphicons-halflings-regular.svg","hash":"de51a8494180a6db074af2dee2383f0a363c5b08","modified":1669631581124},{"_id":"themes/huxblog/source/js/bootstrap.js","hash":"f8752e9ae24daec0a0baffd7819122f8c6fd9103","modified":1669631581126},{"_id":"themes/huxblog/source/js/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1669631581133},{"_id":"source/_posts/fcos-rhcos-basic-usage/quay-coreos-butane-release.png","hash":"b5c02e6ac9bd196524e15c8114d3ff98a11c2fc9","modified":1665231865000},{"_id":"source/_posts/https-handshake-authentication/server-ca-signed-certification.png","hash":"f914d929019c0b6c27d0da40108f2088def8ab35","modified":1672414477000},{"_id":"source/_posts/kani-deploy-k8s/crictl-ssl-ca-request-quay-error.jpg","hash":"b01f928b407f3c61d3c897624058a726e8480aab","modified":1669631581001},{"_id":"source/_posts/kani-deploy-k8s/kubernetes-cluster-status.jpg","hash":"335781aa908ac09c559c7489bc640b68d65a28a6","modified":1669631581013},{"_id":"source/_posts/kani-deploy-k8s/register-var-used-between-two-plays-error.jpg","hash":"bbcc1fed4bf997f62d05945e2188e7141a2b5886","modified":1669631581014},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-6.jpg","hash":"6350f8f4c5b83d1d09f41c9459d0ec011836692a","modified":1617608003000},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-7.jpg","hash":"bc29762a1a76b672c7e411e1021e4c11d5ccbd79","modified":1620057031000},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-5.jpg","hash":"6227cdaa9c93e14aeef391ddfa78ae9d47aaafc1","modified":1620056956000},{"_id":"source/_posts/podman-arch-usage/cockpit-podman-1.jpg","hash":"2ed48ec04ce40bc94daab5199f2a421db451e566","modified":1636526169000},{"_id":"source/_posts/podman-arch-usage/cockpit-podman-2.jpg","hash":"2d5593e61dc10a933a935fcf9812b376f4dffee2","modified":1636527806000},{"_id":"source/_posts/podman-arch-usage/gogs-settings.jpg","hash":"3e05ffb0a5afc46ec844255b0e49b4f23cb28ff6","modified":1636737518000},{"_id":"source/_posts/podman-arch-usage/podman-network-mode.jpg","hash":"dbe1ed815c0607b8a38443bca037c484c801b393","modified":1637721102000},{"_id":"source/_posts/podman-arch-usage/podman-image-list.jps.JPG","hash":"d5ffbd3a6f971c6de9fb62cca4b5d7bea07703db","modified":1636734394000},{"_id":"source/_posts/podman-arch-usage/rootless-slirp4netns-networking.jpg","hash":"0022457652df2d9194f589ad0dd6993046e3bdd7","modified":1637722632000},{"_id":"source/_posts/podman-usage-practice/cockpit-podman-1.jpg","hash":"2ed48ec04ce40bc94daab5199f2a421db451e566","modified":1636526169000},{"_id":"source/_posts/podman-usage-practice/hualf-rootless-container.jpg","hash":"683e74d3b16de4db7c8f172607409f3b88d57058","modified":1637725964000},{"_id":"source/_posts/podman-usage-practice/gogs-settings.jpg","hash":"3e05ffb0a5afc46ec844255b0e49b4f23cb28ff6","modified":1636737518000},{"_id":"source/_posts/podman-usage-practice/podman-image-list.jps.JPG","hash":"d5ffbd3a6f971c6de9fb62cca4b5d7bea07703db","modified":1636734394000},{"_id":"source/_posts/podman-usage-practice/podman-network-mode.jpg","hash":"dbe1ed815c0607b8a38443bca037c484c801b393","modified":1637721102000},{"_id":"source/_posts/podman-usage-practice/rootless-slirp4netns-networking.jpg","hash":"0022457652df2d9194f589ad0dd6993046e3bdd7","modified":1637722632000},{"_id":"source/_posts/redhat-quay-v3-registry/podman-push-quay-permission-denied-1001-2.jpg","hash":"647fcb3baaa75966e4084a952b563dc467a320ca","modified":1639990986000},{"_id":"source/_posts/skopeo-basic-usage/skopeo-copy-transform-image-format.jpg","hash":"235ba0cb6144c34ed1769dc37e42ed6bd47cfa70","modified":1646394039000},{"_id":"source/_posts/skopeo-basic-usage/skopeo-delete-1.jpg","hash":"0288235f6eca18418b38c7412604003a453ff790","modified":1646708636000},{"_id":"source/_posts/skopeo-basic-usage/skopeo-docker-image-format-digest-1.jpg","hash":"855bd8351c8d10b0181ac7f324f218c86e696a08","modified":1649519242000},{"_id":"themes/huxblog/source/css/bootstrap.min.css","hash":"973e37a8502921d56bc02bb55321f45b072b6f71","modified":1669631581122},{"_id":"source/_posts/skopeo-basic-usage/skopeo-sync-between-registry.jpg","hash":"8372bbb26c0b94488dc7af066f757118bd85778b","modified":1646661277000},{"_id":"source/_posts/skopeo-basic-usage/skopeo-inspect-creds.jpg","hash":"8fb1b2cca6fd766abab0fa3f71ca55c987b6a837","modified":1644298484000},{"_id":"source/_posts/https-handshake-authentication/client-hello-body-1.png","hash":"01839c1fa38511bff6c7296c454fcce40ef83a8e","modified":1672413692000},{"_id":"source/_posts/https-handshake-authentication/https-bg.png","hash":"2c68ccda2f4e2c1c8e7c3002706bc9c14386740f","modified":1674191677000},{"_id":"source/_posts/https-handshake-authentication/https-mutual-no-client-cert-error-2.png","hash":"c07b7347c864211a5c0e63690764f20a6c2d2e1a","modified":1674051092000},{"_id":"source/_posts/https-handshake-authentication/https-single-auth-chrome-error-2.png","hash":"761bb96d3cf2f85f180e0d244f94f92974ec4520","modified":1674050248000},{"_id":"source/_posts/k8s-cluster-resource-basic/kubernetes-interface-1.jpg","hash":"0bd4c09b7df615c1034086ae556f8d5cda1099ac","modified":1669631580995},{"_id":"source/_posts/https-handshake-authentication/ssl-tls-single-authentication-progress.png","hash":"4d5f7d197cd0291479ee5848399b2350842a034a","modified":1672393109000},{"_id":"source/_posts/kani-deploy-k8s/kani-ansible-k8s.jpg","hash":"7a35501aa669849c73b2002ebf8bc2e87146ce6c","modified":1669631581004},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-4.jpg","hash":"a8f11a1c9ba264f2d02895d92c85376f1f10e33b","modified":1617607953000},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/quay-push-error-1.jpg","hash":"a2d974e7fdf3b238302b45ca2ccf35b30624bc7c","modified":1620047282000},{"_id":"source/_posts/podman-arch-usage/external-access-container-web-service-iptables.jpg","hash":"fbf816946c2270517a74a40af1cf6c2dc473054e","modified":1637734423000},{"_id":"source/_posts/podman-arch-usage/minio-server-cloud-native-object-storage-demo-2.jpg","hash":"88b0c6576515378cd6399902a61a4da8db750d66","modified":1630469942000},{"_id":"source/_posts/podman-arch-usage/hualf-rootless-container.jpg","hash":"683e74d3b16de4db7c8f172607409f3b88d57058","modified":1637725964000},{"_id":"source/_posts/podman-usage-practice/cockpit-podman-2.jpg","hash":"2d5593e61dc10a933a935fcf9812b376f4dffee2","modified":1636527806000},{"_id":"source/_posts/podman-arch-usage/user-namespace-subuid-mapping-1.jpg","hash":"7e1664afc7d84c7765f690d5d543ea4d43c086c2","modified":1637747578000},{"_id":"source/_posts/podman-usage-practice/external-access-container-web-service-iptables.jpg","hash":"fbf816946c2270517a74a40af1cf6c2dc473054e","modified":1637734423000},{"_id":"source/_posts/podman-usage-practice/minio-server-cloud-native-object-storage-demo-2.jpg","hash":"88b0c6576515378cd6399902a61a4da8db750d66","modified":1630469942000},{"_id":"source/_posts/kani-deploy-k8s/kani-ansible-k8s.svg","hash":"058b1ad3bc58da9e24c28949f6d5691b4f8961e9","modified":1669631581007},{"_id":"source/_posts/skopeo-basic-usage/skopeo-copy-docker-format-image-dir.jpg","hash":"d9c7289d1620f56f7e0095dd63902bbac029097c","modified":1646380701000},{"_id":"source/_posts/skopeo-basic-usage/skopeo-copy-oci-2.jpg","hash":"0b711364bf595e28f0169a12d33a8a181e177a41","modified":1644424523000},{"_id":"themes/huxblog/source/css/bootstrap.css","hash":"41c54bf695145ae0b4d9020a1da308ceb05dcaf3","modified":1669631581120},{"_id":"source/_posts/https-handshake-authentication/ssl-four-handshakes-https-single-and-mutual-authentication.png","hash":"aaa2573ec0d4ff333f2cd2a2ddd0c4d0bd80c20b","modified":1674134003000},{"_id":"source/_posts/https-handshake-authentication/wireshark-https-mutual-progress.png","hash":"ab72112700f6869f63aa3cb35c99024f24afcc58","modified":1674050688000},{"_id":"source/_posts/k8s-cluster-resource-basic/kubernetes-apiserver-manifest.jpg","hash":"61f244e6262b8e1d7f9c0ad49153ac8738fc1036","modified":1669631580983},{"_id":"source/_posts/k8s-cluster-resource-basic/kubernetes-single-master-arch.jpg","hash":"5c20ea9faea6a10912cd1375b09f03dd65e60fdb","modified":1669631580999},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-8.jpg","hash":"6fe8ff80799ce06f136d117db5f6c47b4e8af019","modified":1617608111000},{"_id":"source/_posts/podman-arch-usage/centos79-kernel-not-support-podman-rootless.jpg","hash":"a74d92a8d16cf92299d7c3b4023c95f2058291b4","modified":1630941669000},{"_id":"source/_posts/podman-usage-practice/rootless-container-to-container-bandwidth.jpg","hash":"6f87ae38c8686584e46d01915c52ed42be2fa3a8","modified":1637824939000},{"_id":"source/_posts/podman-usage-practice/user-namespace-subuid-mapping-1.jpg","hash":"7e1664afc7d84c7765f690d5d543ea4d43c086c2","modified":1637747578000},{"_id":"source/_posts/kani-deploy-k8s/kubeadm-init-master-error-2.jpg","hash":"bc4e56c5a1da40ab32ab98b9b74ecc32e195b671","modified":1669631581012},{"_id":"source/_posts/kani-deploy-k8s/kubeadm-init-master-error-1.jpg","hash":"f8677913ae780a3957b04e4e3803cd70b19fe629","modified":1669631581009},{"_id":"source/_posts/redhat-quay-v3-registry/ssl-key-permission-run-quay-error.jpg","hash":"6a3046920f57a2632901bff5cd23bc6578d700e6","modified":1639989903000},{"_id":"source/_posts/rocketchat-mongodb-on-k8s/mongodb-bg-2.png","hash":"66734d327c32386d45e2cee65f1ecfc6bafec7c4","modified":1670296309000},{"_id":"source/_posts/skopeo-basic-usage/skopeo-copy-docker-daemon.jpg","hash":"3e3e9293fd025cdab6d970dcecc594b0d1e61dc5","modified":1646390437000},{"_id":"source/img/contact-bg.jpg","hash":"6af63305c923899017e727b5ca968a2703bc08cf","modified":1669631581026},{"_id":"source/_posts/skopeo-basic-usage/skopeo-copy-oci-1.jpg","hash":"397d21637a0129e688837cead4b53dd67f42ae05","modified":1644421805000},{"_id":"source/_posts/skopeo-basic-usage/skopeo-oci-image-format-digest.jpg","hash":"67af2b24116e26452669bd1feebc50f1b70c1e41","modified":1649521149000},{"_id":"themes/huxblog/source/js/jquery.js","hash":"1852661bd11a09ca9b9cb63d1aa6ff390fffaf4e","modified":1669631581131},{"_id":"source/_posts/fcos-rhcos-basic-usage/fedora-coreos-bg.jpg","hash":"80069c0b6e00f672f6d48da592db0d643c184f92","modified":1669650002000},{"_id":"source/_posts/https-handshake-authentication/client-server-tcp-ssl-socket.png","hash":"78d432604d1626e763eddf9ec4aa2d8b38ba205d","modified":1672386149000},{"_id":"source/_posts/podman-arch-usage/rootless-container-to-container-bandwidth.jpg","hash":"6f87ae38c8686584e46d01915c52ed42be2fa3a8","modified":1637824939000},{"_id":"source/_posts/podman-arch-usage/user-namespace-subuid-mapping-2-edited.png","hash":"cdf0baf52a744c3f20a9f3765b29a24eca95b620","modified":1637771734000},{"_id":"source/_posts/podman-usage-practice/centos79-kernel-not-support-podman-rootless.jpg","hash":"a74d92a8d16cf92299d7c3b4023c95f2058291b4","modified":1630941669000},{"_id":"source/_posts/podman-usage-practice/user-namespace-subuid-mapping-2-edited.png","hash":"cdf0baf52a744c3f20a9f3765b29a24eca95b620","modified":1637771734000},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-3.jpg","hash":"7f7ac414f86f0d48a40afb52c0da736b6e3aa560","modified":1620056662000},{"_id":"source/img/about-bg.svg","hash":"55173e85b5a107bb539e2d2e3858716ebee9644e","modified":1669631581024},{"_id":"source/img/about-bg.jpg","hash":"f197658cf766d9dea12627a43f68ed04cf7a41f5","modified":1669631581020},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/selinux-php-mysql-connection.jpg","hash":"7813de2ca12bb4cd150629c838fa3bf254836584","modified":1617608433000},{"_id":"source/_posts/podman-arch-usage/godev-rootless-container.jpg","hash":"eadca754687ed7a1cff4f4b965c7ef888429f48f","modified":1637726199000},{"_id":"source/_posts/podman-arch-usage/rootfull-container-to-container-bandwidth.jpg","hash":"79a810aa2badd7a0bc5f4d50e823c10a20afbcc5","modified":1637824617000},{"_id":"source/_posts/podman-arch-usage/rootless-user-namespace-mapping.jpg","hash":"406c3a53724907a84e61e43c6afa8c4dc6bfa76e","modified":1637777101000},{"_id":"source/_posts/podman-usage-practice/rootfull-container-to-container-bandwidth.jpg","hash":"79a810aa2badd7a0bc5f4d50e823c10a20afbcc5","modified":1637824617000},{"_id":"source/_posts/podman-usage-practice/rootless-user-namespace-mapping.jpg","hash":"406c3a53724907a84e61e43c6afa8c4dc6bfa76e","modified":1637777101000},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-10.jpg","hash":"d5ad86a3b0d9e0d886f00ae40c17b2972a010189","modified":1617608157000},{"_id":"source/_posts/rocketchat-mongodb-on-k8s/rocketchat-mongo-connect-successfully.png","hash":"b0cf92a065914233e158d824ce35b52bfc4f0692","modified":1670298225000},{"_id":"source/_posts/https-handshake-authentication/wireshark-https-single-progress.png","hash":"87649ce143e604823ae07539339d3212ba9e271c","modified":1672392516000},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/mysql-container-run-error.jpg","hash":"770854edbe9fb577ebc5f74b31d8dad7946d3de0","modified":1620057910000},{"_id":"source/_posts/podman-usage-practice/podman-pull-image.jpg","hash":"d98ad0e5eebbfc7c9961778f5aa76059df4fe837","modified":1636552103000},{"_id":"source/_posts/podman-arch-usage/podman-bg.png","hash":"0f87a77cf55aeadc57a0f2b7c5b768f41ee864be","modified":1670224199000},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/hello-world-dark-bg.jpg","hash":"68c66b89413ad5b8424ee897cffa3bb85801778b","modified":1548430882000},{"_id":"source/_posts/podman-arch-usage/podman-pull-image.jpg","hash":"d98ad0e5eebbfc7c9961778f5aa76059df4fe837","modified":1636552103000},{"_id":"source/_posts/podman-usage-practice/godev-rootless-container.jpg","hash":"eadca754687ed7a1cff4f4b965c7ef888429f48f","modified":1637726199000},{"_id":"source/_posts/rocketchat-mongodb-on-k8s/rocketchat-with-mismatch-version-mongo-error.png","hash":"75e6a227ea1f19a894c824b1c3791954120539c8","modified":1670298231000},{"_id":"source/_posts/redhat-quay-v3-registry/redhat-quay-bg.jpg","hash":"ff153a91c833cdf3c1e669a4cb0645316919e08d","modified":1543677817000},{"_id":"source/_posts/podman-usage-practice/user-namespace-subuid-mapping-1-edited.png","hash":"d01298d9f6ec39da27ba3ea2a0d199079d95a0d3","modified":1637763240000},{"_id":"source/_posts/podman-arch-usage/user-namespace-subuid-mapping-1-edited.png","hash":"d01298d9f6ec39da27ba3ea2a0d199079d95a0d3","modified":1637763240000},{"_id":"source/_posts/k8s-cluster-resource-basic/kubernetes-ha-arch-demo.jpg","hash":"26ff45e914e1dc29b90babc5713cbdbd61073cca","modified":1669631580993},{"_id":"source/_posts/rocketchat-mongodb-on-k8s/rocketchat-mongo-app-resources.png","hash":"7b4fa383943178baae48b26cecc73b378b8e353c","modified":1670298240000},{"_id":"source/_posts/podman-usage-practice/podman-macvlan-network.png","hash":"b73fcbd388f81b35f5a4a6a3a055652ccdc84eb7","modified":1637838258000},{"_id":"source/img/home-bg.jpg","hash":"51e6764382b85848bf9f1532e875b398fea31dad","modified":1669631581045},{"_id":"source/_posts/podman-arch-usage/podman-macvlan-network.png","hash":"b73fcbd388f81b35f5a4a6a3a055652ccdc84eb7","modified":1637838258000},{"_id":"source/img/home-bg.svg","hash":"495f662ffd91fb4e6f8014e43ed9f11f9c47414a","modified":1669631581106}],"Category":[],"Data":[],"Page":[{"layout":"404","description":"你来到了没有知识的荒原 :(","header-img":"img/404-bg.jpg","_content":"","source":"404.md","raw":"---\nlayout: 404\ndescription: \"你来到了没有知识的荒原 :(\"\nheader-img: \"img/404-bg.jpg\"\n---\n","date":"2022-11-28T10:33:00.973Z","updated":"2022-11-28T10:33:00.973Z","path":"404.html","title":"","comments":1,"_id":"cldfonoaf000016vd37lr8z01","content":"","site":{"data":{}},"excerpt":"","more":""},{"layout":"about","title":"关于我","date":"2022-11-27T17:16:05.000Z","description":"Alberthua | 我和博客的故事","header-img":"img/about-bg.svg","comments":1,"_content":"\n## 我和博客的故事\n\n👋 我是华龙飞，很高兴认识你！\n\n👨‍🎓 我毕业于国内某高等院校生物技术专业，毕业后从事生物信息数据分析领域工作 3 年左右，主要实施人类基因组 🧬 与 RNA 深度测序数据与位点的分析解读 👨‍💻。转战 `Linux` 🐧 与云计算领域至今，目前就职于某国际开源系统公司担任 `Instructor`。\n\n🦄 目前，已使用的技术栈包括但不限于：\n- `Linux`\n- `KVM` & `Qemu`\n- `Open vSwitch`\n- `OpenStack`\n- `Ceph`\n- `Ansible` & `Ansible Tower`\n- `Podman` & `Skopeo`\n- `Kubernetes`\n- `OpenShift`\n- `Tekton` & `ArgoCD`（学习中 ✍）\n- `Prometheus`（学习中 ✍）\n- 基于 `Golang` 的 `Cloud Native` 微服务开发（学习中 ✍）\n- `Shell`\n- `Perl`\n- `Gloang`（学习中 ✍）\n- ...\n\n✨ 我的博客中将记录技术与编程语言的学习总结、日常工作中的避坑提示、工作生活中的碎碎念等，谨以此一亩三分地用以记录吧。博客中的文章可能未及时与我的 [GitHub 技术文档](https://github.com/Alberthua-Perl/tech-docs) 同步，您可直接访问我的 [GitHub](https://github.com/Alberthua-Perl/) 以获取最新的动态！\n\n🚀 如果您对我的文章感兴趣、有疑问、提建议，欢迎予我邮件 hualongfeiyyy@163.com 联系，我将感到十分荣幸！","source":"about/index.md","raw":"---\nlayout: \"about\"\ntitle: \"关于我\"\ndate: 2022-11-28 01:16:05\ndescription: \"Alberthua | 我和博客的故事\"\nheader-img: \"img/about-bg.svg\"\ncomments: true\n---\n\n## 我和博客的故事\n\n👋 我是华龙飞，很高兴认识你！\n\n👨‍🎓 我毕业于国内某高等院校生物技术专业，毕业后从事生物信息数据分析领域工作 3 年左右，主要实施人类基因组 🧬 与 RNA 深度测序数据与位点的分析解读 👨‍💻。转战 `Linux` 🐧 与云计算领域至今，目前就职于某国际开源系统公司担任 `Instructor`。\n\n🦄 目前，已使用的技术栈包括但不限于：\n- `Linux`\n- `KVM` & `Qemu`\n- `Open vSwitch`\n- `OpenStack`\n- `Ceph`\n- `Ansible` & `Ansible Tower`\n- `Podman` & `Skopeo`\n- `Kubernetes`\n- `OpenShift`\n- `Tekton` & `ArgoCD`（学习中 ✍）\n- `Prometheus`（学习中 ✍）\n- 基于 `Golang` 的 `Cloud Native` 微服务开发（学习中 ✍）\n- `Shell`\n- `Perl`\n- `Gloang`（学习中 ✍）\n- ...\n\n✨ 我的博客中将记录技术与编程语言的学习总结、日常工作中的避坑提示、工作生活中的碎碎念等，谨以此一亩三分地用以记录吧。博客中的文章可能未及时与我的 [GitHub 技术文档](https://github.com/Alberthua-Perl/tech-docs) 同步，您可直接访问我的 [GitHub](https://github.com/Alberthua-Perl/) 以获取最新的动态！\n\n🚀 如果您对我的文章感兴趣、有疑问、提建议，欢迎予我邮件 hualongfeiyyy@163.com 联系，我将感到十分荣幸！","updated":"2022-12-25T12:39:56.003Z","path":"about/index.html","_id":"cldfonoj1000216vdjbl1diwn","content":"<h2 id=\"我和博客的故事\"><a href=\"#我和博客的故事\" class=\"headerlink\" title=\"我和博客的故事\"></a>我和博客的故事</h2><p>👋 我是华龙飞，很高兴认识你！</p>\n<p>👨‍🎓 我毕业于国内某高等院校生物技术专业，毕业后从事生物信息数据分析领域工作 3 年左右，主要实施人类基因组 🧬 与 RNA 深度测序数据与位点的分析解读 👨‍💻。转战 <code>Linux</code> 🐧 与云计算领域至今，目前就职于某国际开源系统公司担任 <code>Instructor</code>。</p>\n<p>🦄 目前，已使用的技术栈包括但不限于：</p>\n<ul>\n<li><code>Linux</code></li>\n<li><code>KVM</code> &amp; <code>Qemu</code></li>\n<li><code>Open vSwitch</code></li>\n<li><code>OpenStack</code></li>\n<li><code>Ceph</code></li>\n<li><code>Ansible</code> &amp; <code>Ansible Tower</code></li>\n<li><code>Podman</code> &amp; <code>Skopeo</code></li>\n<li><code>Kubernetes</code></li>\n<li><code>OpenShift</code></li>\n<li><code>Tekton</code> &amp; <code>ArgoCD</code>（学习中 ✍）</li>\n<li><code>Prometheus</code>（学习中 ✍）</li>\n<li>基于 <code>Golang</code> 的 <code>Cloud Native</code> 微服务开发（学习中 ✍）</li>\n<li><code>Shell</code></li>\n<li><code>Perl</code></li>\n<li><code>Gloang</code>（学习中 ✍）</li>\n<li>…</li>\n</ul>\n<p>✨ 我的博客中将记录技术与编程语言的学习总结、日常工作中的避坑提示、工作生活中的碎碎念等，谨以此一亩三分地用以记录吧。博客中的文章可能未及时与我的 <a href=\"https://github.com/Alberthua-Perl/tech-docs\" target=\"_blank\" rel=\"noopener\">GitHub 技术文档</a> 同步，您可直接访问我的 <a href=\"https://github.com/Alberthua-Perl/\" target=\"_blank\" rel=\"noopener\">GitHub</a> 以获取最新的动态！</p>\n<p>🚀 如果您对我的文章感兴趣、有疑问、提建议，欢迎予我邮件 <a href=\"mailto:hualongfeiyyy@163.com\" target=\"_blank\" rel=\"noopener\">hualongfeiyyy@163.com</a> 联系，我将感到十分荣幸！</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"我和博客的故事\"><a href=\"#我和博客的故事\" class=\"headerlink\" title=\"我和博客的故事\"></a>我和博客的故事</h2><p>👋 我是华龙飞，很高兴认识你！</p>\n<p>👨‍🎓 我毕业于国内某高等院校生物技术专业，毕业后从事生物信息数据分析领域工作 3 年左右，主要实施人类基因组 🧬 与 RNA 深度测序数据与位点的分析解读 👨‍💻。转战 <code>Linux</code> 🐧 与云计算领域至今，目前就职于某国际开源系统公司担任 <code>Instructor</code>。</p>\n<p>🦄 目前，已使用的技术栈包括但不限于：</p>\n<ul>\n<li><code>Linux</code></li>\n<li><code>KVM</code> &amp; <code>Qemu</code></li>\n<li><code>Open vSwitch</code></li>\n<li><code>OpenStack</code></li>\n<li><code>Ceph</code></li>\n<li><code>Ansible</code> &amp; <code>Ansible Tower</code></li>\n<li><code>Podman</code> &amp; <code>Skopeo</code></li>\n<li><code>Kubernetes</code></li>\n<li><code>OpenShift</code></li>\n<li><code>Tekton</code> &amp; <code>ArgoCD</code>（学习中 ✍）</li>\n<li><code>Prometheus</code>（学习中 ✍）</li>\n<li>基于 <code>Golang</code> 的 <code>Cloud Native</code> 微服务开发（学习中 ✍）</li>\n<li><code>Shell</code></li>\n<li><code>Perl</code></li>\n<li><code>Gloang</code>（学习中 ✍）</li>\n<li>…</li>\n</ul>\n<p>✨ 我的博客中将记录技术与编程语言的学习总结、日常工作中的避坑提示、工作生活中的碎碎念等，谨以此一亩三分地用以记录吧。博客中的文章可能未及时与我的 <a href=\"https://github.com/Alberthua-Perl/tech-docs\" target=\"_blank\" rel=\"noopener\">GitHub 技术文档</a> 同步，您可直接访问我的 <a href=\"https://github.com/Alberthua-Perl/\" target=\"_blank\" rel=\"noopener\">GitHub</a> 以获取最新的动态！</p>\n<p>🚀 如果您对我的文章感兴趣、有疑问、提建议，欢迎予我邮件 <a href=\"mailto:hualongfeiyyy@163.com\" target=\"_blank\" rel=\"noopener\">hualongfeiyyy@163.com</a> 联系，我将感到十分荣幸！</p>\n"},{"layout":"archives","title":"归档","description":"Alberthua | 分类与归档","header-img":"img/tag-bg.svg","_content":"","source":"archives/index.md","raw":"---\nlayout: \"archives\"\ntitle: \"归档\"\ndescription: \"Alberthua | 分类与归档\"\nheader-img: \"img/tag-bg.svg\"\n---\n","date":"2022-12-23T02:31:14.566Z","updated":"2022-12-23T02:31:14.566Z","path":"archives/index.html","comments":1,"_id":"cldfonok5000416vd48du8qr4","content":"","site":{"data":{}},"excerpt":"","more":""},{"layout":"tags","title":"分类","description":"Alberthua | This is Tags","header-img":"img/tag-bg.svg","_content":"","source":"tags/index.md","raw":"---\nlayout: \"tags\"\ntitle: \"分类\"\ndescription: \"Alberthua | This is Tags\"\nheader-img: \"img/tag-bg.svg\"\n---\n","date":"2022-12-23T02:40:05.742Z","updated":"2022-12-23T02:40:05.742Z","path":"tags/index.html","comments":1,"_id":"cldfonosu001q16vdzfxayyr5","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"📦 Fedora CoreOS 及 RHCOS 概述与应用","subtitle":"Fedora CoreOS & RHCOS Basic and Usage","header-img":"fedora-coreos-bg.jpg","date":"2022-11-28T13:32:27.000Z","_content":"\n### 文档目录：\n- 关键技术点\n- Fedora CoreOS 及 RHCOS 介绍与特性\n- Ignition 在 FCOS 或 RHCOS 中的工作特点\n- Ignition 对 OpenShift 4 集群主机的处理顺序\n- Fedora CoreOS 的安装环境与工具说明\n- Fedora CoreOS 的定制化安装与验证\n- 参考链接\n\n### 关键技术点：\n- 以下技术点在文中将根据 Fedora CoreOS 及 RHCOS 中展开说明：  \n  - ignition, butane, ignition-validate  \n  - ostree, rpm-tree,zincati, bootupd\n\n### Fedora CoreOS 及 RHCOS 介绍与特性：\n- 在 OpenShift 4 安装过程会自动安装 CoreOS 的商业版 Red Hat Enterprise Linux CoreOS（简称 `RHCOS`）。根据 OpenShift 4 的文档说明，RHCOS 无法独立运行安装，它必须和 OpenShift 4 一起运行（因此 RHCOS 没有单独的订阅）。\n- 😃 不过好在 CoreOS 还提供了可以独立运行的社区版 `Fedora CoreOS`（简称 `FCOS`）可以完全免费使用。由于 FCOS 可以无需 OpenShift 4 也可以独立安装运行，因此使用 FCOS 作为研究环境，而相关操作基本都可适用 RHCOS 环境。\n- FCOS/RHCOS 是 Red Hat 在收购 CoreOS 公司后结合 `CoreOS Container Linux` 和 `Fedora Atomic Host` 的优点推出的新一代容器操作系统，其目标是提供最佳的容器主机，从而能安全、大规模地运行容器化的工作负载。\n- FCOS/RHCOS 将 [Ignition](https://github.com/coreos/ignition)（点火） 与 rpm-ostree 等技术相集成，是一个自动更新的、最小的、整体的、对运行容器和 Kubernetes 进行了优化的操作系统，因为它们更符合 \"不可变架构\"（`Immutable Infrastructure`）理念，因此成为 Red Hat 推荐的 OpenShift 4 底层操作系统。\n- FCOS/RHCOS 的安装及配置过程和一般的 RHEL 稍有差别，需要通过 Ignition 配置文件在安装的时候初始化网络、存储、内核、用户等方面的配置。\n- FCOS 的设计理念：  \n  - 🐳 由于容器允许将工作负载重复部署到生产环境中，并自动扩展以满足需求。容器提供的隔离意味着主机操作系统可以很小，它只需要一个 `Linux kernel`、`systemd`、`container runtime` 和一些附加服务（如 SSH 服务器）。  \n  - FCOS 是专门为容器工作负载而设计的，无需定期维护，可以使用最新的操作系统改进、bug 修复和安全自动更新，其使用 Ignition 为自身提供服务，使用 `Podman` 和 `Moby` 运行容器，并使用 `rpm-ostree` 自动进行原子更新。\n  > ❗ 注意：\n  > \n  > 1. FCOS 支持 `CRI-O` 作为容器引擎，常用于 OpenShift 4 的底层容器运行时，一般不直接使用 CRI-O 运行容器，OpenShift 4 可通过 `CRI` 接口创建与管理 Pod。\n  > \n  > 2. 可通过 `crictl` 命令行工具创建与管理容器及 Pod，但一般情况下用于容器或 pod 的调试而非容器或 pod 的创建。\n- FCOS 调配不可变架构：  \n  - 在系统首次引导（`first boot`）阶段，FCOS 使用 Ignition 调配系统。  \n  - Ignition 读取用户提供的数据或远程 URL 地址提供的 Ignition 配置文件，并且使用它创建磁盘分区、文件系统、用户、受信任的用户 SSH 公钥、文件与系统单元文件（systemd units）等。  \n  - 调配主机的方式：    \n    - 编辑基于 YAML 格式的 `Fedora CoreOS Config`（FCC）文件，该文件指定主机的期望配置，FCC 支持所有的 Ignition 功能，也提供额外的语法。    \n    - 使用 `Fedora CoreOS Config Transpiler (Butane)` 工具将 FCC 文件（`.fcc`）转换为 Ignition 配置文件（`.ign`）。    \n    - 启动 FCOS 主机并将 Ignition 配置文件同步至主机中调配系统的安装。    \n    > 💁‍♂️ 调配主机的方法：\n    > \n    > 1. 使用 PXE 引导并与指定 Ignition 配置文件调配安装主机。\n    > \n    > 2. 将 Ignition 配置文件同步至使用 FCOS live ISO 引导启动的主机中，再使用 `coreos-installer` 工具调配安装主机（本文使用此方法）。  \n  - FCOS 被设计为不可变架构。在主机被调配之后，不应该更改 /etc 目录或重新配置主机，相反，更改 FCC 文件并且使用该文件调配替换的主机。  \n  - 🐳 这种方式与容器管理相似：容器镜像不可被原地更新，而是重头构建与重新部署。该方式在负载增加时容易横向扩容。只需简单地使用相同的 Ignition 配置文件来启动其他主机。\n- [FCOS 发布版本](https://getfedora.org/en/coreos/download?tab=metal_virtualized&stream=stable&arch=x86_64)：![fedora-coreos-release-version.png](fedora-coreos-release-version.png)  \n  - `testing stream`：    \n    当前 Fedora 发行版的常规快照，加上更新。  \n  - ❤ `stable stream`：    \n    在测试版本可用两周后，它被发送到稳定流，在测试中发现的 `bug` 将在发布稳定流之前被修复。  \n  - `next stream`：    \n    即将发布的 Fedora 版本的常规快照，允许有额外的时间测试较大的更改。  \n  👉 每个 stream 每 2 周发布一次，更新内容会从一个 stream 推广到另一个 stream（`next -> testing -> stable`）。这样落地在 stable stream 中的更新就有机会经过长时间的测试。  \n  👉 所有三个 stream 都收到了安全更新和关键的错误修复，并旨在安全地用于生产使用。大多数机器应该运行 `stable stream`，因为它接受最多的测试。但是，用户应该在 next stream 上运行他们的部分节点，并向问题跟踪器报告问题。这有助于确保只影响特定工作负载或特定硬件的 bug 在稳定之前得到修复。\n- RHCOS 的关键特性：  \n  - 系统基于 RHEL 开发  \n  - 可控制的不可变架构（`controlled immutability`）  \n  - 默认使用 `CRI-O` 容器运行时  \n  - 可使用容器工具集管理容器或 Pod（包括 `podman`、`skopeo` 与 `crictl` 等）  \n  - 🔥 使用 `rpm-ostree` 实现事务性更新升级 \n  > ❗ 注意：\n  > \n  > 1. `OSTree` 是一个用于对基于 Linux 的操作系统进行版本更新的系统，它可以被视为 \"面向操作系统二进制文件的 git\"，它被 endless OS、Flatpak、Fedora、CentOS、Atomic Host 和 GNOME 等项目用来持续交付，有关 OSTree 更多详细的说明可参考 [libostree 官方文档](https://ostreedev.github.io/ostree/)。\n  > \n  > 2. rpm-ostree 是一个混合镜像/包系统，以命令行与守护进程的方式运行，可将软件包以分层的形式构建在 OSTree 之上，将软件包作为系统的扩展，关于 rpm-ostree 更多详细的说明可参考 [rpm-ostree 官方文档](https://coreos.github.io/rpm-ostree)。\n  > \n  > 3. FCOS 中的 `zincati` 服务（`zincati.service`）可检测系统的状态，通过 `rpm-ostreed` 守护进程进行更新，若其发现具有新的系统更新将自动更新系统，可将该服务关闭以禁用此功能。  \n  - 🔥 针对 `fireware` 与 `bootloader` 的 `bootupd` 更新器，bootupd 可以守护进程 `bootupd.service` 的方式运行。\n  - OpenShift 4 集群通过 `Machine Config Operator (MCO)` 更新 RHCOS\n\n### Ignition 在 FCOS 或 RHCOS 中的工作特点：\n- Ignition 是由 FCOS/RHCOS 使用的在系统初始化配置过程（`initramfs`）中操纵磁盘的工具，其可完成常见的磁盘任务，包括磁盘分区、格式化分区、写文件与配置用户等。\n- 在系统首次引导时（first boot），Ignition 读取安装介质或所指定的 Ignition 配置文件所在的路径。\n- ✨ Ignition 的调配方式：  \n  Ignition 配置文件（Ignition config file）或称点火配置文件\n- Ignition 配置与 `cloud-init` 或 `Linux Anaconda kickstart` 配置系统极其相似，但其具有自身的特点：  \n  - 由于 Ignition 能进行磁盘分区、设置文件系统与执行主机永久文件系统的其他改变，因此，在安装 FCOS/RHCOS 过程中 Ignition 运行于与系统相隔离的 `initial RAM disk` 中。与之相对的，cloud-init 作为初始化系统的一部分不能容易地实现磁盘的分区。  \n  - ✨ Ignition 与 cloud-init 对比：\n    - Ignition：\n      - 工作阶段：首次引导安装期间\n      - 工作次数：一次\n      - 功能实现：系统磁盘操作等\n      - 常用场景：安装部署\n    - cloud-init：\n      - 工作阶段：任意系统引导期间\n      - 工作次数：多次\n      - 功能实现：系统配置等\n      - 常用场景：系统配置\n  - Ignition 用于初始化系统而不是更改已存在的系统，OpenShift 4 使用 `Machine Config Operator` 完成所有主机的配置。  \n  - Ignition 以声明式方式（declarative configuration）检查配置中的所有配置项目以满足指定的要求。  \n  - ✨ 在 Ignition 完成主机配置后，kernel 保持运行但丢弃 initial RAM disk，并且转向（pivot to）磁盘上已安装的系统中。无需系统重启，所有的系统服务与其他特性即可启动。  \n  - 由于 Ignition 通过声明式配置将主机调整为指定的状态，因此不能存在具有部分配置的主机，若在部署 OpenShift 4 集群时存在部分配置的主机，该主机将无法加入集群，需更换新的主机再次调配加入集群。  \n  - 若存在问题的 Ignition 配置引起主机配置的失败，Ignition 将不再尝试使用相同的配置来调配另一台主机。  \n  - 由于 Ignition 可使用完整的空磁盘，它能实现 cloud-init 无法完成的任务，如使用 PXE 引导从空磁盘调配裸机系统。\n\n### Ignition 对 OpenShift 4 集群主机的处理顺序：\n- 在 OpenShift 4 集群中的 RHCOS 主机上 Ignition 的处理涉及以下步骤：  \n  - 1️⃣ 控制平面主机（`control plane machines`）从引导主机（`bootstrap machine`）获取 Ignition 配置文件，而工作主机（`worker machines`）从控制平面主机获取 Ignition 配置文件。  \n  - 2️⃣ Ignition 在主机上创建磁盘分区、文件系统、目录与链接，它支持 RAID 阵列但不支持 LVM 逻辑卷。  \n  - 3️⃣ Igition 在 initramfs 中挂载 root 持久化文件系统于 `/sysroot` 目录并在 `/sysroot` 目录中工作。  \n  - 4️⃣ Ignition 配置所有定义的文件系统并恰当地挂载它们。  \n  - 5️⃣ Ignition 运行 `systemd` 临时文件以填充在 `/var` 目录中的所需文件。  \n  - 6️⃣ Ignition 运行其配置文件来配置用户、systemd 单元文件与其他配置文件。  \n  - 7️⃣ Ignition 卸载在 initramfs 中挂载的持久化系统中的所有组件。  \n  - 8️⃣ Ignition 启动新主机的初始化过程，启动系统引导阶段的所有其他的服务。\n- 处理结束后，主机已做好加入集群的准备并且无需重启，与前文所述相同。\n\n### Fedora CoreOS 的安装环境与工具说明：\n- FCOS 支持在多种 IaaS 环境下运行。\n- Fedora CoreOS live ISO 版本：fedora-coreos-36.20220906.3.2-live.x86_64.iso\n- Butane 工具：  \n  - linux 版本：[0.15.0](https://github.com/coreos/butane/releases/download/v0.15.0/butane-x86_64-unknown-linux-gnu)  \n  - 该工具来源于 [coreos/butane](https://github.com/coreos/butane) 项目  \n  - `Butane` 以前称为 Fedora CoreOS 配置转换器（Fedora CoreOS Config Transpiler，`FCCT`），它可将 Butane 配置文件（Butane Config）或称 FCC 文件转换为 Ignition 配置文件（Ignition Config），该文件为 `JSON` 格式将被 FCOS 主机在首次引导调配时使用，可用于创建磁盘分区、文件系统、用户、受信任的用户 SSH 公钥、文件与系统单元文件（systemd units）等。  \n  - ✨ 其中 Butane 配置文件为 `YAML` 格式，关于该文件不同版本的配置规范（configuration specifications）请参考该 [链接](https://github.com/coreos/butane/blob/main/docs/specs.md)。  \n  - ✨ Butane 配置文件使用示例请参考该 [Examples](https://github.com/coreos/butane/blob/main/docs/examples.md)。  \n  - 可在自己指定的节点（非 FCOS 主机）上安装 butane，安装方式包括 butane 容器镜像（`quay.io/coreos/butane:release`）、rpm 软件包或独立的二进制文件（standalone binary），此处使用以上链接的独立二进制文件进行安装。![quay-coreos-butane-release.png](quay-coreos-butane-release.png)  \n  - butane 的使用方法可参考该 [链接](https://github.com/coreos/butane/blob/main/docs/getting-started.md)。\n- ignition-validate 工具：  \n  - linux 版本：[2.14.0](https://github.com/coreos/ignition/releases/download/v2.14.0/ignition-validate-x86_64-linux)  \n  - 该工具来源于 [coreos/ignition](https://github.com/coreos/ignition) 项目  \n  - 该工具用于对 Ignition 配置文件的格式与合法性字段的验证，若语法不合规将无法在 FCOS 中使用 `coreos-installer` 于系统首次引导时安装。\n\n### Fedora CoreOS 的定制化安装与验证：\n- 准备 HTTP 服务器、Ignition 配置文件与相关配置文件（非 FCOS 节点）：  \n  > ❗ 注意：\n  > \n  > 1. 本文安装采用基于 KVM 虚拟机模拟裸金属安装环境。\n  > \n  > 2. 关于 `butane` 工具与 `ignition-validate` 工具的安装如前文所述。\n  > \n  > 3. 💁‍♂️ 本文使用 FCOS live ISO 的方式引导并使用其中的 coreos-installer 工具调配安装主机，若使用 PXE 方式引导安装请参阅官方文档。\n    \n  ```bash\n  $ sudo yum install httpd\n  $ sudo systemctl enable --now httpd.service\n  # 安装与启动 httpd 服务并设置为开机自启\n  $ ssh-keygen -N '' -t rsa -f ~/.ssh/core_fcos_login\n  # 创建用于 SSH 免密登录 FCOS 的公私钥，此处将该 SSH 公钥拷贝至 Butane 配置文件\n  # 的 ssh_authorized_keys 字段中。\n  $ mkdir ~/fcos && cd ~/fcos\n  $ vim fcos-customized-config.yml\n  # 创建 Butane 配置文件\n  ```\n  该配置文件如下所示：\n  ```yaml\n  # 该配置文件可参看前文 GitHub Butane 的 Examples 或 Fedora CoreOS 官方文档\n  # 的 Storage 部分进行编辑。\n  variant: fcos\n  version: 1.1.0\n  # 创建自定义用户、密码、home 家目录与配置 SSH 免密登录的公钥\n  passwd:\n    users:\n      - name: core\n        ssh_authorized_keys:\n          - ssh-rsa AAAAB3Nz...jnXfG+Uj godev@cloud-ctl.domain12.example.com\n        # 由于 FCOS/RHCOS 在安装完成后无法使用密码直接登录，该公钥用于 core 用户的\n        # SSH 免密登录。\n      - name: cloud-admin\n        password_hash: $y$j9T$j0ODWvNUDSXcEcwpDH141.$dvAEVxBHUWbW/NnPd90qkg0Haq6vgkcKF151jvLDgYA\n        # 明文密码 redhat 通过 hash 加密的密文\n        # 虽然该用户已配置密码，但无法通过 SSH 远程登录，该密码只允许本地控制台登录。\n        home_dir: /opt/cloud-admin\n        no_create_home: false\n        groups:\n          - wheel\n        shell: /bin/bash\n        # 注意：当任何用户 SSH 远程登录失效时，可用该用户本地登录并提权！\n  storage:\n    # 将本地指定目录中的文件内容注入 FCOS 的对应文件中，需使用 butane 工具的\n    # --files-dir 选项。\n    files:\n      - path: \"/etc/NetworkManager/system-connections/Wired connection 1.nmconnection\"\n        contents:\n          local: ./Wired_connection_1.nmconnection      \n        mode: 0600\n        # FCOS 的网络接口配置\n      - path: /etc/hostname\n        contents:\n          local: ./hostname\n        mode: 0644\n        # FCOS 的主机名配置\n    # 将 FCOS 的 /dev/vdb 进行分区并挂载至 /var 目录，主要用于容器与镜像的存储。\n    # 注意：Ignition 不支持对 FCOS/RHCOS 的 LVM 逻辑卷功能！\n    disks:\n      - device: /dev/vdb\n        wipe_table: true\n        partitions:\n          - number: 1\n            label: var\n    filesystems:\n      - path: /var\n        device: /dev/disk/by-partlabel/var\n        format: xfs\n        wipe_filesystem: true \n        label: var\n        with_mount_unit: true\n  ```\n  以上 YAML 文件可点击 [此处](https://github.com/Alberthua-Perl/scripts-confs/tree/master/fedora-coreos-36) 获得。 \n  ```bash\n  $ cat ./hostname\n    fcos36-cloud.lab.example.com\n  $ cat ./Wired_connection_1.nmconnection \n    [connection]\n    id=Wired connection 1\n    type=ethernet\n    autoconnect-priority=-999\n    interface-name=ens3\n  \n    [ethernet]\n  \n    [ipv4]\n    address1=192.168.110.13/24,192.168.110.1\n    dns=192.168.110.1;\n    method=manual\n  \n  $ butane --files-dir . \\\n    --pretty --strict \\\n    --output fcos-customized-config.ign fcos-customized-config.yml\n  # 在当前目录中根据 Butane 配置文件转换为 Ignition 配置文件\n  $ ignition-validate fcos-customized-config.ign\n  # 验证 Ignition 配置文件语法的合法性，若无返回则验证通过，该文件可用于 FCOS 的安装。\n  $ sudo cp fcos-customized-config.ign /var/www/html/\n  # 拷贝该文件至 HTTP 服务器的根目录中用于 FCOS 中 coreos-installer 工具的下载\n  # 读取与系统安装。\n  ```\n- 创建 FCOS 虚拟机并使用 FCOS live ISO 引导安装，如下所示：![use-fedora-coreos-live-to-install.png](use-fedora-coreos-live-to-install.png)![login-fedora-coreos-live.png](login-fedora-coreos-live.png)\n  👉 `core` 用户可 `sudo` 免密提权为 root 用户。  \n  👉 使用 `core` 用户正常登录后，再使用 `ip -br a s` 命令查看主机的 IP 地址（一般可通过 `DHCP` 自动获取），若无与 HTTP 服务器通信的 IP 地址，将无法下载 Ignition 配置文件而安装失败，可通过如下命令临时配置加以生效：  \n  ```bash\n  $ sudo ip address add 192.168.110.13/24 dev ens3\n  # 需根据实际场景调整 IP 地址与对应的网络接口\n  ```\n  👉 使用 FCOS live ISO 自带的 `coreos-installer` 工具根据 Ignition 配置文件安装部署，如下所示： \n  ![coreos-installer-customized-install.png](coreos-installer-customized-install.png)  \n  ```bash\n  $ sudo coreos-installer install \\\n    --insecure-ignition \\\n    --ignition-url http://192.168.110.130/fcos-customized-config.ign \\\n    /dev/vda\n  # 下载 Ignition 配置文件并将根系统安装于 /dev/vda 中\n  # 此安装过程根据所配置的内容不同耗时也将不同（笔者环境中安装较快）\n  $ sudo reboot\n  # 重启系统\n  ```\n- 登录 FCOS 验证安装状态：  \n  ```bash\n  $ ssh -i ~/.ssh/core_fcos_login core@fcos36-cloud\n    Fedora CoreOS 36.20221001.3.0\n    Tracker: https://github.com/coreos/fedora-coreos-tracker\n    Discuss: https://discussion.fedoraproject.org/tag/coreos\n  \n    Last login: Mon Oct 24 14:07:00 2022 from 192.168.110.130\n    [core@fcos36-cloud ~]$ sudo -i\n    [root@fcos36-cloud ~]# id cloud-admin\n    uid=1001(cloud-admin) gid=1001(cloud-admin) groups=1001(cloud-admin),10(wheel)\n    [root@fcos36-cloud ~]# su - cloud-admin\n    [cloud-admin@fcos36-cloud ~]$ sudo -i\n    [sudo] password for cloud-admin: \n    [root@fcos36-cloud ~]# lsblk --paths\n    NAME        MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS\n    /dev/sr0     11:0    1 1024M  0 rom  \n    /dev/vda    252:0    0   10G  0 disk \n    |-/dev/vda1 252:1    0    1M  0 part \n    |-/dev/vda2 252:2    0  127M  0 part \n    |-/dev/vda3 252:3    0  384M  0 part /boot\n    `-/dev/vda4 252:4    0  9.5G  0 part /sysroot/ostree/deploy/fedora-coreos/var\n                                         /usr\n                                         /etc\n                                         /\n                                         /sysroot\n    /dev/vdb    252:16   0   10G  0 disk \n    `-/dev/vdb1 252:17   0   10G  0 part /var \n  # Ignition 配置文件中的配置在 FCOS 中已生效\n  ```\n- 由于 FCOS 中使用 `rpm-ostree` 进行软件包的管理，若需安装额外的软件包，可使用如下方式：  \n  ```bash\n  $ sudo rpm-ostree install \\\n    podman skopeo buildah cri-o cri-tools vim-enhanced\n  # 安装容器与镜像管理工具\n  $ sudo systemctl status crio.service\n  # 查看 CRI-O 守护进程状态，可通过 crictl 命令测试管理容器。\n  ```\n\n### 参考链接：\n- [Introducing Fedora CoreOS](https://fedoramagazine.org/introducing-fedora-coreos/)\n- [Getting started with Fedora CoreOS](https://fedoramagazine.org/getting-started-with-fedora-coreos/)\n- [Fedora CoreOS 入门 | Linux 中国](https://mp.weixin.qq.com/s/Vf6TvGSi5sNnMjT5QldUQg)\n- ❤ [Fedora CoreOS Documentation](https://docs.fedoraproject.org/en-US/fedora-coreos/)\n- [Red Hat Enterprise Linux CoreOS (RHCOS)](https://docs.openshift.com/container-platform/4.11/architecture/architecture-rhcos.html)\n- ❤ [How to customize Fedora CoreOS for dedicated workloads with OSTree](https://developers.redhat.com/blog/2020/03/12/how-to-customize-fedora-coreos-for-dedicated-workloads-with-ostree#)","source":"_posts/fcos-rhcos-basic-usage.md","raw":"---\ntitle: 📦 Fedora CoreOS 及 RHCOS 概述与应用\nsubtitle: Fedora CoreOS & RHCOS Basic and Usage\nheader-img: fedora-coreos-bg.jpg\ndate: 2022-11-28 21:32:27\ntags:\n  - Linux\n  - coreos\n  - OpenShift\n---\n\n### 文档目录：\n- 关键技术点\n- Fedora CoreOS 及 RHCOS 介绍与特性\n- Ignition 在 FCOS 或 RHCOS 中的工作特点\n- Ignition 对 OpenShift 4 集群主机的处理顺序\n- Fedora CoreOS 的安装环境与工具说明\n- Fedora CoreOS 的定制化安装与验证\n- 参考链接\n\n### 关键技术点：\n- 以下技术点在文中将根据 Fedora CoreOS 及 RHCOS 中展开说明：  \n  - ignition, butane, ignition-validate  \n  - ostree, rpm-tree,zincati, bootupd\n\n### Fedora CoreOS 及 RHCOS 介绍与特性：\n- 在 OpenShift 4 安装过程会自动安装 CoreOS 的商业版 Red Hat Enterprise Linux CoreOS（简称 `RHCOS`）。根据 OpenShift 4 的文档说明，RHCOS 无法独立运行安装，它必须和 OpenShift 4 一起运行（因此 RHCOS 没有单独的订阅）。\n- 😃 不过好在 CoreOS 还提供了可以独立运行的社区版 `Fedora CoreOS`（简称 `FCOS`）可以完全免费使用。由于 FCOS 可以无需 OpenShift 4 也可以独立安装运行，因此使用 FCOS 作为研究环境，而相关操作基本都可适用 RHCOS 环境。\n- FCOS/RHCOS 是 Red Hat 在收购 CoreOS 公司后结合 `CoreOS Container Linux` 和 `Fedora Atomic Host` 的优点推出的新一代容器操作系统，其目标是提供最佳的容器主机，从而能安全、大规模地运行容器化的工作负载。\n- FCOS/RHCOS 将 [Ignition](https://github.com/coreos/ignition)（点火） 与 rpm-ostree 等技术相集成，是一个自动更新的、最小的、整体的、对运行容器和 Kubernetes 进行了优化的操作系统，因为它们更符合 \"不可变架构\"（`Immutable Infrastructure`）理念，因此成为 Red Hat 推荐的 OpenShift 4 底层操作系统。\n- FCOS/RHCOS 的安装及配置过程和一般的 RHEL 稍有差别，需要通过 Ignition 配置文件在安装的时候初始化网络、存储、内核、用户等方面的配置。\n- FCOS 的设计理念：  \n  - 🐳 由于容器允许将工作负载重复部署到生产环境中，并自动扩展以满足需求。容器提供的隔离意味着主机操作系统可以很小，它只需要一个 `Linux kernel`、`systemd`、`container runtime` 和一些附加服务（如 SSH 服务器）。  \n  - FCOS 是专门为容器工作负载而设计的，无需定期维护，可以使用最新的操作系统改进、bug 修复和安全自动更新，其使用 Ignition 为自身提供服务，使用 `Podman` 和 `Moby` 运行容器，并使用 `rpm-ostree` 自动进行原子更新。\n  > ❗ 注意：\n  > \n  > 1. FCOS 支持 `CRI-O` 作为容器引擎，常用于 OpenShift 4 的底层容器运行时，一般不直接使用 CRI-O 运行容器，OpenShift 4 可通过 `CRI` 接口创建与管理 Pod。\n  > \n  > 2. 可通过 `crictl` 命令行工具创建与管理容器及 Pod，但一般情况下用于容器或 pod 的调试而非容器或 pod 的创建。\n- FCOS 调配不可变架构：  \n  - 在系统首次引导（`first boot`）阶段，FCOS 使用 Ignition 调配系统。  \n  - Ignition 读取用户提供的数据或远程 URL 地址提供的 Ignition 配置文件，并且使用它创建磁盘分区、文件系统、用户、受信任的用户 SSH 公钥、文件与系统单元文件（systemd units）等。  \n  - 调配主机的方式：    \n    - 编辑基于 YAML 格式的 `Fedora CoreOS Config`（FCC）文件，该文件指定主机的期望配置，FCC 支持所有的 Ignition 功能，也提供额外的语法。    \n    - 使用 `Fedora CoreOS Config Transpiler (Butane)` 工具将 FCC 文件（`.fcc`）转换为 Ignition 配置文件（`.ign`）。    \n    - 启动 FCOS 主机并将 Ignition 配置文件同步至主机中调配系统的安装。    \n    > 💁‍♂️ 调配主机的方法：\n    > \n    > 1. 使用 PXE 引导并与指定 Ignition 配置文件调配安装主机。\n    > \n    > 2. 将 Ignition 配置文件同步至使用 FCOS live ISO 引导启动的主机中，再使用 `coreos-installer` 工具调配安装主机（本文使用此方法）。  \n  - FCOS 被设计为不可变架构。在主机被调配之后，不应该更改 /etc 目录或重新配置主机，相反，更改 FCC 文件并且使用该文件调配替换的主机。  \n  - 🐳 这种方式与容器管理相似：容器镜像不可被原地更新，而是重头构建与重新部署。该方式在负载增加时容易横向扩容。只需简单地使用相同的 Ignition 配置文件来启动其他主机。\n- [FCOS 发布版本](https://getfedora.org/en/coreos/download?tab=metal_virtualized&stream=stable&arch=x86_64)：![fedora-coreos-release-version.png](fedora-coreos-release-version.png)  \n  - `testing stream`：    \n    当前 Fedora 发行版的常规快照，加上更新。  \n  - ❤ `stable stream`：    \n    在测试版本可用两周后，它被发送到稳定流，在测试中发现的 `bug` 将在发布稳定流之前被修复。  \n  - `next stream`：    \n    即将发布的 Fedora 版本的常规快照，允许有额外的时间测试较大的更改。  \n  👉 每个 stream 每 2 周发布一次，更新内容会从一个 stream 推广到另一个 stream（`next -> testing -> stable`）。这样落地在 stable stream 中的更新就有机会经过长时间的测试。  \n  👉 所有三个 stream 都收到了安全更新和关键的错误修复，并旨在安全地用于生产使用。大多数机器应该运行 `stable stream`，因为它接受最多的测试。但是，用户应该在 next stream 上运行他们的部分节点，并向问题跟踪器报告问题。这有助于确保只影响特定工作负载或特定硬件的 bug 在稳定之前得到修复。\n- RHCOS 的关键特性：  \n  - 系统基于 RHEL 开发  \n  - 可控制的不可变架构（`controlled immutability`）  \n  - 默认使用 `CRI-O` 容器运行时  \n  - 可使用容器工具集管理容器或 Pod（包括 `podman`、`skopeo` 与 `crictl` 等）  \n  - 🔥 使用 `rpm-ostree` 实现事务性更新升级 \n  > ❗ 注意：\n  > \n  > 1. `OSTree` 是一个用于对基于 Linux 的操作系统进行版本更新的系统，它可以被视为 \"面向操作系统二进制文件的 git\"，它被 endless OS、Flatpak、Fedora、CentOS、Atomic Host 和 GNOME 等项目用来持续交付，有关 OSTree 更多详细的说明可参考 [libostree 官方文档](https://ostreedev.github.io/ostree/)。\n  > \n  > 2. rpm-ostree 是一个混合镜像/包系统，以命令行与守护进程的方式运行，可将软件包以分层的形式构建在 OSTree 之上，将软件包作为系统的扩展，关于 rpm-ostree 更多详细的说明可参考 [rpm-ostree 官方文档](https://coreos.github.io/rpm-ostree)。\n  > \n  > 3. FCOS 中的 `zincati` 服务（`zincati.service`）可检测系统的状态，通过 `rpm-ostreed` 守护进程进行更新，若其发现具有新的系统更新将自动更新系统，可将该服务关闭以禁用此功能。  \n  - 🔥 针对 `fireware` 与 `bootloader` 的 `bootupd` 更新器，bootupd 可以守护进程 `bootupd.service` 的方式运行。\n  - OpenShift 4 集群通过 `Machine Config Operator (MCO)` 更新 RHCOS\n\n### Ignition 在 FCOS 或 RHCOS 中的工作特点：\n- Ignition 是由 FCOS/RHCOS 使用的在系统初始化配置过程（`initramfs`）中操纵磁盘的工具，其可完成常见的磁盘任务，包括磁盘分区、格式化分区、写文件与配置用户等。\n- 在系统首次引导时（first boot），Ignition 读取安装介质或所指定的 Ignition 配置文件所在的路径。\n- ✨ Ignition 的调配方式：  \n  Ignition 配置文件（Ignition config file）或称点火配置文件\n- Ignition 配置与 `cloud-init` 或 `Linux Anaconda kickstart` 配置系统极其相似，但其具有自身的特点：  \n  - 由于 Ignition 能进行磁盘分区、设置文件系统与执行主机永久文件系统的其他改变，因此，在安装 FCOS/RHCOS 过程中 Ignition 运行于与系统相隔离的 `initial RAM disk` 中。与之相对的，cloud-init 作为初始化系统的一部分不能容易地实现磁盘的分区。  \n  - ✨ Ignition 与 cloud-init 对比：\n    - Ignition：\n      - 工作阶段：首次引导安装期间\n      - 工作次数：一次\n      - 功能实现：系统磁盘操作等\n      - 常用场景：安装部署\n    - cloud-init：\n      - 工作阶段：任意系统引导期间\n      - 工作次数：多次\n      - 功能实现：系统配置等\n      - 常用场景：系统配置\n  - Ignition 用于初始化系统而不是更改已存在的系统，OpenShift 4 使用 `Machine Config Operator` 完成所有主机的配置。  \n  - Ignition 以声明式方式（declarative configuration）检查配置中的所有配置项目以满足指定的要求。  \n  - ✨ 在 Ignition 完成主机配置后，kernel 保持运行但丢弃 initial RAM disk，并且转向（pivot to）磁盘上已安装的系统中。无需系统重启，所有的系统服务与其他特性即可启动。  \n  - 由于 Ignition 通过声明式配置将主机调整为指定的状态，因此不能存在具有部分配置的主机，若在部署 OpenShift 4 集群时存在部分配置的主机，该主机将无法加入集群，需更换新的主机再次调配加入集群。  \n  - 若存在问题的 Ignition 配置引起主机配置的失败，Ignition 将不再尝试使用相同的配置来调配另一台主机。  \n  - 由于 Ignition 可使用完整的空磁盘，它能实现 cloud-init 无法完成的任务，如使用 PXE 引导从空磁盘调配裸机系统。\n\n### Ignition 对 OpenShift 4 集群主机的处理顺序：\n- 在 OpenShift 4 集群中的 RHCOS 主机上 Ignition 的处理涉及以下步骤：  \n  - 1️⃣ 控制平面主机（`control plane machines`）从引导主机（`bootstrap machine`）获取 Ignition 配置文件，而工作主机（`worker machines`）从控制平面主机获取 Ignition 配置文件。  \n  - 2️⃣ Ignition 在主机上创建磁盘分区、文件系统、目录与链接，它支持 RAID 阵列但不支持 LVM 逻辑卷。  \n  - 3️⃣ Igition 在 initramfs 中挂载 root 持久化文件系统于 `/sysroot` 目录并在 `/sysroot` 目录中工作。  \n  - 4️⃣ Ignition 配置所有定义的文件系统并恰当地挂载它们。  \n  - 5️⃣ Ignition 运行 `systemd` 临时文件以填充在 `/var` 目录中的所需文件。  \n  - 6️⃣ Ignition 运行其配置文件来配置用户、systemd 单元文件与其他配置文件。  \n  - 7️⃣ Ignition 卸载在 initramfs 中挂载的持久化系统中的所有组件。  \n  - 8️⃣ Ignition 启动新主机的初始化过程，启动系统引导阶段的所有其他的服务。\n- 处理结束后，主机已做好加入集群的准备并且无需重启，与前文所述相同。\n\n### Fedora CoreOS 的安装环境与工具说明：\n- FCOS 支持在多种 IaaS 环境下运行。\n- Fedora CoreOS live ISO 版本：fedora-coreos-36.20220906.3.2-live.x86_64.iso\n- Butane 工具：  \n  - linux 版本：[0.15.0](https://github.com/coreos/butane/releases/download/v0.15.0/butane-x86_64-unknown-linux-gnu)  \n  - 该工具来源于 [coreos/butane](https://github.com/coreos/butane) 项目  \n  - `Butane` 以前称为 Fedora CoreOS 配置转换器（Fedora CoreOS Config Transpiler，`FCCT`），它可将 Butane 配置文件（Butane Config）或称 FCC 文件转换为 Ignition 配置文件（Ignition Config），该文件为 `JSON` 格式将被 FCOS 主机在首次引导调配时使用，可用于创建磁盘分区、文件系统、用户、受信任的用户 SSH 公钥、文件与系统单元文件（systemd units）等。  \n  - ✨ 其中 Butane 配置文件为 `YAML` 格式，关于该文件不同版本的配置规范（configuration specifications）请参考该 [链接](https://github.com/coreos/butane/blob/main/docs/specs.md)。  \n  - ✨ Butane 配置文件使用示例请参考该 [Examples](https://github.com/coreos/butane/blob/main/docs/examples.md)。  \n  - 可在自己指定的节点（非 FCOS 主机）上安装 butane，安装方式包括 butane 容器镜像（`quay.io/coreos/butane:release`）、rpm 软件包或独立的二进制文件（standalone binary），此处使用以上链接的独立二进制文件进行安装。![quay-coreos-butane-release.png](quay-coreos-butane-release.png)  \n  - butane 的使用方法可参考该 [链接](https://github.com/coreos/butane/blob/main/docs/getting-started.md)。\n- ignition-validate 工具：  \n  - linux 版本：[2.14.0](https://github.com/coreos/ignition/releases/download/v2.14.0/ignition-validate-x86_64-linux)  \n  - 该工具来源于 [coreos/ignition](https://github.com/coreos/ignition) 项目  \n  - 该工具用于对 Ignition 配置文件的格式与合法性字段的验证，若语法不合规将无法在 FCOS 中使用 `coreos-installer` 于系统首次引导时安装。\n\n### Fedora CoreOS 的定制化安装与验证：\n- 准备 HTTP 服务器、Ignition 配置文件与相关配置文件（非 FCOS 节点）：  \n  > ❗ 注意：\n  > \n  > 1. 本文安装采用基于 KVM 虚拟机模拟裸金属安装环境。\n  > \n  > 2. 关于 `butane` 工具与 `ignition-validate` 工具的安装如前文所述。\n  > \n  > 3. 💁‍♂️ 本文使用 FCOS live ISO 的方式引导并使用其中的 coreos-installer 工具调配安装主机，若使用 PXE 方式引导安装请参阅官方文档。\n    \n  ```bash\n  $ sudo yum install httpd\n  $ sudo systemctl enable --now httpd.service\n  # 安装与启动 httpd 服务并设置为开机自启\n  $ ssh-keygen -N '' -t rsa -f ~/.ssh/core_fcos_login\n  # 创建用于 SSH 免密登录 FCOS 的公私钥，此处将该 SSH 公钥拷贝至 Butane 配置文件\n  # 的 ssh_authorized_keys 字段中。\n  $ mkdir ~/fcos && cd ~/fcos\n  $ vim fcos-customized-config.yml\n  # 创建 Butane 配置文件\n  ```\n  该配置文件如下所示：\n  ```yaml\n  # 该配置文件可参看前文 GitHub Butane 的 Examples 或 Fedora CoreOS 官方文档\n  # 的 Storage 部分进行编辑。\n  variant: fcos\n  version: 1.1.0\n  # 创建自定义用户、密码、home 家目录与配置 SSH 免密登录的公钥\n  passwd:\n    users:\n      - name: core\n        ssh_authorized_keys:\n          - ssh-rsa AAAAB3Nz...jnXfG+Uj godev@cloud-ctl.domain12.example.com\n        # 由于 FCOS/RHCOS 在安装完成后无法使用密码直接登录，该公钥用于 core 用户的\n        # SSH 免密登录。\n      - name: cloud-admin\n        password_hash: $y$j9T$j0ODWvNUDSXcEcwpDH141.$dvAEVxBHUWbW/NnPd90qkg0Haq6vgkcKF151jvLDgYA\n        # 明文密码 redhat 通过 hash 加密的密文\n        # 虽然该用户已配置密码，但无法通过 SSH 远程登录，该密码只允许本地控制台登录。\n        home_dir: /opt/cloud-admin\n        no_create_home: false\n        groups:\n          - wheel\n        shell: /bin/bash\n        # 注意：当任何用户 SSH 远程登录失效时，可用该用户本地登录并提权！\n  storage:\n    # 将本地指定目录中的文件内容注入 FCOS 的对应文件中，需使用 butane 工具的\n    # --files-dir 选项。\n    files:\n      - path: \"/etc/NetworkManager/system-connections/Wired connection 1.nmconnection\"\n        contents:\n          local: ./Wired_connection_1.nmconnection      \n        mode: 0600\n        # FCOS 的网络接口配置\n      - path: /etc/hostname\n        contents:\n          local: ./hostname\n        mode: 0644\n        # FCOS 的主机名配置\n    # 将 FCOS 的 /dev/vdb 进行分区并挂载至 /var 目录，主要用于容器与镜像的存储。\n    # 注意：Ignition 不支持对 FCOS/RHCOS 的 LVM 逻辑卷功能！\n    disks:\n      - device: /dev/vdb\n        wipe_table: true\n        partitions:\n          - number: 1\n            label: var\n    filesystems:\n      - path: /var\n        device: /dev/disk/by-partlabel/var\n        format: xfs\n        wipe_filesystem: true \n        label: var\n        with_mount_unit: true\n  ```\n  以上 YAML 文件可点击 [此处](https://github.com/Alberthua-Perl/scripts-confs/tree/master/fedora-coreos-36) 获得。 \n  ```bash\n  $ cat ./hostname\n    fcos36-cloud.lab.example.com\n  $ cat ./Wired_connection_1.nmconnection \n    [connection]\n    id=Wired connection 1\n    type=ethernet\n    autoconnect-priority=-999\n    interface-name=ens3\n  \n    [ethernet]\n  \n    [ipv4]\n    address1=192.168.110.13/24,192.168.110.1\n    dns=192.168.110.1;\n    method=manual\n  \n  $ butane --files-dir . \\\n    --pretty --strict \\\n    --output fcos-customized-config.ign fcos-customized-config.yml\n  # 在当前目录中根据 Butane 配置文件转换为 Ignition 配置文件\n  $ ignition-validate fcos-customized-config.ign\n  # 验证 Ignition 配置文件语法的合法性，若无返回则验证通过，该文件可用于 FCOS 的安装。\n  $ sudo cp fcos-customized-config.ign /var/www/html/\n  # 拷贝该文件至 HTTP 服务器的根目录中用于 FCOS 中 coreos-installer 工具的下载\n  # 读取与系统安装。\n  ```\n- 创建 FCOS 虚拟机并使用 FCOS live ISO 引导安装，如下所示：![use-fedora-coreos-live-to-install.png](use-fedora-coreos-live-to-install.png)![login-fedora-coreos-live.png](login-fedora-coreos-live.png)\n  👉 `core` 用户可 `sudo` 免密提权为 root 用户。  \n  👉 使用 `core` 用户正常登录后，再使用 `ip -br a s` 命令查看主机的 IP 地址（一般可通过 `DHCP` 自动获取），若无与 HTTP 服务器通信的 IP 地址，将无法下载 Ignition 配置文件而安装失败，可通过如下命令临时配置加以生效：  \n  ```bash\n  $ sudo ip address add 192.168.110.13/24 dev ens3\n  # 需根据实际场景调整 IP 地址与对应的网络接口\n  ```\n  👉 使用 FCOS live ISO 自带的 `coreos-installer` 工具根据 Ignition 配置文件安装部署，如下所示： \n  ![coreos-installer-customized-install.png](coreos-installer-customized-install.png)  \n  ```bash\n  $ sudo coreos-installer install \\\n    --insecure-ignition \\\n    --ignition-url http://192.168.110.130/fcos-customized-config.ign \\\n    /dev/vda\n  # 下载 Ignition 配置文件并将根系统安装于 /dev/vda 中\n  # 此安装过程根据所配置的内容不同耗时也将不同（笔者环境中安装较快）\n  $ sudo reboot\n  # 重启系统\n  ```\n- 登录 FCOS 验证安装状态：  \n  ```bash\n  $ ssh -i ~/.ssh/core_fcos_login core@fcos36-cloud\n    Fedora CoreOS 36.20221001.3.0\n    Tracker: https://github.com/coreos/fedora-coreos-tracker\n    Discuss: https://discussion.fedoraproject.org/tag/coreos\n  \n    Last login: Mon Oct 24 14:07:00 2022 from 192.168.110.130\n    [core@fcos36-cloud ~]$ sudo -i\n    [root@fcos36-cloud ~]# id cloud-admin\n    uid=1001(cloud-admin) gid=1001(cloud-admin) groups=1001(cloud-admin),10(wheel)\n    [root@fcos36-cloud ~]# su - cloud-admin\n    [cloud-admin@fcos36-cloud ~]$ sudo -i\n    [sudo] password for cloud-admin: \n    [root@fcos36-cloud ~]# lsblk --paths\n    NAME        MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS\n    /dev/sr0     11:0    1 1024M  0 rom  \n    /dev/vda    252:0    0   10G  0 disk \n    |-/dev/vda1 252:1    0    1M  0 part \n    |-/dev/vda2 252:2    0  127M  0 part \n    |-/dev/vda3 252:3    0  384M  0 part /boot\n    `-/dev/vda4 252:4    0  9.5G  0 part /sysroot/ostree/deploy/fedora-coreos/var\n                                         /usr\n                                         /etc\n                                         /\n                                         /sysroot\n    /dev/vdb    252:16   0   10G  0 disk \n    `-/dev/vdb1 252:17   0   10G  0 part /var \n  # Ignition 配置文件中的配置在 FCOS 中已生效\n  ```\n- 由于 FCOS 中使用 `rpm-ostree` 进行软件包的管理，若需安装额外的软件包，可使用如下方式：  \n  ```bash\n  $ sudo rpm-ostree install \\\n    podman skopeo buildah cri-o cri-tools vim-enhanced\n  # 安装容器与镜像管理工具\n  $ sudo systemctl status crio.service\n  # 查看 CRI-O 守护进程状态，可通过 crictl 命令测试管理容器。\n  ```\n\n### 参考链接：\n- [Introducing Fedora CoreOS](https://fedoramagazine.org/introducing-fedora-coreos/)\n- [Getting started with Fedora CoreOS](https://fedoramagazine.org/getting-started-with-fedora-coreos/)\n- [Fedora CoreOS 入门 | Linux 中国](https://mp.weixin.qq.com/s/Vf6TvGSi5sNnMjT5QldUQg)\n- ❤ [Fedora CoreOS Documentation](https://docs.fedoraproject.org/en-US/fedora-coreos/)\n- [Red Hat Enterprise Linux CoreOS (RHCOS)](https://docs.openshift.com/container-platform/4.11/architecture/architecture-rhcos.html)\n- ❤ [How to customize Fedora CoreOS for dedicated workloads with OSTree](https://developers.redhat.com/blog/2020/03/12/how-to-customize-fedora-coreos-for-dedicated-workloads-with-ostree#)","slug":"fcos-rhcos-basic-usage","published":1,"updated":"2022-11-28T15:46:05.854Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldfonoia000116vdetjs0rfb","content":"<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>关键技术点</li>\n<li>Fedora CoreOS 及 RHCOS 介绍与特性</li>\n<li>Ignition 在 FCOS 或 RHCOS 中的工作特点</li>\n<li>Ignition 对 OpenShift 4 集群主机的处理顺序</li>\n<li>Fedora CoreOS 的安装环境与工具说明</li>\n<li>Fedora CoreOS 的定制化安装与验证</li>\n<li>参考链接</li>\n</ul>\n<h3 id=\"关键技术点：\"><a href=\"#关键技术点：\" class=\"headerlink\" title=\"关键技术点：\"></a>关键技术点：</h3><ul>\n<li>以下技术点在文中将根据 Fedora CoreOS 及 RHCOS 中展开说明：  <ul>\n<li>ignition, butane, ignition-validate  </li>\n<li>ostree, rpm-tree,zincati, bootupd</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Fedora-CoreOS-及-RHCOS-介绍与特性：\"><a href=\"#Fedora-CoreOS-及-RHCOS-介绍与特性：\" class=\"headerlink\" title=\"Fedora CoreOS 及 RHCOS 介绍与特性：\"></a>Fedora CoreOS 及 RHCOS 介绍与特性：</h3><ul>\n<li>在 OpenShift 4 安装过程会自动安装 CoreOS 的商业版 Red Hat Enterprise Linux CoreOS（简称 <code>RHCOS</code>）。根据 OpenShift 4 的文档说明，RHCOS 无法独立运行安装，它必须和 OpenShift 4 一起运行（因此 RHCOS 没有单独的订阅）。</li>\n<li>😃 不过好在 CoreOS 还提供了可以独立运行的社区版 <code>Fedora CoreOS</code>（简称 <code>FCOS</code>）可以完全免费使用。由于 FCOS 可以无需 OpenShift 4 也可以独立安装运行，因此使用 FCOS 作为研究环境，而相关操作基本都可适用 RHCOS 环境。</li>\n<li>FCOS/RHCOS 是 Red Hat 在收购 CoreOS 公司后结合 <code>CoreOS Container Linux</code> 和 <code>Fedora Atomic Host</code> 的优点推出的新一代容器操作系统，其目标是提供最佳的容器主机，从而能安全、大规模地运行容器化的工作负载。</li>\n<li>FCOS/RHCOS 将 <a href=\"https://github.com/coreos/ignition\" target=\"_blank\" rel=\"noopener\">Ignition</a>（点火） 与 rpm-ostree 等技术相集成，是一个自动更新的、最小的、整体的、对运行容器和 Kubernetes 进行了优化的操作系统，因为它们更符合 “不可变架构”（<code>Immutable Infrastructure</code>）理念，因此成为 Red Hat 推荐的 OpenShift 4 底层操作系统。</li>\n<li>FCOS/RHCOS 的安装及配置过程和一般的 RHEL 稍有差别，需要通过 Ignition 配置文件在安装的时候初始化网络、存储、内核、用户等方面的配置。</li>\n<li>FCOS 的设计理念：  <ul>\n<li>🐳 由于容器允许将工作负载重复部署到生产环境中，并自动扩展以满足需求。容器提供的隔离意味着主机操作系统可以很小，它只需要一个 <code>Linux kernel</code>、<code>systemd</code>、<code>container runtime</code> 和一些附加服务（如 SSH 服务器）。  </li>\n<li>FCOS 是专门为容器工作负载而设计的，无需定期维护，可以使用最新的操作系统改进、bug 修复和安全自动更新，其使用 Ignition 为自身提供服务，使用 <code>Podman</code> 和 <code>Moby</code> 运行容器，并使用 <code>rpm-ostree</code> 自动进行原子更新。<blockquote>\n<p>❗ 注意：</p>\n<ol>\n<li><p>FCOS 支持 <code>CRI-O</code> 作为容器引擎，常用于 OpenShift 4 的底层容器运行时，一般不直接使用 CRI-O 运行容器，OpenShift 4 可通过 <code>CRI</code> 接口创建与管理 Pod。</p>\n</li>\n<li><p>可通过 <code>crictl</code> 命令行工具创建与管理容器及 Pod，但一般情况下用于容器或 pod 的调试而非容器或 pod 的创建。</p>\n</li>\n</ol>\n</blockquote>\n</li>\n</ul>\n</li>\n<li>FCOS 调配不可变架构：  <ul>\n<li>在系统首次引导（<code>first boot</code>）阶段，FCOS 使用 Ignition 调配系统。  </li>\n<li>Ignition 读取用户提供的数据或远程 URL 地址提供的 Ignition 配置文件，并且使用它创建磁盘分区、文件系统、用户、受信任的用户 SSH 公钥、文件与系统单元文件（systemd units）等。  </li>\n<li>调配主机的方式：    <ul>\n<li>编辑基于 YAML 格式的 <code>Fedora CoreOS Config</code>（FCC）文件，该文件指定主机的期望配置，FCC 支持所有的 Ignition 功能，也提供额外的语法。    </li>\n<li>使用 <code>Fedora CoreOS Config Transpiler (Butane)</code> 工具将 FCC 文件（<code>.fcc</code>）转换为 Ignition 配置文件（<code>.ign</code>）。    </li>\n<li>启动 FCOS 主机并将 Ignition 配置文件同步至主机中调配系统的安装。    <blockquote>\n<p>💁‍♂️ 调配主机的方法：</p>\n<ol>\n<li><p>使用 PXE 引导并与指定 Ignition 配置文件调配安装主机。</p>\n</li>\n<li><p>将 Ignition 配置文件同步至使用 FCOS live ISO 引导启动的主机中，再使用 <code>coreos-installer</code> 工具调配安装主机（本文使用此方法）。  </p>\n</li>\n</ol>\n</blockquote>\n</li>\n</ul>\n</li>\n<li>FCOS 被设计为不可变架构。在主机被调配之后，不应该更改 /etc 目录或重新配置主机，相反，更改 FCC 文件并且使用该文件调配替换的主机。  </li>\n<li>🐳 这种方式与容器管理相似：容器镜像不可被原地更新，而是重头构建与重新部署。该方式在负载增加时容易横向扩容。只需简单地使用相同的 Ignition 配置文件来启动其他主机。</li>\n</ul>\n</li>\n<li><a href=\"https://getfedora.org/en/coreos/download?tab=metal_virtualized&amp;stream=stable&amp;arch=x86_64\" target=\"_blank\" rel=\"noopener\">FCOS 发布版本</a>：<img src=\"fedora-coreos-release-version.png\" alt=\"fedora-coreos-release-version.png\">  <ul>\n<li><code>testing stream</code>：<br>当前 Fedora 发行版的常规快照，加上更新。  </li>\n<li>❤ <code>stable stream</code>：<br>在测试版本可用两周后，它被发送到稳定流，在测试中发现的 <code>bug</code> 将在发布稳定流之前被修复。  </li>\n<li><code>next stream</code>：<br>即将发布的 Fedora 版本的常规快照，允许有额外的时间测试较大的更改。<br>👉 每个 stream 每 2 周发布一次，更新内容会从一个 stream 推广到另一个 stream（<code>next -&gt; testing -&gt; stable</code>）。这样落地在 stable stream 中的更新就有机会经过长时间的测试。<br>👉 所有三个 stream 都收到了安全更新和关键的错误修复，并旨在安全地用于生产使用。大多数机器应该运行 <code>stable stream</code>，因为它接受最多的测试。但是，用户应该在 next stream 上运行他们的部分节点，并向问题跟踪器报告问题。这有助于确保只影响特定工作负载或特定硬件的 bug 在稳定之前得到修复。</li>\n</ul>\n</li>\n<li>RHCOS 的关键特性：  <ul>\n<li>系统基于 RHEL 开发  </li>\n<li>可控制的不可变架构（<code>controlled immutability</code>）  </li>\n<li>默认使用 <code>CRI-O</code> 容器运行时  </li>\n<li>可使用容器工具集管理容器或 Pod（包括 <code>podman</code>、<code>skopeo</code> 与 <code>crictl</code> 等）  </li>\n<li>🔥 使用 <code>rpm-ostree</code> 实现事务性更新升级 <blockquote>\n<p>❗ 注意：</p>\n<ol>\n<li><p><code>OSTree</code> 是一个用于对基于 Linux 的操作系统进行版本更新的系统，它可以被视为 “面向操作系统二进制文件的 git”，它被 endless OS、Flatpak、Fedora、CentOS、Atomic Host 和 GNOME 等项目用来持续交付，有关 OSTree 更多详细的说明可参考 <a href=\"https://ostreedev.github.io/ostree/\" target=\"_blank\" rel=\"noopener\">libostree 官方文档</a>。</p>\n</li>\n<li><p>rpm-ostree 是一个混合镜像/包系统，以命令行与守护进程的方式运行，可将软件包以分层的形式构建在 OSTree 之上，将软件包作为系统的扩展，关于 rpm-ostree 更多详细的说明可参考 <a href=\"https://coreos.github.io/rpm-ostree\" target=\"_blank\" rel=\"noopener\">rpm-ostree 官方文档</a>。</p>\n</li>\n<li><p>FCOS 中的 <code>zincati</code> 服务（<code>zincati.service</code>）可检测系统的状态，通过 <code>rpm-ostreed</code> 守护进程进行更新，若其发现具有新的系统更新将自动更新系统，可将该服务关闭以禁用此功能。  </p>\n</li>\n</ol>\n</blockquote>\n</li>\n<li>🔥 针对 <code>fireware</code> 与 <code>bootloader</code> 的 <code>bootupd</code> 更新器，bootupd 可以守护进程 <code>bootupd.service</code> 的方式运行。</li>\n<li>OpenShift 4 集群通过 <code>Machine Config Operator (MCO)</code> 更新 RHCOS</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Ignition-在-FCOS-或-RHCOS-中的工作特点：\"><a href=\"#Ignition-在-FCOS-或-RHCOS-中的工作特点：\" class=\"headerlink\" title=\"Ignition 在 FCOS 或 RHCOS 中的工作特点：\"></a>Ignition 在 FCOS 或 RHCOS 中的工作特点：</h3><ul>\n<li>Ignition 是由 FCOS/RHCOS 使用的在系统初始化配置过程（<code>initramfs</code>）中操纵磁盘的工具，其可完成常见的磁盘任务，包括磁盘分区、格式化分区、写文件与配置用户等。</li>\n<li>在系统首次引导时（first boot），Ignition 读取安装介质或所指定的 Ignition 配置文件所在的路径。</li>\n<li>✨ Ignition 的调配方式：<br>Ignition 配置文件（Ignition config file）或称点火配置文件</li>\n<li>Ignition 配置与 <code>cloud-init</code> 或 <code>Linux Anaconda kickstart</code> 配置系统极其相似，但其具有自身的特点：  <ul>\n<li>由于 Ignition 能进行磁盘分区、设置文件系统与执行主机永久文件系统的其他改变，因此，在安装 FCOS/RHCOS 过程中 Ignition 运行于与系统相隔离的 <code>initial RAM disk</code> 中。与之相对的，cloud-init 作为初始化系统的一部分不能容易地实现磁盘的分区。  </li>\n<li>✨ Ignition 与 cloud-init 对比：<ul>\n<li>Ignition：<ul>\n<li>工作阶段：首次引导安装期间</li>\n<li>工作次数：一次</li>\n<li>功能实现：系统磁盘操作等</li>\n<li>常用场景：安装部署</li>\n</ul>\n</li>\n<li>cloud-init：<ul>\n<li>工作阶段：任意系统引导期间</li>\n<li>工作次数：多次</li>\n<li>功能实现：系统配置等</li>\n<li>常用场景：系统配置</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Ignition 用于初始化系统而不是更改已存在的系统，OpenShift 4 使用 <code>Machine Config Operator</code> 完成所有主机的配置。  </li>\n<li>Ignition 以声明式方式（declarative configuration）检查配置中的所有配置项目以满足指定的要求。  </li>\n<li>✨ 在 Ignition 完成主机配置后，kernel 保持运行但丢弃 initial RAM disk，并且转向（pivot to）磁盘上已安装的系统中。无需系统重启，所有的系统服务与其他特性即可启动。  </li>\n<li>由于 Ignition 通过声明式配置将主机调整为指定的状态，因此不能存在具有部分配置的主机，若在部署 OpenShift 4 集群时存在部分配置的主机，该主机将无法加入集群，需更换新的主机再次调配加入集群。  </li>\n<li>若存在问题的 Ignition 配置引起主机配置的失败，Ignition 将不再尝试使用相同的配置来调配另一台主机。  </li>\n<li>由于 Ignition 可使用完整的空磁盘，它能实现 cloud-init 无法完成的任务，如使用 PXE 引导从空磁盘调配裸机系统。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Ignition-对-OpenShift-4-集群主机的处理顺序：\"><a href=\"#Ignition-对-OpenShift-4-集群主机的处理顺序：\" class=\"headerlink\" title=\"Ignition 对 OpenShift 4 集群主机的处理顺序：\"></a>Ignition 对 OpenShift 4 集群主机的处理顺序：</h3><ul>\n<li>在 OpenShift 4 集群中的 RHCOS 主机上 Ignition 的处理涉及以下步骤：  <ul>\n<li>1️⃣ 控制平面主机（<code>control plane machines</code>）从引导主机（<code>bootstrap machine</code>）获取 Ignition 配置文件，而工作主机（<code>worker machines</code>）从控制平面主机获取 Ignition 配置文件。  </li>\n<li>2️⃣ Ignition 在主机上创建磁盘分区、文件系统、目录与链接，它支持 RAID 阵列但不支持 LVM 逻辑卷。  </li>\n<li>3️⃣ Igition 在 initramfs 中挂载 root 持久化文件系统于 <code>/sysroot</code> 目录并在 <code>/sysroot</code> 目录中工作。  </li>\n<li>4️⃣ Ignition 配置所有定义的文件系统并恰当地挂载它们。  </li>\n<li>5️⃣ Ignition 运行 <code>systemd</code> 临时文件以填充在 <code>/var</code> 目录中的所需文件。  </li>\n<li>6️⃣ Ignition 运行其配置文件来配置用户、systemd 单元文件与其他配置文件。  </li>\n<li>7️⃣ Ignition 卸载在 initramfs 中挂载的持久化系统中的所有组件。  </li>\n<li>8️⃣ Ignition 启动新主机的初始化过程，启动系统引导阶段的所有其他的服务。</li>\n</ul>\n</li>\n<li>处理结束后，主机已做好加入集群的准备并且无需重启，与前文所述相同。</li>\n</ul>\n<h3 id=\"Fedora-CoreOS-的安装环境与工具说明：\"><a href=\"#Fedora-CoreOS-的安装环境与工具说明：\" class=\"headerlink\" title=\"Fedora CoreOS 的安装环境与工具说明：\"></a>Fedora CoreOS 的安装环境与工具说明：</h3><ul>\n<li>FCOS 支持在多种 IaaS 环境下运行。</li>\n<li>Fedora CoreOS live ISO 版本：fedora-coreos-36.20220906.3.2-live.x86_64.iso</li>\n<li>Butane 工具：  <ul>\n<li>linux 版本：<a href=\"https://github.com/coreos/butane/releases/download/v0.15.0/butane-x86_64-unknown-linux-gnu\" target=\"_blank\" rel=\"noopener\">0.15.0</a>  </li>\n<li>该工具来源于 <a href=\"https://github.com/coreos/butane\" target=\"_blank\" rel=\"noopener\">coreos/butane</a> 项目  </li>\n<li><code>Butane</code> 以前称为 Fedora CoreOS 配置转换器（Fedora CoreOS Config Transpiler，<code>FCCT</code>），它可将 Butane 配置文件（Butane Config）或称 FCC 文件转换为 Ignition 配置文件（Ignition Config），该文件为 <code>JSON</code> 格式将被 FCOS 主机在首次引导调配时使用，可用于创建磁盘分区、文件系统、用户、受信任的用户 SSH 公钥、文件与系统单元文件（systemd units）等。  </li>\n<li>✨ 其中 Butane 配置文件为 <code>YAML</code> 格式，关于该文件不同版本的配置规范（configuration specifications）请参考该 <a href=\"https://github.com/coreos/butane/blob/main/docs/specs.md\" target=\"_blank\" rel=\"noopener\">链接</a>。  </li>\n<li>✨ Butane 配置文件使用示例请参考该 <a href=\"https://github.com/coreos/butane/blob/main/docs/examples.md\" target=\"_blank\" rel=\"noopener\">Examples</a>。  </li>\n<li>可在自己指定的节点（非 FCOS 主机）上安装 butane，安装方式包括 butane 容器镜像（<code>quay.io/coreos/butane:release</code>）、rpm 软件包或独立的二进制文件（standalone binary），此处使用以上链接的独立二进制文件进行安装。<img src=\"quay-coreos-butane-release.png\" alt=\"quay-coreos-butane-release.png\">  </li>\n<li>butane 的使用方法可参考该 <a href=\"https://github.com/coreos/butane/blob/main/docs/getting-started.md\" target=\"_blank\" rel=\"noopener\">链接</a>。</li>\n</ul>\n</li>\n<li>ignition-validate 工具：  <ul>\n<li>linux 版本：<a href=\"https://github.com/coreos/ignition/releases/download/v2.14.0/ignition-validate-x86_64-linux\" target=\"_blank\" rel=\"noopener\">2.14.0</a>  </li>\n<li>该工具来源于 <a href=\"https://github.com/coreos/ignition\" target=\"_blank\" rel=\"noopener\">coreos/ignition</a> 项目  </li>\n<li>该工具用于对 Ignition 配置文件的格式与合法性字段的验证，若语法不合规将无法在 FCOS 中使用 <code>coreos-installer</code> 于系统首次引导时安装。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Fedora-CoreOS-的定制化安装与验证：\"><a href=\"#Fedora-CoreOS-的定制化安装与验证：\" class=\"headerlink\" title=\"Fedora CoreOS 的定制化安装与验证：\"></a>Fedora CoreOS 的定制化安装与验证：</h3><ul>\n<li><p>准备 HTTP 服务器、Ignition 配置文件与相关配置文件（非 FCOS 节点）：  </p>\n<blockquote>\n<p>❗ 注意：</p>\n<ol>\n<li><p>本文安装采用基于 KVM 虚拟机模拟裸金属安装环境。</p>\n</li>\n<li><p>关于 <code>butane</code> 工具与 <code>ignition-validate</code> 工具的安装如前文所述。</p>\n</li>\n<li><p>💁‍♂️ 本文使用 FCOS live ISO 的方式引导并使用其中的 coreos-installer 工具调配安装主机，若使用 PXE 方式引导安装请参阅官方文档。</p>\n</li>\n</ol>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo yum install httpd</span><br><span class=\"line\">$ sudo systemctl <span class=\"built_in\">enable</span> --now httpd.service</span><br><span class=\"line\"><span class=\"comment\"># 安装与启动 httpd 服务并设置为开机自启</span></span><br><span class=\"line\">$ ssh-keygen -N <span class=\"string\">''</span> -t rsa -f ~/.ssh/core_fcos_login</span><br><span class=\"line\"><span class=\"comment\"># 创建用于 SSH 免密登录 FCOS 的公私钥，此处将该 SSH 公钥拷贝至 Butane 配置文件</span></span><br><span class=\"line\"><span class=\"comment\"># 的 ssh_authorized_keys 字段中。</span></span><br><span class=\"line\">$ mkdir ~/fcos &amp;&amp; <span class=\"built_in\">cd</span> ~/fcos</span><br><span class=\"line\">$ vim fcos-customized-config.yml</span><br><span class=\"line\"><span class=\"comment\"># 创建 Butane 配置文件</span></span><br></pre></td></tr></table></figure>\n<p>该配置文件如下所示：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 该配置文件可参看前文 GitHub Butane 的 Examples 或 Fedora CoreOS 官方文档</span></span><br><span class=\"line\"><span class=\"comment\"># 的 Storage 部分进行编辑。</span></span><br><span class=\"line\"><span class=\"attr\">variant:</span> <span class=\"string\">fcos</span></span><br><span class=\"line\"><span class=\"attr\">version:</span> <span class=\"number\">1.1</span><span class=\"number\">.0</span></span><br><span class=\"line\"><span class=\"comment\"># 创建自定义用户、密码、home 家目录与配置 SSH 免密登录的公钥</span></span><br><span class=\"line\"><span class=\"attr\">passwd:</span></span><br><span class=\"line\">  <span class=\"attr\">users:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">core</span></span><br><span class=\"line\">      <span class=\"attr\">ssh_authorized_keys:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">ssh-rsa</span> <span class=\"string\">AAAAB3Nz...jnXfG+Uj</span> <span class=\"string\">godev@cloud-ctl.domain12.example.com</span></span><br><span class=\"line\">      <span class=\"comment\"># 由于 FCOS/RHCOS 在安装完成后无法使用密码直接登录，该公钥用于 core 用户的</span></span><br><span class=\"line\">      <span class=\"comment\"># SSH 免密登录。</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">cloud-admin</span></span><br><span class=\"line\">      <span class=\"attr\">password_hash:</span> <span class=\"string\">$y$j9T$j0ODWvNUDSXcEcwpDH141.$dvAEVxBHUWbW/NnPd90qkg0Haq6vgkcKF151jvLDgYA</span></span><br><span class=\"line\">      <span class=\"comment\"># 明文密码 redhat 通过 hash 加密的密文</span></span><br><span class=\"line\">      <span class=\"comment\"># 虽然该用户已配置密码，但无法通过 SSH 远程登录，该密码只允许本地控制台登录。</span></span><br><span class=\"line\">      <span class=\"attr\">home_dir:</span> <span class=\"string\">/opt/cloud-admin</span></span><br><span class=\"line\">      <span class=\"attr\">no_create_home:</span> <span class=\"literal\">false</span></span><br><span class=\"line\">      <span class=\"attr\">groups:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">wheel</span></span><br><span class=\"line\">      <span class=\"attr\">shell:</span> <span class=\"string\">/bin/bash</span></span><br><span class=\"line\">      <span class=\"comment\"># 注意：当任何用户 SSH 远程登录失效时，可用该用户本地登录并提权！</span></span><br><span class=\"line\"><span class=\"attr\">storage:</span></span><br><span class=\"line\">  <span class=\"comment\"># 将本地指定目录中的文件内容注入 FCOS 的对应文件中，需使用 butane 工具的</span></span><br><span class=\"line\">  <span class=\"comment\"># --files-dir 选项。</span></span><br><span class=\"line\">  <span class=\"attr\">files:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">path:</span> <span class=\"string\">\"/etc/NetworkManager/system-connections/Wired connection 1.nmconnection\"</span></span><br><span class=\"line\">      <span class=\"attr\">contents:</span></span><br><span class=\"line\">        <span class=\"attr\">local:</span> <span class=\"string\">./Wired_connection_1.nmconnection</span>      </span><br><span class=\"line\">      <span class=\"attr\">mode:</span> <span class=\"number\">0600</span></span><br><span class=\"line\">      <span class=\"comment\"># FCOS 的网络接口配置</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">path:</span> <span class=\"string\">/etc/hostname</span></span><br><span class=\"line\">      <span class=\"attr\">contents:</span></span><br><span class=\"line\">        <span class=\"attr\">local:</span> <span class=\"string\">./hostname</span></span><br><span class=\"line\">      <span class=\"attr\">mode:</span> <span class=\"number\">0644</span></span><br><span class=\"line\">      <span class=\"comment\"># FCOS 的主机名配置</span></span><br><span class=\"line\">  <span class=\"comment\"># 将 FCOS 的 /dev/vdb 进行分区并挂载至 /var 目录，主要用于容器与镜像的存储。</span></span><br><span class=\"line\">  <span class=\"comment\"># 注意：Ignition 不支持对 FCOS/RHCOS 的 LVM 逻辑卷功能！</span></span><br><span class=\"line\">  <span class=\"attr\">disks:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">device:</span> <span class=\"string\">/dev/vdb</span></span><br><span class=\"line\">      <span class=\"attr\">wipe_table:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">      <span class=\"attr\">partitions:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">number:</span> <span class=\"number\">1</span></span><br><span class=\"line\">          <span class=\"attr\">label:</span> <span class=\"string\">var</span></span><br><span class=\"line\">  <span class=\"attr\">filesystems:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">path:</span> <span class=\"string\">/var</span></span><br><span class=\"line\">      <span class=\"attr\">device:</span> <span class=\"string\">/dev/disk/by-partlabel/var</span></span><br><span class=\"line\">      <span class=\"attr\">format:</span> <span class=\"string\">xfs</span></span><br><span class=\"line\">      <span class=\"attr\">wipe_filesystem:</span> <span class=\"literal\">true</span> </span><br><span class=\"line\">      <span class=\"attr\">label:</span> <span class=\"string\">var</span></span><br><span class=\"line\">      <span class=\"attr\">with_mount_unit:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n<p>以上 YAML 文件可点击 <a href=\"https://github.com/Alberthua-Perl/scripts-confs/tree/master/fedora-coreos-36\" target=\"_blank\" rel=\"noopener\">此处</a> 获得。 </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cat ./hostname</span><br><span class=\"line\">  fcos36-cloud.lab.example.com</span><br><span class=\"line\">$ cat ./Wired_connection_1.nmconnection </span><br><span class=\"line\">  [connection]</span><br><span class=\"line\">  id=Wired connection 1</span><br><span class=\"line\">  <span class=\"built_in\">type</span>=ethernet</span><br><span class=\"line\">  autoconnect-priority=-999</span><br><span class=\"line\">  interface-name=ens3</span><br><span class=\"line\"></span><br><span class=\"line\">  [ethernet]</span><br><span class=\"line\"></span><br><span class=\"line\">  [ipv4]</span><br><span class=\"line\">  address1=192.168.110.13/24,192.168.110.1</span><br><span class=\"line\">  dns=192.168.110.1;</span><br><span class=\"line\">  method=manual</span><br><span class=\"line\"></span><br><span class=\"line\">$ butane --files-dir . \\</span><br><span class=\"line\">  --pretty --strict \\</span><br><span class=\"line\">  --output fcos-customized-config.ign fcos-customized-config.yml</span><br><span class=\"line\"><span class=\"comment\"># 在当前目录中根据 Butane 配置文件转换为 Ignition 配置文件</span></span><br><span class=\"line\">$ ignition-validate fcos-customized-config.ign</span><br><span class=\"line\"><span class=\"comment\"># 验证 Ignition 配置文件语法的合法性，若无返回则验证通过，该文件可用于 FCOS 的安装。</span></span><br><span class=\"line\">$ sudo cp fcos-customized-config.ign /var/www/html/</span><br><span class=\"line\"><span class=\"comment\"># 拷贝该文件至 HTTP 服务器的根目录中用于 FCOS 中 coreos-installer 工具的下载</span></span><br><span class=\"line\"><span class=\"comment\"># 读取与系统安装。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>创建 FCOS 虚拟机并使用 FCOS live ISO 引导安装，如下所示：<img src=\"use-fedora-coreos-live-to-install.png\" alt=\"use-fedora-coreos-live-to-install.png\"><img src=\"login-fedora-coreos-live.png\" alt=\"login-fedora-coreos-live.png\"><br>👉 <code>core</code> 用户可 <code>sudo</code> 免密提权为 root 用户。<br>👉 使用 <code>core</code> 用户正常登录后，再使用 <code>ip -br a s</code> 命令查看主机的 IP 地址（一般可通过 <code>DHCP</code> 自动获取），若无与 HTTP 服务器通信的 IP 地址，将无法下载 Ignition 配置文件而安装失败，可通过如下命令临时配置加以生效：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo ip address add 192.168.110.13/24 dev ens3</span><br><span class=\"line\"><span class=\"comment\"># 需根据实际场景调整 IP 地址与对应的网络接口</span></span><br></pre></td></tr></table></figure>\n<p>👉 使用 FCOS live ISO 自带的 <code>coreos-installer</code> 工具根据 Ignition 配置文件安装部署，如下所示：<br><img src=\"coreos-installer-customized-install.png\" alt=\"coreos-installer-customized-install.png\">  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo coreos-installer install \\</span><br><span class=\"line\">  --insecure-ignition \\</span><br><span class=\"line\">  --ignition-url http://192.168.110.130/fcos-customized-config.ign \\</span><br><span class=\"line\">  /dev/vda</span><br><span class=\"line\"><span class=\"comment\"># 下载 Ignition 配置文件并将根系统安装于 /dev/vda 中</span></span><br><span class=\"line\"><span class=\"comment\"># 此安装过程根据所配置的内容不同耗时也将不同（笔者环境中安装较快）</span></span><br><span class=\"line\">$ sudo reboot</span><br><span class=\"line\"><span class=\"comment\"># 重启系统</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>登录 FCOS 验证安装状态：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ssh -i ~/.ssh/core_fcos_login core@fcos36-cloud</span><br><span class=\"line\">  Fedora CoreOS 36.20221001.3.0</span><br><span class=\"line\">  Tracker: https://github.com/coreos/fedora-coreos-tracker</span><br><span class=\"line\">  Discuss: https://discussion.fedoraproject.org/tag/coreos</span><br><span class=\"line\"></span><br><span class=\"line\">  Last login: Mon Oct 24 14:07:00 2022 from 192.168.110.130</span><br><span class=\"line\">  [core@fcos36-cloud ~]$ sudo -i</span><br><span class=\"line\">  [root@fcos36-cloud ~]<span class=\"comment\"># id cloud-admin</span></span><br><span class=\"line\">  uid=1001(cloud-admin) gid=1001(cloud-admin) groups=1001(cloud-admin),10(wheel)</span><br><span class=\"line\">  [root@fcos36-cloud ~]<span class=\"comment\"># su - cloud-admin</span></span><br><span class=\"line\">  [cloud-admin@fcos36-cloud ~]$ sudo -i</span><br><span class=\"line\">  [sudo] password <span class=\"keyword\">for</span> cloud-admin: </span><br><span class=\"line\">  [root@fcos36-cloud ~]<span class=\"comment\"># lsblk --paths</span></span><br><span class=\"line\">  NAME        MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS</span><br><span class=\"line\">  /dev/sr0     11:0    1 1024M  0 rom  </span><br><span class=\"line\">  /dev/vda    252:0    0   10G  0 disk </span><br><span class=\"line\">  |-/dev/vda1 252:1    0    1M  0 part </span><br><span class=\"line\">  |-/dev/vda2 252:2    0  127M  0 part </span><br><span class=\"line\">  |-/dev/vda3 252:3    0  384M  0 part /boot</span><br><span class=\"line\">  `-/dev/vda4 252:4    0  9.5G  0 part /sysroot/ostree/deploy/fedora-coreos/var</span><br><span class=\"line\">                                       /usr</span><br><span class=\"line\">                                       /etc</span><br><span class=\"line\">                                       /</span><br><span class=\"line\">                                       /sysroot</span><br><span class=\"line\">  /dev/vdb    252:16   0   10G  0 disk </span><br><span class=\"line\">  `-/dev/vdb1 252:17   0   10G  0 part /var </span><br><span class=\"line\"><span class=\"comment\"># Ignition 配置文件中的配置在 FCOS 中已生效</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>由于 FCOS 中使用 <code>rpm-ostree</code> 进行软件包的管理，若需安装额外的软件包，可使用如下方式：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo rpm-ostree install \\</span><br><span class=\"line\">  podman skopeo buildah cri-o cri-tools vim-enhanced</span><br><span class=\"line\"><span class=\"comment\"># 安装容器与镜像管理工具</span></span><br><span class=\"line\">$ sudo systemctl status crio.service</span><br><span class=\"line\"><span class=\"comment\"># 查看 CRI-O 守护进程状态，可通过 crictl 命令测试管理容器。</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://fedoramagazine.org/introducing-fedora-coreos/\" target=\"_blank\" rel=\"noopener\">Introducing Fedora CoreOS</a></li>\n<li><a href=\"https://fedoramagazine.org/getting-started-with-fedora-coreos/\" target=\"_blank\" rel=\"noopener\">Getting started with Fedora CoreOS</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/Vf6TvGSi5sNnMjT5QldUQg\" target=\"_blank\" rel=\"noopener\">Fedora CoreOS 入门 | Linux 中国</a></li>\n<li>❤ <a href=\"https://docs.fedoraproject.org/en-US/fedora-coreos/\" target=\"_blank\" rel=\"noopener\">Fedora CoreOS Documentation</a></li>\n<li><a href=\"https://docs.openshift.com/container-platform/4.11/architecture/architecture-rhcos.html\" target=\"_blank\" rel=\"noopener\">Red Hat Enterprise Linux CoreOS (RHCOS)</a></li>\n<li>❤ <a href=\"https://developers.redhat.com/blog/2020/03/12/how-to-customize-fedora-coreos-for-dedicated-workloads-with-ostree#\" target=\"_blank\" rel=\"noopener\">How to customize Fedora CoreOS for dedicated workloads with OSTree</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>关键技术点</li>\n<li>Fedora CoreOS 及 RHCOS 介绍与特性</li>\n<li>Ignition 在 FCOS 或 RHCOS 中的工作特点</li>\n<li>Ignition 对 OpenShift 4 集群主机的处理顺序</li>\n<li>Fedora CoreOS 的安装环境与工具说明</li>\n<li>Fedora CoreOS 的定制化安装与验证</li>\n<li>参考链接</li>\n</ul>\n<h3 id=\"关键技术点：\"><a href=\"#关键技术点：\" class=\"headerlink\" title=\"关键技术点：\"></a>关键技术点：</h3><ul>\n<li>以下技术点在文中将根据 Fedora CoreOS 及 RHCOS 中展开说明：  <ul>\n<li>ignition, butane, ignition-validate  </li>\n<li>ostree, rpm-tree,zincati, bootupd</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Fedora-CoreOS-及-RHCOS-介绍与特性：\"><a href=\"#Fedora-CoreOS-及-RHCOS-介绍与特性：\" class=\"headerlink\" title=\"Fedora CoreOS 及 RHCOS 介绍与特性：\"></a>Fedora CoreOS 及 RHCOS 介绍与特性：</h3><ul>\n<li>在 OpenShift 4 安装过程会自动安装 CoreOS 的商业版 Red Hat Enterprise Linux CoreOS（简称 <code>RHCOS</code>）。根据 OpenShift 4 的文档说明，RHCOS 无法独立运行安装，它必须和 OpenShift 4 一起运行（因此 RHCOS 没有单独的订阅）。</li>\n<li>😃 不过好在 CoreOS 还提供了可以独立运行的社区版 <code>Fedora CoreOS</code>（简称 <code>FCOS</code>）可以完全免费使用。由于 FCOS 可以无需 OpenShift 4 也可以独立安装运行，因此使用 FCOS 作为研究环境，而相关操作基本都可适用 RHCOS 环境。</li>\n<li>FCOS/RHCOS 是 Red Hat 在收购 CoreOS 公司后结合 <code>CoreOS Container Linux</code> 和 <code>Fedora Atomic Host</code> 的优点推出的新一代容器操作系统，其目标是提供最佳的容器主机，从而能安全、大规模地运行容器化的工作负载。</li>\n<li>FCOS/RHCOS 将 <a href=\"https://github.com/coreos/ignition\" target=\"_blank\" rel=\"noopener\">Ignition</a>（点火） 与 rpm-ostree 等技术相集成，是一个自动更新的、最小的、整体的、对运行容器和 Kubernetes 进行了优化的操作系统，因为它们更符合 “不可变架构”（<code>Immutable Infrastructure</code>）理念，因此成为 Red Hat 推荐的 OpenShift 4 底层操作系统。</li>\n<li>FCOS/RHCOS 的安装及配置过程和一般的 RHEL 稍有差别，需要通过 Ignition 配置文件在安装的时候初始化网络、存储、内核、用户等方面的配置。</li>\n<li>FCOS 的设计理念：  <ul>\n<li>🐳 由于容器允许将工作负载重复部署到生产环境中，并自动扩展以满足需求。容器提供的隔离意味着主机操作系统可以很小，它只需要一个 <code>Linux kernel</code>、<code>systemd</code>、<code>container runtime</code> 和一些附加服务（如 SSH 服务器）。  </li>\n<li>FCOS 是专门为容器工作负载而设计的，无需定期维护，可以使用最新的操作系统改进、bug 修复和安全自动更新，其使用 Ignition 为自身提供服务，使用 <code>Podman</code> 和 <code>Moby</code> 运行容器，并使用 <code>rpm-ostree</code> 自动进行原子更新。<blockquote>\n<p>❗ 注意：</p>\n<ol>\n<li><p>FCOS 支持 <code>CRI-O</code> 作为容器引擎，常用于 OpenShift 4 的底层容器运行时，一般不直接使用 CRI-O 运行容器，OpenShift 4 可通过 <code>CRI</code> 接口创建与管理 Pod。</p>\n</li>\n<li><p>可通过 <code>crictl</code> 命令行工具创建与管理容器及 Pod，但一般情况下用于容器或 pod 的调试而非容器或 pod 的创建。</p>\n</li>\n</ol>\n</blockquote>\n</li>\n</ul>\n</li>\n<li>FCOS 调配不可变架构：  <ul>\n<li>在系统首次引导（<code>first boot</code>）阶段，FCOS 使用 Ignition 调配系统。  </li>\n<li>Ignition 读取用户提供的数据或远程 URL 地址提供的 Ignition 配置文件，并且使用它创建磁盘分区、文件系统、用户、受信任的用户 SSH 公钥、文件与系统单元文件（systemd units）等。  </li>\n<li>调配主机的方式：    <ul>\n<li>编辑基于 YAML 格式的 <code>Fedora CoreOS Config</code>（FCC）文件，该文件指定主机的期望配置，FCC 支持所有的 Ignition 功能，也提供额外的语法。    </li>\n<li>使用 <code>Fedora CoreOS Config Transpiler (Butane)</code> 工具将 FCC 文件（<code>.fcc</code>）转换为 Ignition 配置文件（<code>.ign</code>）。    </li>\n<li>启动 FCOS 主机并将 Ignition 配置文件同步至主机中调配系统的安装。    <blockquote>\n<p>💁‍♂️ 调配主机的方法：</p>\n<ol>\n<li><p>使用 PXE 引导并与指定 Ignition 配置文件调配安装主机。</p>\n</li>\n<li><p>将 Ignition 配置文件同步至使用 FCOS live ISO 引导启动的主机中，再使用 <code>coreos-installer</code> 工具调配安装主机（本文使用此方法）。  </p>\n</li>\n</ol>\n</blockquote>\n</li>\n</ul>\n</li>\n<li>FCOS 被设计为不可变架构。在主机被调配之后，不应该更改 /etc 目录或重新配置主机，相反，更改 FCC 文件并且使用该文件调配替换的主机。  </li>\n<li>🐳 这种方式与容器管理相似：容器镜像不可被原地更新，而是重头构建与重新部署。该方式在负载增加时容易横向扩容。只需简单地使用相同的 Ignition 配置文件来启动其他主机。</li>\n</ul>\n</li>\n<li><a href=\"https://getfedora.org/en/coreos/download?tab=metal_virtualized&amp;stream=stable&amp;arch=x86_64\" target=\"_blank\" rel=\"noopener\">FCOS 发布版本</a>：<img src=\"fedora-coreos-release-version.png\" alt=\"fedora-coreos-release-version.png\">  <ul>\n<li><code>testing stream</code>：<br>当前 Fedora 发行版的常规快照，加上更新。  </li>\n<li>❤ <code>stable stream</code>：<br>在测试版本可用两周后，它被发送到稳定流，在测试中发现的 <code>bug</code> 将在发布稳定流之前被修复。  </li>\n<li><code>next stream</code>：<br>即将发布的 Fedora 版本的常规快照，允许有额外的时间测试较大的更改。<br>👉 每个 stream 每 2 周发布一次，更新内容会从一个 stream 推广到另一个 stream（<code>next -&gt; testing -&gt; stable</code>）。这样落地在 stable stream 中的更新就有机会经过长时间的测试。<br>👉 所有三个 stream 都收到了安全更新和关键的错误修复，并旨在安全地用于生产使用。大多数机器应该运行 <code>stable stream</code>，因为它接受最多的测试。但是，用户应该在 next stream 上运行他们的部分节点，并向问题跟踪器报告问题。这有助于确保只影响特定工作负载或特定硬件的 bug 在稳定之前得到修复。</li>\n</ul>\n</li>\n<li>RHCOS 的关键特性：  <ul>\n<li>系统基于 RHEL 开发  </li>\n<li>可控制的不可变架构（<code>controlled immutability</code>）  </li>\n<li>默认使用 <code>CRI-O</code> 容器运行时  </li>\n<li>可使用容器工具集管理容器或 Pod（包括 <code>podman</code>、<code>skopeo</code> 与 <code>crictl</code> 等）  </li>\n<li>🔥 使用 <code>rpm-ostree</code> 实现事务性更新升级 <blockquote>\n<p>❗ 注意：</p>\n<ol>\n<li><p><code>OSTree</code> 是一个用于对基于 Linux 的操作系统进行版本更新的系统，它可以被视为 “面向操作系统二进制文件的 git”，它被 endless OS、Flatpak、Fedora、CentOS、Atomic Host 和 GNOME 等项目用来持续交付，有关 OSTree 更多详细的说明可参考 <a href=\"https://ostreedev.github.io/ostree/\" target=\"_blank\" rel=\"noopener\">libostree 官方文档</a>。</p>\n</li>\n<li><p>rpm-ostree 是一个混合镜像/包系统，以命令行与守护进程的方式运行，可将软件包以分层的形式构建在 OSTree 之上，将软件包作为系统的扩展，关于 rpm-ostree 更多详细的说明可参考 <a href=\"https://coreos.github.io/rpm-ostree\" target=\"_blank\" rel=\"noopener\">rpm-ostree 官方文档</a>。</p>\n</li>\n<li><p>FCOS 中的 <code>zincati</code> 服务（<code>zincati.service</code>）可检测系统的状态，通过 <code>rpm-ostreed</code> 守护进程进行更新，若其发现具有新的系统更新将自动更新系统，可将该服务关闭以禁用此功能。  </p>\n</li>\n</ol>\n</blockquote>\n</li>\n<li>🔥 针对 <code>fireware</code> 与 <code>bootloader</code> 的 <code>bootupd</code> 更新器，bootupd 可以守护进程 <code>bootupd.service</code> 的方式运行。</li>\n<li>OpenShift 4 集群通过 <code>Machine Config Operator (MCO)</code> 更新 RHCOS</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Ignition-在-FCOS-或-RHCOS-中的工作特点：\"><a href=\"#Ignition-在-FCOS-或-RHCOS-中的工作特点：\" class=\"headerlink\" title=\"Ignition 在 FCOS 或 RHCOS 中的工作特点：\"></a>Ignition 在 FCOS 或 RHCOS 中的工作特点：</h3><ul>\n<li>Ignition 是由 FCOS/RHCOS 使用的在系统初始化配置过程（<code>initramfs</code>）中操纵磁盘的工具，其可完成常见的磁盘任务，包括磁盘分区、格式化分区、写文件与配置用户等。</li>\n<li>在系统首次引导时（first boot），Ignition 读取安装介质或所指定的 Ignition 配置文件所在的路径。</li>\n<li>✨ Ignition 的调配方式：<br>Ignition 配置文件（Ignition config file）或称点火配置文件</li>\n<li>Ignition 配置与 <code>cloud-init</code> 或 <code>Linux Anaconda kickstart</code> 配置系统极其相似，但其具有自身的特点：  <ul>\n<li>由于 Ignition 能进行磁盘分区、设置文件系统与执行主机永久文件系统的其他改变，因此，在安装 FCOS/RHCOS 过程中 Ignition 运行于与系统相隔离的 <code>initial RAM disk</code> 中。与之相对的，cloud-init 作为初始化系统的一部分不能容易地实现磁盘的分区。  </li>\n<li>✨ Ignition 与 cloud-init 对比：<ul>\n<li>Ignition：<ul>\n<li>工作阶段：首次引导安装期间</li>\n<li>工作次数：一次</li>\n<li>功能实现：系统磁盘操作等</li>\n<li>常用场景：安装部署</li>\n</ul>\n</li>\n<li>cloud-init：<ul>\n<li>工作阶段：任意系统引导期间</li>\n<li>工作次数：多次</li>\n<li>功能实现：系统配置等</li>\n<li>常用场景：系统配置</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Ignition 用于初始化系统而不是更改已存在的系统，OpenShift 4 使用 <code>Machine Config Operator</code> 完成所有主机的配置。  </li>\n<li>Ignition 以声明式方式（declarative configuration）检查配置中的所有配置项目以满足指定的要求。  </li>\n<li>✨ 在 Ignition 完成主机配置后，kernel 保持运行但丢弃 initial RAM disk，并且转向（pivot to）磁盘上已安装的系统中。无需系统重启，所有的系统服务与其他特性即可启动。  </li>\n<li>由于 Ignition 通过声明式配置将主机调整为指定的状态，因此不能存在具有部分配置的主机，若在部署 OpenShift 4 集群时存在部分配置的主机，该主机将无法加入集群，需更换新的主机再次调配加入集群。  </li>\n<li>若存在问题的 Ignition 配置引起主机配置的失败，Ignition 将不再尝试使用相同的配置来调配另一台主机。  </li>\n<li>由于 Ignition 可使用完整的空磁盘，它能实现 cloud-init 无法完成的任务，如使用 PXE 引导从空磁盘调配裸机系统。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Ignition-对-OpenShift-4-集群主机的处理顺序：\"><a href=\"#Ignition-对-OpenShift-4-集群主机的处理顺序：\" class=\"headerlink\" title=\"Ignition 对 OpenShift 4 集群主机的处理顺序：\"></a>Ignition 对 OpenShift 4 集群主机的处理顺序：</h3><ul>\n<li>在 OpenShift 4 集群中的 RHCOS 主机上 Ignition 的处理涉及以下步骤：  <ul>\n<li>1️⃣ 控制平面主机（<code>control plane machines</code>）从引导主机（<code>bootstrap machine</code>）获取 Ignition 配置文件，而工作主机（<code>worker machines</code>）从控制平面主机获取 Ignition 配置文件。  </li>\n<li>2️⃣ Ignition 在主机上创建磁盘分区、文件系统、目录与链接，它支持 RAID 阵列但不支持 LVM 逻辑卷。  </li>\n<li>3️⃣ Igition 在 initramfs 中挂载 root 持久化文件系统于 <code>/sysroot</code> 目录并在 <code>/sysroot</code> 目录中工作。  </li>\n<li>4️⃣ Ignition 配置所有定义的文件系统并恰当地挂载它们。  </li>\n<li>5️⃣ Ignition 运行 <code>systemd</code> 临时文件以填充在 <code>/var</code> 目录中的所需文件。  </li>\n<li>6️⃣ Ignition 运行其配置文件来配置用户、systemd 单元文件与其他配置文件。  </li>\n<li>7️⃣ Ignition 卸载在 initramfs 中挂载的持久化系统中的所有组件。  </li>\n<li>8️⃣ Ignition 启动新主机的初始化过程，启动系统引导阶段的所有其他的服务。</li>\n</ul>\n</li>\n<li>处理结束后，主机已做好加入集群的准备并且无需重启，与前文所述相同。</li>\n</ul>\n<h3 id=\"Fedora-CoreOS-的安装环境与工具说明：\"><a href=\"#Fedora-CoreOS-的安装环境与工具说明：\" class=\"headerlink\" title=\"Fedora CoreOS 的安装环境与工具说明：\"></a>Fedora CoreOS 的安装环境与工具说明：</h3><ul>\n<li>FCOS 支持在多种 IaaS 环境下运行。</li>\n<li>Fedora CoreOS live ISO 版本：fedora-coreos-36.20220906.3.2-live.x86_64.iso</li>\n<li>Butane 工具：  <ul>\n<li>linux 版本：<a href=\"https://github.com/coreos/butane/releases/download/v0.15.0/butane-x86_64-unknown-linux-gnu\" target=\"_blank\" rel=\"noopener\">0.15.0</a>  </li>\n<li>该工具来源于 <a href=\"https://github.com/coreos/butane\" target=\"_blank\" rel=\"noopener\">coreos/butane</a> 项目  </li>\n<li><code>Butane</code> 以前称为 Fedora CoreOS 配置转换器（Fedora CoreOS Config Transpiler，<code>FCCT</code>），它可将 Butane 配置文件（Butane Config）或称 FCC 文件转换为 Ignition 配置文件（Ignition Config），该文件为 <code>JSON</code> 格式将被 FCOS 主机在首次引导调配时使用，可用于创建磁盘分区、文件系统、用户、受信任的用户 SSH 公钥、文件与系统单元文件（systemd units）等。  </li>\n<li>✨ 其中 Butane 配置文件为 <code>YAML</code> 格式，关于该文件不同版本的配置规范（configuration specifications）请参考该 <a href=\"https://github.com/coreos/butane/blob/main/docs/specs.md\" target=\"_blank\" rel=\"noopener\">链接</a>。  </li>\n<li>✨ Butane 配置文件使用示例请参考该 <a href=\"https://github.com/coreos/butane/blob/main/docs/examples.md\" target=\"_blank\" rel=\"noopener\">Examples</a>。  </li>\n<li>可在自己指定的节点（非 FCOS 主机）上安装 butane，安装方式包括 butane 容器镜像（<code>quay.io/coreos/butane:release</code>）、rpm 软件包或独立的二进制文件（standalone binary），此处使用以上链接的独立二进制文件进行安装。<img src=\"quay-coreos-butane-release.png\" alt=\"quay-coreos-butane-release.png\">  </li>\n<li>butane 的使用方法可参考该 <a href=\"https://github.com/coreos/butane/blob/main/docs/getting-started.md\" target=\"_blank\" rel=\"noopener\">链接</a>。</li>\n</ul>\n</li>\n<li>ignition-validate 工具：  <ul>\n<li>linux 版本：<a href=\"https://github.com/coreos/ignition/releases/download/v2.14.0/ignition-validate-x86_64-linux\" target=\"_blank\" rel=\"noopener\">2.14.0</a>  </li>\n<li>该工具来源于 <a href=\"https://github.com/coreos/ignition\" target=\"_blank\" rel=\"noopener\">coreos/ignition</a> 项目  </li>\n<li>该工具用于对 Ignition 配置文件的格式与合法性字段的验证，若语法不合规将无法在 FCOS 中使用 <code>coreos-installer</code> 于系统首次引导时安装。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Fedora-CoreOS-的定制化安装与验证：\"><a href=\"#Fedora-CoreOS-的定制化安装与验证：\" class=\"headerlink\" title=\"Fedora CoreOS 的定制化安装与验证：\"></a>Fedora CoreOS 的定制化安装与验证：</h3><ul>\n<li><p>准备 HTTP 服务器、Ignition 配置文件与相关配置文件（非 FCOS 节点）：  </p>\n<blockquote>\n<p>❗ 注意：</p>\n<ol>\n<li><p>本文安装采用基于 KVM 虚拟机模拟裸金属安装环境。</p>\n</li>\n<li><p>关于 <code>butane</code> 工具与 <code>ignition-validate</code> 工具的安装如前文所述。</p>\n</li>\n<li><p>💁‍♂️ 本文使用 FCOS live ISO 的方式引导并使用其中的 coreos-installer 工具调配安装主机，若使用 PXE 方式引导安装请参阅官方文档。</p>\n</li>\n</ol>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo yum install httpd</span><br><span class=\"line\">$ sudo systemctl <span class=\"built_in\">enable</span> --now httpd.service</span><br><span class=\"line\"><span class=\"comment\"># 安装与启动 httpd 服务并设置为开机自启</span></span><br><span class=\"line\">$ ssh-keygen -N <span class=\"string\">''</span> -t rsa -f ~/.ssh/core_fcos_login</span><br><span class=\"line\"><span class=\"comment\"># 创建用于 SSH 免密登录 FCOS 的公私钥，此处将该 SSH 公钥拷贝至 Butane 配置文件</span></span><br><span class=\"line\"><span class=\"comment\"># 的 ssh_authorized_keys 字段中。</span></span><br><span class=\"line\">$ mkdir ~/fcos &amp;&amp; <span class=\"built_in\">cd</span> ~/fcos</span><br><span class=\"line\">$ vim fcos-customized-config.yml</span><br><span class=\"line\"><span class=\"comment\"># 创建 Butane 配置文件</span></span><br></pre></td></tr></table></figure>\n<p>该配置文件如下所示：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 该配置文件可参看前文 GitHub Butane 的 Examples 或 Fedora CoreOS 官方文档</span></span><br><span class=\"line\"><span class=\"comment\"># 的 Storage 部分进行编辑。</span></span><br><span class=\"line\"><span class=\"attr\">variant:</span> <span class=\"string\">fcos</span></span><br><span class=\"line\"><span class=\"attr\">version:</span> <span class=\"number\">1.1</span><span class=\"number\">.0</span></span><br><span class=\"line\"><span class=\"comment\"># 创建自定义用户、密码、home 家目录与配置 SSH 免密登录的公钥</span></span><br><span class=\"line\"><span class=\"attr\">passwd:</span></span><br><span class=\"line\">  <span class=\"attr\">users:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">core</span></span><br><span class=\"line\">      <span class=\"attr\">ssh_authorized_keys:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">ssh-rsa</span> <span class=\"string\">AAAAB3Nz...jnXfG+Uj</span> <span class=\"string\">godev@cloud-ctl.domain12.example.com</span></span><br><span class=\"line\">      <span class=\"comment\"># 由于 FCOS/RHCOS 在安装完成后无法使用密码直接登录，该公钥用于 core 用户的</span></span><br><span class=\"line\">      <span class=\"comment\"># SSH 免密登录。</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">cloud-admin</span></span><br><span class=\"line\">      <span class=\"attr\">password_hash:</span> <span class=\"string\">$y$j9T$j0ODWvNUDSXcEcwpDH141.$dvAEVxBHUWbW/NnPd90qkg0Haq6vgkcKF151jvLDgYA</span></span><br><span class=\"line\">      <span class=\"comment\"># 明文密码 redhat 通过 hash 加密的密文</span></span><br><span class=\"line\">      <span class=\"comment\"># 虽然该用户已配置密码，但无法通过 SSH 远程登录，该密码只允许本地控制台登录。</span></span><br><span class=\"line\">      <span class=\"attr\">home_dir:</span> <span class=\"string\">/opt/cloud-admin</span></span><br><span class=\"line\">      <span class=\"attr\">no_create_home:</span> <span class=\"literal\">false</span></span><br><span class=\"line\">      <span class=\"attr\">groups:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">wheel</span></span><br><span class=\"line\">      <span class=\"attr\">shell:</span> <span class=\"string\">/bin/bash</span></span><br><span class=\"line\">      <span class=\"comment\"># 注意：当任何用户 SSH 远程登录失效时，可用该用户本地登录并提权！</span></span><br><span class=\"line\"><span class=\"attr\">storage:</span></span><br><span class=\"line\">  <span class=\"comment\"># 将本地指定目录中的文件内容注入 FCOS 的对应文件中，需使用 butane 工具的</span></span><br><span class=\"line\">  <span class=\"comment\"># --files-dir 选项。</span></span><br><span class=\"line\">  <span class=\"attr\">files:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">path:</span> <span class=\"string\">\"/etc/NetworkManager/system-connections/Wired connection 1.nmconnection\"</span></span><br><span class=\"line\">      <span class=\"attr\">contents:</span></span><br><span class=\"line\">        <span class=\"attr\">local:</span> <span class=\"string\">./Wired_connection_1.nmconnection</span>      </span><br><span class=\"line\">      <span class=\"attr\">mode:</span> <span class=\"number\">0600</span></span><br><span class=\"line\">      <span class=\"comment\"># FCOS 的网络接口配置</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">path:</span> <span class=\"string\">/etc/hostname</span></span><br><span class=\"line\">      <span class=\"attr\">contents:</span></span><br><span class=\"line\">        <span class=\"attr\">local:</span> <span class=\"string\">./hostname</span></span><br><span class=\"line\">      <span class=\"attr\">mode:</span> <span class=\"number\">0644</span></span><br><span class=\"line\">      <span class=\"comment\"># FCOS 的主机名配置</span></span><br><span class=\"line\">  <span class=\"comment\"># 将 FCOS 的 /dev/vdb 进行分区并挂载至 /var 目录，主要用于容器与镜像的存储。</span></span><br><span class=\"line\">  <span class=\"comment\"># 注意：Ignition 不支持对 FCOS/RHCOS 的 LVM 逻辑卷功能！</span></span><br><span class=\"line\">  <span class=\"attr\">disks:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">device:</span> <span class=\"string\">/dev/vdb</span></span><br><span class=\"line\">      <span class=\"attr\">wipe_table:</span> <span class=\"literal\">true</span></span><br><span class=\"line\">      <span class=\"attr\">partitions:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">number:</span> <span class=\"number\">1</span></span><br><span class=\"line\">          <span class=\"attr\">label:</span> <span class=\"string\">var</span></span><br><span class=\"line\">  <span class=\"attr\">filesystems:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">path:</span> <span class=\"string\">/var</span></span><br><span class=\"line\">      <span class=\"attr\">device:</span> <span class=\"string\">/dev/disk/by-partlabel/var</span></span><br><span class=\"line\">      <span class=\"attr\">format:</span> <span class=\"string\">xfs</span></span><br><span class=\"line\">      <span class=\"attr\">wipe_filesystem:</span> <span class=\"literal\">true</span> </span><br><span class=\"line\">      <span class=\"attr\">label:</span> <span class=\"string\">var</span></span><br><span class=\"line\">      <span class=\"attr\">with_mount_unit:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n<p>以上 YAML 文件可点击 <a href=\"https://github.com/Alberthua-Perl/scripts-confs/tree/master/fedora-coreos-36\" target=\"_blank\" rel=\"noopener\">此处</a> 获得。 </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cat ./hostname</span><br><span class=\"line\">  fcos36-cloud.lab.example.com</span><br><span class=\"line\">$ cat ./Wired_connection_1.nmconnection </span><br><span class=\"line\">  [connection]</span><br><span class=\"line\">  id=Wired connection 1</span><br><span class=\"line\">  <span class=\"built_in\">type</span>=ethernet</span><br><span class=\"line\">  autoconnect-priority=-999</span><br><span class=\"line\">  interface-name=ens3</span><br><span class=\"line\"></span><br><span class=\"line\">  [ethernet]</span><br><span class=\"line\"></span><br><span class=\"line\">  [ipv4]</span><br><span class=\"line\">  address1=192.168.110.13/24,192.168.110.1</span><br><span class=\"line\">  dns=192.168.110.1;</span><br><span class=\"line\">  method=manual</span><br><span class=\"line\"></span><br><span class=\"line\">$ butane --files-dir . \\</span><br><span class=\"line\">  --pretty --strict \\</span><br><span class=\"line\">  --output fcos-customized-config.ign fcos-customized-config.yml</span><br><span class=\"line\"><span class=\"comment\"># 在当前目录中根据 Butane 配置文件转换为 Ignition 配置文件</span></span><br><span class=\"line\">$ ignition-validate fcos-customized-config.ign</span><br><span class=\"line\"><span class=\"comment\"># 验证 Ignition 配置文件语法的合法性，若无返回则验证通过，该文件可用于 FCOS 的安装。</span></span><br><span class=\"line\">$ sudo cp fcos-customized-config.ign /var/www/html/</span><br><span class=\"line\"><span class=\"comment\"># 拷贝该文件至 HTTP 服务器的根目录中用于 FCOS 中 coreos-installer 工具的下载</span></span><br><span class=\"line\"><span class=\"comment\"># 读取与系统安装。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>创建 FCOS 虚拟机并使用 FCOS live ISO 引导安装，如下所示：<img src=\"use-fedora-coreos-live-to-install.png\" alt=\"use-fedora-coreos-live-to-install.png\"><img src=\"login-fedora-coreos-live.png\" alt=\"login-fedora-coreos-live.png\"><br>👉 <code>core</code> 用户可 <code>sudo</code> 免密提权为 root 用户。<br>👉 使用 <code>core</code> 用户正常登录后，再使用 <code>ip -br a s</code> 命令查看主机的 IP 地址（一般可通过 <code>DHCP</code> 自动获取），若无与 HTTP 服务器通信的 IP 地址，将无法下载 Ignition 配置文件而安装失败，可通过如下命令临时配置加以生效：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo ip address add 192.168.110.13/24 dev ens3</span><br><span class=\"line\"><span class=\"comment\"># 需根据实际场景调整 IP 地址与对应的网络接口</span></span><br></pre></td></tr></table></figure>\n<p>👉 使用 FCOS live ISO 自带的 <code>coreos-installer</code> 工具根据 Ignition 配置文件安装部署，如下所示：<br><img src=\"coreos-installer-customized-install.png\" alt=\"coreos-installer-customized-install.png\">  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo coreos-installer install \\</span><br><span class=\"line\">  --insecure-ignition \\</span><br><span class=\"line\">  --ignition-url http://192.168.110.130/fcos-customized-config.ign \\</span><br><span class=\"line\">  /dev/vda</span><br><span class=\"line\"><span class=\"comment\"># 下载 Ignition 配置文件并将根系统安装于 /dev/vda 中</span></span><br><span class=\"line\"><span class=\"comment\"># 此安装过程根据所配置的内容不同耗时也将不同（笔者环境中安装较快）</span></span><br><span class=\"line\">$ sudo reboot</span><br><span class=\"line\"><span class=\"comment\"># 重启系统</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>登录 FCOS 验证安装状态：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ssh -i ~/.ssh/core_fcos_login core@fcos36-cloud</span><br><span class=\"line\">  Fedora CoreOS 36.20221001.3.0</span><br><span class=\"line\">  Tracker: https://github.com/coreos/fedora-coreos-tracker</span><br><span class=\"line\">  Discuss: https://discussion.fedoraproject.org/tag/coreos</span><br><span class=\"line\"></span><br><span class=\"line\">  Last login: Mon Oct 24 14:07:00 2022 from 192.168.110.130</span><br><span class=\"line\">  [core@fcos36-cloud ~]$ sudo -i</span><br><span class=\"line\">  [root@fcos36-cloud ~]<span class=\"comment\"># id cloud-admin</span></span><br><span class=\"line\">  uid=1001(cloud-admin) gid=1001(cloud-admin) groups=1001(cloud-admin),10(wheel)</span><br><span class=\"line\">  [root@fcos36-cloud ~]<span class=\"comment\"># su - cloud-admin</span></span><br><span class=\"line\">  [cloud-admin@fcos36-cloud ~]$ sudo -i</span><br><span class=\"line\">  [sudo] password <span class=\"keyword\">for</span> cloud-admin: </span><br><span class=\"line\">  [root@fcos36-cloud ~]<span class=\"comment\"># lsblk --paths</span></span><br><span class=\"line\">  NAME        MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS</span><br><span class=\"line\">  /dev/sr0     11:0    1 1024M  0 rom  </span><br><span class=\"line\">  /dev/vda    252:0    0   10G  0 disk </span><br><span class=\"line\">  |-/dev/vda1 252:1    0    1M  0 part </span><br><span class=\"line\">  |-/dev/vda2 252:2    0  127M  0 part </span><br><span class=\"line\">  |-/dev/vda3 252:3    0  384M  0 part /boot</span><br><span class=\"line\">  `-/dev/vda4 252:4    0  9.5G  0 part /sysroot/ostree/deploy/fedora-coreos/var</span><br><span class=\"line\">                                       /usr</span><br><span class=\"line\">                                       /etc</span><br><span class=\"line\">                                       /</span><br><span class=\"line\">                                       /sysroot</span><br><span class=\"line\">  /dev/vdb    252:16   0   10G  0 disk </span><br><span class=\"line\">  `-/dev/vdb1 252:17   0   10G  0 part /var </span><br><span class=\"line\"><span class=\"comment\"># Ignition 配置文件中的配置在 FCOS 中已生效</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>由于 FCOS 中使用 <code>rpm-ostree</code> 进行软件包的管理，若需安装额外的软件包，可使用如下方式：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo rpm-ostree install \\</span><br><span class=\"line\">  podman skopeo buildah cri-o cri-tools vim-enhanced</span><br><span class=\"line\"><span class=\"comment\"># 安装容器与镜像管理工具</span></span><br><span class=\"line\">$ sudo systemctl status crio.service</span><br><span class=\"line\"><span class=\"comment\"># 查看 CRI-O 守护进程状态，可通过 crictl 命令测试管理容器。</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://fedoramagazine.org/introducing-fedora-coreos/\" target=\"_blank\" rel=\"noopener\">Introducing Fedora CoreOS</a></li>\n<li><a href=\"https://fedoramagazine.org/getting-started-with-fedora-coreos/\" target=\"_blank\" rel=\"noopener\">Getting started with Fedora CoreOS</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/Vf6TvGSi5sNnMjT5QldUQg\" target=\"_blank\" rel=\"noopener\">Fedora CoreOS 入门 | Linux 中国</a></li>\n<li>❤ <a href=\"https://docs.fedoraproject.org/en-US/fedora-coreos/\" target=\"_blank\" rel=\"noopener\">Fedora CoreOS Documentation</a></li>\n<li><a href=\"https://docs.openshift.com/container-platform/4.11/architecture/architecture-rhcos.html\" target=\"_blank\" rel=\"noopener\">Red Hat Enterprise Linux CoreOS (RHCOS)</a></li>\n<li>❤ <a href=\"https://developers.redhat.com/blog/2020/03/12/how-to-customize-fedora-coreos-for-dedicated-workloads-with-ostree#\" target=\"_blank\" rel=\"noopener\">How to customize Fedora CoreOS for dedicated workloads with OSTree</a></li>\n</ul>\n"},{"title":"Code Server v4.8.3 容器镜像构建","subtitle":"Build Code Server for Golang","header-img":"code-server-bg.png","date":"2022-12-05T15:45:01.000Z","_content":"\n### 文档说明：\n- 🔗 可参考 [该链接](https://github.com/Alberthua-Perl/dockerfile-s2i-demo/tree/master/code-server-4.8.3)，以获得项目的 GitHub 仓库。\n- `Red Hat OpenShift` 中使用 `Red Hat Code Ready Workspace` 作为 PaaS 平台中的实时 IDE 开发平台，可兼容众多开发语言。\n- 该示例的目的在于构建类似于 Red Hat Code Ready Workspace 的容器化 Golang IDE 开发平台。\n- 可使用此 Golang IDE 开发平台提供与本地 `Microsoft VS Code` 平台相同的功能，并可实现实时登录开发环境与远程代码仓库的一致性。\n- 容器镜像构建与使用：\n  - 该容器镜像可提供的功能：\n    - 👉 基于 `VS Code` 的 `Web UI` 开发界面\n    - 👉 集成 `Golang v1.19.3` 语言开发环境\n  - 使用该目录中的 `Dockerfile` 构建 `Code Server v4.8.3` 容器镜像，如下所示：\n    ```bash\n    $ tree -h .\n      .\n      ├── [103M]  code-server_4.8.3_amd64.deb\n      ├── [1.9K]  Dockerfile\n      ├── [ 17K]  oh-my-zsh-install.sh\n      ├── [1.3K]  README.md\n      └── [ 614]  sources.list\n  \n    $ sudo docker build -t golang-code-server:v1.1 .\n    # 在当前目录上下文中构建\n    $ sudo docker run -d --name=golang-code-server -p 8080:8080 golang-code-server:v1.1\n    # 使用构建的容器镜像运行容器，并登录访问 Web 界面。\n    ```\n\n  > 💥 注意：由于 `code-server_4.8.3_amd64.deb` 软件包的容量大小限制无法上传至 GitHub 中，可从  [百度网盘](https://pan.baidu.com/s/1ul4ZYZa1Cpmp_5fXxyGJtg) 下载，提取码为 `no8o`。\n\n  - 该容器镜像可在 `Kubernetes` 或 `OpenShift` 集群外使用 `Docker` 或 `Podman` 先行测试，再导入容器镜像仓库 `registry`，用于后续的部署使用。\n- 可使用如下所示的 [资源定义文件](https://github.com/Alberthua-Perl/go-kubernetes-learn-path/blob/hotfixes/golang-codeready-workspace-deployment.yml)，将该应用部署于 `Kubernetes` 或 `OpenShift` 集群中：\n  ```yaml\n  apiVersion: v1\n  kind: Service\n  metadata: \n    labels: \n      name: golang-codeready-workspace\n    name: golang-codeready-workspace\n    namespace: codeready-workspace\n  spec: \n    ports:\n      # the port that this service should serve on\n      - port: 8080\n        protocol: TCP\n        targetPort: 8080\n        nodePort: 30001\n    # label keys and values that must match in order to receive traffic for this service\n    selector: \n      app: golang-codeready-workspace\n    type: NodePort\n  ---  \n  apiVersion: apps/v1\n  kind: Deployment\n  metadata:\n    labels:\n      app: golang-codeready-workspace\n    name: golang-codeready-workspace\n    namespace: codeready-workspace\n  spec:\n    replicas: 1\n    selector:\n      matchLabels:\n        app: golang-codeready-workspace\n    template:\n      metadata:\n        creationTimestamp: null\n        labels:\n          app: golang-codeready-workspace\n      spec:\n        containers:\n        - image: quay-registry.lab.example.com/godev/golang-code-server:v1.1\n          # image also pulled from quay.io/alberthua/golang-code-server:v1.1\n          imagePullPolicy: IfNotPresent\n          name: golang-codeready-workspace\n          ports:\n          - containerPort: 8080\n            protocol: TCP\n        restartPolicy: Always\n        schedulerName: default-scheduler\n        securityContext: {}\n        terminationGracePeriodSeconds: 30\n  ```\n\n### 参考链接：\n- [GitHub - coder/code-server](https://github.com/coder/code-server)\n- [code-server v4.8.0 docs](https://coder.com/docs/code-server/latest)\n- [dockerhub - golang](https://hub.docker.com/_/golang)\n- [云 vscode 搭建之使用容器化部署的方法](https://www.jb51.net/article/261704.htm)\n- [docker build 时出现错误 \"debconf: unable to initialize frontend: Dialog\" 如何处理？](https://blog.51cto.com/u_15061952/3607022)","source":"_posts/golang-code-server.md","raw":"---\ntitle: Code Server v4.8.3 容器镜像构建\nsubtitle: Build Code Server for Golang\nheader-img: code-server-bg.png \ndate: 2022-12-05 23:45:01\ntags:\n  - Golang\n---\n\n### 文档说明：\n- 🔗 可参考 [该链接](https://github.com/Alberthua-Perl/dockerfile-s2i-demo/tree/master/code-server-4.8.3)，以获得项目的 GitHub 仓库。\n- `Red Hat OpenShift` 中使用 `Red Hat Code Ready Workspace` 作为 PaaS 平台中的实时 IDE 开发平台，可兼容众多开发语言。\n- 该示例的目的在于构建类似于 Red Hat Code Ready Workspace 的容器化 Golang IDE 开发平台。\n- 可使用此 Golang IDE 开发平台提供与本地 `Microsoft VS Code` 平台相同的功能，并可实现实时登录开发环境与远程代码仓库的一致性。\n- 容器镜像构建与使用：\n  - 该容器镜像可提供的功能：\n    - 👉 基于 `VS Code` 的 `Web UI` 开发界面\n    - 👉 集成 `Golang v1.19.3` 语言开发环境\n  - 使用该目录中的 `Dockerfile` 构建 `Code Server v4.8.3` 容器镜像，如下所示：\n    ```bash\n    $ tree -h .\n      .\n      ├── [103M]  code-server_4.8.3_amd64.deb\n      ├── [1.9K]  Dockerfile\n      ├── [ 17K]  oh-my-zsh-install.sh\n      ├── [1.3K]  README.md\n      └── [ 614]  sources.list\n  \n    $ sudo docker build -t golang-code-server:v1.1 .\n    # 在当前目录上下文中构建\n    $ sudo docker run -d --name=golang-code-server -p 8080:8080 golang-code-server:v1.1\n    # 使用构建的容器镜像运行容器，并登录访问 Web 界面。\n    ```\n\n  > 💥 注意：由于 `code-server_4.8.3_amd64.deb` 软件包的容量大小限制无法上传至 GitHub 中，可从  [百度网盘](https://pan.baidu.com/s/1ul4ZYZa1Cpmp_5fXxyGJtg) 下载，提取码为 `no8o`。\n\n  - 该容器镜像可在 `Kubernetes` 或 `OpenShift` 集群外使用 `Docker` 或 `Podman` 先行测试，再导入容器镜像仓库 `registry`，用于后续的部署使用。\n- 可使用如下所示的 [资源定义文件](https://github.com/Alberthua-Perl/go-kubernetes-learn-path/blob/hotfixes/golang-codeready-workspace-deployment.yml)，将该应用部署于 `Kubernetes` 或 `OpenShift` 集群中：\n  ```yaml\n  apiVersion: v1\n  kind: Service\n  metadata: \n    labels: \n      name: golang-codeready-workspace\n    name: golang-codeready-workspace\n    namespace: codeready-workspace\n  spec: \n    ports:\n      # the port that this service should serve on\n      - port: 8080\n        protocol: TCP\n        targetPort: 8080\n        nodePort: 30001\n    # label keys and values that must match in order to receive traffic for this service\n    selector: \n      app: golang-codeready-workspace\n    type: NodePort\n  ---  \n  apiVersion: apps/v1\n  kind: Deployment\n  metadata:\n    labels:\n      app: golang-codeready-workspace\n    name: golang-codeready-workspace\n    namespace: codeready-workspace\n  spec:\n    replicas: 1\n    selector:\n      matchLabels:\n        app: golang-codeready-workspace\n    template:\n      metadata:\n        creationTimestamp: null\n        labels:\n          app: golang-codeready-workspace\n      spec:\n        containers:\n        - image: quay-registry.lab.example.com/godev/golang-code-server:v1.1\n          # image also pulled from quay.io/alberthua/golang-code-server:v1.1\n          imagePullPolicy: IfNotPresent\n          name: golang-codeready-workspace\n          ports:\n          - containerPort: 8080\n            protocol: TCP\n        restartPolicy: Always\n        schedulerName: default-scheduler\n        securityContext: {}\n        terminationGracePeriodSeconds: 30\n  ```\n\n### 参考链接：\n- [GitHub - coder/code-server](https://github.com/coder/code-server)\n- [code-server v4.8.0 docs](https://coder.com/docs/code-server/latest)\n- [dockerhub - golang](https://hub.docker.com/_/golang)\n- [云 vscode 搭建之使用容器化部署的方法](https://www.jb51.net/article/261704.htm)\n- [docker build 时出现错误 \"debconf: unable to initialize frontend: Dialog\" 如何处理？](https://blog.51cto.com/u_15061952/3607022)","slug":"golang-code-server","published":1,"updated":"2022-12-06T02:18:41.438Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldfonojo000316vdbsql1wkd","content":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li>🔗 可参考 <a href=\"https://github.com/Alberthua-Perl/dockerfile-s2i-demo/tree/master/code-server-4.8.3\" target=\"_blank\" rel=\"noopener\">该链接</a>，以获得项目的 GitHub 仓库。</li>\n<li><code>Red Hat OpenShift</code> 中使用 <code>Red Hat Code Ready Workspace</code> 作为 PaaS 平台中的实时 IDE 开发平台，可兼容众多开发语言。</li>\n<li>该示例的目的在于构建类似于 Red Hat Code Ready Workspace 的容器化 Golang IDE 开发平台。</li>\n<li>可使用此 Golang IDE 开发平台提供与本地 <code>Microsoft VS Code</code> 平台相同的功能，并可实现实时登录开发环境与远程代码仓库的一致性。</li>\n<li><p>容器镜像构建与使用：</p>\n<ul>\n<li>该容器镜像可提供的功能：<ul>\n<li>👉 基于 <code>VS Code</code> 的 <code>Web UI</code> 开发界面</li>\n<li>👉 集成 <code>Golang v1.19.3</code> 语言开发环境</li>\n</ul>\n</li>\n<li>使用该目录中的 <code>Dockerfile</code> 构建 <code>Code Server v4.8.3</code> 容器镜像，如下所示：<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ tree -h .</span><br><span class=\"line\">  .</span><br><span class=\"line\">  ├── [103M]  code-server_4.8.3_amd64.deb</span><br><span class=\"line\">  ├── [1.9K]  Dockerfile</span><br><span class=\"line\">  ├── [ 17K]  oh-my-zsh-install.sh</span><br><span class=\"line\">  ├── [1.3K]  README.md</span><br><span class=\"line\">  └── [ 614]  sources.list</span><br><span class=\"line\">  </span><br><span class=\"line\">$ sudo docker build -t golang-code-server:v1.1 .</span><br><span class=\"line\"><span class=\"comment\"># 在当前目录上下文中构建</span></span><br><span class=\"line\">$ sudo docker run -d --name=golang-code-server -p 8080:8080 golang-code-server:v1.1</span><br><span class=\"line\"><span class=\"comment\"># 使用构建的容器镜像运行容器，并登录访问 Web 界面。</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<blockquote>\n<p>💥 注意：由于 <code>code-server_4.8.3_amd64.deb</code> 软件包的容量大小限制无法上传至 GitHub 中，可从  <a href=\"https://pan.baidu.com/s/1ul4ZYZa1Cpmp_5fXxyGJtg\" target=\"_blank\" rel=\"noopener\">百度网盘</a> 下载，提取码为 <code>no8o</code>。</p>\n</blockquote>\n<ul>\n<li>该容器镜像可在 <code>Kubernetes</code> 或 <code>OpenShift</code> 集群外使用 <code>Docker</code> 或 <code>Podman</code> 先行测试，再导入容器镜像仓库 <code>registry</code>，用于后续的部署使用。</li>\n</ul>\n</li>\n<li>可使用如下所示的 <a href=\"https://github.com/Alberthua-Perl/go-kubernetes-learn-path/blob/hotfixes/golang-codeready-workspace-deployment.yml\" target=\"_blank\" rel=\"noopener\">资源定义文件</a>，将该应用部署于 <code>Kubernetes</code> 或 <code>OpenShift</code> 集群中：<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Service</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span> </span><br><span class=\"line\">  <span class=\"attr\">labels:</span> </span><br><span class=\"line\">    <span class=\"attr\">name:</span> <span class=\"string\">golang-codeready-workspace</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">golang-codeready-workspace</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">codeready-workspace</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span> </span><br><span class=\"line\">  <span class=\"attr\">ports:</span></span><br><span class=\"line\">    <span class=\"comment\"># the port that this service should serve on</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">port:</span> <span class=\"number\">8080</span></span><br><span class=\"line\">      <span class=\"attr\">protocol:</span> <span class=\"string\">TCP</span></span><br><span class=\"line\">      <span class=\"attr\">targetPort:</span> <span class=\"number\">8080</span></span><br><span class=\"line\">      <span class=\"attr\">nodePort:</span> <span class=\"number\">30001</span></span><br><span class=\"line\">  <span class=\"comment\"># label keys and values that must match in order to receive traffic for this service</span></span><br><span class=\"line\">  <span class=\"attr\">selector:</span> </span><br><span class=\"line\">    <span class=\"attr\">app:</span> <span class=\"string\">golang-codeready-workspace</span></span><br><span class=\"line\">  <span class=\"attr\">type:</span> <span class=\"string\">NodePort</span></span><br><span class=\"line\"><span class=\"string\">---</span>  </span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">apps/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Deployment</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">app:</span> <span class=\"string\">golang-codeready-workspace</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">golang-codeready-workspace</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">codeready-workspace</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">replicas:</span> <span class=\"number\">1</span></span><br><span class=\"line\">  <span class=\"attr\">selector:</span></span><br><span class=\"line\">    <span class=\"attr\">matchLabels:</span></span><br><span class=\"line\">      <span class=\"attr\">app:</span> <span class=\"string\">golang-codeready-workspace</span></span><br><span class=\"line\">  <span class=\"attr\">template:</span></span><br><span class=\"line\">    <span class=\"attr\">metadata:</span></span><br><span class=\"line\">      <span class=\"attr\">creationTimestamp:</span> <span class=\"literal\">null</span></span><br><span class=\"line\">      <span class=\"attr\">labels:</span></span><br><span class=\"line\">        <span class=\"attr\">app:</span> <span class=\"string\">golang-codeready-workspace</span></span><br><span class=\"line\">    <span class=\"attr\">spec:</span></span><br><span class=\"line\">      <span class=\"attr\">containers:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"attr\">image:</span> <span class=\"string\">quay-registry.lab.example.com/godev/golang-code-server:v1.1</span></span><br><span class=\"line\">        <span class=\"comment\"># image also pulled from quay.io/alberthua/golang-code-server:v1.1</span></span><br><span class=\"line\">        <span class=\"attr\">imagePullPolicy:</span> <span class=\"string\">IfNotPresent</span></span><br><span class=\"line\">        <span class=\"attr\">name:</span> <span class=\"string\">golang-codeready-workspace</span></span><br><span class=\"line\">        <span class=\"attr\">ports:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">containerPort:</span> <span class=\"number\">8080</span></span><br><span class=\"line\">          <span class=\"attr\">protocol:</span> <span class=\"string\">TCP</span></span><br><span class=\"line\">      <span class=\"attr\">restartPolicy:</span> <span class=\"string\">Always</span></span><br><span class=\"line\">      <span class=\"attr\">schedulerName:</span> <span class=\"string\">default-scheduler</span></span><br><span class=\"line\">      <span class=\"attr\">securityContext:</span> <span class=\"string\">&#123;&#125;</span></span><br><span class=\"line\">      <span class=\"attr\">terminationGracePeriodSeconds:</span> <span class=\"number\">30</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://github.com/coder/code-server\" target=\"_blank\" rel=\"noopener\">GitHub - coder/code-server</a></li>\n<li><a href=\"https://coder.com/docs/code-server/latest\" target=\"_blank\" rel=\"noopener\">code-server v4.8.0 docs</a></li>\n<li><a href=\"https://hub.docker.com/_/golang\" target=\"_blank\" rel=\"noopener\">dockerhub - golang</a></li>\n<li><a href=\"https://www.jb51.net/article/261704.htm\" target=\"_blank\" rel=\"noopener\">云 vscode 搭建之使用容器化部署的方法</a></li>\n<li><a href=\"https://blog.51cto.com/u_15061952/3607022\" target=\"_blank\" rel=\"noopener\">docker build 时出现错误 “debconf: unable to initialize frontend: Dialog” 如何处理？</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li>🔗 可参考 <a href=\"https://github.com/Alberthua-Perl/dockerfile-s2i-demo/tree/master/code-server-4.8.3\" target=\"_blank\" rel=\"noopener\">该链接</a>，以获得项目的 GitHub 仓库。</li>\n<li><code>Red Hat OpenShift</code> 中使用 <code>Red Hat Code Ready Workspace</code> 作为 PaaS 平台中的实时 IDE 开发平台，可兼容众多开发语言。</li>\n<li>该示例的目的在于构建类似于 Red Hat Code Ready Workspace 的容器化 Golang IDE 开发平台。</li>\n<li>可使用此 Golang IDE 开发平台提供与本地 <code>Microsoft VS Code</code> 平台相同的功能，并可实现实时登录开发环境与远程代码仓库的一致性。</li>\n<li><p>容器镜像构建与使用：</p>\n<ul>\n<li>该容器镜像可提供的功能：<ul>\n<li>👉 基于 <code>VS Code</code> 的 <code>Web UI</code> 开发界面</li>\n<li>👉 集成 <code>Golang v1.19.3</code> 语言开发环境</li>\n</ul>\n</li>\n<li>使用该目录中的 <code>Dockerfile</code> 构建 <code>Code Server v4.8.3</code> 容器镜像，如下所示：<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ tree -h .</span><br><span class=\"line\">  .</span><br><span class=\"line\">  ├── [103M]  code-server_4.8.3_amd64.deb</span><br><span class=\"line\">  ├── [1.9K]  Dockerfile</span><br><span class=\"line\">  ├── [ 17K]  oh-my-zsh-install.sh</span><br><span class=\"line\">  ├── [1.3K]  README.md</span><br><span class=\"line\">  └── [ 614]  sources.list</span><br><span class=\"line\">  </span><br><span class=\"line\">$ sudo docker build -t golang-code-server:v1.1 .</span><br><span class=\"line\"><span class=\"comment\"># 在当前目录上下文中构建</span></span><br><span class=\"line\">$ sudo docker run -d --name=golang-code-server -p 8080:8080 golang-code-server:v1.1</span><br><span class=\"line\"><span class=\"comment\"># 使用构建的容器镜像运行容器，并登录访问 Web 界面。</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<blockquote>\n<p>💥 注意：由于 <code>code-server_4.8.3_amd64.deb</code> 软件包的容量大小限制无法上传至 GitHub 中，可从  <a href=\"https://pan.baidu.com/s/1ul4ZYZa1Cpmp_5fXxyGJtg\" target=\"_blank\" rel=\"noopener\">百度网盘</a> 下载，提取码为 <code>no8o</code>。</p>\n</blockquote>\n<ul>\n<li>该容器镜像可在 <code>Kubernetes</code> 或 <code>OpenShift</code> 集群外使用 <code>Docker</code> 或 <code>Podman</code> 先行测试，再导入容器镜像仓库 <code>registry</code>，用于后续的部署使用。</li>\n</ul>\n</li>\n<li>可使用如下所示的 <a href=\"https://github.com/Alberthua-Perl/go-kubernetes-learn-path/blob/hotfixes/golang-codeready-workspace-deployment.yml\" target=\"_blank\" rel=\"noopener\">资源定义文件</a>，将该应用部署于 <code>Kubernetes</code> 或 <code>OpenShift</code> 集群中：<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Service</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span> </span><br><span class=\"line\">  <span class=\"attr\">labels:</span> </span><br><span class=\"line\">    <span class=\"attr\">name:</span> <span class=\"string\">golang-codeready-workspace</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">golang-codeready-workspace</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">codeready-workspace</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span> </span><br><span class=\"line\">  <span class=\"attr\">ports:</span></span><br><span class=\"line\">    <span class=\"comment\"># the port that this service should serve on</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">port:</span> <span class=\"number\">8080</span></span><br><span class=\"line\">      <span class=\"attr\">protocol:</span> <span class=\"string\">TCP</span></span><br><span class=\"line\">      <span class=\"attr\">targetPort:</span> <span class=\"number\">8080</span></span><br><span class=\"line\">      <span class=\"attr\">nodePort:</span> <span class=\"number\">30001</span></span><br><span class=\"line\">  <span class=\"comment\"># label keys and values that must match in order to receive traffic for this service</span></span><br><span class=\"line\">  <span class=\"attr\">selector:</span> </span><br><span class=\"line\">    <span class=\"attr\">app:</span> <span class=\"string\">golang-codeready-workspace</span></span><br><span class=\"line\">  <span class=\"attr\">type:</span> <span class=\"string\">NodePort</span></span><br><span class=\"line\"><span class=\"string\">---</span>  </span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">apps/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Deployment</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">app:</span> <span class=\"string\">golang-codeready-workspace</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">golang-codeready-workspace</span></span><br><span class=\"line\">  <span class=\"attr\">namespace:</span> <span class=\"string\">codeready-workspace</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">replicas:</span> <span class=\"number\">1</span></span><br><span class=\"line\">  <span class=\"attr\">selector:</span></span><br><span class=\"line\">    <span class=\"attr\">matchLabels:</span></span><br><span class=\"line\">      <span class=\"attr\">app:</span> <span class=\"string\">golang-codeready-workspace</span></span><br><span class=\"line\">  <span class=\"attr\">template:</span></span><br><span class=\"line\">    <span class=\"attr\">metadata:</span></span><br><span class=\"line\">      <span class=\"attr\">creationTimestamp:</span> <span class=\"literal\">null</span></span><br><span class=\"line\">      <span class=\"attr\">labels:</span></span><br><span class=\"line\">        <span class=\"attr\">app:</span> <span class=\"string\">golang-codeready-workspace</span></span><br><span class=\"line\">    <span class=\"attr\">spec:</span></span><br><span class=\"line\">      <span class=\"attr\">containers:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"attr\">image:</span> <span class=\"string\">quay-registry.lab.example.com/godev/golang-code-server:v1.1</span></span><br><span class=\"line\">        <span class=\"comment\"># image also pulled from quay.io/alberthua/golang-code-server:v1.1</span></span><br><span class=\"line\">        <span class=\"attr\">imagePullPolicy:</span> <span class=\"string\">IfNotPresent</span></span><br><span class=\"line\">        <span class=\"attr\">name:</span> <span class=\"string\">golang-codeready-workspace</span></span><br><span class=\"line\">        <span class=\"attr\">ports:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"attr\">containerPort:</span> <span class=\"number\">8080</span></span><br><span class=\"line\">          <span class=\"attr\">protocol:</span> <span class=\"string\">TCP</span></span><br><span class=\"line\">      <span class=\"attr\">restartPolicy:</span> <span class=\"string\">Always</span></span><br><span class=\"line\">      <span class=\"attr\">schedulerName:</span> <span class=\"string\">default-scheduler</span></span><br><span class=\"line\">      <span class=\"attr\">securityContext:</span> <span class=\"string\">&#123;&#125;</span></span><br><span class=\"line\">      <span class=\"attr\">terminationGracePeriodSeconds:</span> <span class=\"number\">30</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://github.com/coder/code-server\" target=\"_blank\" rel=\"noopener\">GitHub - coder/code-server</a></li>\n<li><a href=\"https://coder.com/docs/code-server/latest\" target=\"_blank\" rel=\"noopener\">code-server v4.8.0 docs</a></li>\n<li><a href=\"https://hub.docker.com/_/golang\" target=\"_blank\" rel=\"noopener\">dockerhub - golang</a></li>\n<li><a href=\"https://www.jb51.net/article/261704.htm\" target=\"_blank\" rel=\"noopener\">云 vscode 搭建之使用容器化部署的方法</a></li>\n<li><a href=\"https://blog.51cto.com/u_15061952/3607022\" target=\"_blank\" rel=\"noopener\">docker build 时出现错误 “debconf: unable to initialize frontend: Dialog” 如何处理？</a></li>\n</ul>\n"},{"title":"Go 语言开发环境部署","subtitle":"Deploy Golang Developement Environment on Linux and Windows","header-img":"golang-develop-bg.svg","date":"2022-11-26T05:41:05.000Z","_content":"\n### 文档说明：\n- OS 版本：CentOS Linux release 7.4.1708 (Core)\n- Golang 版本：go1.12 linux/amd64\n\n### 文档目录：\n- Windows 安装 Go 语言环境\n- Windows 下 Sublime Text 3 安装配色方案与 Golang 开发环境插件\n- Linux 安装 Go 语言环境\n- vim-go 插件配置 Go 语言开发环境\n\n### Windows 安装 Go 语言环境：\n- 可直接使用 `.msi` 安装包根据提示安装，go 环境变量可参考 Linux 中 go 环境变量设置。\n\n### Windows 下 Sublime Text 3 安装配色方案与 Go 开发环境插件：\n- 安装配色方案（以 **`Panda`** 配色方案为例）：  \n  - 常用配色方案：Dracula、Panda。  \n  - 打开 Sublime Text 3，按 **`Ctrl+Shift+P`** 打开控制窗口。  \n  - 输入 `install`，选择第一个 Install Package 以安装相关配色方案。    \n    ![sublime-text-golang-1](sublime-text-golang-1.png)  \n  - 输入相关配色方案名称，并选择安装，其安装过程显示在窗口最底端。    \n    ![sublime-text-golang-2](sublime-text-golang-2.png)  \n  - 配色方案安装完毕后，可在如下路径选择使用：    \n    Preferences > Color Scheme... > **`panda-syntax`**    \n    ![sublime-text-golang-3](sublime-text-golang-3.png)\n- 安装 Golang 开发环境插件：  \n  - 按 **`Ctrl+Shift+P`** 打开控制窗口。  \n  - 输入 golang 后将加载显示 **`Golang Build`** 官方插件，点击安装该插件。  \n  - 完成安装后配置该插件：    \n    Preferences > Package Settings > Golang Config > **`Settings-User`**  \n  - 为 Golang Build 插件定义 Golang 语言环境变量：    \n    ![sublime-text-golang-4](sublime-text-golang-4.png)  \n  - 配置自动编译运行 Golang：    \n    - 创建自动编译运行 Golang 的配置文件：    \n    - Tools > Build System > **`New Build System...`**    \n    - 定义编译运行 Golang 的命令与参数，并将其命名为 **`GoBuild.sublime-build`** 保存。    \n    - 该定义文件名称可自定义。      \n      ![sublime-text-golang-5](sublime-text-golang-5.png)![sublime-text-golang-6](sublime-text-golang-6.png)  \n  - 打开测试用 go 文件，使用 **`Ctrl+B`** 编译运行查看结果。    \n    ![sublime-text-golang-7.png](sublime-text-golang-7.png)![sublime-text-golang-8.png](sublime-text-golang-8.png)\n\n### Linux 安装 Go 语言环境：\n- 下载 Golang 语言环境压缩包：go1.12.linux-amd64.tar.gz\n- Golang 语言环境安装：  \n  ```bash\n  $ sudo tar -zxvf go1.12.linux-amd64.tar.gz -C /usr/local\n  # 解压并解包 go 语言环境\n  $ mkdir -p $HOME/go/{bin,pkg,src}\n  # 创建 go 语言工作目录树\n  $ vim $HOME/.bashrc\n    ### Define Go programme environment ###\n    export GOROOT=/usr/local/go  \n    # root directory to install go\n    export GOPATH=$HOME/go       \n    # directory to store go project \n    export GOBIN=$GOPATH/bin     \n    # store go command builded \n    export PATH=$PATH:$GOROOT/bin:$GOBIN\n  \n  $ source $HOME/.bashrc\n  # 加载 go 语言环境变量\n  $ go version\n    go version go1.12 linux/amd64\n  # 查看 go 语言环境版本\n  ```\n\n### vim-go 插件配置 Go 语言开发环境：\n- 由于 CentOS 7.4 自带的 vim 版本为 `vim-enhanced-7.4.160-2.el7.x86_64`，该版本不支持 golang 语言的语法高亮特性，因此需要额外安装 **`vim-go`** 插件用以支持该特性，而 CentOS 8.x 或 RHEL 8.x 中自带 `vim 8` 可支持。\n- 配置方法如下所示：\n  - 👉 Vim 插件管理器使用：\n  ```bash\n  $ git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim\n  # 下载安装 vim 插件管理器\n  $ cd ~/.vim/bundle/Vundle.vim/ && vim README.md\n    set nocompatible              # be iMproved, required\n    filetype off                  # required\n  \n    # set the runtime path to include Vundle and initialize\n    set rtp+=~/.vim/bundle/Vundle.vim\n    call vundle#begin()\n    # alternatively, pass a path where Vundle should install plugins\n    #call vundle#begin('~/some/path/here')\n  \n    # let Vundle manage Vundle, required\n    Plugin 'VundleVim/Vundle.vim'\n  \n    # The following are examples of different formats supported.\n    # Keep Plugin commands between vundle#begin/end.\n    # plugin on GitHub repo\n    Plugin 'tpope/vim-fugitive'\n    # plugin from http://vim-scripts.org/vim/scripts.html\n    # Plugin 'L9'\n    # Git plugin not hosted on GitHub\n    Plugin 'git://git.wincent.com/command-t.git'\n    # git repos on your local machine (i.e. when working on your own plugin)\n    Plugin 'file:///home/gmarik/path/to/plugin'\n    # The sparkup vim script is in a subdirectory of this repo called vim.\n    # Pass the path to set the runtimepath properly.\n    Plugin 'rstacruz/sparkup', {'rtp': 'vim/'}\n    # Install L9 and avoid a Naming conflict if you've already installed a\n    # different version somewhere else.\n    # Plugin 'ascenator/L9', {'name': 'newL9'}\n  \n    # All of your Plugins must be added before the following line\n    call vundle#end()            \" required\n    filetype plugin indent on    \" required\n    # To ignore plugin indent changes, instead use:\n    #filetype plugin on\n    #\n    # Brief help\n    # :PluginList       - lists configured plugins\n    # :PluginInstall    - installs plugins; append `!` to update or just :PluginUpdate\n    # :PluginSearch foo - searches for foo; append `!` to refresh local cache\n    # :PluginClean      - confirms removal of unused plugins; append `!` to auto-approve removal\n    #\n    # see :h vundle for more details or wiki for FAQ\n    # Put your non-Plugin stuff after this line   \n  # 进入 vim 插件管理器目录，并选择 \"3. Configure Plugins\" 中的相应插件内容，将其复制至 ~/.vimrc 文件的顶部。\n  # 可根据需要添加或删除指定的插件。\n  \n  $ git clone https://github.com/fatih/vim-go.git ~/.vim/bundle/vim-go\n  # 下载安装 vim-go 插件使 vim 支持 Go 语言开发，包括语法高亮、语法错误检查等。\n  # 注意该插件的下载路径！\n  ```\n  - 👉 启用 `vim-go` 插件：\n  ```bash\n  $ vim ~/.vimrc\n    # Configure Go Programming Language vim Environment\n    # set nocompatible              \" be iMproved, required\n    filetype off                    # required\n  \n    set rtp+=~/.vim/bundle/Vundle.vim\n    call vundle#begin()\n  \n    # Install vim-go\n    Plugin 'fatih/vim-go'\n    # Install Dracula color theme\n    Plugin 'dracula/vim', {'name': 'dracula'}\n  \n    call vundle#end()            \" required\n    filetype plugin indent on    \" required\n  \n    # Extented Command\n    let g:go_version_warning = 0\n    # 由于 vim 版本过低在启动时将报错，该指令可去除报错。\n    set nu\n    set tabstop=2\n    # set cursorline\n    # set cursorcolumn\n    # colorscheme dracula\n    colorscheme elflord\n  \n    # Auto YAML syntax\n    autocmd FileType yaml setlocal ai ts=2 sw=2 et\n  \n  $ vim +PluginInstall +qall\n  # 安装所有的 vim 插件\n  $ vim <go_filename>.go\n  # 编辑 go 文件验证 vim-go 插件安装\n  ```\n\n- 若不添加 **`let g:go_version_warning = 0`**，报错如下，可直接回车继续使用 vim。\n  ![vim-error](vim-error.jpg)\n","source":"_posts/golang-environment-deploy.md","raw":"---\ntitle: Go 语言开发环境部署\nsubtitle: Deploy Golang Developement Environment on Linux and Windows\nheader-img: golang-develop-bg.svg\ndate: 2022-11-26 13:41:05\ntags:\n  - Golang\n  - 云原生\n---\n\n### 文档说明：\n- OS 版本：CentOS Linux release 7.4.1708 (Core)\n- Golang 版本：go1.12 linux/amd64\n\n### 文档目录：\n- Windows 安装 Go 语言环境\n- Windows 下 Sublime Text 3 安装配色方案与 Golang 开发环境插件\n- Linux 安装 Go 语言环境\n- vim-go 插件配置 Go 语言开发环境\n\n### Windows 安装 Go 语言环境：\n- 可直接使用 `.msi` 安装包根据提示安装，go 环境变量可参考 Linux 中 go 环境变量设置。\n\n### Windows 下 Sublime Text 3 安装配色方案与 Go 开发环境插件：\n- 安装配色方案（以 **`Panda`** 配色方案为例）：  \n  - 常用配色方案：Dracula、Panda。  \n  - 打开 Sublime Text 3，按 **`Ctrl+Shift+P`** 打开控制窗口。  \n  - 输入 `install`，选择第一个 Install Package 以安装相关配色方案。    \n    ![sublime-text-golang-1](sublime-text-golang-1.png)  \n  - 输入相关配色方案名称，并选择安装，其安装过程显示在窗口最底端。    \n    ![sublime-text-golang-2](sublime-text-golang-2.png)  \n  - 配色方案安装完毕后，可在如下路径选择使用：    \n    Preferences > Color Scheme... > **`panda-syntax`**    \n    ![sublime-text-golang-3](sublime-text-golang-3.png)\n- 安装 Golang 开发环境插件：  \n  - 按 **`Ctrl+Shift+P`** 打开控制窗口。  \n  - 输入 golang 后将加载显示 **`Golang Build`** 官方插件，点击安装该插件。  \n  - 完成安装后配置该插件：    \n    Preferences > Package Settings > Golang Config > **`Settings-User`**  \n  - 为 Golang Build 插件定义 Golang 语言环境变量：    \n    ![sublime-text-golang-4](sublime-text-golang-4.png)  \n  - 配置自动编译运行 Golang：    \n    - 创建自动编译运行 Golang 的配置文件：    \n    - Tools > Build System > **`New Build System...`**    \n    - 定义编译运行 Golang 的命令与参数，并将其命名为 **`GoBuild.sublime-build`** 保存。    \n    - 该定义文件名称可自定义。      \n      ![sublime-text-golang-5](sublime-text-golang-5.png)![sublime-text-golang-6](sublime-text-golang-6.png)  \n  - 打开测试用 go 文件，使用 **`Ctrl+B`** 编译运行查看结果。    \n    ![sublime-text-golang-7.png](sublime-text-golang-7.png)![sublime-text-golang-8.png](sublime-text-golang-8.png)\n\n### Linux 安装 Go 语言环境：\n- 下载 Golang 语言环境压缩包：go1.12.linux-amd64.tar.gz\n- Golang 语言环境安装：  \n  ```bash\n  $ sudo tar -zxvf go1.12.linux-amd64.tar.gz -C /usr/local\n  # 解压并解包 go 语言环境\n  $ mkdir -p $HOME/go/{bin,pkg,src}\n  # 创建 go 语言工作目录树\n  $ vim $HOME/.bashrc\n    ### Define Go programme environment ###\n    export GOROOT=/usr/local/go  \n    # root directory to install go\n    export GOPATH=$HOME/go       \n    # directory to store go project \n    export GOBIN=$GOPATH/bin     \n    # store go command builded \n    export PATH=$PATH:$GOROOT/bin:$GOBIN\n  \n  $ source $HOME/.bashrc\n  # 加载 go 语言环境变量\n  $ go version\n    go version go1.12 linux/amd64\n  # 查看 go 语言环境版本\n  ```\n\n### vim-go 插件配置 Go 语言开发环境：\n- 由于 CentOS 7.4 自带的 vim 版本为 `vim-enhanced-7.4.160-2.el7.x86_64`，该版本不支持 golang 语言的语法高亮特性，因此需要额外安装 **`vim-go`** 插件用以支持该特性，而 CentOS 8.x 或 RHEL 8.x 中自带 `vim 8` 可支持。\n- 配置方法如下所示：\n  - 👉 Vim 插件管理器使用：\n  ```bash\n  $ git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim\n  # 下载安装 vim 插件管理器\n  $ cd ~/.vim/bundle/Vundle.vim/ && vim README.md\n    set nocompatible              # be iMproved, required\n    filetype off                  # required\n  \n    # set the runtime path to include Vundle and initialize\n    set rtp+=~/.vim/bundle/Vundle.vim\n    call vundle#begin()\n    # alternatively, pass a path where Vundle should install plugins\n    #call vundle#begin('~/some/path/here')\n  \n    # let Vundle manage Vundle, required\n    Plugin 'VundleVim/Vundle.vim'\n  \n    # The following are examples of different formats supported.\n    # Keep Plugin commands between vundle#begin/end.\n    # plugin on GitHub repo\n    Plugin 'tpope/vim-fugitive'\n    # plugin from http://vim-scripts.org/vim/scripts.html\n    # Plugin 'L9'\n    # Git plugin not hosted on GitHub\n    Plugin 'git://git.wincent.com/command-t.git'\n    # git repos on your local machine (i.e. when working on your own plugin)\n    Plugin 'file:///home/gmarik/path/to/plugin'\n    # The sparkup vim script is in a subdirectory of this repo called vim.\n    # Pass the path to set the runtimepath properly.\n    Plugin 'rstacruz/sparkup', {'rtp': 'vim/'}\n    # Install L9 and avoid a Naming conflict if you've already installed a\n    # different version somewhere else.\n    # Plugin 'ascenator/L9', {'name': 'newL9'}\n  \n    # All of your Plugins must be added before the following line\n    call vundle#end()            \" required\n    filetype plugin indent on    \" required\n    # To ignore plugin indent changes, instead use:\n    #filetype plugin on\n    #\n    # Brief help\n    # :PluginList       - lists configured plugins\n    # :PluginInstall    - installs plugins; append `!` to update or just :PluginUpdate\n    # :PluginSearch foo - searches for foo; append `!` to refresh local cache\n    # :PluginClean      - confirms removal of unused plugins; append `!` to auto-approve removal\n    #\n    # see :h vundle for more details or wiki for FAQ\n    # Put your non-Plugin stuff after this line   \n  # 进入 vim 插件管理器目录，并选择 \"3. Configure Plugins\" 中的相应插件内容，将其复制至 ~/.vimrc 文件的顶部。\n  # 可根据需要添加或删除指定的插件。\n  \n  $ git clone https://github.com/fatih/vim-go.git ~/.vim/bundle/vim-go\n  # 下载安装 vim-go 插件使 vim 支持 Go 语言开发，包括语法高亮、语法错误检查等。\n  # 注意该插件的下载路径！\n  ```\n  - 👉 启用 `vim-go` 插件：\n  ```bash\n  $ vim ~/.vimrc\n    # Configure Go Programming Language vim Environment\n    # set nocompatible              \" be iMproved, required\n    filetype off                    # required\n  \n    set rtp+=~/.vim/bundle/Vundle.vim\n    call vundle#begin()\n  \n    # Install vim-go\n    Plugin 'fatih/vim-go'\n    # Install Dracula color theme\n    Plugin 'dracula/vim', {'name': 'dracula'}\n  \n    call vundle#end()            \" required\n    filetype plugin indent on    \" required\n  \n    # Extented Command\n    let g:go_version_warning = 0\n    # 由于 vim 版本过低在启动时将报错，该指令可去除报错。\n    set nu\n    set tabstop=2\n    # set cursorline\n    # set cursorcolumn\n    # colorscheme dracula\n    colorscheme elflord\n  \n    # Auto YAML syntax\n    autocmd FileType yaml setlocal ai ts=2 sw=2 et\n  \n  $ vim +PluginInstall +qall\n  # 安装所有的 vim 插件\n  $ vim <go_filename>.go\n  # 编辑 go 文件验证 vim-go 插件安装\n  ```\n\n- 若不添加 **`let g:go_version_warning = 0`**，报错如下，可直接回车继续使用 vim。\n  ![vim-error](vim-error.jpg)\n","slug":"golang-environment-deploy","published":1,"updated":"2022-11-28T10:33:00.973Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldfonokg000616vdxjsn08as","content":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li>OS 版本：CentOS Linux release 7.4.1708 (Core)</li>\n<li>Golang 版本：go1.12 linux/amd64</li>\n</ul>\n<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>Windows 安装 Go 语言环境</li>\n<li>Windows 下 Sublime Text 3 安装配色方案与 Golang 开发环境插件</li>\n<li>Linux 安装 Go 语言环境</li>\n<li>vim-go 插件配置 Go 语言开发环境</li>\n</ul>\n<h3 id=\"Windows-安装-Go-语言环境：\"><a href=\"#Windows-安装-Go-语言环境：\" class=\"headerlink\" title=\"Windows 安装 Go 语言环境：\"></a>Windows 安装 Go 语言环境：</h3><ul>\n<li>可直接使用 <code>.msi</code> 安装包根据提示安装，go 环境变量可参考 Linux 中 go 环境变量设置。</li>\n</ul>\n<h3 id=\"Windows-下-Sublime-Text-3-安装配色方案与-Go-开发环境插件：\"><a href=\"#Windows-下-Sublime-Text-3-安装配色方案与-Go-开发环境插件：\" class=\"headerlink\" title=\"Windows 下 Sublime Text 3 安装配色方案与 Go 开发环境插件：\"></a>Windows 下 Sublime Text 3 安装配色方案与 Go 开发环境插件：</h3><ul>\n<li>安装配色方案（以 <strong><code>Panda</code></strong> 配色方案为例）：  <ul>\n<li>常用配色方案：Dracula、Panda。  </li>\n<li>打开 Sublime Text 3，按 <strong><code>Ctrl+Shift+P</code></strong> 打开控制窗口。  </li>\n<li>输入 <code>install</code>，选择第一个 Install Package 以安装相关配色方案。<br><img src=\"sublime-text-golang-1.png\" alt=\"sublime-text-golang-1\">  </li>\n<li>输入相关配色方案名称，并选择安装，其安装过程显示在窗口最底端。<br><img src=\"sublime-text-golang-2.png\" alt=\"sublime-text-golang-2\">  </li>\n<li>配色方案安装完毕后，可在如下路径选择使用：<br>Preferences &gt; Color Scheme… &gt; <strong><code>panda-syntax</code></strong><br><img src=\"sublime-text-golang-3.png\" alt=\"sublime-text-golang-3\"></li>\n</ul>\n</li>\n<li>安装 Golang 开发环境插件：  <ul>\n<li>按 <strong><code>Ctrl+Shift+P</code></strong> 打开控制窗口。  </li>\n<li>输入 golang 后将加载显示 <strong><code>Golang Build</code></strong> 官方插件，点击安装该插件。  </li>\n<li>完成安装后配置该插件：<br>Preferences &gt; Package Settings &gt; Golang Config &gt; <strong><code>Settings-User</code></strong>  </li>\n<li>为 Golang Build 插件定义 Golang 语言环境变量：<br><img src=\"sublime-text-golang-4.png\" alt=\"sublime-text-golang-4\">  </li>\n<li>配置自动编译运行 Golang：    <ul>\n<li>创建自动编译运行 Golang 的配置文件：    </li>\n<li>Tools &gt; Build System &gt; <strong><code>New Build System...</code></strong>    </li>\n<li>定义编译运行 Golang 的命令与参数，并将其命名为 <strong><code>GoBuild.sublime-build</code></strong> 保存。    </li>\n<li>该定义文件名称可自定义。<br><img src=\"sublime-text-golang-5.png\" alt=\"sublime-text-golang-5\"><img src=\"sublime-text-golang-6.png\" alt=\"sublime-text-golang-6\">  </li>\n</ul>\n</li>\n<li>打开测试用 go 文件，使用 <strong><code>Ctrl+B</code></strong> 编译运行查看结果。<br><img src=\"sublime-text-golang-7.png\" alt=\"sublime-text-golang-7.png\"><img src=\"sublime-text-golang-8.png\" alt=\"sublime-text-golang-8.png\"></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Linux-安装-Go-语言环境：\"><a href=\"#Linux-安装-Go-语言环境：\" class=\"headerlink\" title=\"Linux 安装 Go 语言环境：\"></a>Linux 安装 Go 语言环境：</h3><ul>\n<li>下载 Golang 语言环境压缩包：go1.12.linux-amd64.tar.gz</li>\n<li>Golang 语言环境安装：  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo tar -zxvf go1.12.linux-amd64.tar.gz -C /usr/<span class=\"built_in\">local</span></span><br><span class=\"line\"><span class=\"comment\"># 解压并解包 go 语言环境</span></span><br><span class=\"line\">$ mkdir -p <span class=\"variable\">$HOME</span>/go/&#123;bin,pkg,src&#125;</span><br><span class=\"line\"><span class=\"comment\"># 创建 go 语言工作目录树</span></span><br><span class=\"line\">$ vim <span class=\"variable\">$HOME</span>/.bashrc</span><br><span class=\"line\">  <span class=\"comment\">### Define Go programme environment ###</span></span><br><span class=\"line\">  <span class=\"built_in\">export</span> GOROOT=/usr/<span class=\"built_in\">local</span>/go  </span><br><span class=\"line\">  <span class=\"comment\"># root directory to install go</span></span><br><span class=\"line\">  <span class=\"built_in\">export</span> GOPATH=<span class=\"variable\">$HOME</span>/go       </span><br><span class=\"line\">  <span class=\"comment\"># directory to store go project </span></span><br><span class=\"line\">  <span class=\"built_in\">export</span> GOBIN=<span class=\"variable\">$GOPATH</span>/bin     </span><br><span class=\"line\">  <span class=\"comment\"># store go command builded </span></span><br><span class=\"line\">  <span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$GOROOT</span>/bin:<span class=\"variable\">$GOBIN</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ <span class=\"built_in\">source</span> <span class=\"variable\">$HOME</span>/.bashrc</span><br><span class=\"line\"><span class=\"comment\"># 加载 go 语言环境变量</span></span><br><span class=\"line\">$ go version</span><br><span class=\"line\">  go version go1.12 linux/amd64</span><br><span class=\"line\"><span class=\"comment\"># 查看 go 语言环境版本</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"vim-go-插件配置-Go-语言开发环境：\"><a href=\"#vim-go-插件配置-Go-语言开发环境：\" class=\"headerlink\" title=\"vim-go 插件配置 Go 语言开发环境：\"></a>vim-go 插件配置 Go 语言开发环境：</h3><ul>\n<li>由于 CentOS 7.4 自带的 vim 版本为 <code>vim-enhanced-7.4.160-2.el7.x86_64</code>，该版本不支持 golang 语言的语法高亮特性，因此需要额外安装 <strong><code>vim-go</code></strong> 插件用以支持该特性，而 CentOS 8.x 或 RHEL 8.x 中自带 <code>vim 8</code> 可支持。</li>\n<li><p>配置方法如下所示：</p>\n<ul>\n<li><p>👉 Vim 插件管理器使用：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git <span class=\"built_in\">clone</span> https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim</span><br><span class=\"line\"><span class=\"comment\"># 下载安装 vim 插件管理器</span></span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> ~/.vim/bundle/Vundle.vim/ &amp;&amp; vim README.md</span><br><span class=\"line\">  <span class=\"built_in\">set</span> nocompatible              <span class=\"comment\"># be iMproved, required</span></span><br><span class=\"line\">  filetype off                  <span class=\"comment\"># required</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\"># set the runtime path to include Vundle and initialize</span></span><br><span class=\"line\">  <span class=\"built_in\">set</span> rtp+=~/.vim/bundle/Vundle.vim</span><br><span class=\"line\">  call vundle<span class=\"comment\">#begin()</span></span><br><span class=\"line\">  <span class=\"comment\"># alternatively, pass a path where Vundle should install plugins</span></span><br><span class=\"line\">  <span class=\"comment\">#call vundle#begin('~/some/path/here')</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\"># let Vundle manage Vundle, required</span></span><br><span class=\"line\">  Plugin <span class=\"string\">'VundleVim/Vundle.vim'</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\"># The following are examples of different formats supported.</span></span><br><span class=\"line\">  <span class=\"comment\"># Keep Plugin commands between vundle#begin/end.</span></span><br><span class=\"line\">  <span class=\"comment\"># plugin on GitHub repo</span></span><br><span class=\"line\">  Plugin <span class=\"string\">'tpope/vim-fugitive'</span></span><br><span class=\"line\">  <span class=\"comment\"># plugin from http://vim-scripts.org/vim/scripts.html</span></span><br><span class=\"line\">  <span class=\"comment\"># Plugin 'L9'</span></span><br><span class=\"line\">  <span class=\"comment\"># Git plugin not hosted on GitHub</span></span><br><span class=\"line\">  Plugin <span class=\"string\">'git://git.wincent.com/command-t.git'</span></span><br><span class=\"line\">  <span class=\"comment\"># git repos on your local machine (i.e. when working on your own plugin)</span></span><br><span class=\"line\">  Plugin <span class=\"string\">'file:///home/gmarik/path/to/plugin'</span></span><br><span class=\"line\">  <span class=\"comment\"># The sparkup vim script is in a subdirectory of this repo called vim.</span></span><br><span class=\"line\">  <span class=\"comment\"># Pass the path to set the runtimepath properly.</span></span><br><span class=\"line\">  Plugin <span class=\"string\">'rstacruz/sparkup'</span>, &#123;<span class=\"string\">'rtp'</span>: <span class=\"string\">'vim/'</span>&#125;</span><br><span class=\"line\">  <span class=\"comment\"># Install L9 and avoid a Naming conflict if you've already installed a</span></span><br><span class=\"line\">  <span class=\"comment\"># different version somewhere else.</span></span><br><span class=\"line\">  <span class=\"comment\"># Plugin 'ascenator/L9', &#123;'name': 'newL9'&#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\"># All of your Plugins must be added before the following line</span></span><br><span class=\"line\">  call vundle<span class=\"comment\">#end()            \" required</span></span><br><span class=\"line\">  filetype plugin indent on    <span class=\"string\">\" required</span></span><br><span class=\"line\"><span class=\"string\">  # To ignore plugin indent changes, instead use:</span></span><br><span class=\"line\"><span class=\"string\">  #filetype plugin on</span></span><br><span class=\"line\"><span class=\"string\">  #</span></span><br><span class=\"line\"><span class=\"string\">  # Brief help</span></span><br><span class=\"line\"><span class=\"string\">  # :PluginList       - lists configured plugins</span></span><br><span class=\"line\"><span class=\"string\">  # :PluginInstall    - installs plugins; append `!` to update or just :PluginUpdate</span></span><br><span class=\"line\"><span class=\"string\">  # :PluginSearch foo - searches for foo; append `!` to refresh local cache</span></span><br><span class=\"line\"><span class=\"string\">  # :PluginClean      - confirms removal of unused plugins; append `!` to auto-approve removal</span></span><br><span class=\"line\"><span class=\"string\">  #</span></span><br><span class=\"line\"><span class=\"string\">  # see :h vundle for more details or wiki for FAQ</span></span><br><span class=\"line\"><span class=\"string\">  # Put your non-Plugin stuff after this line   </span></span><br><span class=\"line\"><span class=\"string\"># 进入 vim 插件管理器目录，并选择 \"</span>3. Configure Plugins<span class=\"string\">\" 中的相应插件内容，将其复制至 ~/.vimrc 文件的顶部。</span></span><br><span class=\"line\"><span class=\"string\"># 可根据需要添加或删除指定的插件。</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">$ git clone https://github.com/fatih/vim-go.git ~/.vim/bundle/vim-go</span></span><br><span class=\"line\"><span class=\"string\"># 下载安装 vim-go 插件使 vim 支持 Go 语言开发，包括语法高亮、语法错误检查等。</span></span><br><span class=\"line\"><span class=\"string\"># 注意该插件的下载路径！</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>👉 启用 <code>vim-go</code> 插件：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ vim ~/.vimrc</span><br><span class=\"line\">  <span class=\"comment\"># Configure Go Programming Language vim Environment</span></span><br><span class=\"line\">  <span class=\"comment\"># set nocompatible              \" be iMproved, required</span></span><br><span class=\"line\">  filetype off                    <span class=\"comment\"># required</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"built_in\">set</span> rtp+=~/.vim/bundle/Vundle.vim</span><br><span class=\"line\">  call vundle<span class=\"comment\">#begin()</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\"># Install vim-go</span></span><br><span class=\"line\">  Plugin <span class=\"string\">'fatih/vim-go'</span></span><br><span class=\"line\">  <span class=\"comment\"># Install Dracula color theme</span></span><br><span class=\"line\">  Plugin <span class=\"string\">'dracula/vim'</span>, &#123;<span class=\"string\">'name'</span>: <span class=\"string\">'dracula'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  call vundle<span class=\"comment\">#end()            \" required</span></span><br><span class=\"line\">  filetype plugin indent on    <span class=\"string\">\" required</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">  # Extented Command</span></span><br><span class=\"line\"><span class=\"string\">  let g:go_version_warning = 0</span></span><br><span class=\"line\"><span class=\"string\">  # 由于 vim 版本过低在启动时将报错，该指令可去除报错。</span></span><br><span class=\"line\"><span class=\"string\">  set nu</span></span><br><span class=\"line\"><span class=\"string\">  set tabstop=2</span></span><br><span class=\"line\"><span class=\"string\">  # set cursorline</span></span><br><span class=\"line\"><span class=\"string\">  # set cursorcolumn</span></span><br><span class=\"line\"><span class=\"string\">  # colorscheme dracula</span></span><br><span class=\"line\"><span class=\"string\">  colorscheme elflord</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">  # Auto YAML syntax</span></span><br><span class=\"line\"><span class=\"string\">  autocmd FileType yaml setlocal ai ts=2 sw=2 et</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">$ vim +PluginInstall +qall</span></span><br><span class=\"line\"><span class=\"string\"># 安装所有的 vim 插件</span></span><br><span class=\"line\"><span class=\"string\">$ vim &lt;go_filename&gt;.go</span></span><br><span class=\"line\"><span class=\"string\"># 编辑 go 文件验证 vim-go 插件安装</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>若不添加 <strong><code>let g:go_version_warning = 0</code></strong>，报错如下，可直接回车继续使用 vim。<br><img src=\"vim-error.jpg\" alt=\"vim-error\"></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li>OS 版本：CentOS Linux release 7.4.1708 (Core)</li>\n<li>Golang 版本：go1.12 linux/amd64</li>\n</ul>\n<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>Windows 安装 Go 语言环境</li>\n<li>Windows 下 Sublime Text 3 安装配色方案与 Golang 开发环境插件</li>\n<li>Linux 安装 Go 语言环境</li>\n<li>vim-go 插件配置 Go 语言开发环境</li>\n</ul>\n<h3 id=\"Windows-安装-Go-语言环境：\"><a href=\"#Windows-安装-Go-语言环境：\" class=\"headerlink\" title=\"Windows 安装 Go 语言环境：\"></a>Windows 安装 Go 语言环境：</h3><ul>\n<li>可直接使用 <code>.msi</code> 安装包根据提示安装，go 环境变量可参考 Linux 中 go 环境变量设置。</li>\n</ul>\n<h3 id=\"Windows-下-Sublime-Text-3-安装配色方案与-Go-开发环境插件：\"><a href=\"#Windows-下-Sublime-Text-3-安装配色方案与-Go-开发环境插件：\" class=\"headerlink\" title=\"Windows 下 Sublime Text 3 安装配色方案与 Go 开发环境插件：\"></a>Windows 下 Sublime Text 3 安装配色方案与 Go 开发环境插件：</h3><ul>\n<li>安装配色方案（以 <strong><code>Panda</code></strong> 配色方案为例）：  <ul>\n<li>常用配色方案：Dracula、Panda。  </li>\n<li>打开 Sublime Text 3，按 <strong><code>Ctrl+Shift+P</code></strong> 打开控制窗口。  </li>\n<li>输入 <code>install</code>，选择第一个 Install Package 以安装相关配色方案。<br><img src=\"sublime-text-golang-1.png\" alt=\"sublime-text-golang-1\">  </li>\n<li>输入相关配色方案名称，并选择安装，其安装过程显示在窗口最底端。<br><img src=\"sublime-text-golang-2.png\" alt=\"sublime-text-golang-2\">  </li>\n<li>配色方案安装完毕后，可在如下路径选择使用：<br>Preferences &gt; Color Scheme… &gt; <strong><code>panda-syntax</code></strong><br><img src=\"sublime-text-golang-3.png\" alt=\"sublime-text-golang-3\"></li>\n</ul>\n</li>\n<li>安装 Golang 开发环境插件：  <ul>\n<li>按 <strong><code>Ctrl+Shift+P</code></strong> 打开控制窗口。  </li>\n<li>输入 golang 后将加载显示 <strong><code>Golang Build</code></strong> 官方插件，点击安装该插件。  </li>\n<li>完成安装后配置该插件：<br>Preferences &gt; Package Settings &gt; Golang Config &gt; <strong><code>Settings-User</code></strong>  </li>\n<li>为 Golang Build 插件定义 Golang 语言环境变量：<br><img src=\"sublime-text-golang-4.png\" alt=\"sublime-text-golang-4\">  </li>\n<li>配置自动编译运行 Golang：    <ul>\n<li>创建自动编译运行 Golang 的配置文件：    </li>\n<li>Tools &gt; Build System &gt; <strong><code>New Build System...</code></strong>    </li>\n<li>定义编译运行 Golang 的命令与参数，并将其命名为 <strong><code>GoBuild.sublime-build</code></strong> 保存。    </li>\n<li>该定义文件名称可自定义。<br><img src=\"sublime-text-golang-5.png\" alt=\"sublime-text-golang-5\"><img src=\"sublime-text-golang-6.png\" alt=\"sublime-text-golang-6\">  </li>\n</ul>\n</li>\n<li>打开测试用 go 文件，使用 <strong><code>Ctrl+B</code></strong> 编译运行查看结果。<br><img src=\"sublime-text-golang-7.png\" alt=\"sublime-text-golang-7.png\"><img src=\"sublime-text-golang-8.png\" alt=\"sublime-text-golang-8.png\"></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Linux-安装-Go-语言环境：\"><a href=\"#Linux-安装-Go-语言环境：\" class=\"headerlink\" title=\"Linux 安装 Go 语言环境：\"></a>Linux 安装 Go 语言环境：</h3><ul>\n<li>下载 Golang 语言环境压缩包：go1.12.linux-amd64.tar.gz</li>\n<li>Golang 语言环境安装：  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo tar -zxvf go1.12.linux-amd64.tar.gz -C /usr/<span class=\"built_in\">local</span></span><br><span class=\"line\"><span class=\"comment\"># 解压并解包 go 语言环境</span></span><br><span class=\"line\">$ mkdir -p <span class=\"variable\">$HOME</span>/go/&#123;bin,pkg,src&#125;</span><br><span class=\"line\"><span class=\"comment\"># 创建 go 语言工作目录树</span></span><br><span class=\"line\">$ vim <span class=\"variable\">$HOME</span>/.bashrc</span><br><span class=\"line\">  <span class=\"comment\">### Define Go programme environment ###</span></span><br><span class=\"line\">  <span class=\"built_in\">export</span> GOROOT=/usr/<span class=\"built_in\">local</span>/go  </span><br><span class=\"line\">  <span class=\"comment\"># root directory to install go</span></span><br><span class=\"line\">  <span class=\"built_in\">export</span> GOPATH=<span class=\"variable\">$HOME</span>/go       </span><br><span class=\"line\">  <span class=\"comment\"># directory to store go project </span></span><br><span class=\"line\">  <span class=\"built_in\">export</span> GOBIN=<span class=\"variable\">$GOPATH</span>/bin     </span><br><span class=\"line\">  <span class=\"comment\"># store go command builded </span></span><br><span class=\"line\">  <span class=\"built_in\">export</span> PATH=<span class=\"variable\">$PATH</span>:<span class=\"variable\">$GOROOT</span>/bin:<span class=\"variable\">$GOBIN</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ <span class=\"built_in\">source</span> <span class=\"variable\">$HOME</span>/.bashrc</span><br><span class=\"line\"><span class=\"comment\"># 加载 go 语言环境变量</span></span><br><span class=\"line\">$ go version</span><br><span class=\"line\">  go version go1.12 linux/amd64</span><br><span class=\"line\"><span class=\"comment\"># 查看 go 语言环境版本</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"vim-go-插件配置-Go-语言开发环境：\"><a href=\"#vim-go-插件配置-Go-语言开发环境：\" class=\"headerlink\" title=\"vim-go 插件配置 Go 语言开发环境：\"></a>vim-go 插件配置 Go 语言开发环境：</h3><ul>\n<li>由于 CentOS 7.4 自带的 vim 版本为 <code>vim-enhanced-7.4.160-2.el7.x86_64</code>，该版本不支持 golang 语言的语法高亮特性，因此需要额外安装 <strong><code>vim-go</code></strong> 插件用以支持该特性，而 CentOS 8.x 或 RHEL 8.x 中自带 <code>vim 8</code> 可支持。</li>\n<li><p>配置方法如下所示：</p>\n<ul>\n<li><p>👉 Vim 插件管理器使用：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git <span class=\"built_in\">clone</span> https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim</span><br><span class=\"line\"><span class=\"comment\"># 下载安装 vim 插件管理器</span></span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> ~/.vim/bundle/Vundle.vim/ &amp;&amp; vim README.md</span><br><span class=\"line\">  <span class=\"built_in\">set</span> nocompatible              <span class=\"comment\"># be iMproved, required</span></span><br><span class=\"line\">  filetype off                  <span class=\"comment\"># required</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\"># set the runtime path to include Vundle and initialize</span></span><br><span class=\"line\">  <span class=\"built_in\">set</span> rtp+=~/.vim/bundle/Vundle.vim</span><br><span class=\"line\">  call vundle<span class=\"comment\">#begin()</span></span><br><span class=\"line\">  <span class=\"comment\"># alternatively, pass a path where Vundle should install plugins</span></span><br><span class=\"line\">  <span class=\"comment\">#call vundle#begin('~/some/path/here')</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\"># let Vundle manage Vundle, required</span></span><br><span class=\"line\">  Plugin <span class=\"string\">'VundleVim/Vundle.vim'</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\"># The following are examples of different formats supported.</span></span><br><span class=\"line\">  <span class=\"comment\"># Keep Plugin commands between vundle#begin/end.</span></span><br><span class=\"line\">  <span class=\"comment\"># plugin on GitHub repo</span></span><br><span class=\"line\">  Plugin <span class=\"string\">'tpope/vim-fugitive'</span></span><br><span class=\"line\">  <span class=\"comment\"># plugin from http://vim-scripts.org/vim/scripts.html</span></span><br><span class=\"line\">  <span class=\"comment\"># Plugin 'L9'</span></span><br><span class=\"line\">  <span class=\"comment\"># Git plugin not hosted on GitHub</span></span><br><span class=\"line\">  Plugin <span class=\"string\">'git://git.wincent.com/command-t.git'</span></span><br><span class=\"line\">  <span class=\"comment\"># git repos on your local machine (i.e. when working on your own plugin)</span></span><br><span class=\"line\">  Plugin <span class=\"string\">'file:///home/gmarik/path/to/plugin'</span></span><br><span class=\"line\">  <span class=\"comment\"># The sparkup vim script is in a subdirectory of this repo called vim.</span></span><br><span class=\"line\">  <span class=\"comment\"># Pass the path to set the runtimepath properly.</span></span><br><span class=\"line\">  Plugin <span class=\"string\">'rstacruz/sparkup'</span>, &#123;<span class=\"string\">'rtp'</span>: <span class=\"string\">'vim/'</span>&#125;</span><br><span class=\"line\">  <span class=\"comment\"># Install L9 and avoid a Naming conflict if you've already installed a</span></span><br><span class=\"line\">  <span class=\"comment\"># different version somewhere else.</span></span><br><span class=\"line\">  <span class=\"comment\"># Plugin 'ascenator/L9', &#123;'name': 'newL9'&#125;</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\"># All of your Plugins must be added before the following line</span></span><br><span class=\"line\">  call vundle<span class=\"comment\">#end()            \" required</span></span><br><span class=\"line\">  filetype plugin indent on    <span class=\"string\">\" required</span></span><br><span class=\"line\"><span class=\"string\">  # To ignore plugin indent changes, instead use:</span></span><br><span class=\"line\"><span class=\"string\">  #filetype plugin on</span></span><br><span class=\"line\"><span class=\"string\">  #</span></span><br><span class=\"line\"><span class=\"string\">  # Brief help</span></span><br><span class=\"line\"><span class=\"string\">  # :PluginList       - lists configured plugins</span></span><br><span class=\"line\"><span class=\"string\">  # :PluginInstall    - installs plugins; append `!` to update or just :PluginUpdate</span></span><br><span class=\"line\"><span class=\"string\">  # :PluginSearch foo - searches for foo; append `!` to refresh local cache</span></span><br><span class=\"line\"><span class=\"string\">  # :PluginClean      - confirms removal of unused plugins; append `!` to auto-approve removal</span></span><br><span class=\"line\"><span class=\"string\">  #</span></span><br><span class=\"line\"><span class=\"string\">  # see :h vundle for more details or wiki for FAQ</span></span><br><span class=\"line\"><span class=\"string\">  # Put your non-Plugin stuff after this line   </span></span><br><span class=\"line\"><span class=\"string\"># 进入 vim 插件管理器目录，并选择 \"</span>3. Configure Plugins<span class=\"string\">\" 中的相应插件内容，将其复制至 ~/.vimrc 文件的顶部。</span></span><br><span class=\"line\"><span class=\"string\"># 可根据需要添加或删除指定的插件。</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">$ git clone https://github.com/fatih/vim-go.git ~/.vim/bundle/vim-go</span></span><br><span class=\"line\"><span class=\"string\"># 下载安装 vim-go 插件使 vim 支持 Go 语言开发，包括语法高亮、语法错误检查等。</span></span><br><span class=\"line\"><span class=\"string\"># 注意该插件的下载路径！</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>👉 启用 <code>vim-go</code> 插件：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ vim ~/.vimrc</span><br><span class=\"line\">  <span class=\"comment\"># Configure Go Programming Language vim Environment</span></span><br><span class=\"line\">  <span class=\"comment\"># set nocompatible              \" be iMproved, required</span></span><br><span class=\"line\">  filetype off                    <span class=\"comment\"># required</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"built_in\">set</span> rtp+=~/.vim/bundle/Vundle.vim</span><br><span class=\"line\">  call vundle<span class=\"comment\">#begin()</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"comment\"># Install vim-go</span></span><br><span class=\"line\">  Plugin <span class=\"string\">'fatih/vim-go'</span></span><br><span class=\"line\">  <span class=\"comment\"># Install Dracula color theme</span></span><br><span class=\"line\">  Plugin <span class=\"string\">'dracula/vim'</span>, &#123;<span class=\"string\">'name'</span>: <span class=\"string\">'dracula'</span>&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  call vundle<span class=\"comment\">#end()            \" required</span></span><br><span class=\"line\">  filetype plugin indent on    <span class=\"string\">\" required</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">  # Extented Command</span></span><br><span class=\"line\"><span class=\"string\">  let g:go_version_warning = 0</span></span><br><span class=\"line\"><span class=\"string\">  # 由于 vim 版本过低在启动时将报错，该指令可去除报错。</span></span><br><span class=\"line\"><span class=\"string\">  set nu</span></span><br><span class=\"line\"><span class=\"string\">  set tabstop=2</span></span><br><span class=\"line\"><span class=\"string\">  # set cursorline</span></span><br><span class=\"line\"><span class=\"string\">  # set cursorcolumn</span></span><br><span class=\"line\"><span class=\"string\">  # colorscheme dracula</span></span><br><span class=\"line\"><span class=\"string\">  colorscheme elflord</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">  # Auto YAML syntax</span></span><br><span class=\"line\"><span class=\"string\">  autocmd FileType yaml setlocal ai ts=2 sw=2 et</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">$ vim +PluginInstall +qall</span></span><br><span class=\"line\"><span class=\"string\"># 安装所有的 vim 插件</span></span><br><span class=\"line\"><span class=\"string\">$ vim &lt;go_filename&gt;.go</span></span><br><span class=\"line\"><span class=\"string\"># 编辑 go 文件验证 vim-go 插件安装</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>若不添加 <strong><code>let g:go_version_warning = 0</code></strong>，报错如下，可直接回车继续使用 vim。<br><img src=\"vim-error.jpg\" alt=\"vim-error\"></p>\n</li>\n</ul>\n"},{"title":"kubeadm 更新 Kubernetes 集群到期证书","subtitle":"kubeadm Update Kubernetes Expired Certifications","date":"2022-12-29T03:24:05.000Z","header-img":"kubeadm-certs-bg.jpg","_content":"\n### 环境说明：\n- Kubernetes 版本：`v1.22.1`\n- kubeadm 版本：`v1.22.1`\n\n### 处理方法：\n- kubeadm 更新集群证书从 Kubernetes `v1.15` 进入 `stable` 状态，可在 GA 环境中使用。\n- 默认情况下，由 kubeadm 为集群生成的所有证书在 1 年后到期。\n- 更新（重新签发）集群证书需根据其部署方式而定，通过二进制部署的集群需手动更新集群证书，而通过 kubeadm 部署的集群可使用 kubeadm 更新证书，也可重新编译 kubeadm 用以生成自定义有效期的证书。\n- 👉 笔者环境中直接使用 kubeadm 更新证书。\n- 集群证书更新方式，步骤如下：  \n  - 检查集群证书有效期（通常于 `master` 节点执行）：    \n    ```bash\n    $ kubeadm certs check-expiration\n    $ openssl x509 -noout -in /etc/kubernetes/pki/apiserver.crt -dates\n    # 也可通过以上命令单独查看证书是否过期\n    ```\n  - 集群 master 节点上的 `/etc/kubernetes/pki/*` 的证书在更新之前应继续保留在节点上不可删除，删除后将导致集群异常无法恢复。  \n  - 🏷 kubeadm 更新集群 master 节点上的证书，而 worker 节点上 `kubelet` 证书默认自动轮换更新，无需关心证书到期问题。`kube-apiserver` 访问 kubelet 时，并不校验 kubelet 服务端证书，kubeadm 也并不提供更新 kubelet 服务端证书的办法。  \n  - 更新延期集群证书 1 年有效期：    \n    ```bash\n    $ kubeadm certs renew all --config ./kubeadm-conf.yml\n      W1213 21:45:40.125346   15197 strict.go:55] error unmarshaling configuration schema.GroupVersionKind{Group:\"kubelet.config.k8s.io\", Version:\"v1beta1\", Kind:\"KubeletConfiguration\"}: error converting YAML to JSON: yaml: unmarshal errors:\n        line 27: key \"cgroupDriver\" already set in map\n      certificate embedded in the kubeconfig file for the admin to use and for kubeadm itself renewed\n      certificate for serving the Kubernetes API renewed\n      certificate the apiserver uses to access etcd renewed\n      certificate for the API server to connect to kubelet renewed\n      certificate embedded in the kubeconfig file for the controller manager to use renewed\n      certificate for liveness probes to healthcheck etcd renewed\n      certificate for etcd nodes to communicate with each other renewed\n      certificate for serving etcd renewed\n      certificate for the front proxy client renewed\n      certificate embedded in the kubeconfig file for the scheduler manager to use renewed\n    \n      Done renewing certificates. You must restart the kube-apiserver, kube-controller-manager, kube-scheduler and etcd, so that they can use the new certificates.\n    # 根据集群部署时使用的 kubeadm-conf.yml 配置文件更新所有集群证书\n    \n    $ tree -D /etc/kubernetes/pki\n      /etc/kubernetes/pki\n      ├── [Dec 13 21:45]  apiserver.crt\n      ├── [Dec 13 21:45]  apiserver-etcd-client.crt\n      ├── [Dec 13 21:45]  apiserver-etcd-client.key\n      ├── [Dec 13 21:45]  apiserver.key\n      ├── [Dec 13 21:45]  apiserver-kubelet-client.crt\n      ├── [Dec 13 21:45]  apiserver-kubelet-client.key\n      ├── [Dec 25  2021]  ca.crt\n      ├── [Dec 25  2021]  ca.key\n      ├── [Dec 25  2021]  etcd\n      │   ├── [Dec 25  2021]  ca.crt\n      │   ├── [Dec 25  2021]  ca.key\n      │   ├── [Dec 13 21:45]  healthcheck-client.crt\n      │   ├── [Dec 13 21:45]  healthcheck-client.key\n      │   ├── [Dec 13 21:45]  peer.crt\n      │   ├── [Dec 13 21:45]  peer.key\n      │   ├── [Dec 13 21:45]  server.crt\n      │   └── [Dec 13 21:45]  server.key\n      ├── [Dec 25  2021]  front-proxy-ca.crt\n      ├── [Dec 25  2021]  front-proxy-ca.key\n      ├── [Dec 13 21:45]  front-proxy-client.crt\n      ├── [Dec 13 21:45]  front-proxy-client.key\n      ├── [Dec 25  2021]  sa.key\n      └── [Dec 25  2021]  sa.pub\n    \n      1 directory, 22 files\n    # 查看更新后的所有集群证书\n    ```\n    🔗 上述 kubeadm-conf.yml 可参考此 [链接](https://github.com/Alberthua-Perl/kani/blob/main/files/kube-utils/kubeadm-conf.yml)，可根据自身的实际情况进行修改后运行。  \n  - 更新集群证书后，需更新集群 `kubeconfig` 配置文件：    \n    ```bash\n    $ mkdir ~/kubeconfig-backup\n    $ mv /etc/kubernetes/*.conf ~/kubeconfig-backup/\n    # 备份集群原始 kubeconfig 配置文件\n    \n    $ kubeadm init phase kubeconfig all --config ./kubeadm-conf.yml \n      W1213 21:53:42.328419   19385 strict.go:55] error unmarshaling configuration schema.GroupVersionKind{Group:\"kubelet.config.k8s.io\", Version:\"v1beta1\", Kind:\"KubeletConfiguration\"}: error converting YAML to JSON: yaml: unmarshal errors:\n        line 27: key \"cgroupDriver\" already set in map\n      [kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n      [kubeconfig] Writing \"admin.conf\" kubeconfig file\n      [kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n      [kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n      [kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n    # 根据集群部署时使用的 kubeadm-conf.yml 配置文件重新生成集群 kubeconfig 配置文件\n    \n    $ ls -lh /etc/kubernetes/\n      total 36K\n      -rw------- 1 root root 5.6K Dec 13 21:53 admin.conf\n      -rw------- 1 root root 5.6K Dec 13 21:53 controller-manager.conf\n      -rw------- 1 root root 5.7K Dec 13 21:53 kubelet.conf\n      drwxr-xr-x 2 root root  113 Nov 22 00:40 manifests\n      drwxr-xr-x 3 root root 4.0K Dec 25  2021 pki\n      -rw------- 1 root root 5.5K Dec 13 21:53 scheduler.conf\n    ```\n  - 更新完成后检查集群所有证书有效期：    \n    ```bash\n    $ kubeadm certs check-expiration\n     [check-expiration] Reading configuration from the cluster...\n     [check-expiration] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'\n    \n     CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED\n     admin.conf                 Dec 13, 2023 13:53 UTC   364d                                    no      \n     apiserver                  Dec 13, 2023 13:45 UTC   364d            ca                      no      \n     apiserver-etcd-client      Dec 13, 2023 13:45 UTC   364d            etcd-ca                 no      \n     apiserver-kubelet-client   Dec 13, 2023 13:45 UTC   364d            ca                      no      \n     controller-manager.conf    Dec 13, 2023 13:53 UTC   364d                                    no      \n     etcd-healthcheck-client    Dec 13, 2023 13:45 UTC   364d            etcd-ca                 no      \n     etcd-peer                  Dec 13, 2023 13:45 UTC   364d            etcd-ca                 no      \n     etcd-server                Dec 13, 2023 13:45 UTC   364d            etcd-ca                 no      \n     front-proxy-client         Dec 13, 2023 13:45 UTC   364d            front-proxy-ca          no      \n     scheduler.conf             Dec 13, 2023 13:53 UTC   364d                                    no      \n    \n     CERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED\n     ca                      Dec 23, 2031 13:09 UTC   9y              no      \n     etcd-ca                 Dec 23, 2031 13:09 UTC   9y              no      \n     front-proxy-ca          Dec 23, 2031 13:09 UTC   9y              no\n    # 集群所有证书有效期延期 1 年\n    ```\n- 💥 需要注意的是，此时新生成的集群 `/etc/kubernetes/admin.conf` 配置文件嵌套新的证书，在集群外部或可使用 kubectl 命令连接至集群的节点上需使用该文件更新节点 `$HOME/.kube/config` 文件，否则无法连接至集群中，直接报错 `error: You must be logged in to the server (Unauthorized)`。\n\n### 参考文档：\n- [Kubernetes Doc - 使用 kubeadm 进行证书管理](https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/)\n- [Kubernetes Doc - PKI 证书和要求](https://kubernetes.io/zh-cn/docs/setup/best-practices/certificates/)\n- [Kubeadm 证书过期时间调整](https://www.cnblogs.com/skymyyang/p/11093686.html)\n","source":"_posts/kubeadm-update-k8s-certs.md","raw":"---\ntitle: kubeadm 更新 Kubernetes 集群到期证书\nsubtitle: kubeadm Update Kubernetes Expired Certifications\ndate: 2022-12-29 11:24:05\nheader-img: kubeadm-certs-bg.jpg\ntags:\n  - Kubernetes\n  - 云原生\n---\n\n### 环境说明：\n- Kubernetes 版本：`v1.22.1`\n- kubeadm 版本：`v1.22.1`\n\n### 处理方法：\n- kubeadm 更新集群证书从 Kubernetes `v1.15` 进入 `stable` 状态，可在 GA 环境中使用。\n- 默认情况下，由 kubeadm 为集群生成的所有证书在 1 年后到期。\n- 更新（重新签发）集群证书需根据其部署方式而定，通过二进制部署的集群需手动更新集群证书，而通过 kubeadm 部署的集群可使用 kubeadm 更新证书，也可重新编译 kubeadm 用以生成自定义有效期的证书。\n- 👉 笔者环境中直接使用 kubeadm 更新证书。\n- 集群证书更新方式，步骤如下：  \n  - 检查集群证书有效期（通常于 `master` 节点执行）：    \n    ```bash\n    $ kubeadm certs check-expiration\n    $ openssl x509 -noout -in /etc/kubernetes/pki/apiserver.crt -dates\n    # 也可通过以上命令单独查看证书是否过期\n    ```\n  - 集群 master 节点上的 `/etc/kubernetes/pki/*` 的证书在更新之前应继续保留在节点上不可删除，删除后将导致集群异常无法恢复。  \n  - 🏷 kubeadm 更新集群 master 节点上的证书，而 worker 节点上 `kubelet` 证书默认自动轮换更新，无需关心证书到期问题。`kube-apiserver` 访问 kubelet 时，并不校验 kubelet 服务端证书，kubeadm 也并不提供更新 kubelet 服务端证书的办法。  \n  - 更新延期集群证书 1 年有效期：    \n    ```bash\n    $ kubeadm certs renew all --config ./kubeadm-conf.yml\n      W1213 21:45:40.125346   15197 strict.go:55] error unmarshaling configuration schema.GroupVersionKind{Group:\"kubelet.config.k8s.io\", Version:\"v1beta1\", Kind:\"KubeletConfiguration\"}: error converting YAML to JSON: yaml: unmarshal errors:\n        line 27: key \"cgroupDriver\" already set in map\n      certificate embedded in the kubeconfig file for the admin to use and for kubeadm itself renewed\n      certificate for serving the Kubernetes API renewed\n      certificate the apiserver uses to access etcd renewed\n      certificate for the API server to connect to kubelet renewed\n      certificate embedded in the kubeconfig file for the controller manager to use renewed\n      certificate for liveness probes to healthcheck etcd renewed\n      certificate for etcd nodes to communicate with each other renewed\n      certificate for serving etcd renewed\n      certificate for the front proxy client renewed\n      certificate embedded in the kubeconfig file for the scheduler manager to use renewed\n    \n      Done renewing certificates. You must restart the kube-apiserver, kube-controller-manager, kube-scheduler and etcd, so that they can use the new certificates.\n    # 根据集群部署时使用的 kubeadm-conf.yml 配置文件更新所有集群证书\n    \n    $ tree -D /etc/kubernetes/pki\n      /etc/kubernetes/pki\n      ├── [Dec 13 21:45]  apiserver.crt\n      ├── [Dec 13 21:45]  apiserver-etcd-client.crt\n      ├── [Dec 13 21:45]  apiserver-etcd-client.key\n      ├── [Dec 13 21:45]  apiserver.key\n      ├── [Dec 13 21:45]  apiserver-kubelet-client.crt\n      ├── [Dec 13 21:45]  apiserver-kubelet-client.key\n      ├── [Dec 25  2021]  ca.crt\n      ├── [Dec 25  2021]  ca.key\n      ├── [Dec 25  2021]  etcd\n      │   ├── [Dec 25  2021]  ca.crt\n      │   ├── [Dec 25  2021]  ca.key\n      │   ├── [Dec 13 21:45]  healthcheck-client.crt\n      │   ├── [Dec 13 21:45]  healthcheck-client.key\n      │   ├── [Dec 13 21:45]  peer.crt\n      │   ├── [Dec 13 21:45]  peer.key\n      │   ├── [Dec 13 21:45]  server.crt\n      │   └── [Dec 13 21:45]  server.key\n      ├── [Dec 25  2021]  front-proxy-ca.crt\n      ├── [Dec 25  2021]  front-proxy-ca.key\n      ├── [Dec 13 21:45]  front-proxy-client.crt\n      ├── [Dec 13 21:45]  front-proxy-client.key\n      ├── [Dec 25  2021]  sa.key\n      └── [Dec 25  2021]  sa.pub\n    \n      1 directory, 22 files\n    # 查看更新后的所有集群证书\n    ```\n    🔗 上述 kubeadm-conf.yml 可参考此 [链接](https://github.com/Alberthua-Perl/kani/blob/main/files/kube-utils/kubeadm-conf.yml)，可根据自身的实际情况进行修改后运行。  \n  - 更新集群证书后，需更新集群 `kubeconfig` 配置文件：    \n    ```bash\n    $ mkdir ~/kubeconfig-backup\n    $ mv /etc/kubernetes/*.conf ~/kubeconfig-backup/\n    # 备份集群原始 kubeconfig 配置文件\n    \n    $ kubeadm init phase kubeconfig all --config ./kubeadm-conf.yml \n      W1213 21:53:42.328419   19385 strict.go:55] error unmarshaling configuration schema.GroupVersionKind{Group:\"kubelet.config.k8s.io\", Version:\"v1beta1\", Kind:\"KubeletConfiguration\"}: error converting YAML to JSON: yaml: unmarshal errors:\n        line 27: key \"cgroupDriver\" already set in map\n      [kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n      [kubeconfig] Writing \"admin.conf\" kubeconfig file\n      [kubeconfig] Writing \"kubelet.conf\" kubeconfig file\n      [kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n      [kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n    # 根据集群部署时使用的 kubeadm-conf.yml 配置文件重新生成集群 kubeconfig 配置文件\n    \n    $ ls -lh /etc/kubernetes/\n      total 36K\n      -rw------- 1 root root 5.6K Dec 13 21:53 admin.conf\n      -rw------- 1 root root 5.6K Dec 13 21:53 controller-manager.conf\n      -rw------- 1 root root 5.7K Dec 13 21:53 kubelet.conf\n      drwxr-xr-x 2 root root  113 Nov 22 00:40 manifests\n      drwxr-xr-x 3 root root 4.0K Dec 25  2021 pki\n      -rw------- 1 root root 5.5K Dec 13 21:53 scheduler.conf\n    ```\n  - 更新完成后检查集群所有证书有效期：    \n    ```bash\n    $ kubeadm certs check-expiration\n     [check-expiration] Reading configuration from the cluster...\n     [check-expiration] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'\n    \n     CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED\n     admin.conf                 Dec 13, 2023 13:53 UTC   364d                                    no      \n     apiserver                  Dec 13, 2023 13:45 UTC   364d            ca                      no      \n     apiserver-etcd-client      Dec 13, 2023 13:45 UTC   364d            etcd-ca                 no      \n     apiserver-kubelet-client   Dec 13, 2023 13:45 UTC   364d            ca                      no      \n     controller-manager.conf    Dec 13, 2023 13:53 UTC   364d                                    no      \n     etcd-healthcheck-client    Dec 13, 2023 13:45 UTC   364d            etcd-ca                 no      \n     etcd-peer                  Dec 13, 2023 13:45 UTC   364d            etcd-ca                 no      \n     etcd-server                Dec 13, 2023 13:45 UTC   364d            etcd-ca                 no      \n     front-proxy-client         Dec 13, 2023 13:45 UTC   364d            front-proxy-ca          no      \n     scheduler.conf             Dec 13, 2023 13:53 UTC   364d                                    no      \n    \n     CERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED\n     ca                      Dec 23, 2031 13:09 UTC   9y              no      \n     etcd-ca                 Dec 23, 2031 13:09 UTC   9y              no      \n     front-proxy-ca          Dec 23, 2031 13:09 UTC   9y              no\n    # 集群所有证书有效期延期 1 年\n    ```\n- 💥 需要注意的是，此时新生成的集群 `/etc/kubernetes/admin.conf` 配置文件嵌套新的证书，在集群外部或可使用 kubectl 命令连接至集群的节点上需使用该文件更新节点 `$HOME/.kube/config` 文件，否则无法连接至集群中，直接报错 `error: You must be logged in to the server (Unauthorized)`。\n\n### 参考文档：\n- [Kubernetes Doc - 使用 kubeadm 进行证书管理](https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/)\n- [Kubernetes Doc - PKI 证书和要求](https://kubernetes.io/zh-cn/docs/setup/best-practices/certificates/)\n- [Kubeadm 证书过期时间调整](https://www.cnblogs.com/skymyyang/p/11093686.html)\n","slug":"kubeadm-update-k8s-certs","published":1,"updated":"2022-12-29T04:08:30.460Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldfonokl000716vde5os9l41","content":"<h3 id=\"环境说明：\"><a href=\"#环境说明：\" class=\"headerlink\" title=\"环境说明：\"></a>环境说明：</h3><ul>\n<li>Kubernetes 版本：<code>v1.22.1</code></li>\n<li>kubeadm 版本：<code>v1.22.1</code></li>\n</ul>\n<h3 id=\"处理方法：\"><a href=\"#处理方法：\" class=\"headerlink\" title=\"处理方法：\"></a>处理方法：</h3><ul>\n<li>kubeadm 更新集群证书从 Kubernetes <code>v1.15</code> 进入 <code>stable</code> 状态，可在 GA 环境中使用。</li>\n<li>默认情况下，由 kubeadm 为集群生成的所有证书在 1 年后到期。</li>\n<li>更新（重新签发）集群证书需根据其部署方式而定，通过二进制部署的集群需手动更新集群证书，而通过 kubeadm 部署的集群可使用 kubeadm 更新证书，也可重新编译 kubeadm 用以生成自定义有效期的证书。</li>\n<li>👉 笔者环境中直接使用 kubeadm 更新证书。</li>\n<li><p>集群证书更新方式，步骤如下：  </p>\n<ul>\n<li><p>检查集群证书有效期（通常于 <code>master</code> 节点执行）：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubeadm certs check-expiration</span><br><span class=\"line\">$ openssl x509 -noout -<span class=\"keyword\">in</span> /etc/kubernetes/pki/apiserver.crt -dates</span><br><span class=\"line\"><span class=\"comment\"># 也可通过以上命令单独查看证书是否过期</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>集群 master 节点上的 <code>/etc/kubernetes/pki/*</code> 的证书在更新之前应继续保留在节点上不可删除，删除后将导致集群异常无法恢复。  </p>\n</li>\n<li>🏷 kubeadm 更新集群 master 节点上的证书，而 worker 节点上 <code>kubelet</code> 证书默认自动轮换更新，无需关心证书到期问题。<code>kube-apiserver</code> 访问 kubelet 时，并不校验 kubelet 服务端证书，kubeadm 也并不提供更新 kubelet 服务端证书的办法。  </li>\n<li><p>更新延期集群证书 1 年有效期：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubeadm certs renew all --config ./kubeadm-conf.yml</span><br><span class=\"line\">  W1213 21:45:40.125346   15197 strict.go:55] error unmarshaling configuration schema.GroupVersionKind&#123;Group:<span class=\"string\">\"kubelet.config.k8s.io\"</span>, Version:<span class=\"string\">\"v1beta1\"</span>, Kind:<span class=\"string\">\"KubeletConfiguration\"</span>&#125;: error converting YAML to JSON: yaml: unmarshal errors:</span><br><span class=\"line\">    line 27: key <span class=\"string\">\"cgroupDriver\"</span> already <span class=\"built_in\">set</span> <span class=\"keyword\">in</span> map</span><br><span class=\"line\">  certificate embedded <span class=\"keyword\">in</span> the kubeconfig file <span class=\"keyword\">for</span> the admin to use and <span class=\"keyword\">for</span> kubeadm itself renewed</span><br><span class=\"line\">  certificate <span class=\"keyword\">for</span> serving the Kubernetes API renewed</span><br><span class=\"line\">  certificate the apiserver uses to access etcd renewed</span><br><span class=\"line\">  certificate <span class=\"keyword\">for</span> the API server to connect to kubelet renewed</span><br><span class=\"line\">  certificate embedded <span class=\"keyword\">in</span> the kubeconfig file <span class=\"keyword\">for</span> the controller manager to use renewed</span><br><span class=\"line\">  certificate <span class=\"keyword\">for</span> liveness probes to healthcheck etcd renewed</span><br><span class=\"line\">  certificate <span class=\"keyword\">for</span> etcd nodes to communicate with each other renewed</span><br><span class=\"line\">  certificate <span class=\"keyword\">for</span> serving etcd renewed</span><br><span class=\"line\">  certificate <span class=\"keyword\">for</span> the front proxy client renewed</span><br><span class=\"line\">  certificate embedded <span class=\"keyword\">in</span> the kubeconfig file <span class=\"keyword\">for</span> the scheduler manager to use renewed</span><br><span class=\"line\"></span><br><span class=\"line\">  Done renewing certificates. You must restart the kube-apiserver, kube-controller-manager, kube-scheduler and etcd, so that they can use the new certificates.</span><br><span class=\"line\"><span class=\"comment\"># 根据集群部署时使用的 kubeadm-conf.yml 配置文件更新所有集群证书</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ tree -D /etc/kubernetes/pki</span><br><span class=\"line\">  /etc/kubernetes/pki</span><br><span class=\"line\">  ├── [Dec 13 21:45]  apiserver.crt</span><br><span class=\"line\">  ├── [Dec 13 21:45]  apiserver-etcd-client.crt</span><br><span class=\"line\">  ├── [Dec 13 21:45]  apiserver-etcd-client.key</span><br><span class=\"line\">  ├── [Dec 13 21:45]  apiserver.key</span><br><span class=\"line\">  ├── [Dec 13 21:45]  apiserver-kubelet-client.crt</span><br><span class=\"line\">  ├── [Dec 13 21:45]  apiserver-kubelet-client.key</span><br><span class=\"line\">  ├── [Dec 25  2021]  ca.crt</span><br><span class=\"line\">  ├── [Dec 25  2021]  ca.key</span><br><span class=\"line\">  ├── [Dec 25  2021]  etcd</span><br><span class=\"line\">  │   ├── [Dec 25  2021]  ca.crt</span><br><span class=\"line\">  │   ├── [Dec 25  2021]  ca.key</span><br><span class=\"line\">  │   ├── [Dec 13 21:45]  healthcheck-client.crt</span><br><span class=\"line\">  │   ├── [Dec 13 21:45]  healthcheck-client.key</span><br><span class=\"line\">  │   ├── [Dec 13 21:45]  peer.crt</span><br><span class=\"line\">  │   ├── [Dec 13 21:45]  peer.key</span><br><span class=\"line\">  │   ├── [Dec 13 21:45]  server.crt</span><br><span class=\"line\">  │   └── [Dec 13 21:45]  server.key</span><br><span class=\"line\">  ├── [Dec 25  2021]  front-proxy-ca.crt</span><br><span class=\"line\">  ├── [Dec 25  2021]  front-proxy-ca.key</span><br><span class=\"line\">  ├── [Dec 13 21:45]  front-proxy-client.crt</span><br><span class=\"line\">  ├── [Dec 13 21:45]  front-proxy-client.key</span><br><span class=\"line\">  ├── [Dec 25  2021]  sa.key</span><br><span class=\"line\">  └── [Dec 25  2021]  sa.pub</span><br><span class=\"line\"></span><br><span class=\"line\">  1 directory, 22 files</span><br><span class=\"line\"><span class=\"comment\"># 查看更新后的所有集群证书</span></span><br></pre></td></tr></table></figure>\n<p>🔗 上述 kubeadm-conf.yml 可参考此 <a href=\"https://github.com/Alberthua-Perl/kani/blob/main/files/kube-utils/kubeadm-conf.yml\" target=\"_blank\" rel=\"noopener\">链接</a>，可根据自身的实际情况进行修改后运行。  </p>\n</li>\n<li><p>更新集群证书后，需更新集群 <code>kubeconfig</code> 配置文件：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mkdir ~/kubeconfig-backup</span><br><span class=\"line\">$ mv /etc/kubernetes/*.conf ~/kubeconfig-backup/</span><br><span class=\"line\"><span class=\"comment\"># 备份集群原始 kubeconfig 配置文件</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubeadm init phase kubeconfig all --config ./kubeadm-conf.yml </span><br><span class=\"line\">  W1213 21:53:42.328419   19385 strict.go:55] error unmarshaling configuration schema.GroupVersionKind&#123;Group:<span class=\"string\">\"kubelet.config.k8s.io\"</span>, Version:<span class=\"string\">\"v1beta1\"</span>, Kind:<span class=\"string\">\"KubeletConfiguration\"</span>&#125;: error converting YAML to JSON: yaml: unmarshal errors:</span><br><span class=\"line\">    line 27: key <span class=\"string\">\"cgroupDriver\"</span> already <span class=\"built_in\">set</span> <span class=\"keyword\">in</span> map</span><br><span class=\"line\">  [kubeconfig] Using kubeconfig folder <span class=\"string\">\"/etc/kubernetes\"</span></span><br><span class=\"line\">  [kubeconfig] Writing <span class=\"string\">\"admin.conf\"</span> kubeconfig file</span><br><span class=\"line\">  [kubeconfig] Writing <span class=\"string\">\"kubelet.conf\"</span> kubeconfig file</span><br><span class=\"line\">  [kubeconfig] Writing <span class=\"string\">\"controller-manager.conf\"</span> kubeconfig file</span><br><span class=\"line\">  [kubeconfig] Writing <span class=\"string\">\"scheduler.conf\"</span> kubeconfig file</span><br><span class=\"line\"><span class=\"comment\"># 根据集群部署时使用的 kubeadm-conf.yml 配置文件重新生成集群 kubeconfig 配置文件</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ ls -lh /etc/kubernetes/</span><br><span class=\"line\">  total 36K</span><br><span class=\"line\">  -rw------- 1 root root 5.6K Dec 13 21:53 admin.conf</span><br><span class=\"line\">  -rw------- 1 root root 5.6K Dec 13 21:53 controller-manager.conf</span><br><span class=\"line\">  -rw------- 1 root root 5.7K Dec 13 21:53 kubelet.conf</span><br><span class=\"line\">  drwxr-xr-x 2 root root  113 Nov 22 00:40 manifests</span><br><span class=\"line\">  drwxr-xr-x 3 root root 4.0K Dec 25  2021 pki</span><br><span class=\"line\">  -rw------- 1 root root 5.5K Dec 13 21:53 scheduler.conf</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>更新完成后检查集群所有证书有效期：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubeadm certs check-expiration</span><br><span class=\"line\"> [check-expiration] Reading configuration from the cluster...</span><br><span class=\"line\"> [check-expiration] FYI: You can look at this config file with <span class=\"string\">'kubectl -n kube-system get cm kubeadm-config -o yaml'</span></span><br><span class=\"line\"></span><br><span class=\"line\"> CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED</span><br><span class=\"line\"> admin.conf                 Dec 13, 2023 13:53 UTC   364d                                    no      </span><br><span class=\"line\"> apiserver                  Dec 13, 2023 13:45 UTC   364d            ca                      no      </span><br><span class=\"line\"> apiserver-etcd-client      Dec 13, 2023 13:45 UTC   364d            etcd-ca                 no      </span><br><span class=\"line\"> apiserver-kubelet-client   Dec 13, 2023 13:45 UTC   364d            ca                      no      </span><br><span class=\"line\"> controller-manager.conf    Dec 13, 2023 13:53 UTC   364d                                    no      </span><br><span class=\"line\"> etcd-healthcheck-client    Dec 13, 2023 13:45 UTC   364d            etcd-ca                 no      </span><br><span class=\"line\"> etcd-peer                  Dec 13, 2023 13:45 UTC   364d            etcd-ca                 no      </span><br><span class=\"line\"> etcd-server                Dec 13, 2023 13:45 UTC   364d            etcd-ca                 no      </span><br><span class=\"line\"> front-proxy-client         Dec 13, 2023 13:45 UTC   364d            front-proxy-ca          no      </span><br><span class=\"line\"> scheduler.conf             Dec 13, 2023 13:53 UTC   364d                                    no      </span><br><span class=\"line\"></span><br><span class=\"line\"> CERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED</span><br><span class=\"line\"> ca                      Dec 23, 2031 13:09 UTC   9y              no      </span><br><span class=\"line\"> etcd-ca                 Dec 23, 2031 13:09 UTC   9y              no      </span><br><span class=\"line\"> front-proxy-ca          Dec 23, 2031 13:09 UTC   9y              no</span><br><span class=\"line\"><span class=\"comment\"># 集群所有证书有效期延期 1 年</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>💥 需要注意的是，此时新生成的集群 <code>/etc/kubernetes/admin.conf</code> 配置文件嵌套新的证书，在集群外部或可使用 kubectl 命令连接至集群的节点上需使用该文件更新节点 <code>$HOME/.kube/config</code> 文件，否则无法连接至集群中，直接报错 <code>error: You must be logged in to the server (Unauthorized)</code>。</p>\n</li>\n</ul>\n<h3 id=\"参考文档：\"><a href=\"#参考文档：\" class=\"headerlink\" title=\"参考文档：\"></a>参考文档：</h3><ul>\n<li><a href=\"https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/\" target=\"_blank\" rel=\"noopener\">Kubernetes Doc - 使用 kubeadm 进行证书管理</a></li>\n<li><a href=\"https://kubernetes.io/zh-cn/docs/setup/best-practices/certificates/\" target=\"_blank\" rel=\"noopener\">Kubernetes Doc - PKI 证书和要求</a></li>\n<li><a href=\"https://www.cnblogs.com/skymyyang/p/11093686.html\" target=\"_blank\" rel=\"noopener\">Kubeadm 证书过期时间调整</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"环境说明：\"><a href=\"#环境说明：\" class=\"headerlink\" title=\"环境说明：\"></a>环境说明：</h3><ul>\n<li>Kubernetes 版本：<code>v1.22.1</code></li>\n<li>kubeadm 版本：<code>v1.22.1</code></li>\n</ul>\n<h3 id=\"处理方法：\"><a href=\"#处理方法：\" class=\"headerlink\" title=\"处理方法：\"></a>处理方法：</h3><ul>\n<li>kubeadm 更新集群证书从 Kubernetes <code>v1.15</code> 进入 <code>stable</code> 状态，可在 GA 环境中使用。</li>\n<li>默认情况下，由 kubeadm 为集群生成的所有证书在 1 年后到期。</li>\n<li>更新（重新签发）集群证书需根据其部署方式而定，通过二进制部署的集群需手动更新集群证书，而通过 kubeadm 部署的集群可使用 kubeadm 更新证书，也可重新编译 kubeadm 用以生成自定义有效期的证书。</li>\n<li>👉 笔者环境中直接使用 kubeadm 更新证书。</li>\n<li><p>集群证书更新方式，步骤如下：  </p>\n<ul>\n<li><p>检查集群证书有效期（通常于 <code>master</code> 节点执行）：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubeadm certs check-expiration</span><br><span class=\"line\">$ openssl x509 -noout -<span class=\"keyword\">in</span> /etc/kubernetes/pki/apiserver.crt -dates</span><br><span class=\"line\"><span class=\"comment\"># 也可通过以上命令单独查看证书是否过期</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>集群 master 节点上的 <code>/etc/kubernetes/pki/*</code> 的证书在更新之前应继续保留在节点上不可删除，删除后将导致集群异常无法恢复。  </p>\n</li>\n<li>🏷 kubeadm 更新集群 master 节点上的证书，而 worker 节点上 <code>kubelet</code> 证书默认自动轮换更新，无需关心证书到期问题。<code>kube-apiserver</code> 访问 kubelet 时，并不校验 kubelet 服务端证书，kubeadm 也并不提供更新 kubelet 服务端证书的办法。  </li>\n<li><p>更新延期集群证书 1 年有效期：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubeadm certs renew all --config ./kubeadm-conf.yml</span><br><span class=\"line\">  W1213 21:45:40.125346   15197 strict.go:55] error unmarshaling configuration schema.GroupVersionKind&#123;Group:<span class=\"string\">\"kubelet.config.k8s.io\"</span>, Version:<span class=\"string\">\"v1beta1\"</span>, Kind:<span class=\"string\">\"KubeletConfiguration\"</span>&#125;: error converting YAML to JSON: yaml: unmarshal errors:</span><br><span class=\"line\">    line 27: key <span class=\"string\">\"cgroupDriver\"</span> already <span class=\"built_in\">set</span> <span class=\"keyword\">in</span> map</span><br><span class=\"line\">  certificate embedded <span class=\"keyword\">in</span> the kubeconfig file <span class=\"keyword\">for</span> the admin to use and <span class=\"keyword\">for</span> kubeadm itself renewed</span><br><span class=\"line\">  certificate <span class=\"keyword\">for</span> serving the Kubernetes API renewed</span><br><span class=\"line\">  certificate the apiserver uses to access etcd renewed</span><br><span class=\"line\">  certificate <span class=\"keyword\">for</span> the API server to connect to kubelet renewed</span><br><span class=\"line\">  certificate embedded <span class=\"keyword\">in</span> the kubeconfig file <span class=\"keyword\">for</span> the controller manager to use renewed</span><br><span class=\"line\">  certificate <span class=\"keyword\">for</span> liveness probes to healthcheck etcd renewed</span><br><span class=\"line\">  certificate <span class=\"keyword\">for</span> etcd nodes to communicate with each other renewed</span><br><span class=\"line\">  certificate <span class=\"keyword\">for</span> serving etcd renewed</span><br><span class=\"line\">  certificate <span class=\"keyword\">for</span> the front proxy client renewed</span><br><span class=\"line\">  certificate embedded <span class=\"keyword\">in</span> the kubeconfig file <span class=\"keyword\">for</span> the scheduler manager to use renewed</span><br><span class=\"line\"></span><br><span class=\"line\">  Done renewing certificates. You must restart the kube-apiserver, kube-controller-manager, kube-scheduler and etcd, so that they can use the new certificates.</span><br><span class=\"line\"><span class=\"comment\"># 根据集群部署时使用的 kubeadm-conf.yml 配置文件更新所有集群证书</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ tree -D /etc/kubernetes/pki</span><br><span class=\"line\">  /etc/kubernetes/pki</span><br><span class=\"line\">  ├── [Dec 13 21:45]  apiserver.crt</span><br><span class=\"line\">  ├── [Dec 13 21:45]  apiserver-etcd-client.crt</span><br><span class=\"line\">  ├── [Dec 13 21:45]  apiserver-etcd-client.key</span><br><span class=\"line\">  ├── [Dec 13 21:45]  apiserver.key</span><br><span class=\"line\">  ├── [Dec 13 21:45]  apiserver-kubelet-client.crt</span><br><span class=\"line\">  ├── [Dec 13 21:45]  apiserver-kubelet-client.key</span><br><span class=\"line\">  ├── [Dec 25  2021]  ca.crt</span><br><span class=\"line\">  ├── [Dec 25  2021]  ca.key</span><br><span class=\"line\">  ├── [Dec 25  2021]  etcd</span><br><span class=\"line\">  │   ├── [Dec 25  2021]  ca.crt</span><br><span class=\"line\">  │   ├── [Dec 25  2021]  ca.key</span><br><span class=\"line\">  │   ├── [Dec 13 21:45]  healthcheck-client.crt</span><br><span class=\"line\">  │   ├── [Dec 13 21:45]  healthcheck-client.key</span><br><span class=\"line\">  │   ├── [Dec 13 21:45]  peer.crt</span><br><span class=\"line\">  │   ├── [Dec 13 21:45]  peer.key</span><br><span class=\"line\">  │   ├── [Dec 13 21:45]  server.crt</span><br><span class=\"line\">  │   └── [Dec 13 21:45]  server.key</span><br><span class=\"line\">  ├── [Dec 25  2021]  front-proxy-ca.crt</span><br><span class=\"line\">  ├── [Dec 25  2021]  front-proxy-ca.key</span><br><span class=\"line\">  ├── [Dec 13 21:45]  front-proxy-client.crt</span><br><span class=\"line\">  ├── [Dec 13 21:45]  front-proxy-client.key</span><br><span class=\"line\">  ├── [Dec 25  2021]  sa.key</span><br><span class=\"line\">  └── [Dec 25  2021]  sa.pub</span><br><span class=\"line\"></span><br><span class=\"line\">  1 directory, 22 files</span><br><span class=\"line\"><span class=\"comment\"># 查看更新后的所有集群证书</span></span><br></pre></td></tr></table></figure>\n<p>🔗 上述 kubeadm-conf.yml 可参考此 <a href=\"https://github.com/Alberthua-Perl/kani/blob/main/files/kube-utils/kubeadm-conf.yml\" target=\"_blank\" rel=\"noopener\">链接</a>，可根据自身的实际情况进行修改后运行。  </p>\n</li>\n<li><p>更新集群证书后，需更新集群 <code>kubeconfig</code> 配置文件：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mkdir ~/kubeconfig-backup</span><br><span class=\"line\">$ mv /etc/kubernetes/*.conf ~/kubeconfig-backup/</span><br><span class=\"line\"><span class=\"comment\"># 备份集群原始 kubeconfig 配置文件</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubeadm init phase kubeconfig all --config ./kubeadm-conf.yml </span><br><span class=\"line\">  W1213 21:53:42.328419   19385 strict.go:55] error unmarshaling configuration schema.GroupVersionKind&#123;Group:<span class=\"string\">\"kubelet.config.k8s.io\"</span>, Version:<span class=\"string\">\"v1beta1\"</span>, Kind:<span class=\"string\">\"KubeletConfiguration\"</span>&#125;: error converting YAML to JSON: yaml: unmarshal errors:</span><br><span class=\"line\">    line 27: key <span class=\"string\">\"cgroupDriver\"</span> already <span class=\"built_in\">set</span> <span class=\"keyword\">in</span> map</span><br><span class=\"line\">  [kubeconfig] Using kubeconfig folder <span class=\"string\">\"/etc/kubernetes\"</span></span><br><span class=\"line\">  [kubeconfig] Writing <span class=\"string\">\"admin.conf\"</span> kubeconfig file</span><br><span class=\"line\">  [kubeconfig] Writing <span class=\"string\">\"kubelet.conf\"</span> kubeconfig file</span><br><span class=\"line\">  [kubeconfig] Writing <span class=\"string\">\"controller-manager.conf\"</span> kubeconfig file</span><br><span class=\"line\">  [kubeconfig] Writing <span class=\"string\">\"scheduler.conf\"</span> kubeconfig file</span><br><span class=\"line\"><span class=\"comment\"># 根据集群部署时使用的 kubeadm-conf.yml 配置文件重新生成集群 kubeconfig 配置文件</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ ls -lh /etc/kubernetes/</span><br><span class=\"line\">  total 36K</span><br><span class=\"line\">  -rw------- 1 root root 5.6K Dec 13 21:53 admin.conf</span><br><span class=\"line\">  -rw------- 1 root root 5.6K Dec 13 21:53 controller-manager.conf</span><br><span class=\"line\">  -rw------- 1 root root 5.7K Dec 13 21:53 kubelet.conf</span><br><span class=\"line\">  drwxr-xr-x 2 root root  113 Nov 22 00:40 manifests</span><br><span class=\"line\">  drwxr-xr-x 3 root root 4.0K Dec 25  2021 pki</span><br><span class=\"line\">  -rw------- 1 root root 5.5K Dec 13 21:53 scheduler.conf</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>更新完成后检查集群所有证书有效期：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubeadm certs check-expiration</span><br><span class=\"line\"> [check-expiration] Reading configuration from the cluster...</span><br><span class=\"line\"> [check-expiration] FYI: You can look at this config file with <span class=\"string\">'kubectl -n kube-system get cm kubeadm-config -o yaml'</span></span><br><span class=\"line\"></span><br><span class=\"line\"> CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED</span><br><span class=\"line\"> admin.conf                 Dec 13, 2023 13:53 UTC   364d                                    no      </span><br><span class=\"line\"> apiserver                  Dec 13, 2023 13:45 UTC   364d            ca                      no      </span><br><span class=\"line\"> apiserver-etcd-client      Dec 13, 2023 13:45 UTC   364d            etcd-ca                 no      </span><br><span class=\"line\"> apiserver-kubelet-client   Dec 13, 2023 13:45 UTC   364d            ca                      no      </span><br><span class=\"line\"> controller-manager.conf    Dec 13, 2023 13:53 UTC   364d                                    no      </span><br><span class=\"line\"> etcd-healthcheck-client    Dec 13, 2023 13:45 UTC   364d            etcd-ca                 no      </span><br><span class=\"line\"> etcd-peer                  Dec 13, 2023 13:45 UTC   364d            etcd-ca                 no      </span><br><span class=\"line\"> etcd-server                Dec 13, 2023 13:45 UTC   364d            etcd-ca                 no      </span><br><span class=\"line\"> front-proxy-client         Dec 13, 2023 13:45 UTC   364d            front-proxy-ca          no      </span><br><span class=\"line\"> scheduler.conf             Dec 13, 2023 13:53 UTC   364d                                    no      </span><br><span class=\"line\"></span><br><span class=\"line\"> CERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED</span><br><span class=\"line\"> ca                      Dec 23, 2031 13:09 UTC   9y              no      </span><br><span class=\"line\"> etcd-ca                 Dec 23, 2031 13:09 UTC   9y              no      </span><br><span class=\"line\"> front-proxy-ca          Dec 23, 2031 13:09 UTC   9y              no</span><br><span class=\"line\"><span class=\"comment\"># 集群所有证书有效期延期 1 年</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>💥 需要注意的是，此时新生成的集群 <code>/etc/kubernetes/admin.conf</code> 配置文件嵌套新的证书，在集群外部或可使用 kubectl 命令连接至集群的节点上需使用该文件更新节点 <code>$HOME/.kube/config</code> 文件，否则无法连接至集群中，直接报错 <code>error: You must be logged in to the server (Unauthorized)</code>。</p>\n</li>\n</ul>\n<h3 id=\"参考文档：\"><a href=\"#参考文档：\" class=\"headerlink\" title=\"参考文档：\"></a>参考文档：</h3><ul>\n<li><a href=\"https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/\" target=\"_blank\" rel=\"noopener\">Kubernetes Doc - 使用 kubeadm 进行证书管理</a></li>\n<li><a href=\"https://kubernetes.io/zh-cn/docs/setup/best-practices/certificates/\" target=\"_blank\" rel=\"noopener\">Kubernetes Doc - PKI 证书和要求</a></li>\n<li><a href=\"https://www.cnblogs.com/skymyyang/p/11093686.html\" target=\"_blank\" rel=\"noopener\">Kubeadm 证书过期时间调整</a></li>\n</ul>\n"},{"title":"☸️ Kubernetes 集群与资源管理基础","subtitle":"Kubernetes Cluster and Resource Basic","header-img":"k8s-resource-basic.svg","date":"2022-11-28T07:40:47.000Z","_content":"\n### 文档说明：\n- 该文档使用的 Kubernetes 版本为 `1.12.x`\n- 文档所示的命令可能与当前 Kubernetes 版本存在差异，请以实际使用的版本为基准！\n\n### 文档目录：\n- Kubernetes 集群架构概览\n- Kubernetes 集群的资源对象管理\n- 资源对象操作相关命令\n\n### Kubernetes 集群架构概览：\n- `API Server` 作为 Kubernetes 集群的网关（gateway）\n- `etcd` 键值型数据库作为 Kubernetes 集群的核心数据库\n- Kubernetes 集群可部署为单 master 集群或多 master（常见为 3 个）的 HA 集群  \n  - 单 master 节点的 Kubernetes 集群架构示意：    \n    ![kubernetes-single-master-arch.jpg](kubernetes-single-master-arch.jpg)  \n  - 多 master 节点的 Kubernetes 集群架构示意：    \n    ![kubernetes-ha-arch-demo.jpg](kubernetes-ha-arch-demo.jpg)  \n  > 👉 该示例中将 etcd 集群分别部署于 3 个 master 节点上。\n- Kubernetes 中的接口规范：  \n  - `CRI`：Container Runtime Interface（容器运行时接口）  \n  - `gRPC`：Google Remote Process Call（Google 发布的远程过程调用框架）  \n  - `OCI`：Open Container Initiative（开放容器标准）  \n  - `CNI`：Container Network Interface（容器网络接口）  \n  - `CSI`：Container Storage Interface（容器存储接口）  \n  - 以上各接口规范在集群中组件之间的调用示意：    \n    ![kubernetes-interface-1.jpg](kubernetes-interface-1.jpg)![kubernetes-interface-2.jpg](kubernetes-interface-2.jpg)\n- Kubernetes 集群中的网络概述：  \n  - 集群中的通信种类：    \n    - 同一 Pod 资源对象中容器间的通信    \n    - 各 Pod 资源对象彼此间的通信    \n    > 👉 Pod 间在同一节点上通信或彼此跨节点间通信    \n    - Pod 资源对象与 Service 资源对象间的通信    \n    - 集群外部的流量与 Service 资源对象间的通信  \n  - 集群网络规划部署：    \n    - Kubernetes 集群主机间的网络    \n    - Service 资源对象定义的 `ClusterIP` 网络    \n    - 由不同 `CNI` 定义的 Pod 间的通信网络\n- Kubernetes 集群的客户端类型：  \n  - Kubernetes 的 API Server 的客户端：    \n    集群及项目管理人员、开发人员、集群中与 API Server 交互的组件  \n  - Kubernetes 的访问 Pod 的客户端：    \n    集群外的普通用户、命名空间内的 Pod 应用（Pod Client）\n\n### Kubernetes 集群的资源对象管理：\n- kubectl 命令管理资源对象的 3 种方式：  \n  - 陈述式命令：使用命令行选项管理  \n  - 陈述式资源配置文件：使用 `kubectl create` 命令创建  \n  - 声明式资源配置文件：使用 `kubectl apply` 命令创建\n- Kubernetes 使用 `Deployment` 资源对象（Pod 控制器）部署与管理前端无状态（`Stateless`）的 Pod 资源对象，而 Deployment 资源对象并不直接作用于 Pod 资源对象，而是使用 `ReplicaSet` 资源对象进行部署与管理。\n- Deployment 资源对象是 ReplicaSet 资源对象之上的 Pod 控制器，两者都为工作负载型（workload）资源对象。\n- 使用 Deployment 资源对象部署的 Pod 资源对象都具有 `run=<pod_controller_name>` 的标签（label）。\n- Pod 资源对象的名称：`<replicaset_name>-<random_char>`  \n  ![pod-name.jpg](pod-name.jpg)\n- Pod资源对象的状态：  \n  Pending、Running、Succeeded、Failed、Unknown\n- Pod 容器日志信息管理：  \n  - 🐳 Kubernetes 集群中 Pod 容器日志信息默认以标准错误（`standard error`）输出至控制台，可使用 kubectl logs 命令查看容器日志信息。  \n  - 必须使用集中式的日志收集系统管理 Pod 容器日志。  \n  - 使用 kubectl logs 命令只能查看存在的 Pod 资源对象中的容器日志，不能查看已删除的Pod 资源对象日志。\n- Kubernetes 的 `API` 资源概述：  \n  - API Server 提供基于 `RESTful` 风格架构的编程接口，接收基于 `HTTP/HTTPS` 的客户端组件请求，并将其处理返回。  \n  - Kubernetes 的其他组件被抽象为标准的 REST 资源，可以使用标准的 `JSON` 序列化数据对 其管理与控制。  \n  - API 资源类型包括：    \n    - 对象类（Object）    \n    - 列表类（List）    \n    - 简单类（Simple）  \n  - Kubernetes 中的 API 资源类型绝大多数以对象的方式存在，对象是资源运行时生成的实例，且为持久化的实体。  \n  - API 对应于资源类型的 `URI`，即资源类型的 `YAML` 配置文件中的 `selfLink` 字段，其状态存储于后端 etcd 数据库中。  \n  > 💥 Kubernetes v1.20 版本开始，默认删除了 `metadata.selfLink` 字段，然而，部分应用仍然依赖于该字段，如 `nfs-client-provisioner`。如果仍然要继续使用这些应用，需要重新启用该字段。  \n  - 🚀 若集群使用 `kubeadm` 组件部署，可修改控制平面（control plan）各节点的 `/etc/kubernetes/manifests/kube-apiserver.yaml` 文件，在其中添加 `--feature-gates=RemoveSelfLink=false` 选项以启用该字段，如下所示：    \n    ![kubernetes-apiserver-manifest.jpg](kubernetes-apiserver-manifest.jpg)    \n    - 关于 selfLink 的说明可参考 [该链接](https://kuboard.cn/install/faq/selfLink.html)    \n    - 关于 kube-apiserver 命令的选项可参考 [kube-apiserver 官方文档](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/)  \n  - Kubernetes 将 API 进行逻辑分组，称为 API 群组（API group）。  \n  - 🚀 Kubernetes 的 API Server 支持相同的 API 群组中使用不同的版本，因此能在不同的版本中使用同名的资源类型，从而在稳定版本与新的实验版本中能以不同的特性使用同名的资源类型。  \n  > 关于 API 群组的分类与详细信息可参考 [该链接](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/)  \n  - Kubernetes 的 API 层级结构：    \n    - 核心 API 群组（core group）：      \n      - REST 路径：`/api/v1`      \n      - 资源配置文件中的字段：`apiVersion: v1`    \n    - 命名的 API 群组（named group）：      \n      - REST 路径：`/apis/<group_name>/<version>`      \n      - 资源配置文件中的字段：`apiVersion: <group_name>/<version>`    \n    - 命名空间级别的 REST API：      \n      - REST 路径：        \n        `/apis/<group_name>/<version>/namespaces/<namespace>/<resource_kind>/<object_name>`      \n      - 示例：        \n        `/apis/apps/v1/namespaces/default/deployments/nginx-deploy`    \n    - 访问 Kubernetes RESTful API 的方法：      \n      - kubectl get 命令行方式：        \n        ![kubectl-get-raw-json.jpg](kubectl-get-raw-json.jpg)      \n      - kubectl proxy 命令行方式：        \n        ```bash\n        $ kubectl proxy --port=<port>\n        # 启动本地主机为代理网关，使其能够访问 API Server 的 REST API，该端口不可被占用。\n        ```\n      - kubectl proxy 方式使用 kubectl 打开本地 `unix socket`，使 curl 命令通过进程间通信（IPC）的方式与代理网关通信，实现与 API Server 的交互。        \n      - Kubernetes 集群默认使用 `HTTPS` 的方式访问 API Server 的 REST API。        \n      - 使用 kubectl proxy 命令启动本地主机为代理网关后，在另一终端中即可使用 curl 命令以 HTTP 的方式访问，如下所示：          \n        ```bash\n        $ curl -s http://localhost:8080/api/v1/namespaces/default\n        ```\n\n- Kubernetes 的 API 资源分类：  \n  - 工作负载类型（workload）：    \n    - ReplicationController（rc）    \n    - ReplicaSet    \n    - Deployment    \n    - `StatefulSet`    \n    - DaemonSet    \n    - Job  \n  - 服务发现与负载均衡（Discovery & LB）：    \n    - Service    \n    - `Ingress`  \n  - 配置与存储（Config & Storage）：    \n    - Secret    \n    - `ConfigMap`    \n    - PersistentVolumeClaim（pvc）  \n  - 集群（Cluster）：    \n    - Namespace    \n    - Node    \n    - Role、ClusterRole、ClusterRoleBinding、RoleBinding    \n    - PersistentVolume（pv）  \n  - 元数据（Metadata）：    \n    - `HorizontalPodAutoscaler`（HPA）    \n    - LimitRange\n- Kubernetes 资源配置清单基础：  \n  - Kubernetes 资源配置清单的主要一级字段：    \n    apiVersion、kind、metadata、spec、status  \n  - 其中 metadata、spec 与 status 为嵌套字段：    \n    - `metadata`：记录资源的元数据数据    \n    - `spec`：记录资源的用户期望状态（desired）信息，由用户自定义并维护。    \n    - `status`：      \n      - 记录活动对象的当前状态（实际状态），由 Kubernetes 自动填充并维护，对用户为只读字段。      \n      > 👉 活动对象是指由 Kubernetes 创建的资源对象。      \n      - 该字段记录的活动对象的状态应与 spec 字段的状态相同，或者两者无限接近。    \n    - 💥 Kubernetes 的 API Server 只能接收并响应 `JSON` 对象，YAML 格式的对象需经过 API Server 转换后才能被接收处理。\n- Kubernetes 资源管理方式：  \n  - Kubernetes 的 API Server 支持声明式编程（`delarative programming`）与陈述式编程（`impreative programming`）。  \n  - 推荐优先使用 `apply` 或 `patch` 命令的声明式对象配置。  \n  - 可将不同资源类型的对象配置信息写在同一个资源配置清单中，并使用 `---` 符号将每个资源对象配置信息进行资源分割。  \n  - 使用 `Git` 版本控制系统管理资源配置清单文件。\n- 命名空间的资源管理：  \n  - 命名空间（namespace）通过将不同资源进行隔离，使命名空间的资源被不同的用户、租户与项目使用。  \n  - 命名空间只隔离不同的资源，不隔离跨命名空间的 Pod 间的通信，因此单纯使用命名空间的隔离机制为软隔离，而对网络流量的隔离需要由网络策略（`network policy`）来实现。  \n  > ✅ 不同的 CNI 插件可提供不同的网络策略功能，如 Calico、OVS plugin 等。  \n  - 创建自定义的命名空间，如下所示：    \n    ```bash\n    $ kubectl create namespace <namespace_name>\n    ```\n\n### 资源对象操作相关命令：\n- API 版本与资源对象解释命令：  \n  ```bash\n  $ kubectl --help\n  # 查看 kubectl 命令的使用方法\n  \n  $ kubectl api-versions\n  # 查看 API Server 支持的 API 版本，并以 group/version 的格式返回。\n  \n  $ kubectl api-resources\n  # 查看 API Server 支持的 API 资源类型\n  \n  $ kubectl explain <resource_type>\n  # 查看 API 资源类型的解释信息\n  \n  ### 示例 ###\n  $ kubectl explain pods.spec.containers.imagePullPolicy\n  # 查看 Pod 资源对象相关配置字段的详细信息\n  ```\n\n- 创建 `Deployment` 资源对象并运行 Pod：  \n  ```bash\n  $ kubectl run <deployment_name> \\\n    --image=<image_name>:<tag> --replicas=<number> --port=<port> \\\n    -n <namespace>\n  # 陈述式命令创建 Deployment 资源对象\n  # 一般情况下，不直接创建 Pod 资源对象，而是通过 Pod 控制器创建并管理 Pod 对象。\n  # kubectl run 常用命令选项：kubectl run --help\n  #   --image=''                   Pod 资源对象中容器镜像的名称\n  #   --port=''                    Pod 资源对象中容器的端口号\n  #   --replicas=''                Pod 资源对象的副本数\n  #   --record=[false|true]        将当前的 kubectl 命令记录于资源对象的\n  #                                annotation 注释中\n  #   --save-config=[false|true]   将当前的资源对象配置信息记录于 annotation\n  #                                注释中，默认为 false，在使用 kubectl apply\n  #                                时有用。          \n  #  --restart=[Always|OnFailure|Never]\n  #                                Pod 资源对象的重启策略，默认为 Always。            \n  #  --dry-run=[false|true]        测试运行（干运行），默认为 false。\n  #  -n，--namespace=''            资源对象所在的命名空间\n  \n  ### 示例 ###\n  $ kubectl run nginx-deploy \\\n    --image=nginx:v1.12 --replicas=2 --port=80 -n default\n  # 创建 Deployment 资源对象 nginx-deploy\n  \n  $ kubectl run client \\\n    --image=busybox:latest --restart=Never --replicas=1 \\\n    -it -n default -- /bin/sh\n  # 指定 --restart=Never 选项时，只创建 Pod 资源对象 client 并进入 Pod 交互式界面。             \n  # 退出交互式界面后，终止 Pod 资源对象运行，并进入 Completed 状态。\n  ```\n\n- 创建 Service 资源对象与暴露应用端口：  \n  ```bash\n  $ kubectl expose deployment <deployment_name> \\\n    --name=<service_name> --port=<port> --target-port=<port_num> \\\n    -n <namespace>\n  # 创建 Service 资源对象，对外暴露并关联 Pod 资源对象的 Pod IP 与端口。\n  # kubectl expose 常用命令选项：kubectl expose --help\n  #   --name=''                创建的 Service 资源对象名称\n  #   --port=''                Service 资源对象的端口号\n  #   --target-port=''         Service 资源对象关联的后端 Pod 资源对象的端口号\n  #   -n，--namespace=''       资源对象所在的命名空间\n  \n  ### 示例 ###\n  $ kubectl expose deployment nginx-deploy \\\n    --name=nginx-svc --port=8080 --target-port=80 -n default\n  # 创建名称为 nginx-svc 的 Service 资源对象\n  ```\n\n- 查看与操作相关资源对象：\n  ```bash\n  $ kubectl get pods,services -n <namespace> -o wide\n  # 查看命名空间中 Pod 与 Service 资源对象的详细信息（逗号分隔）\n  \n  $ kubectl get <resource_type> \\\n    -n <namespace> -o {yaml|json|jsonpath|wide|custom-columns=...}\n  # 查看命名空间中的资源对象信息，并以 YAML、JSON、完整格式或自定义格式输出。\n  \n  ### 示例 ###\n  $ kubectl get pods \\\n    -o custom-columns=NAME:metadata.name,STATUS:status.phase \n    -n kube-system\n  # 查看 kube-system 命名空间中 Pod 资源对象的名称与状态信息，以自定义格式输出。\n  \n  $ kubectl logs <pod_name> [-c <container_name>] -n <namespace>\n  # 查看命名空间中 Pod 资源对象中的容器日志信息\n  # Pod 资源对象中存在多个容器时，使用 -c 选项指定容器。\n  \n  $ kubectl exec <pod_name> \\\n    [-c <container_name>] -n <namespace> -- <command> <opts> <args...>\n  # 执行命名空间中 Pod 资源对象中的命令\n  # Pod 资源对象中存在多个容器时，使用 -c 选项指定容器。\n  \n  $ kubectl delete \\\n    <resource_type> <resource_name> -l <key>=<value> -n <namespace>\n  # 删除命名空间中具有指定标签的资源对象\n  \n  ### 示例 ###\n  $ kubectl delete deployment myapp --cascade=false -n default\n  # 删除 default 命名空间中名为 myapp 的 Deployment 资源对象，但不删除其创建的 Pod。    \n  \n  $ kubectl create -f <file>.yaml|<dir>|<url>\n  # 使用陈述式命令 create 创建不同的 API 资源对象\n  \n  $ kubectl apply -f <file>.yaml|<dir>|<url> \n  # 使用声明式命令 apply 创建、更新与替换不同的 API 资源对象\n  # 注意：\n  #   1. 声明式对象配置管理具有高级的补丁更新机制，将相应的配置信息记录于 annotation 注释中。\n  #   2. Kubernetes 建议使用声明式对象配置方式！ \n  \n  $ kubectl delete -f <file>.yaml\n  # 删除该 YAML 配置文件创建的 API 资源对象\n  \n  $ kubectl scale deployment <deployment_name> --replicas=<number> -n <namespace>\n  # 指定命名空间中扩容或缩容 Pod 资源对象的副本数目\n  \n  ### 示例 ###\n  $ kubectl scale deployment myapp --replicas=3 -n default\n  # 指定 default 命名空间中扩容或缩容 Pod 资源对象的副本数目为 3 个\n  # 注意：\n  #   扩容或缩容 Pod 资源对象副本数目的方法：\n  #   1. 通过该命令行方式进行扩容或缩容\n  #   2. 使用如下命令更改 Deployment 资源对象的配置信息，更改后实时生效：\n  #      $ kubectl edit deployment myapp -n default\n  ```","source":"_posts/k8s-cluster-resource-basic.md","raw":"---\ntitle: ☸️ Kubernetes 集群与资源管理基础\nsubtitle: Kubernetes Cluster and Resource Basic\nheader-img: k8s-resource-basic.svg\ndate: 2022-11-28 15:40:47\ntags:\n  - Kubernetes\n  - 云原生\n---\n\n### 文档说明：\n- 该文档使用的 Kubernetes 版本为 `1.12.x`\n- 文档所示的命令可能与当前 Kubernetes 版本存在差异，请以实际使用的版本为基准！\n\n### 文档目录：\n- Kubernetes 集群架构概览\n- Kubernetes 集群的资源对象管理\n- 资源对象操作相关命令\n\n### Kubernetes 集群架构概览：\n- `API Server` 作为 Kubernetes 集群的网关（gateway）\n- `etcd` 键值型数据库作为 Kubernetes 集群的核心数据库\n- Kubernetes 集群可部署为单 master 集群或多 master（常见为 3 个）的 HA 集群  \n  - 单 master 节点的 Kubernetes 集群架构示意：    \n    ![kubernetes-single-master-arch.jpg](kubernetes-single-master-arch.jpg)  \n  - 多 master 节点的 Kubernetes 集群架构示意：    \n    ![kubernetes-ha-arch-demo.jpg](kubernetes-ha-arch-demo.jpg)  \n  > 👉 该示例中将 etcd 集群分别部署于 3 个 master 节点上。\n- Kubernetes 中的接口规范：  \n  - `CRI`：Container Runtime Interface（容器运行时接口）  \n  - `gRPC`：Google Remote Process Call（Google 发布的远程过程调用框架）  \n  - `OCI`：Open Container Initiative（开放容器标准）  \n  - `CNI`：Container Network Interface（容器网络接口）  \n  - `CSI`：Container Storage Interface（容器存储接口）  \n  - 以上各接口规范在集群中组件之间的调用示意：    \n    ![kubernetes-interface-1.jpg](kubernetes-interface-1.jpg)![kubernetes-interface-2.jpg](kubernetes-interface-2.jpg)\n- Kubernetes 集群中的网络概述：  \n  - 集群中的通信种类：    \n    - 同一 Pod 资源对象中容器间的通信    \n    - 各 Pod 资源对象彼此间的通信    \n    > 👉 Pod 间在同一节点上通信或彼此跨节点间通信    \n    - Pod 资源对象与 Service 资源对象间的通信    \n    - 集群外部的流量与 Service 资源对象间的通信  \n  - 集群网络规划部署：    \n    - Kubernetes 集群主机间的网络    \n    - Service 资源对象定义的 `ClusterIP` 网络    \n    - 由不同 `CNI` 定义的 Pod 间的通信网络\n- Kubernetes 集群的客户端类型：  \n  - Kubernetes 的 API Server 的客户端：    \n    集群及项目管理人员、开发人员、集群中与 API Server 交互的组件  \n  - Kubernetes 的访问 Pod 的客户端：    \n    集群外的普通用户、命名空间内的 Pod 应用（Pod Client）\n\n### Kubernetes 集群的资源对象管理：\n- kubectl 命令管理资源对象的 3 种方式：  \n  - 陈述式命令：使用命令行选项管理  \n  - 陈述式资源配置文件：使用 `kubectl create` 命令创建  \n  - 声明式资源配置文件：使用 `kubectl apply` 命令创建\n- Kubernetes 使用 `Deployment` 资源对象（Pod 控制器）部署与管理前端无状态（`Stateless`）的 Pod 资源对象，而 Deployment 资源对象并不直接作用于 Pod 资源对象，而是使用 `ReplicaSet` 资源对象进行部署与管理。\n- Deployment 资源对象是 ReplicaSet 资源对象之上的 Pod 控制器，两者都为工作负载型（workload）资源对象。\n- 使用 Deployment 资源对象部署的 Pod 资源对象都具有 `run=<pod_controller_name>` 的标签（label）。\n- Pod 资源对象的名称：`<replicaset_name>-<random_char>`  \n  ![pod-name.jpg](pod-name.jpg)\n- Pod资源对象的状态：  \n  Pending、Running、Succeeded、Failed、Unknown\n- Pod 容器日志信息管理：  \n  - 🐳 Kubernetes 集群中 Pod 容器日志信息默认以标准错误（`standard error`）输出至控制台，可使用 kubectl logs 命令查看容器日志信息。  \n  - 必须使用集中式的日志收集系统管理 Pod 容器日志。  \n  - 使用 kubectl logs 命令只能查看存在的 Pod 资源对象中的容器日志，不能查看已删除的Pod 资源对象日志。\n- Kubernetes 的 `API` 资源概述：  \n  - API Server 提供基于 `RESTful` 风格架构的编程接口，接收基于 `HTTP/HTTPS` 的客户端组件请求，并将其处理返回。  \n  - Kubernetes 的其他组件被抽象为标准的 REST 资源，可以使用标准的 `JSON` 序列化数据对 其管理与控制。  \n  - API 资源类型包括：    \n    - 对象类（Object）    \n    - 列表类（List）    \n    - 简单类（Simple）  \n  - Kubernetes 中的 API 资源类型绝大多数以对象的方式存在，对象是资源运行时生成的实例，且为持久化的实体。  \n  - API 对应于资源类型的 `URI`，即资源类型的 `YAML` 配置文件中的 `selfLink` 字段，其状态存储于后端 etcd 数据库中。  \n  > 💥 Kubernetes v1.20 版本开始，默认删除了 `metadata.selfLink` 字段，然而，部分应用仍然依赖于该字段，如 `nfs-client-provisioner`。如果仍然要继续使用这些应用，需要重新启用该字段。  \n  - 🚀 若集群使用 `kubeadm` 组件部署，可修改控制平面（control plan）各节点的 `/etc/kubernetes/manifests/kube-apiserver.yaml` 文件，在其中添加 `--feature-gates=RemoveSelfLink=false` 选项以启用该字段，如下所示：    \n    ![kubernetes-apiserver-manifest.jpg](kubernetes-apiserver-manifest.jpg)    \n    - 关于 selfLink 的说明可参考 [该链接](https://kuboard.cn/install/faq/selfLink.html)    \n    - 关于 kube-apiserver 命令的选项可参考 [kube-apiserver 官方文档](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/)  \n  - Kubernetes 将 API 进行逻辑分组，称为 API 群组（API group）。  \n  - 🚀 Kubernetes 的 API Server 支持相同的 API 群组中使用不同的版本，因此能在不同的版本中使用同名的资源类型，从而在稳定版本与新的实验版本中能以不同的特性使用同名的资源类型。  \n  > 关于 API 群组的分类与详细信息可参考 [该链接](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/)  \n  - Kubernetes 的 API 层级结构：    \n    - 核心 API 群组（core group）：      \n      - REST 路径：`/api/v1`      \n      - 资源配置文件中的字段：`apiVersion: v1`    \n    - 命名的 API 群组（named group）：      \n      - REST 路径：`/apis/<group_name>/<version>`      \n      - 资源配置文件中的字段：`apiVersion: <group_name>/<version>`    \n    - 命名空间级别的 REST API：      \n      - REST 路径：        \n        `/apis/<group_name>/<version>/namespaces/<namespace>/<resource_kind>/<object_name>`      \n      - 示例：        \n        `/apis/apps/v1/namespaces/default/deployments/nginx-deploy`    \n    - 访问 Kubernetes RESTful API 的方法：      \n      - kubectl get 命令行方式：        \n        ![kubectl-get-raw-json.jpg](kubectl-get-raw-json.jpg)      \n      - kubectl proxy 命令行方式：        \n        ```bash\n        $ kubectl proxy --port=<port>\n        # 启动本地主机为代理网关，使其能够访问 API Server 的 REST API，该端口不可被占用。\n        ```\n      - kubectl proxy 方式使用 kubectl 打开本地 `unix socket`，使 curl 命令通过进程间通信（IPC）的方式与代理网关通信，实现与 API Server 的交互。        \n      - Kubernetes 集群默认使用 `HTTPS` 的方式访问 API Server 的 REST API。        \n      - 使用 kubectl proxy 命令启动本地主机为代理网关后，在另一终端中即可使用 curl 命令以 HTTP 的方式访问，如下所示：          \n        ```bash\n        $ curl -s http://localhost:8080/api/v1/namespaces/default\n        ```\n\n- Kubernetes 的 API 资源分类：  \n  - 工作负载类型（workload）：    \n    - ReplicationController（rc）    \n    - ReplicaSet    \n    - Deployment    \n    - `StatefulSet`    \n    - DaemonSet    \n    - Job  \n  - 服务发现与负载均衡（Discovery & LB）：    \n    - Service    \n    - `Ingress`  \n  - 配置与存储（Config & Storage）：    \n    - Secret    \n    - `ConfigMap`    \n    - PersistentVolumeClaim（pvc）  \n  - 集群（Cluster）：    \n    - Namespace    \n    - Node    \n    - Role、ClusterRole、ClusterRoleBinding、RoleBinding    \n    - PersistentVolume（pv）  \n  - 元数据（Metadata）：    \n    - `HorizontalPodAutoscaler`（HPA）    \n    - LimitRange\n- Kubernetes 资源配置清单基础：  \n  - Kubernetes 资源配置清单的主要一级字段：    \n    apiVersion、kind、metadata、spec、status  \n  - 其中 metadata、spec 与 status 为嵌套字段：    \n    - `metadata`：记录资源的元数据数据    \n    - `spec`：记录资源的用户期望状态（desired）信息，由用户自定义并维护。    \n    - `status`：      \n      - 记录活动对象的当前状态（实际状态），由 Kubernetes 自动填充并维护，对用户为只读字段。      \n      > 👉 活动对象是指由 Kubernetes 创建的资源对象。      \n      - 该字段记录的活动对象的状态应与 spec 字段的状态相同，或者两者无限接近。    \n    - 💥 Kubernetes 的 API Server 只能接收并响应 `JSON` 对象，YAML 格式的对象需经过 API Server 转换后才能被接收处理。\n- Kubernetes 资源管理方式：  \n  - Kubernetes 的 API Server 支持声明式编程（`delarative programming`）与陈述式编程（`impreative programming`）。  \n  - 推荐优先使用 `apply` 或 `patch` 命令的声明式对象配置。  \n  - 可将不同资源类型的对象配置信息写在同一个资源配置清单中，并使用 `---` 符号将每个资源对象配置信息进行资源分割。  \n  - 使用 `Git` 版本控制系统管理资源配置清单文件。\n- 命名空间的资源管理：  \n  - 命名空间（namespace）通过将不同资源进行隔离，使命名空间的资源被不同的用户、租户与项目使用。  \n  - 命名空间只隔离不同的资源，不隔离跨命名空间的 Pod 间的通信，因此单纯使用命名空间的隔离机制为软隔离，而对网络流量的隔离需要由网络策略（`network policy`）来实现。  \n  > ✅ 不同的 CNI 插件可提供不同的网络策略功能，如 Calico、OVS plugin 等。  \n  - 创建自定义的命名空间，如下所示：    \n    ```bash\n    $ kubectl create namespace <namespace_name>\n    ```\n\n### 资源对象操作相关命令：\n- API 版本与资源对象解释命令：  \n  ```bash\n  $ kubectl --help\n  # 查看 kubectl 命令的使用方法\n  \n  $ kubectl api-versions\n  # 查看 API Server 支持的 API 版本，并以 group/version 的格式返回。\n  \n  $ kubectl api-resources\n  # 查看 API Server 支持的 API 资源类型\n  \n  $ kubectl explain <resource_type>\n  # 查看 API 资源类型的解释信息\n  \n  ### 示例 ###\n  $ kubectl explain pods.spec.containers.imagePullPolicy\n  # 查看 Pod 资源对象相关配置字段的详细信息\n  ```\n\n- 创建 `Deployment` 资源对象并运行 Pod：  \n  ```bash\n  $ kubectl run <deployment_name> \\\n    --image=<image_name>:<tag> --replicas=<number> --port=<port> \\\n    -n <namespace>\n  # 陈述式命令创建 Deployment 资源对象\n  # 一般情况下，不直接创建 Pod 资源对象，而是通过 Pod 控制器创建并管理 Pod 对象。\n  # kubectl run 常用命令选项：kubectl run --help\n  #   --image=''                   Pod 资源对象中容器镜像的名称\n  #   --port=''                    Pod 资源对象中容器的端口号\n  #   --replicas=''                Pod 资源对象的副本数\n  #   --record=[false|true]        将当前的 kubectl 命令记录于资源对象的\n  #                                annotation 注释中\n  #   --save-config=[false|true]   将当前的资源对象配置信息记录于 annotation\n  #                                注释中，默认为 false，在使用 kubectl apply\n  #                                时有用。          \n  #  --restart=[Always|OnFailure|Never]\n  #                                Pod 资源对象的重启策略，默认为 Always。            \n  #  --dry-run=[false|true]        测试运行（干运行），默认为 false。\n  #  -n，--namespace=''            资源对象所在的命名空间\n  \n  ### 示例 ###\n  $ kubectl run nginx-deploy \\\n    --image=nginx:v1.12 --replicas=2 --port=80 -n default\n  # 创建 Deployment 资源对象 nginx-deploy\n  \n  $ kubectl run client \\\n    --image=busybox:latest --restart=Never --replicas=1 \\\n    -it -n default -- /bin/sh\n  # 指定 --restart=Never 选项时，只创建 Pod 资源对象 client 并进入 Pod 交互式界面。             \n  # 退出交互式界面后，终止 Pod 资源对象运行，并进入 Completed 状态。\n  ```\n\n- 创建 Service 资源对象与暴露应用端口：  \n  ```bash\n  $ kubectl expose deployment <deployment_name> \\\n    --name=<service_name> --port=<port> --target-port=<port_num> \\\n    -n <namespace>\n  # 创建 Service 资源对象，对外暴露并关联 Pod 资源对象的 Pod IP 与端口。\n  # kubectl expose 常用命令选项：kubectl expose --help\n  #   --name=''                创建的 Service 资源对象名称\n  #   --port=''                Service 资源对象的端口号\n  #   --target-port=''         Service 资源对象关联的后端 Pod 资源对象的端口号\n  #   -n，--namespace=''       资源对象所在的命名空间\n  \n  ### 示例 ###\n  $ kubectl expose deployment nginx-deploy \\\n    --name=nginx-svc --port=8080 --target-port=80 -n default\n  # 创建名称为 nginx-svc 的 Service 资源对象\n  ```\n\n- 查看与操作相关资源对象：\n  ```bash\n  $ kubectl get pods,services -n <namespace> -o wide\n  # 查看命名空间中 Pod 与 Service 资源对象的详细信息（逗号分隔）\n  \n  $ kubectl get <resource_type> \\\n    -n <namespace> -o {yaml|json|jsonpath|wide|custom-columns=...}\n  # 查看命名空间中的资源对象信息，并以 YAML、JSON、完整格式或自定义格式输出。\n  \n  ### 示例 ###\n  $ kubectl get pods \\\n    -o custom-columns=NAME:metadata.name,STATUS:status.phase \n    -n kube-system\n  # 查看 kube-system 命名空间中 Pod 资源对象的名称与状态信息，以自定义格式输出。\n  \n  $ kubectl logs <pod_name> [-c <container_name>] -n <namespace>\n  # 查看命名空间中 Pod 资源对象中的容器日志信息\n  # Pod 资源对象中存在多个容器时，使用 -c 选项指定容器。\n  \n  $ kubectl exec <pod_name> \\\n    [-c <container_name>] -n <namespace> -- <command> <opts> <args...>\n  # 执行命名空间中 Pod 资源对象中的命令\n  # Pod 资源对象中存在多个容器时，使用 -c 选项指定容器。\n  \n  $ kubectl delete \\\n    <resource_type> <resource_name> -l <key>=<value> -n <namespace>\n  # 删除命名空间中具有指定标签的资源对象\n  \n  ### 示例 ###\n  $ kubectl delete deployment myapp --cascade=false -n default\n  # 删除 default 命名空间中名为 myapp 的 Deployment 资源对象，但不删除其创建的 Pod。    \n  \n  $ kubectl create -f <file>.yaml|<dir>|<url>\n  # 使用陈述式命令 create 创建不同的 API 资源对象\n  \n  $ kubectl apply -f <file>.yaml|<dir>|<url> \n  # 使用声明式命令 apply 创建、更新与替换不同的 API 资源对象\n  # 注意：\n  #   1. 声明式对象配置管理具有高级的补丁更新机制，将相应的配置信息记录于 annotation 注释中。\n  #   2. Kubernetes 建议使用声明式对象配置方式！ \n  \n  $ kubectl delete -f <file>.yaml\n  # 删除该 YAML 配置文件创建的 API 资源对象\n  \n  $ kubectl scale deployment <deployment_name> --replicas=<number> -n <namespace>\n  # 指定命名空间中扩容或缩容 Pod 资源对象的副本数目\n  \n  ### 示例 ###\n  $ kubectl scale deployment myapp --replicas=3 -n default\n  # 指定 default 命名空间中扩容或缩容 Pod 资源对象的副本数目为 3 个\n  # 注意：\n  #   扩容或缩容 Pod 资源对象副本数目的方法：\n  #   1. 通过该命令行方式进行扩容或缩容\n  #   2. 使用如下命令更改 Deployment 资源对象的配置信息，更改后实时生效：\n  #      $ kubectl edit deployment myapp -n default\n  ```","slug":"k8s-cluster-resource-basic","published":1,"updated":"2022-11-28T13:47:24.090Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldfonoko000816vdmg3j0qwb","content":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li>该文档使用的 Kubernetes 版本为 <code>1.12.x</code></li>\n<li>文档所示的命令可能与当前 Kubernetes 版本存在差异，请以实际使用的版本为基准！</li>\n</ul>\n<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>Kubernetes 集群架构概览</li>\n<li>Kubernetes 集群的资源对象管理</li>\n<li>资源对象操作相关命令</li>\n</ul>\n<h3 id=\"Kubernetes-集群架构概览：\"><a href=\"#Kubernetes-集群架构概览：\" class=\"headerlink\" title=\"Kubernetes 集群架构概览：\"></a>Kubernetes 集群架构概览：</h3><ul>\n<li><code>API Server</code> 作为 Kubernetes 集群的网关（gateway）</li>\n<li><code>etcd</code> 键值型数据库作为 Kubernetes 集群的核心数据库</li>\n<li>Kubernetes 集群可部署为单 master 集群或多 master（常见为 3 个）的 HA 集群  <ul>\n<li>单 master 节点的 Kubernetes 集群架构示意：<br><img src=\"kubernetes-single-master-arch.jpg\" alt=\"kubernetes-single-master-arch.jpg\">  </li>\n<li>多 master 节点的 Kubernetes 集群架构示意：<br><img src=\"kubernetes-ha-arch-demo.jpg\" alt=\"kubernetes-ha-arch-demo.jpg\">  <blockquote>\n<p>👉 该示例中将 etcd 集群分别部署于 3 个 master 节点上。</p>\n</blockquote>\n</li>\n</ul>\n</li>\n<li>Kubernetes 中的接口规范：  <ul>\n<li><code>CRI</code>：Container Runtime Interface（容器运行时接口）  </li>\n<li><code>gRPC</code>：Google Remote Process Call（Google 发布的远程过程调用框架）  </li>\n<li><code>OCI</code>：Open Container Initiative（开放容器标准）  </li>\n<li><code>CNI</code>：Container Network Interface（容器网络接口）  </li>\n<li><code>CSI</code>：Container Storage Interface（容器存储接口）  </li>\n<li>以上各接口规范在集群中组件之间的调用示意：<br><img src=\"kubernetes-interface-1.jpg\" alt=\"kubernetes-interface-1.jpg\"><img src=\"kubernetes-interface-2.jpg\" alt=\"kubernetes-interface-2.jpg\"></li>\n</ul>\n</li>\n<li>Kubernetes 集群中的网络概述：  <ul>\n<li>集群中的通信种类：    <ul>\n<li>同一 Pod 资源对象中容器间的通信    </li>\n<li>各 Pod 资源对象彼此间的通信    <blockquote>\n<p>👉 Pod 间在同一节点上通信或彼此跨节点间通信    </p>\n</blockquote>\n</li>\n<li>Pod 资源对象与 Service 资源对象间的通信    </li>\n<li>集群外部的流量与 Service 资源对象间的通信  </li>\n</ul>\n</li>\n<li>集群网络规划部署：    <ul>\n<li>Kubernetes 集群主机间的网络    </li>\n<li>Service 资源对象定义的 <code>ClusterIP</code> 网络    </li>\n<li>由不同 <code>CNI</code> 定义的 Pod 间的通信网络</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Kubernetes 集群的客户端类型：  <ul>\n<li>Kubernetes 的 API Server 的客户端：<br>集群及项目管理人员、开发人员、集群中与 API Server 交互的组件  </li>\n<li>Kubernetes 的访问 Pod 的客户端：<br>集群外的普通用户、命名空间内的 Pod 应用（Pod Client）</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Kubernetes-集群的资源对象管理：\"><a href=\"#Kubernetes-集群的资源对象管理：\" class=\"headerlink\" title=\"Kubernetes 集群的资源对象管理：\"></a>Kubernetes 集群的资源对象管理：</h3><ul>\n<li>kubectl 命令管理资源对象的 3 种方式：  <ul>\n<li>陈述式命令：使用命令行选项管理  </li>\n<li>陈述式资源配置文件：使用 <code>kubectl create</code> 命令创建  </li>\n<li>声明式资源配置文件：使用 <code>kubectl apply</code> 命令创建</li>\n</ul>\n</li>\n<li>Kubernetes 使用 <code>Deployment</code> 资源对象（Pod 控制器）部署与管理前端无状态（<code>Stateless</code>）的 Pod 资源对象，而 Deployment 资源对象并不直接作用于 Pod 资源对象，而是使用 <code>ReplicaSet</code> 资源对象进行部署与管理。</li>\n<li>Deployment 资源对象是 ReplicaSet 资源对象之上的 Pod 控制器，两者都为工作负载型（workload）资源对象。</li>\n<li>使用 Deployment 资源对象部署的 Pod 资源对象都具有 <code>run=&lt;pod_controller_name&gt;</code> 的标签（label）。</li>\n<li>Pod 资源对象的名称：<code>&lt;replicaset_name&gt;-&lt;random_char&gt;</code><br><img src=\"pod-name.jpg\" alt=\"pod-name.jpg\"></li>\n<li>Pod资源对象的状态：<br>Pending、Running、Succeeded、Failed、Unknown</li>\n<li>Pod 容器日志信息管理：  <ul>\n<li>🐳 Kubernetes 集群中 Pod 容器日志信息默认以标准错误（<code>standard error</code>）输出至控制台，可使用 kubectl logs 命令查看容器日志信息。  </li>\n<li>必须使用集中式的日志收集系统管理 Pod 容器日志。  </li>\n<li>使用 kubectl logs 命令只能查看存在的 Pod 资源对象中的容器日志，不能查看已删除的Pod 资源对象日志。</li>\n</ul>\n</li>\n<li><p>Kubernetes 的 <code>API</code> 资源概述：  </p>\n<ul>\n<li>API Server 提供基于 <code>RESTful</code> 风格架构的编程接口，接收基于 <code>HTTP/HTTPS</code> 的客户端组件请求，并将其处理返回。  </li>\n<li>Kubernetes 的其他组件被抽象为标准的 REST 资源，可以使用标准的 <code>JSON</code> 序列化数据对 其管理与控制。  </li>\n<li>API 资源类型包括：    <ul>\n<li>对象类（Object）    </li>\n<li>列表类（List）    </li>\n<li>简单类（Simple）  </li>\n</ul>\n</li>\n<li>Kubernetes 中的 API 资源类型绝大多数以对象的方式存在，对象是资源运行时生成的实例，且为持久化的实体。  </li>\n<li>API 对应于资源类型的 <code>URI</code>，即资源类型的 <code>YAML</code> 配置文件中的 <code>selfLink</code> 字段，其状态存储于后端 etcd 数据库中。  <blockquote>\n<p>💥 Kubernetes v1.20 版本开始，默认删除了 <code>metadata.selfLink</code> 字段，然而，部分应用仍然依赖于该字段，如 <code>nfs-client-provisioner</code>。如果仍然要继续使用这些应用，需要重新启用该字段。  </p>\n</blockquote>\n</li>\n<li>🚀 若集群使用 <code>kubeadm</code> 组件部署，可修改控制平面（control plan）各节点的 <code>/etc/kubernetes/manifests/kube-apiserver.yaml</code> 文件，在其中添加 <code>--feature-gates=RemoveSelfLink=false</code> 选项以启用该字段，如下所示：<br><img src=\"kubernetes-apiserver-manifest.jpg\" alt=\"kubernetes-apiserver-manifest.jpg\">    <ul>\n<li>关于 selfLink 的说明可参考 <a href=\"https://kuboard.cn/install/faq/selfLink.html\" target=\"_blank\" rel=\"noopener\">该链接</a>    </li>\n<li>关于 kube-apiserver 命令的选项可参考 <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/\" target=\"_blank\" rel=\"noopener\">kube-apiserver 官方文档</a>  </li>\n</ul>\n</li>\n<li>Kubernetes 将 API 进行逻辑分组，称为 API 群组（API group）。  </li>\n<li>🚀 Kubernetes 的 API Server 支持相同的 API 群组中使用不同的版本，因此能在不同的版本中使用同名的资源类型，从而在稳定版本与新的实验版本中能以不同的特性使用同名的资源类型。  <blockquote>\n<p>关于 API 群组的分类与详细信息可参考 <a href=\"https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/\" target=\"_blank\" rel=\"noopener\">该链接</a>  </p>\n</blockquote>\n</li>\n<li><p>Kubernetes 的 API 层级结构：    </p>\n<ul>\n<li>核心 API 群组（core group）：      <ul>\n<li>REST 路径：<code>/api/v1</code>      </li>\n<li>资源配置文件中的字段：<code>apiVersion: v1</code>    </li>\n</ul>\n</li>\n<li>命名的 API 群组（named group）：      <ul>\n<li>REST 路径：<code>/apis/&lt;group_name&gt;/&lt;version&gt;</code>      </li>\n<li>资源配置文件中的字段：<code>apiVersion: &lt;group_name&gt;/&lt;version&gt;</code>    </li>\n</ul>\n</li>\n<li>命名空间级别的 REST API：      <ul>\n<li>REST 路径：<br><code>/apis/&lt;group_name&gt;/&lt;version&gt;/namespaces/&lt;namespace&gt;/&lt;resource_kind&gt;/&lt;object_name&gt;</code>      </li>\n<li>示例：<br><code>/apis/apps/v1/namespaces/default/deployments/nginx-deploy</code>    </li>\n</ul>\n</li>\n<li><p>访问 Kubernetes RESTful API 的方法：      </p>\n<ul>\n<li>kubectl get 命令行方式：<br><img src=\"kubectl-get-raw-json.jpg\" alt=\"kubectl-get-raw-json.jpg\">      </li>\n<li><p>kubectl proxy 命令行方式：        </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl proxy --port=&lt;port&gt;</span><br><span class=\"line\"><span class=\"comment\"># 启动本地主机为代理网关，使其能够访问 API Server 的 REST API，该端口不可被占用。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>kubectl proxy 方式使用 kubectl 打开本地 <code>unix socket</code>，使 curl 命令通过进程间通信（IPC）的方式与代理网关通信，实现与 API Server 的交互。        </p>\n</li>\n<li>Kubernetes 集群默认使用 <code>HTTPS</code> 的方式访问 API Server 的 REST API。        </li>\n<li>使用 kubectl proxy 命令启动本地主机为代理网关后，在另一终端中即可使用 curl 命令以 HTTP 的方式访问，如下所示：          <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl -s http://localhost:8080/api/v1/namespaces/default</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>Kubernetes 的 API 资源分类：  </p>\n<ul>\n<li>工作负载类型（workload）：    <ul>\n<li>ReplicationController（rc）    </li>\n<li>ReplicaSet    </li>\n<li>Deployment    </li>\n<li><code>StatefulSet</code>    </li>\n<li>DaemonSet    </li>\n<li>Job  </li>\n</ul>\n</li>\n<li>服务发现与负载均衡（Discovery &amp; LB）：    <ul>\n<li>Service    </li>\n<li><code>Ingress</code>  </li>\n</ul>\n</li>\n<li>配置与存储（Config &amp; Storage）：    <ul>\n<li>Secret    </li>\n<li><code>ConfigMap</code>    </li>\n<li>PersistentVolumeClaim（pvc）  </li>\n</ul>\n</li>\n<li>集群（Cluster）：    <ul>\n<li>Namespace    </li>\n<li>Node    </li>\n<li>Role、ClusterRole、ClusterRoleBinding、RoleBinding    </li>\n<li>PersistentVolume（pv）  </li>\n</ul>\n</li>\n<li>元数据（Metadata）：    <ul>\n<li><code>HorizontalPodAutoscaler</code>（HPA）    </li>\n<li>LimitRange</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Kubernetes 资源配置清单基础：  <ul>\n<li>Kubernetes 资源配置清单的主要一级字段：<br>apiVersion、kind、metadata、spec、status  </li>\n<li>其中 metadata、spec 与 status 为嵌套字段：    <ul>\n<li><code>metadata</code>：记录资源的元数据数据    </li>\n<li><code>spec</code>：记录资源的用户期望状态（desired）信息，由用户自定义并维护。    </li>\n<li><code>status</code>：      <ul>\n<li>记录活动对象的当前状态（实际状态），由 Kubernetes 自动填充并维护，对用户为只读字段。      <blockquote>\n<p>👉 活动对象是指由 Kubernetes 创建的资源对象。      </p>\n</blockquote>\n</li>\n<li>该字段记录的活动对象的状态应与 spec 字段的状态相同，或者两者无限接近。    </li>\n</ul>\n</li>\n<li>💥 Kubernetes 的 API Server 只能接收并响应 <code>JSON</code> 对象，YAML 格式的对象需经过 API Server 转换后才能被接收处理。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Kubernetes 资源管理方式：  <ul>\n<li>Kubernetes 的 API Server 支持声明式编程（<code>delarative programming</code>）与陈述式编程（<code>impreative programming</code>）。  </li>\n<li>推荐优先使用 <code>apply</code> 或 <code>patch</code> 命令的声明式对象配置。  </li>\n<li>可将不同资源类型的对象配置信息写在同一个资源配置清单中，并使用 <code>---</code> 符号将每个资源对象配置信息进行资源分割。  </li>\n<li>使用 <code>Git</code> 版本控制系统管理资源配置清单文件。</li>\n</ul>\n</li>\n<li>命名空间的资源管理：  <ul>\n<li>命名空间（namespace）通过将不同资源进行隔离，使命名空间的资源被不同的用户、租户与项目使用。  </li>\n<li>命名空间只隔离不同的资源，不隔离跨命名空间的 Pod 间的通信，因此单纯使用命名空间的隔离机制为软隔离，而对网络流量的隔离需要由网络策略（<code>network policy</code>）来实现。  <blockquote>\n<p>✅ 不同的 CNI 插件可提供不同的网络策略功能，如 Calico、OVS plugin 等。  </p>\n</blockquote>\n</li>\n<li>创建自定义的命名空间，如下所示：    <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl create namespace &lt;namespace_name&gt;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"资源对象操作相关命令：\"><a href=\"#资源对象操作相关命令：\" class=\"headerlink\" title=\"资源对象操作相关命令：\"></a>资源对象操作相关命令：</h3><ul>\n<li><p>API 版本与资源对象解释命令：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl --<span class=\"built_in\">help</span></span><br><span class=\"line\"><span class=\"comment\"># 查看 kubectl 命令的使用方法</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl api-versions</span><br><span class=\"line\"><span class=\"comment\"># 查看 API Server 支持的 API 版本，并以 group/version 的格式返回。</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl api-resources</span><br><span class=\"line\"><span class=\"comment\"># 查看 API Server 支持的 API 资源类型</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl explain &lt;resource_type&gt;</span><br><span class=\"line\"><span class=\"comment\"># 查看 API 资源类型的解释信息</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 示例 ###</span></span><br><span class=\"line\">$ kubectl explain pods.spec.containers.imagePullPolicy</span><br><span class=\"line\"><span class=\"comment\"># 查看 Pod 资源对象相关配置字段的详细信息</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>创建 <code>Deployment</code> 资源对象并运行 Pod：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl run &lt;deployment_name&gt; \\</span><br><span class=\"line\">  --image=&lt;image_name&gt;:&lt;tag&gt; --replicas=&lt;number&gt; --port=&lt;port&gt; \\</span><br><span class=\"line\">  -n &lt;namespace&gt;</span><br><span class=\"line\"><span class=\"comment\"># 陈述式命令创建 Deployment 资源对象</span></span><br><span class=\"line\"><span class=\"comment\"># 一般情况下，不直接创建 Pod 资源对象，而是通过 Pod 控制器创建并管理 Pod 对象。</span></span><br><span class=\"line\"><span class=\"comment\"># kubectl run 常用命令选项：kubectl run --help</span></span><br><span class=\"line\"><span class=\"comment\">#   --image=''                   Pod 资源对象中容器镜像的名称</span></span><br><span class=\"line\"><span class=\"comment\">#   --port=''                    Pod 资源对象中容器的端口号</span></span><br><span class=\"line\"><span class=\"comment\">#   --replicas=''                Pod 资源对象的副本数</span></span><br><span class=\"line\"><span class=\"comment\">#   --record=[false|true]        将当前的 kubectl 命令记录于资源对象的</span></span><br><span class=\"line\"><span class=\"comment\">#                                annotation 注释中</span></span><br><span class=\"line\"><span class=\"comment\">#   --save-config=[false|true]   将当前的资源对象配置信息记录于 annotation</span></span><br><span class=\"line\"><span class=\"comment\">#                                注释中，默认为 false，在使用 kubectl apply</span></span><br><span class=\"line\"><span class=\"comment\">#                                时有用。          </span></span><br><span class=\"line\"><span class=\"comment\">#  --restart=[Always|OnFailure|Never]</span></span><br><span class=\"line\"><span class=\"comment\">#                                Pod 资源对象的重启策略，默认为 Always。            </span></span><br><span class=\"line\"><span class=\"comment\">#  --dry-run=[false|true]        测试运行（干运行），默认为 false。</span></span><br><span class=\"line\"><span class=\"comment\">#  -n，--namespace=''            资源对象所在的命名空间</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 示例 ###</span></span><br><span class=\"line\">$ kubectl run nginx-deploy \\</span><br><span class=\"line\">  --image=nginx:v1.12 --replicas=2 --port=80 -n default</span><br><span class=\"line\"><span class=\"comment\"># 创建 Deployment 资源对象 nginx-deploy</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl run client \\</span><br><span class=\"line\">  --image=busybox:latest --restart=Never --replicas=1 \\</span><br><span class=\"line\">  -it -n default -- /bin/sh</span><br><span class=\"line\"><span class=\"comment\"># 指定 --restart=Never 选项时，只创建 Pod 资源对象 client 并进入 Pod 交互式界面。             </span></span><br><span class=\"line\"><span class=\"comment\"># 退出交互式界面后，终止 Pod 资源对象运行，并进入 Completed 状态。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>创建 Service 资源对象与暴露应用端口：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl expose deployment &lt;deployment_name&gt; \\</span><br><span class=\"line\">  --name=&lt;service_name&gt; --port=&lt;port&gt; --target-port=&lt;port_num&gt; \\</span><br><span class=\"line\">  -n &lt;namespace&gt;</span><br><span class=\"line\"><span class=\"comment\"># 创建 Service 资源对象，对外暴露并关联 Pod 资源对象的 Pod IP 与端口。</span></span><br><span class=\"line\"><span class=\"comment\"># kubectl expose 常用命令选项：kubectl expose --help</span></span><br><span class=\"line\"><span class=\"comment\">#   --name=''                创建的 Service 资源对象名称</span></span><br><span class=\"line\"><span class=\"comment\">#   --port=''                Service 资源对象的端口号</span></span><br><span class=\"line\"><span class=\"comment\">#   --target-port=''         Service 资源对象关联的后端 Pod 资源对象的端口号</span></span><br><span class=\"line\"><span class=\"comment\">#   -n，--namespace=''       资源对象所在的命名空间</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 示例 ###</span></span><br><span class=\"line\">$ kubectl expose deployment nginx-deploy \\</span><br><span class=\"line\">  --name=nginx-svc --port=8080 --target-port=80 -n default</span><br><span class=\"line\"><span class=\"comment\"># 创建名称为 nginx-svc 的 Service 资源对象</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>查看与操作相关资源对象：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get pods,services -n &lt;namespace&gt; -o wide</span><br><span class=\"line\"><span class=\"comment\"># 查看命名空间中 Pod 与 Service 资源对象的详细信息（逗号分隔）</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get &lt;resource_type&gt; \\</span><br><span class=\"line\">  -n &lt;namespace&gt; -o &#123;yaml|json|jsonpath|wide|custom-columns=...&#125;</span><br><span class=\"line\"><span class=\"comment\"># 查看命名空间中的资源对象信息，并以 YAML、JSON、完整格式或自定义格式输出。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 示例 ###</span></span><br><span class=\"line\">$ kubectl get pods \\</span><br><span class=\"line\">  -o custom-columns=NAME:metadata.name,STATUS:status.phase </span><br><span class=\"line\">  -n kube-system</span><br><span class=\"line\"><span class=\"comment\"># 查看 kube-system 命名空间中 Pod 资源对象的名称与状态信息，以自定义格式输出。</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl logs &lt;pod_name&gt; [-c &lt;container_name&gt;] -n &lt;namespace&gt;</span><br><span class=\"line\"><span class=\"comment\"># 查看命名空间中 Pod 资源对象中的容器日志信息</span></span><br><span class=\"line\"><span class=\"comment\"># Pod 资源对象中存在多个容器时，使用 -c 选项指定容器。</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl <span class=\"built_in\">exec</span> &lt;pod_name&gt; \\</span><br><span class=\"line\">  [-c &lt;container_name&gt;] -n &lt;namespace&gt; -- &lt;<span class=\"built_in\">command</span>&gt; &lt;opts&gt; &lt;args...&gt;</span><br><span class=\"line\"><span class=\"comment\"># 执行命名空间中 Pod 资源对象中的命令</span></span><br><span class=\"line\"><span class=\"comment\"># Pod 资源对象中存在多个容器时，使用 -c 选项指定容器。</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl delete \\</span><br><span class=\"line\">  &lt;resource_type&gt; &lt;resource_name&gt; -l &lt;key&gt;=&lt;value&gt; -n &lt;namespace&gt;</span><br><span class=\"line\"><span class=\"comment\"># 删除命名空间中具有指定标签的资源对象</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 示例 ###</span></span><br><span class=\"line\">$ kubectl delete deployment myapp --cascade=<span class=\"literal\">false</span> -n default</span><br><span class=\"line\"><span class=\"comment\"># 删除 default 命名空间中名为 myapp 的 Deployment 资源对象，但不删除其创建的 Pod。    </span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl create -f &lt;file&gt;.yaml|&lt;dir&gt;|&lt;url&gt;</span><br><span class=\"line\"><span class=\"comment\"># 使用陈述式命令 create 创建不同的 API 资源对象</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl apply -f &lt;file&gt;.yaml|&lt;dir&gt;|&lt;url&gt; </span><br><span class=\"line\"><span class=\"comment\"># 使用声明式命令 apply 创建、更新与替换不同的 API 资源对象</span></span><br><span class=\"line\"><span class=\"comment\"># 注意：</span></span><br><span class=\"line\"><span class=\"comment\">#   1. 声明式对象配置管理具有高级的补丁更新机制，将相应的配置信息记录于 annotation 注释中。</span></span><br><span class=\"line\"><span class=\"comment\">#   2. Kubernetes 建议使用声明式对象配置方式！ </span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl delete -f &lt;file&gt;.yaml</span><br><span class=\"line\"><span class=\"comment\"># 删除该 YAML 配置文件创建的 API 资源对象</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl scale deployment &lt;deployment_name&gt; --replicas=&lt;number&gt; -n &lt;namespace&gt;</span><br><span class=\"line\"><span class=\"comment\"># 指定命名空间中扩容或缩容 Pod 资源对象的副本数目</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 示例 ###</span></span><br><span class=\"line\">$ kubectl scale deployment myapp --replicas=3 -n default</span><br><span class=\"line\"><span class=\"comment\"># 指定 default 命名空间中扩容或缩容 Pod 资源对象的副本数目为 3 个</span></span><br><span class=\"line\"><span class=\"comment\"># 注意：</span></span><br><span class=\"line\"><span class=\"comment\">#   扩容或缩容 Pod 资源对象副本数目的方法：</span></span><br><span class=\"line\"><span class=\"comment\">#   1. 通过该命令行方式进行扩容或缩容</span></span><br><span class=\"line\"><span class=\"comment\">#   2. 使用如下命令更改 Deployment 资源对象的配置信息，更改后实时生效：</span></span><br><span class=\"line\"><span class=\"comment\">#      $ kubectl edit deployment myapp -n default</span></span><br></pre></td></tr></table></figure></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li>该文档使用的 Kubernetes 版本为 <code>1.12.x</code></li>\n<li>文档所示的命令可能与当前 Kubernetes 版本存在差异，请以实际使用的版本为基准！</li>\n</ul>\n<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>Kubernetes 集群架构概览</li>\n<li>Kubernetes 集群的资源对象管理</li>\n<li>资源对象操作相关命令</li>\n</ul>\n<h3 id=\"Kubernetes-集群架构概览：\"><a href=\"#Kubernetes-集群架构概览：\" class=\"headerlink\" title=\"Kubernetes 集群架构概览：\"></a>Kubernetes 集群架构概览：</h3><ul>\n<li><code>API Server</code> 作为 Kubernetes 集群的网关（gateway）</li>\n<li><code>etcd</code> 键值型数据库作为 Kubernetes 集群的核心数据库</li>\n<li>Kubernetes 集群可部署为单 master 集群或多 master（常见为 3 个）的 HA 集群  <ul>\n<li>单 master 节点的 Kubernetes 集群架构示意：<br><img src=\"kubernetes-single-master-arch.jpg\" alt=\"kubernetes-single-master-arch.jpg\">  </li>\n<li>多 master 节点的 Kubernetes 集群架构示意：<br><img src=\"kubernetes-ha-arch-demo.jpg\" alt=\"kubernetes-ha-arch-demo.jpg\">  <blockquote>\n<p>👉 该示例中将 etcd 集群分别部署于 3 个 master 节点上。</p>\n</blockquote>\n</li>\n</ul>\n</li>\n<li>Kubernetes 中的接口规范：  <ul>\n<li><code>CRI</code>：Container Runtime Interface（容器运行时接口）  </li>\n<li><code>gRPC</code>：Google Remote Process Call（Google 发布的远程过程调用框架）  </li>\n<li><code>OCI</code>：Open Container Initiative（开放容器标准）  </li>\n<li><code>CNI</code>：Container Network Interface（容器网络接口）  </li>\n<li><code>CSI</code>：Container Storage Interface（容器存储接口）  </li>\n<li>以上各接口规范在集群中组件之间的调用示意：<br><img src=\"kubernetes-interface-1.jpg\" alt=\"kubernetes-interface-1.jpg\"><img src=\"kubernetes-interface-2.jpg\" alt=\"kubernetes-interface-2.jpg\"></li>\n</ul>\n</li>\n<li>Kubernetes 集群中的网络概述：  <ul>\n<li>集群中的通信种类：    <ul>\n<li>同一 Pod 资源对象中容器间的通信    </li>\n<li>各 Pod 资源对象彼此间的通信    <blockquote>\n<p>👉 Pod 间在同一节点上通信或彼此跨节点间通信    </p>\n</blockquote>\n</li>\n<li>Pod 资源对象与 Service 资源对象间的通信    </li>\n<li>集群外部的流量与 Service 资源对象间的通信  </li>\n</ul>\n</li>\n<li>集群网络规划部署：    <ul>\n<li>Kubernetes 集群主机间的网络    </li>\n<li>Service 资源对象定义的 <code>ClusterIP</code> 网络    </li>\n<li>由不同 <code>CNI</code> 定义的 Pod 间的通信网络</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Kubernetes 集群的客户端类型：  <ul>\n<li>Kubernetes 的 API Server 的客户端：<br>集群及项目管理人员、开发人员、集群中与 API Server 交互的组件  </li>\n<li>Kubernetes 的访问 Pod 的客户端：<br>集群外的普通用户、命名空间内的 Pod 应用（Pod Client）</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Kubernetes-集群的资源对象管理：\"><a href=\"#Kubernetes-集群的资源对象管理：\" class=\"headerlink\" title=\"Kubernetes 集群的资源对象管理：\"></a>Kubernetes 集群的资源对象管理：</h3><ul>\n<li>kubectl 命令管理资源对象的 3 种方式：  <ul>\n<li>陈述式命令：使用命令行选项管理  </li>\n<li>陈述式资源配置文件：使用 <code>kubectl create</code> 命令创建  </li>\n<li>声明式资源配置文件：使用 <code>kubectl apply</code> 命令创建</li>\n</ul>\n</li>\n<li>Kubernetes 使用 <code>Deployment</code> 资源对象（Pod 控制器）部署与管理前端无状态（<code>Stateless</code>）的 Pod 资源对象，而 Deployment 资源对象并不直接作用于 Pod 资源对象，而是使用 <code>ReplicaSet</code> 资源对象进行部署与管理。</li>\n<li>Deployment 资源对象是 ReplicaSet 资源对象之上的 Pod 控制器，两者都为工作负载型（workload）资源对象。</li>\n<li>使用 Deployment 资源对象部署的 Pod 资源对象都具有 <code>run=&lt;pod_controller_name&gt;</code> 的标签（label）。</li>\n<li>Pod 资源对象的名称：<code>&lt;replicaset_name&gt;-&lt;random_char&gt;</code><br><img src=\"pod-name.jpg\" alt=\"pod-name.jpg\"></li>\n<li>Pod资源对象的状态：<br>Pending、Running、Succeeded、Failed、Unknown</li>\n<li>Pod 容器日志信息管理：  <ul>\n<li>🐳 Kubernetes 集群中 Pod 容器日志信息默认以标准错误（<code>standard error</code>）输出至控制台，可使用 kubectl logs 命令查看容器日志信息。  </li>\n<li>必须使用集中式的日志收集系统管理 Pod 容器日志。  </li>\n<li>使用 kubectl logs 命令只能查看存在的 Pod 资源对象中的容器日志，不能查看已删除的Pod 资源对象日志。</li>\n</ul>\n</li>\n<li><p>Kubernetes 的 <code>API</code> 资源概述：  </p>\n<ul>\n<li>API Server 提供基于 <code>RESTful</code> 风格架构的编程接口，接收基于 <code>HTTP/HTTPS</code> 的客户端组件请求，并将其处理返回。  </li>\n<li>Kubernetes 的其他组件被抽象为标准的 REST 资源，可以使用标准的 <code>JSON</code> 序列化数据对 其管理与控制。  </li>\n<li>API 资源类型包括：    <ul>\n<li>对象类（Object）    </li>\n<li>列表类（List）    </li>\n<li>简单类（Simple）  </li>\n</ul>\n</li>\n<li>Kubernetes 中的 API 资源类型绝大多数以对象的方式存在，对象是资源运行时生成的实例，且为持久化的实体。  </li>\n<li>API 对应于资源类型的 <code>URI</code>，即资源类型的 <code>YAML</code> 配置文件中的 <code>selfLink</code> 字段，其状态存储于后端 etcd 数据库中。  <blockquote>\n<p>💥 Kubernetes v1.20 版本开始，默认删除了 <code>metadata.selfLink</code> 字段，然而，部分应用仍然依赖于该字段，如 <code>nfs-client-provisioner</code>。如果仍然要继续使用这些应用，需要重新启用该字段。  </p>\n</blockquote>\n</li>\n<li>🚀 若集群使用 <code>kubeadm</code> 组件部署，可修改控制平面（control plan）各节点的 <code>/etc/kubernetes/manifests/kube-apiserver.yaml</code> 文件，在其中添加 <code>--feature-gates=RemoveSelfLink=false</code> 选项以启用该字段，如下所示：<br><img src=\"kubernetes-apiserver-manifest.jpg\" alt=\"kubernetes-apiserver-manifest.jpg\">    <ul>\n<li>关于 selfLink 的说明可参考 <a href=\"https://kuboard.cn/install/faq/selfLink.html\" target=\"_blank\" rel=\"noopener\">该链接</a>    </li>\n<li>关于 kube-apiserver 命令的选项可参考 <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/\" target=\"_blank\" rel=\"noopener\">kube-apiserver 官方文档</a>  </li>\n</ul>\n</li>\n<li>Kubernetes 将 API 进行逻辑分组，称为 API 群组（API group）。  </li>\n<li>🚀 Kubernetes 的 API Server 支持相同的 API 群组中使用不同的版本，因此能在不同的版本中使用同名的资源类型，从而在稳定版本与新的实验版本中能以不同的特性使用同名的资源类型。  <blockquote>\n<p>关于 API 群组的分类与详细信息可参考 <a href=\"https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/\" target=\"_blank\" rel=\"noopener\">该链接</a>  </p>\n</blockquote>\n</li>\n<li><p>Kubernetes 的 API 层级结构：    </p>\n<ul>\n<li>核心 API 群组（core group）：      <ul>\n<li>REST 路径：<code>/api/v1</code>      </li>\n<li>资源配置文件中的字段：<code>apiVersion: v1</code>    </li>\n</ul>\n</li>\n<li>命名的 API 群组（named group）：      <ul>\n<li>REST 路径：<code>/apis/&lt;group_name&gt;/&lt;version&gt;</code>      </li>\n<li>资源配置文件中的字段：<code>apiVersion: &lt;group_name&gt;/&lt;version&gt;</code>    </li>\n</ul>\n</li>\n<li>命名空间级别的 REST API：      <ul>\n<li>REST 路径：<br><code>/apis/&lt;group_name&gt;/&lt;version&gt;/namespaces/&lt;namespace&gt;/&lt;resource_kind&gt;/&lt;object_name&gt;</code>      </li>\n<li>示例：<br><code>/apis/apps/v1/namespaces/default/deployments/nginx-deploy</code>    </li>\n</ul>\n</li>\n<li><p>访问 Kubernetes RESTful API 的方法：      </p>\n<ul>\n<li>kubectl get 命令行方式：<br><img src=\"kubectl-get-raw-json.jpg\" alt=\"kubectl-get-raw-json.jpg\">      </li>\n<li><p>kubectl proxy 命令行方式：        </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl proxy --port=&lt;port&gt;</span><br><span class=\"line\"><span class=\"comment\"># 启动本地主机为代理网关，使其能够访问 API Server 的 REST API，该端口不可被占用。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>kubectl proxy 方式使用 kubectl 打开本地 <code>unix socket</code>，使 curl 命令通过进程间通信（IPC）的方式与代理网关通信，实现与 API Server 的交互。        </p>\n</li>\n<li>Kubernetes 集群默认使用 <code>HTTPS</code> 的方式访问 API Server 的 REST API。        </li>\n<li>使用 kubectl proxy 命令启动本地主机为代理网关后，在另一终端中即可使用 curl 命令以 HTTP 的方式访问，如下所示：          <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl -s http://localhost:8080/api/v1/namespaces/default</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>Kubernetes 的 API 资源分类：  </p>\n<ul>\n<li>工作负载类型（workload）：    <ul>\n<li>ReplicationController（rc）    </li>\n<li>ReplicaSet    </li>\n<li>Deployment    </li>\n<li><code>StatefulSet</code>    </li>\n<li>DaemonSet    </li>\n<li>Job  </li>\n</ul>\n</li>\n<li>服务发现与负载均衡（Discovery &amp; LB）：    <ul>\n<li>Service    </li>\n<li><code>Ingress</code>  </li>\n</ul>\n</li>\n<li>配置与存储（Config &amp; Storage）：    <ul>\n<li>Secret    </li>\n<li><code>ConfigMap</code>    </li>\n<li>PersistentVolumeClaim（pvc）  </li>\n</ul>\n</li>\n<li>集群（Cluster）：    <ul>\n<li>Namespace    </li>\n<li>Node    </li>\n<li>Role、ClusterRole、ClusterRoleBinding、RoleBinding    </li>\n<li>PersistentVolume（pv）  </li>\n</ul>\n</li>\n<li>元数据（Metadata）：    <ul>\n<li><code>HorizontalPodAutoscaler</code>（HPA）    </li>\n<li>LimitRange</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Kubernetes 资源配置清单基础：  <ul>\n<li>Kubernetes 资源配置清单的主要一级字段：<br>apiVersion、kind、metadata、spec、status  </li>\n<li>其中 metadata、spec 与 status 为嵌套字段：    <ul>\n<li><code>metadata</code>：记录资源的元数据数据    </li>\n<li><code>spec</code>：记录资源的用户期望状态（desired）信息，由用户自定义并维护。    </li>\n<li><code>status</code>：      <ul>\n<li>记录活动对象的当前状态（实际状态），由 Kubernetes 自动填充并维护，对用户为只读字段。      <blockquote>\n<p>👉 活动对象是指由 Kubernetes 创建的资源对象。      </p>\n</blockquote>\n</li>\n<li>该字段记录的活动对象的状态应与 spec 字段的状态相同，或者两者无限接近。    </li>\n</ul>\n</li>\n<li>💥 Kubernetes 的 API Server 只能接收并响应 <code>JSON</code> 对象，YAML 格式的对象需经过 API Server 转换后才能被接收处理。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Kubernetes 资源管理方式：  <ul>\n<li>Kubernetes 的 API Server 支持声明式编程（<code>delarative programming</code>）与陈述式编程（<code>impreative programming</code>）。  </li>\n<li>推荐优先使用 <code>apply</code> 或 <code>patch</code> 命令的声明式对象配置。  </li>\n<li>可将不同资源类型的对象配置信息写在同一个资源配置清单中，并使用 <code>---</code> 符号将每个资源对象配置信息进行资源分割。  </li>\n<li>使用 <code>Git</code> 版本控制系统管理资源配置清单文件。</li>\n</ul>\n</li>\n<li>命名空间的资源管理：  <ul>\n<li>命名空间（namespace）通过将不同资源进行隔离，使命名空间的资源被不同的用户、租户与项目使用。  </li>\n<li>命名空间只隔离不同的资源，不隔离跨命名空间的 Pod 间的通信，因此单纯使用命名空间的隔离机制为软隔离，而对网络流量的隔离需要由网络策略（<code>network policy</code>）来实现。  <blockquote>\n<p>✅ 不同的 CNI 插件可提供不同的网络策略功能，如 Calico、OVS plugin 等。  </p>\n</blockquote>\n</li>\n<li>创建自定义的命名空间，如下所示：    <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl create namespace &lt;namespace_name&gt;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"资源对象操作相关命令：\"><a href=\"#资源对象操作相关命令：\" class=\"headerlink\" title=\"资源对象操作相关命令：\"></a>资源对象操作相关命令：</h3><ul>\n<li><p>API 版本与资源对象解释命令：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl --<span class=\"built_in\">help</span></span><br><span class=\"line\"><span class=\"comment\"># 查看 kubectl 命令的使用方法</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl api-versions</span><br><span class=\"line\"><span class=\"comment\"># 查看 API Server 支持的 API 版本，并以 group/version 的格式返回。</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl api-resources</span><br><span class=\"line\"><span class=\"comment\"># 查看 API Server 支持的 API 资源类型</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl explain &lt;resource_type&gt;</span><br><span class=\"line\"><span class=\"comment\"># 查看 API 资源类型的解释信息</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 示例 ###</span></span><br><span class=\"line\">$ kubectl explain pods.spec.containers.imagePullPolicy</span><br><span class=\"line\"><span class=\"comment\"># 查看 Pod 资源对象相关配置字段的详细信息</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>创建 <code>Deployment</code> 资源对象并运行 Pod：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl run &lt;deployment_name&gt; \\</span><br><span class=\"line\">  --image=&lt;image_name&gt;:&lt;tag&gt; --replicas=&lt;number&gt; --port=&lt;port&gt; \\</span><br><span class=\"line\">  -n &lt;namespace&gt;</span><br><span class=\"line\"><span class=\"comment\"># 陈述式命令创建 Deployment 资源对象</span></span><br><span class=\"line\"><span class=\"comment\"># 一般情况下，不直接创建 Pod 资源对象，而是通过 Pod 控制器创建并管理 Pod 对象。</span></span><br><span class=\"line\"><span class=\"comment\"># kubectl run 常用命令选项：kubectl run --help</span></span><br><span class=\"line\"><span class=\"comment\">#   --image=''                   Pod 资源对象中容器镜像的名称</span></span><br><span class=\"line\"><span class=\"comment\">#   --port=''                    Pod 资源对象中容器的端口号</span></span><br><span class=\"line\"><span class=\"comment\">#   --replicas=''                Pod 资源对象的副本数</span></span><br><span class=\"line\"><span class=\"comment\">#   --record=[false|true]        将当前的 kubectl 命令记录于资源对象的</span></span><br><span class=\"line\"><span class=\"comment\">#                                annotation 注释中</span></span><br><span class=\"line\"><span class=\"comment\">#   --save-config=[false|true]   将当前的资源对象配置信息记录于 annotation</span></span><br><span class=\"line\"><span class=\"comment\">#                                注释中，默认为 false，在使用 kubectl apply</span></span><br><span class=\"line\"><span class=\"comment\">#                                时有用。          </span></span><br><span class=\"line\"><span class=\"comment\">#  --restart=[Always|OnFailure|Never]</span></span><br><span class=\"line\"><span class=\"comment\">#                                Pod 资源对象的重启策略，默认为 Always。            </span></span><br><span class=\"line\"><span class=\"comment\">#  --dry-run=[false|true]        测试运行（干运行），默认为 false。</span></span><br><span class=\"line\"><span class=\"comment\">#  -n，--namespace=''            资源对象所在的命名空间</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 示例 ###</span></span><br><span class=\"line\">$ kubectl run nginx-deploy \\</span><br><span class=\"line\">  --image=nginx:v1.12 --replicas=2 --port=80 -n default</span><br><span class=\"line\"><span class=\"comment\"># 创建 Deployment 资源对象 nginx-deploy</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl run client \\</span><br><span class=\"line\">  --image=busybox:latest --restart=Never --replicas=1 \\</span><br><span class=\"line\">  -it -n default -- /bin/sh</span><br><span class=\"line\"><span class=\"comment\"># 指定 --restart=Never 选项时，只创建 Pod 资源对象 client 并进入 Pod 交互式界面。             </span></span><br><span class=\"line\"><span class=\"comment\"># 退出交互式界面后，终止 Pod 资源对象运行，并进入 Completed 状态。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>创建 Service 资源对象与暴露应用端口：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl expose deployment &lt;deployment_name&gt; \\</span><br><span class=\"line\">  --name=&lt;service_name&gt; --port=&lt;port&gt; --target-port=&lt;port_num&gt; \\</span><br><span class=\"line\">  -n &lt;namespace&gt;</span><br><span class=\"line\"><span class=\"comment\"># 创建 Service 资源对象，对外暴露并关联 Pod 资源对象的 Pod IP 与端口。</span></span><br><span class=\"line\"><span class=\"comment\"># kubectl expose 常用命令选项：kubectl expose --help</span></span><br><span class=\"line\"><span class=\"comment\">#   --name=''                创建的 Service 资源对象名称</span></span><br><span class=\"line\"><span class=\"comment\">#   --port=''                Service 资源对象的端口号</span></span><br><span class=\"line\"><span class=\"comment\">#   --target-port=''         Service 资源对象关联的后端 Pod 资源对象的端口号</span></span><br><span class=\"line\"><span class=\"comment\">#   -n，--namespace=''       资源对象所在的命名空间</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 示例 ###</span></span><br><span class=\"line\">$ kubectl expose deployment nginx-deploy \\</span><br><span class=\"line\">  --name=nginx-svc --port=8080 --target-port=80 -n default</span><br><span class=\"line\"><span class=\"comment\"># 创建名称为 nginx-svc 的 Service 资源对象</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>查看与操作相关资源对象：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get pods,services -n &lt;namespace&gt; -o wide</span><br><span class=\"line\"><span class=\"comment\"># 查看命名空间中 Pod 与 Service 资源对象的详细信息（逗号分隔）</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get &lt;resource_type&gt; \\</span><br><span class=\"line\">  -n &lt;namespace&gt; -o &#123;yaml|json|jsonpath|wide|custom-columns=...&#125;</span><br><span class=\"line\"><span class=\"comment\"># 查看命名空间中的资源对象信息，并以 YAML、JSON、完整格式或自定义格式输出。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 示例 ###</span></span><br><span class=\"line\">$ kubectl get pods \\</span><br><span class=\"line\">  -o custom-columns=NAME:metadata.name,STATUS:status.phase </span><br><span class=\"line\">  -n kube-system</span><br><span class=\"line\"><span class=\"comment\"># 查看 kube-system 命名空间中 Pod 资源对象的名称与状态信息，以自定义格式输出。</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl logs &lt;pod_name&gt; [-c &lt;container_name&gt;] -n &lt;namespace&gt;</span><br><span class=\"line\"><span class=\"comment\"># 查看命名空间中 Pod 资源对象中的容器日志信息</span></span><br><span class=\"line\"><span class=\"comment\"># Pod 资源对象中存在多个容器时，使用 -c 选项指定容器。</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl <span class=\"built_in\">exec</span> &lt;pod_name&gt; \\</span><br><span class=\"line\">  [-c &lt;container_name&gt;] -n &lt;namespace&gt; -- &lt;<span class=\"built_in\">command</span>&gt; &lt;opts&gt; &lt;args...&gt;</span><br><span class=\"line\"><span class=\"comment\"># 执行命名空间中 Pod 资源对象中的命令</span></span><br><span class=\"line\"><span class=\"comment\"># Pod 资源对象中存在多个容器时，使用 -c 选项指定容器。</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl delete \\</span><br><span class=\"line\">  &lt;resource_type&gt; &lt;resource_name&gt; -l &lt;key&gt;=&lt;value&gt; -n &lt;namespace&gt;</span><br><span class=\"line\"><span class=\"comment\"># 删除命名空间中具有指定标签的资源对象</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 示例 ###</span></span><br><span class=\"line\">$ kubectl delete deployment myapp --cascade=<span class=\"literal\">false</span> -n default</span><br><span class=\"line\"><span class=\"comment\"># 删除 default 命名空间中名为 myapp 的 Deployment 资源对象，但不删除其创建的 Pod。    </span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl create -f &lt;file&gt;.yaml|&lt;dir&gt;|&lt;url&gt;</span><br><span class=\"line\"><span class=\"comment\"># 使用陈述式命令 create 创建不同的 API 资源对象</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl apply -f &lt;file&gt;.yaml|&lt;dir&gt;|&lt;url&gt; </span><br><span class=\"line\"><span class=\"comment\"># 使用声明式命令 apply 创建、更新与替换不同的 API 资源对象</span></span><br><span class=\"line\"><span class=\"comment\"># 注意：</span></span><br><span class=\"line\"><span class=\"comment\">#   1. 声明式对象配置管理具有高级的补丁更新机制，将相应的配置信息记录于 annotation 注释中。</span></span><br><span class=\"line\"><span class=\"comment\">#   2. Kubernetes 建议使用声明式对象配置方式！ </span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl delete -f &lt;file&gt;.yaml</span><br><span class=\"line\"><span class=\"comment\"># 删除该 YAML 配置文件创建的 API 资源对象</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl scale deployment &lt;deployment_name&gt; --replicas=&lt;number&gt; -n &lt;namespace&gt;</span><br><span class=\"line\"><span class=\"comment\"># 指定命名空间中扩容或缩容 Pod 资源对象的副本数目</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 示例 ###</span></span><br><span class=\"line\">$ kubectl scale deployment myapp --replicas=3 -n default</span><br><span class=\"line\"><span class=\"comment\"># 指定 default 命名空间中扩容或缩容 Pod 资源对象的副本数目为 3 个</span></span><br><span class=\"line\"><span class=\"comment\"># 注意：</span></span><br><span class=\"line\"><span class=\"comment\">#   扩容或缩容 Pod 资源对象副本数目的方法：</span></span><br><span class=\"line\"><span class=\"comment\">#   1. 通过该命令行方式进行扩容或缩容</span></span><br><span class=\"line\"><span class=\"comment\">#   2. 使用如下命令更改 Deployment 资源对象的配置信息，更改后实时生效：</span></span><br><span class=\"line\"><span class=\"comment\">#      $ kubectl edit deployment myapp -n default</span></span><br></pre></td></tr></table></figure></li>\n</ul>\n"},{"title":"Linux 进程权限的各类 UID 探讨","subtitle":"Linux Process UID Analyse","date":"2023-01-28T07:30:30.000Z","header-img":"linux-process_bg.jpg","_content":"\n### 文档说明：\n- OS 版本：`Ubuntu 20.04.3 LTS`\n- kernel 版本：`5.15.0-57-generic`\n- Linux 中各类 UID 的联系与区别对于理解进程权限与 Audit 审计系统发挥至关重要的作用，这些 UID 作为进程凭证。\n- ✍ 可参考 `man 7 credentials` 手册中的说明加以理解。\n\n### 文档目录：\n- 各类 UID 的解析\n- ruid、euid 与 Saved set-user-ID 间的关系\n- ruid 与 euid 的验证示例\n- 各类 UID 在 Audit 审计系统中的说明\n- 参考链接\n\n### 各类 UID 的解析：\n- user ID：  \n  - 常规 Linux 用户 ID，作为系统中用户的唯一识别符。\n- Real user ID（`ruid`）：  \n  - 真实用户 ID  \n  - 🤘 ruid 为拥有当前进程的用户 ID，即调用该可执行文件的用户。  \n  - 一般情况下，最初登录 Shell 的 user ID 与 ruid 相同，但是该登录用户有可能通过 su 或 sudo 提权为其他非特权用户或特权用户，此时的 ruid 与最初的登录 user ID 不同。\n- Effective user ID（`euid`）：  \n  - 有效用户 ID  \n  - 🤘 euid 被内核使用确定进程可访问资源的权限  \n  - 进程的权限由保存在 euid 中的 UID 来决定  \n  - 通常而言，进程的 ruid 与 euid 保持一致，ruid 与 euid 对进程而言。  \n  - euid 临时存储了另一个用户的 UID  \n  - 🚀 euid 在使用系统调用与执行 set-user-ID 程序或 set-group-ID 程序时被修改。  \n  - 也就是说，set-user-ID 程序或 set-group-ID 程序的可执行文件其本身也需要设置 set-user-ID 权限位（bit）后，euid 被更改为与可执行文件的所有者（owner）UID 相同，而未设置 set-user-ID 权限位（bit）的可执行文件，euid 依然与 ruid 保持一致，可参见下文 \"ruid 与 euid 的验证示例\" 部分。  \n  - set-user-ID 权限位指的是 Linux 中的特殊权限 suid\n  - privileged 在不同的上下文中需加以辨别，可能是特权用户 root，也可能是其他普通用户。\n\n- Saved set-user-ID：  \n  - 保存设置用户 ID  \n  - 🚀 该 ID 相当于一个 `buffer`，在进程启动后，它会从 euid 拷贝信息到自身。对于非 root 用户，可以在未来使用 `setuid()` 系统调用来将 euid 设置成为 ruid 和 saved set-user-ID 中的任何一个。但是非 root 用户是不允许用 setuid() 将 euid 设置成为任何第三个 user ID。\n- Audit user ID（`auid`）：  \n  - 审计用户 ID，用于记录 Linux Audit 审计系统中的用户标识。  \n  - auid 为最初登录 Shell 的的用户 ID\n\n### ruid、euid 与 Saved set-user-ID 间的关系：\n- 进程启动过程中三者的赋值关系，如下图所示：![](linux-process-uid-mapping.png)  \n  - 1️⃣2️⃣ 假定最初登录 Shell 的用户启动运行可执行文件，启动进程。  \n  - 3️⃣ 设置进程的 `ruid/rgid` 为当前用户的 uid/gid  \n  - 4️⃣ 设置进程的 `euid/egid`，根据可执行文件的 `set-user-ID` 与 `set-group-ID` 权限位进行设置，图中红色 0 表示关闭，紫色 1 表示开启。为 1 时，将进程的 euid/egid 设置为可执行文件的 uid/gid，否则从 ruid/rgid 拷贝。\n- 以上过程可总结为下表：![](linux-process-uid-table.png)\n\n### 🚀 ruid 与 euid 的验证示例：\n- 需要注意的是 Linux 系统中 set-user-ID 与 set-group-ID 权限位对 shell 脚本无效，如下 [process-cred-sample.c](https://github.com/Alberthua-Perl/scripts-confs/blob/master/ruid-euid-suid-test/process-cred-sample.c) 程序所示：  \n  ```c\n  #define _GNU_SOURCE\n  #include <stdio.h>\n  #include <stdlib.h>\n  #include <unistd.h>\n  #include <sys/types.h>\n  \n  int main()\n  {\n      uid_t ruid, euid, suid;\n      getresuid(&ruid, &euid, &suid);\n      printf(\"RUID: %d, EUID: %d, SUID: %d\\n\", ruid, euid, suid);\n      system(\"cat file-read-only-by-sysadmin\");  // file-read-only-by-sysadmin: -r-------- sysadmin sysadmin\n      setreuid(geteuid(), geteuid());  // use euid to set ruid\n      getresuid(&ruid, &euid, &suid);\n      printf(\"RUID: %d, EUID: %d, SUID: %d\\n\", ruid, euid, suid);\n      system(\"cat file-read-only-by-sysadmin\");  // file-read-only-by-sysadmin: -r-------- sysadmin sysadmin\n      return 0;\n  }\n  ```\n  以上程序中获取当前进程的 ruid、euid 与 suid，但是 `system()` 函数调用了 shell 脚本，即使将该可执行文件的 set-user-ID 权限位开启也无法使用此权限位：\n  ```bash\n  $ id\n    uid=1000(godev) gid=1000(godev) groups=1000(godev)\n  # 笔者示例使用 godev 普通用户验证\n  $ id -u sysadmin\n    1001\n  $ ls -lh file-read-only-by-sysadmin \n    -r-------- 1 sysadmin sysadmin 5 Jan 24 17:08 file-read-only-by-sysadmin\n  # 当前目录中先创建该文件，其中 Test 作为文本内容。\n  $ gcc -o process-cred-sample process-cred-sample.c\n  $ sudo chown sysadmin:godev process-cred-sample\n  # 更改可执行程序的所有者，sysadmin 为系统上的另一个普通用户。\n  $ ./process-cred-sample\n    RUID: 1000, EUID: 1000, SUID: 1000\n    cat: file-read-only-by-sysadmin: Permission denied\n    RUID: 1000, EUID: 1000, SUID: 1000\n    cat: file-read-only-by-sysadmin: Permission denied\n  # 由于可执行文件不具有 set-user-ID 权限位而无法更改 euid\n  $ sudo chmod u+s process-cred-sample\n  # 添加可执行文件的 set-user-ID 权限位\n  $ ls -lh process-cred-sample\n  -rwsrwxr-x 1 sysadmin godev 17K Jan 25 23:19 process-cred-sample\n  $ ./process-cred-sample\n    RUID: 1000, EUID: 1001, SUID: 1001\n    cat: file-read-only-by-sysadmin: Permission denied  # 第一次输出\n    RUID: 1001, EUID: 1001, SUID: 1001\n    Test  # 第二次输出  \n  ```\n\n  以上命令第一次输出调用 shell 脚本而无法使用 set-user-ID 权限位返回 `Permission denied`。第二次输出使用 `setreuid()` 系统调用，将 euid 的值代替 ruid 的值作为参数传入，因此 ruid 也返回 1001，此时该进程可读取对应的文件内容，但请注意的是，此处的 ruid 是 setreuid() 系统调用的行为，从 kernel 的角度来看 ruid 依然是实际运行进程的 UID，即为 godev(1000)。\n- 因此，若要实现 shell 脚本相同的效果，可使用 `fopen()` 与 `fread()` 函数将以上源码更改为名为 [process-cred-sample-adv.c](https://github.com/Alberthua-Perl/scripts-confs/blob/master/ruid-euid-suid-test/process-cred-sample-adv.c) 程序：\n  ```c\n  #define _GNU_SOURCE\n  #include <stdio.h>\n  #include <stdlib.h>\n  #include <string.h>\n  #include <unistd.h>\n  #include <sys/types.h>\n  \n  #define BUFF_SIZE 100\n  \n  void read_file() {\n      FILE *fp;\n      char buffer[BUFF_SIZE];\n  \n      /* Open file for both reading and writing */\n      fp = fopen(\"file-read-only-by-sysadmin\", \"r\");\n      /* Read and display data */\n      fread(buffer, BUFF_SIZE - 1, sizeof(char), fp);\n      printf(\"%s\\n\", buffer);\n      fclose(fp);\n  }\n  \n  int main()\n  {\n      uid_t ruid, euid, suid;\n      getresuid(&ruid, &euid, &suid);\n      printf(\"RUID: %d, EUID: %d, SUID: %d\\n\", ruid, euid, suid);\n      read_file();  // file-read-only-by-sysadmin: -r-------- sysadmin sysadmin\n      setreuid(geteuid(), geteuid());\n      getresuid(&ruid, &euid, &suid);\n      printf(\"RUID: %d, EUID: %d, SUID: %d\\n\", ruid, euid, suid);\n      read_file();  // file-read-only-by-sysadmin: -r-------- sysadmin sysadmin\n      return 0;\n  }\n  ```\n  同样编译程序，更改可执行文件所有者并添加 set-user-ID 权限位：\n  ```bash\n  $ gcc -o process-cred-sample-adv process-cred-sample-adv.c\n  $ sudo chown sysadmin:godev process-cred-sample-adv\n  $ sudo chmod u+s process-cred-sample-adv\n  $ ./process-cred-sample-adv\n    RUID: 1000, EUID: 1001, SUID: 1001  # 第一次输出\n    Test\n  \n    RUID: 1001, EUID: 1001, SUID: 1001  # 第二次输出\n    Test\n  ```\n  第一次输出由于直接使用 fopen() 与 fread() 函数且 euid 更改为 1001，可读取对应文件的内容，而第二次输出通过 setreuid() 系统调用将 ruid 与 euid 都设置为 1001，也可读取对应文件的内容，因此对于系统资源的访问取决于 `euid`。\n- 以上验证源码与文件的权限如下所示：![](linux-ruid-euid-test.png)\n\n### 各类 UID 在 Audit 审计系统中的说明：\n- 使用 Audit 审计系统过程中对文件、目录或系统调用的审计结果以审计日志的方式呈现，在众多的 type=SYSCALL 类型审计日志中包含了大量的 auid、uid、euid、suid 等的信息。\n- 以下将审计上述 process-cred-sample-adv 可执行文件，进一步理解各类 UID 的作用：  \n  ```bash\n  $ sudo apt-get install -y auditd\n  # 安装 auditd 软件包\n  $ sudo systemctl enable --now auditd.service\n  # 启动 auditd.service 守护进程\n  $ sudo auditctl -w ~/backup/ruid-euid-suid-test/process-cred-sample-adv \\\n    -p x -k new-uid-adv\n  # 添加名为 new-uid-adv 搜索关键字的审计规则，监控可执行文件的执行权限属性，日志将写入\n  # /var/log/audit/audit.log 中\n  $ sudo auditctl -l\n    -w /home/godev/backup/ruid-euid-suid-test/process-cred-sample-adv -p x -k new-uid-adv\n  $ ./process-cred-sample-adv\n  $ sudo ausearch -i -k new-uid-adv\n    type=PROCTITLE msg=audit(01/26/2023 13:47:38.727:1185) : proctitle=./process-cred-sample-adv \n    type=PATH msg=audit(01/26/2023 13:47:38.727:1185) : item=1 name=/lib64/ld-linux-x86-64.so.2 \n    inode=403317285 dev=08:02 mode=file,755 ouid=root ogid=root rdev=00:00 nametype=NORMAL cap_fp=none \n    cap_fi=none cap_fe=0 cap_fver=0 cap_frootid=0 \n    type=PATH msg=audit(01/26/2023 13:47:38.727:1185) : item=0 name=./process-cred-sample-adv \n    inode=137438286 dev=08:03 mode=file,suid,775 ouid=sysadmin ogid=godev rdev=00:00 nametype=NORMAL \n    cap_fp=none cap_fi=none cap_fe=0 cap_fver=0 cap_frootid=0 \n    type=CWD msg=audit(01/26/2023 13:47:38.727:1185) : cwd=/home/godev/backup/ruid-euid-suid-test \n    type=EXECVE msg=audit(01/26/2023 13:47:38.727:1185) : argc=1 a0=./process-cred-sample-adv \n    type=SYSCALL msg=audit(01/26/2023 13:47:38.727:1185) : arch=x86_64 syscall=execve success=yes \n    exit=0 a0=0x55e64d0712b0 a1=0x55e64d1fab50 a2=0x55e64d1ed380 a3=0x8 items=2 ppid=22490 pid=41229 \n    auid=godev uid=godev gid=godev euid=sysadmin suid=sysadmin fsuid=sysadmin egid=godev sgid=godev \n    fsgid=godev tty=pts3 ses=4 comm=process-cred-sa exe=/home/godev/backup/ruid-euid-suid-test/process-cred-sample-adv \n    subj=unconfined key=new-uid-adv\n  ```\n  在执行 process-cred-sample-adv 可执行文件后，使用 `ausearch` 查找对应的执行日志，其中 `type=SYSCALL` 中 `uid=godev` 为 kernel 确定的 ruid 值 1000(godev)，虽然在 process-cred-sample-adv 进程返回中 ruid 为 1001，但该值为 setreuid() 系统调用重新设置的值，真实的 ruid 依然为 1000(godev)。`euid=sysadmin` 与 `suid=sysadmin` 的结果与进程返回的结果完全一致。\n\n### 参考链接：\n- [credentials(7) - Linux man page](https://linux.die.net/man/7/credentials)\n- [setreuid(2) - Linux manual page](https://man7.org/linux/man-pages/man2/setregid.2.html)\n- [Difference between Real User ID, Effective User ID and Saved User ID](https://stackoverflow.com/questions/32455684/difference-between-real-user-id-effective-user-id-and-saved-user-id)\n- [深刻理解 - real user id, effective user id, saved user id in Linux](https://blog.csdn.net/fmeng23/article/details/23115989?spm=1001.2101.3001.6650.4&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-23115989-blog-40857821.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-23115989-blog-40857821.pc_relevant_default&utm_relevant_index=5)\n- [《Linux/Unix 系统编程手册》（上册）- 第9章 进程凭证（提取码：wop8）](https://pan.baidu.com/s/1DX8AEVBqepVDp3tiR06nBQ)\n- [ruid, euid, suid usage in Linux](https://mudongliang.github.io/2020/09/17/ruid-euid-suid-usage-in-linux.html)\n","source":"_posts/linux-process-uid.md","raw":"---\ntitle: Linux 进程权限的各类 UID 探讨\nsubtitle: Linux Process UID Analyse\ndate: 2023-01-28 15:30:30\nheader-img: linux-process_bg.jpg\ntags:\n  - Linux\n  - 进程\n---\n\n### 文档说明：\n- OS 版本：`Ubuntu 20.04.3 LTS`\n- kernel 版本：`5.15.0-57-generic`\n- Linux 中各类 UID 的联系与区别对于理解进程权限与 Audit 审计系统发挥至关重要的作用，这些 UID 作为进程凭证。\n- ✍ 可参考 `man 7 credentials` 手册中的说明加以理解。\n\n### 文档目录：\n- 各类 UID 的解析\n- ruid、euid 与 Saved set-user-ID 间的关系\n- ruid 与 euid 的验证示例\n- 各类 UID 在 Audit 审计系统中的说明\n- 参考链接\n\n### 各类 UID 的解析：\n- user ID：  \n  - 常规 Linux 用户 ID，作为系统中用户的唯一识别符。\n- Real user ID（`ruid`）：  \n  - 真实用户 ID  \n  - 🤘 ruid 为拥有当前进程的用户 ID，即调用该可执行文件的用户。  \n  - 一般情况下，最初登录 Shell 的 user ID 与 ruid 相同，但是该登录用户有可能通过 su 或 sudo 提权为其他非特权用户或特权用户，此时的 ruid 与最初的登录 user ID 不同。\n- Effective user ID（`euid`）：  \n  - 有效用户 ID  \n  - 🤘 euid 被内核使用确定进程可访问资源的权限  \n  - 进程的权限由保存在 euid 中的 UID 来决定  \n  - 通常而言，进程的 ruid 与 euid 保持一致，ruid 与 euid 对进程而言。  \n  - euid 临时存储了另一个用户的 UID  \n  - 🚀 euid 在使用系统调用与执行 set-user-ID 程序或 set-group-ID 程序时被修改。  \n  - 也就是说，set-user-ID 程序或 set-group-ID 程序的可执行文件其本身也需要设置 set-user-ID 权限位（bit）后，euid 被更改为与可执行文件的所有者（owner）UID 相同，而未设置 set-user-ID 权限位（bit）的可执行文件，euid 依然与 ruid 保持一致，可参见下文 \"ruid 与 euid 的验证示例\" 部分。  \n  - set-user-ID 权限位指的是 Linux 中的特殊权限 suid\n  - privileged 在不同的上下文中需加以辨别，可能是特权用户 root，也可能是其他普通用户。\n\n- Saved set-user-ID：  \n  - 保存设置用户 ID  \n  - 🚀 该 ID 相当于一个 `buffer`，在进程启动后，它会从 euid 拷贝信息到自身。对于非 root 用户，可以在未来使用 `setuid()` 系统调用来将 euid 设置成为 ruid 和 saved set-user-ID 中的任何一个。但是非 root 用户是不允许用 setuid() 将 euid 设置成为任何第三个 user ID。\n- Audit user ID（`auid`）：  \n  - 审计用户 ID，用于记录 Linux Audit 审计系统中的用户标识。  \n  - auid 为最初登录 Shell 的的用户 ID\n\n### ruid、euid 与 Saved set-user-ID 间的关系：\n- 进程启动过程中三者的赋值关系，如下图所示：![](linux-process-uid-mapping.png)  \n  - 1️⃣2️⃣ 假定最初登录 Shell 的用户启动运行可执行文件，启动进程。  \n  - 3️⃣ 设置进程的 `ruid/rgid` 为当前用户的 uid/gid  \n  - 4️⃣ 设置进程的 `euid/egid`，根据可执行文件的 `set-user-ID` 与 `set-group-ID` 权限位进行设置，图中红色 0 表示关闭，紫色 1 表示开启。为 1 时，将进程的 euid/egid 设置为可执行文件的 uid/gid，否则从 ruid/rgid 拷贝。\n- 以上过程可总结为下表：![](linux-process-uid-table.png)\n\n### 🚀 ruid 与 euid 的验证示例：\n- 需要注意的是 Linux 系统中 set-user-ID 与 set-group-ID 权限位对 shell 脚本无效，如下 [process-cred-sample.c](https://github.com/Alberthua-Perl/scripts-confs/blob/master/ruid-euid-suid-test/process-cred-sample.c) 程序所示：  \n  ```c\n  #define _GNU_SOURCE\n  #include <stdio.h>\n  #include <stdlib.h>\n  #include <unistd.h>\n  #include <sys/types.h>\n  \n  int main()\n  {\n      uid_t ruid, euid, suid;\n      getresuid(&ruid, &euid, &suid);\n      printf(\"RUID: %d, EUID: %d, SUID: %d\\n\", ruid, euid, suid);\n      system(\"cat file-read-only-by-sysadmin\");  // file-read-only-by-sysadmin: -r-------- sysadmin sysadmin\n      setreuid(geteuid(), geteuid());  // use euid to set ruid\n      getresuid(&ruid, &euid, &suid);\n      printf(\"RUID: %d, EUID: %d, SUID: %d\\n\", ruid, euid, suid);\n      system(\"cat file-read-only-by-sysadmin\");  // file-read-only-by-sysadmin: -r-------- sysadmin sysadmin\n      return 0;\n  }\n  ```\n  以上程序中获取当前进程的 ruid、euid 与 suid，但是 `system()` 函数调用了 shell 脚本，即使将该可执行文件的 set-user-ID 权限位开启也无法使用此权限位：\n  ```bash\n  $ id\n    uid=1000(godev) gid=1000(godev) groups=1000(godev)\n  # 笔者示例使用 godev 普通用户验证\n  $ id -u sysadmin\n    1001\n  $ ls -lh file-read-only-by-sysadmin \n    -r-------- 1 sysadmin sysadmin 5 Jan 24 17:08 file-read-only-by-sysadmin\n  # 当前目录中先创建该文件，其中 Test 作为文本内容。\n  $ gcc -o process-cred-sample process-cred-sample.c\n  $ sudo chown sysadmin:godev process-cred-sample\n  # 更改可执行程序的所有者，sysadmin 为系统上的另一个普通用户。\n  $ ./process-cred-sample\n    RUID: 1000, EUID: 1000, SUID: 1000\n    cat: file-read-only-by-sysadmin: Permission denied\n    RUID: 1000, EUID: 1000, SUID: 1000\n    cat: file-read-only-by-sysadmin: Permission denied\n  # 由于可执行文件不具有 set-user-ID 权限位而无法更改 euid\n  $ sudo chmod u+s process-cred-sample\n  # 添加可执行文件的 set-user-ID 权限位\n  $ ls -lh process-cred-sample\n  -rwsrwxr-x 1 sysadmin godev 17K Jan 25 23:19 process-cred-sample\n  $ ./process-cred-sample\n    RUID: 1000, EUID: 1001, SUID: 1001\n    cat: file-read-only-by-sysadmin: Permission denied  # 第一次输出\n    RUID: 1001, EUID: 1001, SUID: 1001\n    Test  # 第二次输出  \n  ```\n\n  以上命令第一次输出调用 shell 脚本而无法使用 set-user-ID 权限位返回 `Permission denied`。第二次输出使用 `setreuid()` 系统调用，将 euid 的值代替 ruid 的值作为参数传入，因此 ruid 也返回 1001，此时该进程可读取对应的文件内容，但请注意的是，此处的 ruid 是 setreuid() 系统调用的行为，从 kernel 的角度来看 ruid 依然是实际运行进程的 UID，即为 godev(1000)。\n- 因此，若要实现 shell 脚本相同的效果，可使用 `fopen()` 与 `fread()` 函数将以上源码更改为名为 [process-cred-sample-adv.c](https://github.com/Alberthua-Perl/scripts-confs/blob/master/ruid-euid-suid-test/process-cred-sample-adv.c) 程序：\n  ```c\n  #define _GNU_SOURCE\n  #include <stdio.h>\n  #include <stdlib.h>\n  #include <string.h>\n  #include <unistd.h>\n  #include <sys/types.h>\n  \n  #define BUFF_SIZE 100\n  \n  void read_file() {\n      FILE *fp;\n      char buffer[BUFF_SIZE];\n  \n      /* Open file for both reading and writing */\n      fp = fopen(\"file-read-only-by-sysadmin\", \"r\");\n      /* Read and display data */\n      fread(buffer, BUFF_SIZE - 1, sizeof(char), fp);\n      printf(\"%s\\n\", buffer);\n      fclose(fp);\n  }\n  \n  int main()\n  {\n      uid_t ruid, euid, suid;\n      getresuid(&ruid, &euid, &suid);\n      printf(\"RUID: %d, EUID: %d, SUID: %d\\n\", ruid, euid, suid);\n      read_file();  // file-read-only-by-sysadmin: -r-------- sysadmin sysadmin\n      setreuid(geteuid(), geteuid());\n      getresuid(&ruid, &euid, &suid);\n      printf(\"RUID: %d, EUID: %d, SUID: %d\\n\", ruid, euid, suid);\n      read_file();  // file-read-only-by-sysadmin: -r-------- sysadmin sysadmin\n      return 0;\n  }\n  ```\n  同样编译程序，更改可执行文件所有者并添加 set-user-ID 权限位：\n  ```bash\n  $ gcc -o process-cred-sample-adv process-cred-sample-adv.c\n  $ sudo chown sysadmin:godev process-cred-sample-adv\n  $ sudo chmod u+s process-cred-sample-adv\n  $ ./process-cred-sample-adv\n    RUID: 1000, EUID: 1001, SUID: 1001  # 第一次输出\n    Test\n  \n    RUID: 1001, EUID: 1001, SUID: 1001  # 第二次输出\n    Test\n  ```\n  第一次输出由于直接使用 fopen() 与 fread() 函数且 euid 更改为 1001，可读取对应文件的内容，而第二次输出通过 setreuid() 系统调用将 ruid 与 euid 都设置为 1001，也可读取对应文件的内容，因此对于系统资源的访问取决于 `euid`。\n- 以上验证源码与文件的权限如下所示：![](linux-ruid-euid-test.png)\n\n### 各类 UID 在 Audit 审计系统中的说明：\n- 使用 Audit 审计系统过程中对文件、目录或系统调用的审计结果以审计日志的方式呈现，在众多的 type=SYSCALL 类型审计日志中包含了大量的 auid、uid、euid、suid 等的信息。\n- 以下将审计上述 process-cred-sample-adv 可执行文件，进一步理解各类 UID 的作用：  \n  ```bash\n  $ sudo apt-get install -y auditd\n  # 安装 auditd 软件包\n  $ sudo systemctl enable --now auditd.service\n  # 启动 auditd.service 守护进程\n  $ sudo auditctl -w ~/backup/ruid-euid-suid-test/process-cred-sample-adv \\\n    -p x -k new-uid-adv\n  # 添加名为 new-uid-adv 搜索关键字的审计规则，监控可执行文件的执行权限属性，日志将写入\n  # /var/log/audit/audit.log 中\n  $ sudo auditctl -l\n    -w /home/godev/backup/ruid-euid-suid-test/process-cred-sample-adv -p x -k new-uid-adv\n  $ ./process-cred-sample-adv\n  $ sudo ausearch -i -k new-uid-adv\n    type=PROCTITLE msg=audit(01/26/2023 13:47:38.727:1185) : proctitle=./process-cred-sample-adv \n    type=PATH msg=audit(01/26/2023 13:47:38.727:1185) : item=1 name=/lib64/ld-linux-x86-64.so.2 \n    inode=403317285 dev=08:02 mode=file,755 ouid=root ogid=root rdev=00:00 nametype=NORMAL cap_fp=none \n    cap_fi=none cap_fe=0 cap_fver=0 cap_frootid=0 \n    type=PATH msg=audit(01/26/2023 13:47:38.727:1185) : item=0 name=./process-cred-sample-adv \n    inode=137438286 dev=08:03 mode=file,suid,775 ouid=sysadmin ogid=godev rdev=00:00 nametype=NORMAL \n    cap_fp=none cap_fi=none cap_fe=0 cap_fver=0 cap_frootid=0 \n    type=CWD msg=audit(01/26/2023 13:47:38.727:1185) : cwd=/home/godev/backup/ruid-euid-suid-test \n    type=EXECVE msg=audit(01/26/2023 13:47:38.727:1185) : argc=1 a0=./process-cred-sample-adv \n    type=SYSCALL msg=audit(01/26/2023 13:47:38.727:1185) : arch=x86_64 syscall=execve success=yes \n    exit=0 a0=0x55e64d0712b0 a1=0x55e64d1fab50 a2=0x55e64d1ed380 a3=0x8 items=2 ppid=22490 pid=41229 \n    auid=godev uid=godev gid=godev euid=sysadmin suid=sysadmin fsuid=sysadmin egid=godev sgid=godev \n    fsgid=godev tty=pts3 ses=4 comm=process-cred-sa exe=/home/godev/backup/ruid-euid-suid-test/process-cred-sample-adv \n    subj=unconfined key=new-uid-adv\n  ```\n  在执行 process-cred-sample-adv 可执行文件后，使用 `ausearch` 查找对应的执行日志，其中 `type=SYSCALL` 中 `uid=godev` 为 kernel 确定的 ruid 值 1000(godev)，虽然在 process-cred-sample-adv 进程返回中 ruid 为 1001，但该值为 setreuid() 系统调用重新设置的值，真实的 ruid 依然为 1000(godev)。`euid=sysadmin` 与 `suid=sysadmin` 的结果与进程返回的结果完全一致。\n\n### 参考链接：\n- [credentials(7) - Linux man page](https://linux.die.net/man/7/credentials)\n- [setreuid(2) - Linux manual page](https://man7.org/linux/man-pages/man2/setregid.2.html)\n- [Difference between Real User ID, Effective User ID and Saved User ID](https://stackoverflow.com/questions/32455684/difference-between-real-user-id-effective-user-id-and-saved-user-id)\n- [深刻理解 - real user id, effective user id, saved user id in Linux](https://blog.csdn.net/fmeng23/article/details/23115989?spm=1001.2101.3001.6650.4&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-23115989-blog-40857821.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-23115989-blog-40857821.pc_relevant_default&utm_relevant_index=5)\n- [《Linux/Unix 系统编程手册》（上册）- 第9章 进程凭证（提取码：wop8）](https://pan.baidu.com/s/1DX8AEVBqepVDp3tiR06nBQ)\n- [ruid, euid, suid usage in Linux](https://mudongliang.github.io/2020/09/17/ruid-euid-suid-usage-in-linux.html)\n","slug":"linux-process-uid","published":1,"updated":"2023-01-28T09:40:27.275Z","_id":"cldfonoky000a16vd2mlvz048","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li>OS 版本：<code>Ubuntu 20.04.3 LTS</code></li>\n<li>kernel 版本：<code>5.15.0-57-generic</code></li>\n<li>Linux 中各类 UID 的联系与区别对于理解进程权限与 Audit 审计系统发挥至关重要的作用，这些 UID 作为进程凭证。</li>\n<li>✍ 可参考 <code>man 7 credentials</code> 手册中的说明加以理解。</li>\n</ul>\n<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>各类 UID 的解析</li>\n<li>ruid、euid 与 Saved set-user-ID 间的关系</li>\n<li>ruid 与 euid 的验证示例</li>\n<li>各类 UID 在 Audit 审计系统中的说明</li>\n<li>参考链接</li>\n</ul>\n<h3 id=\"各类-UID-的解析：\"><a href=\"#各类-UID-的解析：\" class=\"headerlink\" title=\"各类 UID 的解析：\"></a>各类 UID 的解析：</h3><ul>\n<li>user ID：  <ul>\n<li>常规 Linux 用户 ID，作为系统中用户的唯一识别符。</li>\n</ul>\n</li>\n<li>Real user ID（<code>ruid</code>）：  <ul>\n<li>真实用户 ID  </li>\n<li>🤘 ruid 为拥有当前进程的用户 ID，即调用该可执行文件的用户。  </li>\n<li>一般情况下，最初登录 Shell 的 user ID 与 ruid 相同，但是该登录用户有可能通过 su 或 sudo 提权为其他非特权用户或特权用户，此时的 ruid 与最初的登录 user ID 不同。</li>\n</ul>\n</li>\n<li><p>Effective user ID（<code>euid</code>）：  </p>\n<ul>\n<li>有效用户 ID  </li>\n<li>🤘 euid 被内核使用确定进程可访问资源的权限  </li>\n<li>进程的权限由保存在 euid 中的 UID 来决定  </li>\n<li>通常而言，进程的 ruid 与 euid 保持一致，ruid 与 euid 对进程而言。  </li>\n<li>euid 临时存储了另一个用户的 UID  </li>\n<li>🚀 euid 在使用系统调用与执行 set-user-ID 程序或 set-group-ID 程序时被修改。  </li>\n<li>也就是说，set-user-ID 程序或 set-group-ID 程序的可执行文件其本身也需要设置 set-user-ID 权限位（bit）后，euid 被更改为与可执行文件的所有者（owner）UID 相同，而未设置 set-user-ID 权限位（bit）的可执行文件，euid 依然与 ruid 保持一致，可参见下文 “ruid 与 euid 的验证示例” 部分。  </li>\n<li>set-user-ID 权限位指的是 Linux 中的特殊权限 suid</li>\n<li>privileged 在不同的上下文中需加以辨别，可能是特权用户 root，也可能是其他普通用户。</li>\n</ul>\n</li>\n<li><p>Saved set-user-ID：  </p>\n<ul>\n<li>保存设置用户 ID  </li>\n<li>🚀 该 ID 相当于一个 <code>buffer</code>，在进程启动后，它会从 euid 拷贝信息到自身。对于非 root 用户，可以在未来使用 <code>setuid()</code> 系统调用来将 euid 设置成为 ruid 和 saved set-user-ID 中的任何一个。但是非 root 用户是不允许用 setuid() 将 euid 设置成为任何第三个 user ID。</li>\n</ul>\n</li>\n<li>Audit user ID（<code>auid</code>）：  <ul>\n<li>审计用户 ID，用于记录 Linux Audit 审计系统中的用户标识。  </li>\n<li>auid 为最初登录 Shell 的的用户 ID</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"ruid、euid-与-Saved-set-user-ID-间的关系：\"><a href=\"#ruid、euid-与-Saved-set-user-ID-间的关系：\" class=\"headerlink\" title=\"ruid、euid 与 Saved set-user-ID 间的关系：\"></a>ruid、euid 与 Saved set-user-ID 间的关系：</h3><ul>\n<li>进程启动过程中三者的赋值关系，如下图所示：<img src=\"linux-process-uid-mapping.png\" alt>  <ul>\n<li>1️⃣2️⃣ 假定最初登录 Shell 的用户启动运行可执行文件，启动进程。  </li>\n<li>3️⃣ 设置进程的 <code>ruid/rgid</code> 为当前用户的 uid/gid  </li>\n<li>4️⃣ 设置进程的 <code>euid/egid</code>，根据可执行文件的 <code>set-user-ID</code> 与 <code>set-group-ID</code> 权限位进行设置，图中红色 0 表示关闭，紫色 1 表示开启。为 1 时，将进程的 euid/egid 设置为可执行文件的 uid/gid，否则从 ruid/rgid 拷贝。</li>\n</ul>\n</li>\n<li>以上过程可总结为下表：<img src=\"linux-process-uid-table.png\" alt></li>\n</ul>\n<h3 id=\"🚀-ruid-与-euid-的验证示例：\"><a href=\"#🚀-ruid-与-euid-的验证示例：\" class=\"headerlink\" title=\"🚀 ruid 与 euid 的验证示例：\"></a>🚀 ruid 与 euid 的验证示例：</h3><ul>\n<li><p>需要注意的是 Linux 系统中 set-user-ID 与 set-group-ID 权限位对 shell 脚本无效，如下 <a href=\"https://github.com/Alberthua-Perl/scripts-confs/blob/master/ruid-euid-suid-test/process-cred-sample.c\" target=\"_blank\" rel=\"noopener\">process-cred-sample.c</a> 程序所示：  </p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> _GNU_SOURCE</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;sys/types.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">uid_t</span> ruid, euid, suid;</span><br><span class=\"line\">    getresuid(&amp;ruid, &amp;euid, &amp;suid);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"RUID: %d, EUID: %d, SUID: %d\\n\"</span>, ruid, euid, suid);</span><br><span class=\"line\">    system(<span class=\"string\">\"cat file-read-only-by-sysadmin\"</span>);  <span class=\"comment\">// file-read-only-by-sysadmin: -r-------- sysadmin sysadmin</span></span><br><span class=\"line\">    setreuid(geteuid(), geteuid());  <span class=\"comment\">// use euid to set ruid</span></span><br><span class=\"line\">    getresuid(&amp;ruid, &amp;euid, &amp;suid);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"RUID: %d, EUID: %d, SUID: %d\\n\"</span>, ruid, euid, suid);</span><br><span class=\"line\">    system(<span class=\"string\">\"cat file-read-only-by-sysadmin\"</span>);  <span class=\"comment\">// file-read-only-by-sysadmin: -r-------- sysadmin sysadmin</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>以上程序中获取当前进程的 ruid、euid 与 suid，但是 <code>system()</code> 函数调用了 shell 脚本，即使将该可执行文件的 set-user-ID 权限位开启也无法使用此权限位：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ id</span><br><span class=\"line\">  uid=1000(godev) gid=1000(godev) groups=1000(godev)</span><br><span class=\"line\"><span class=\"comment\"># 笔者示例使用 godev 普通用户验证</span></span><br><span class=\"line\">$ id -u sysadmin</span><br><span class=\"line\">  1001</span><br><span class=\"line\">$ ls -lh file-read-only-by-sysadmin </span><br><span class=\"line\">  -r-------- 1 sysadmin sysadmin 5 Jan 24 17:08 file-read-only-by-sysadmin</span><br><span class=\"line\"><span class=\"comment\"># 当前目录中先创建该文件，其中 Test 作为文本内容。</span></span><br><span class=\"line\">$ gcc -o process-cred-sample process-cred-sample.c</span><br><span class=\"line\">$ sudo chown sysadmin:godev process-cred-sample</span><br><span class=\"line\"><span class=\"comment\"># 更改可执行程序的所有者，sysadmin 为系统上的另一个普通用户。</span></span><br><span class=\"line\">$ ./process-cred-sample</span><br><span class=\"line\">  RUID: 1000, EUID: 1000, SUID: 1000</span><br><span class=\"line\">  cat: file-read-only-by-sysadmin: Permission denied</span><br><span class=\"line\">  RUID: 1000, EUID: 1000, SUID: 1000</span><br><span class=\"line\">  cat: file-read-only-by-sysadmin: Permission denied</span><br><span class=\"line\"><span class=\"comment\"># 由于可执行文件不具有 set-user-ID 权限位而无法更改 euid</span></span><br><span class=\"line\">$ sudo chmod u+s process-cred-sample</span><br><span class=\"line\"><span class=\"comment\"># 添加可执行文件的 set-user-ID 权限位</span></span><br><span class=\"line\">$ ls -lh process-cred-sample</span><br><span class=\"line\">-rwsrwxr-x 1 sysadmin godev 17K Jan 25 23:19 process-cred-sample</span><br><span class=\"line\">$ ./process-cred-sample</span><br><span class=\"line\">  RUID: 1000, EUID: 1001, SUID: 1001</span><br><span class=\"line\">  cat: file-read-only-by-sysadmin: Permission denied  <span class=\"comment\"># 第一次输出</span></span><br><span class=\"line\">  RUID: 1001, EUID: 1001, SUID: 1001</span><br><span class=\"line\">  Test  <span class=\"comment\"># 第二次输出</span></span><br></pre></td></tr></table></figure>\n<p>以上命令第一次输出调用 shell 脚本而无法使用 set-user-ID 权限位返回 <code>Permission denied</code>。第二次输出使用 <code>setreuid()</code> 系统调用，将 euid 的值代替 ruid 的值作为参数传入，因此 ruid 也返回 1001，此时该进程可读取对应的文件内容，但请注意的是，此处的 ruid 是 setreuid() 系统调用的行为，从 kernel 的角度来看 ruid 依然是实际运行进程的 UID，即为 godev(1000)。</p>\n</li>\n<li><p>因此，若要实现 shell 脚本相同的效果，可使用 <code>fopen()</code> 与 <code>fread()</code> 函数将以上源码更改为名为 <a href=\"https://github.com/Alberthua-Perl/scripts-confs/blob/master/ruid-euid-suid-test/process-cred-sample-adv.c\" target=\"_blank\" rel=\"noopener\">process-cred-sample-adv.c</a> 程序：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> _GNU_SOURCE</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;sys/types.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> BUFF_SIZE 100</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">read_file</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    FILE *fp;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> buffer[BUFF_SIZE];</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Open file for both reading and writing */</span></span><br><span class=\"line\">    fp = fopen(<span class=\"string\">\"file-read-only-by-sysadmin\"</span>, <span class=\"string\">\"r\"</span>);</span><br><span class=\"line\">    <span class=\"comment\">/* Read and display data */</span></span><br><span class=\"line\">    fread(buffer, BUFF_SIZE - <span class=\"number\">1</span>, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">char</span>), fp);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"%s\\n\"</span>, buffer);</span><br><span class=\"line\">    fclose(fp);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">uid_t</span> ruid, euid, suid;</span><br><span class=\"line\">    getresuid(&amp;ruid, &amp;euid, &amp;suid);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"RUID: %d, EUID: %d, SUID: %d\\n\"</span>, ruid, euid, suid);</span><br><span class=\"line\">    read_file();  <span class=\"comment\">// file-read-only-by-sysadmin: -r-------- sysadmin sysadmin</span></span><br><span class=\"line\">    setreuid(geteuid(), geteuid());</span><br><span class=\"line\">    getresuid(&amp;ruid, &amp;euid, &amp;suid);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"RUID: %d, EUID: %d, SUID: %d\\n\"</span>, ruid, euid, suid);</span><br><span class=\"line\">    read_file();  <span class=\"comment\">// file-read-only-by-sysadmin: -r-------- sysadmin sysadmin</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>同样编译程序，更改可执行文件所有者并添加 set-user-ID 权限位：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ gcc -o process-cred-sample-adv process-cred-sample-adv.c</span><br><span class=\"line\">$ sudo chown sysadmin:godev process-cred-sample-adv</span><br><span class=\"line\">$ sudo chmod u+s process-cred-sample-adv</span><br><span class=\"line\">$ ./process-cred-sample-adv</span><br><span class=\"line\">  RUID: 1000, EUID: 1001, SUID: 1001  <span class=\"comment\"># 第一次输出</span></span><br><span class=\"line\">  Test</span><br><span class=\"line\"></span><br><span class=\"line\">  RUID: 1001, EUID: 1001, SUID: 1001  <span class=\"comment\"># 第二次输出</span></span><br><span class=\"line\">  Test</span><br></pre></td></tr></table></figure>\n<p>第一次输出由于直接使用 fopen() 与 fread() 函数且 euid 更改为 1001，可读取对应文件的内容，而第二次输出通过 setreuid() 系统调用将 ruid 与 euid 都设置为 1001，也可读取对应文件的内容，因此对于系统资源的访问取决于 <code>euid</code>。</p>\n</li>\n<li>以上验证源码与文件的权限如下所示：<img src=\"linux-ruid-euid-test.png\" alt></li>\n</ul>\n<h3 id=\"各类-UID-在-Audit-审计系统中的说明：\"><a href=\"#各类-UID-在-Audit-审计系统中的说明：\" class=\"headerlink\" title=\"各类 UID 在 Audit 审计系统中的说明：\"></a>各类 UID 在 Audit 审计系统中的说明：</h3><ul>\n<li>使用 Audit 审计系统过程中对文件、目录或系统调用的审计结果以审计日志的方式呈现，在众多的 type=SYSCALL 类型审计日志中包含了大量的 auid、uid、euid、suid 等的信息。</li>\n<li><p>以下将审计上述 process-cred-sample-adv 可执行文件，进一步理解各类 UID 的作用：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install -y auditd</span><br><span class=\"line\"><span class=\"comment\"># 安装 auditd 软件包</span></span><br><span class=\"line\">$ sudo systemctl <span class=\"built_in\">enable</span> --now auditd.service</span><br><span class=\"line\"><span class=\"comment\"># 启动 auditd.service 守护进程</span></span><br><span class=\"line\">$ sudo auditctl -w ~/backup/ruid-euid-suid-test/process-cred-sample-adv \\</span><br><span class=\"line\">  -p x -k new-uid-adv</span><br><span class=\"line\"><span class=\"comment\"># 添加名为 new-uid-adv 搜索关键字的审计规则，监控可执行文件的执行权限属性，日志将写入</span></span><br><span class=\"line\"><span class=\"comment\"># /var/log/audit/audit.log 中</span></span><br><span class=\"line\">$ sudo auditctl -l</span><br><span class=\"line\">  -w /home/godev/backup/ruid-euid-suid-test/process-cred-sample-adv -p x -k new-uid-adv</span><br><span class=\"line\">$ ./process-cred-sample-adv</span><br><span class=\"line\">$ sudo ausearch -i -k new-uid-adv</span><br><span class=\"line\">  <span class=\"built_in\">type</span>=PROCTITLE msg=audit(01/26/2023 13:47:38.727:1185) : proctitle=./process-cred-sample-adv </span><br><span class=\"line\">  <span class=\"built_in\">type</span>=PATH msg=audit(01/26/2023 13:47:38.727:1185) : item=1 name=/lib64/ld-linux-x86-64.so.2 </span><br><span class=\"line\">  inode=403317285 dev=08:02 mode=file,755 ouid=root ogid=root rdev=00:00 nametype=NORMAL cap_fp=none </span><br><span class=\"line\">  cap_fi=none cap_fe=0 cap_fver=0 cap_frootid=0 </span><br><span class=\"line\">  <span class=\"built_in\">type</span>=PATH msg=audit(01/26/2023 13:47:38.727:1185) : item=0 name=./process-cred-sample-adv </span><br><span class=\"line\">  inode=137438286 dev=08:03 mode=file,suid,775 ouid=sysadmin ogid=godev rdev=00:00 nametype=NORMAL </span><br><span class=\"line\">  cap_fp=none cap_fi=none cap_fe=0 cap_fver=0 cap_frootid=0 </span><br><span class=\"line\">  <span class=\"built_in\">type</span>=CWD msg=audit(01/26/2023 13:47:38.727:1185) : cwd=/home/godev/backup/ruid-euid-suid-test </span><br><span class=\"line\">  <span class=\"built_in\">type</span>=EXECVE msg=audit(01/26/2023 13:47:38.727:1185) : argc=1 a0=./process-cred-sample-adv </span><br><span class=\"line\">  <span class=\"built_in\">type</span>=SYSCALL msg=audit(01/26/2023 13:47:38.727:1185) : arch=x86_64 syscall=execve success=yes </span><br><span class=\"line\">  <span class=\"built_in\">exit</span>=0 a0=0x55e64d0712b0 a1=0x55e64d1fab50 a2=0x55e64d1ed380 a3=0x8 items=2 ppid=22490 pid=41229 </span><br><span class=\"line\">  auid=godev uid=godev gid=godev euid=sysadmin suid=sysadmin fsuid=sysadmin egid=godev sgid=godev </span><br><span class=\"line\">  fsgid=godev tty=pts3 ses=4 comm=process-cred-sa exe=/home/godev/backup/ruid-euid-suid-test/process-cred-sample-adv </span><br><span class=\"line\">  subj=unconfined key=new-uid-adv</span><br></pre></td></tr></table></figure>\n<p>在执行 process-cred-sample-adv 可执行文件后，使用 <code>ausearch</code> 查找对应的执行日志，其中 <code>type=SYSCALL</code> 中 <code>uid=godev</code> 为 kernel 确定的 ruid 值 1000(godev)，虽然在 process-cred-sample-adv 进程返回中 ruid 为 1001，但该值为 setreuid() 系统调用重新设置的值，真实的 ruid 依然为 1000(godev)。<code>euid=sysadmin</code> 与 <code>suid=sysadmin</code> 的结果与进程返回的结果完全一致。</p>\n</li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://linux.die.net/man/7/credentials\" target=\"_blank\" rel=\"noopener\">credentials(7) - Linux man page</a></li>\n<li><a href=\"https://man7.org/linux/man-pages/man2/setregid.2.html\" target=\"_blank\" rel=\"noopener\">setreuid(2) - Linux manual page</a></li>\n<li><a href=\"https://stackoverflow.com/questions/32455684/difference-between-real-user-id-effective-user-id-and-saved-user-id\" target=\"_blank\" rel=\"noopener\">Difference between Real User ID, Effective User ID and Saved User ID</a></li>\n<li><a href=\"https://blog.csdn.net/fmeng23/article/details/23115989?spm=1001.2101.3001.6650.4&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-23115989-blog-40857821.pc_relevant_default&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-23115989-blog-40857821.pc_relevant_default&amp;utm_relevant_index=5\" target=\"_blank\" rel=\"noopener\">深刻理解 - real user id, effective user id, saved user id in Linux</a></li>\n<li><a href=\"https://pan.baidu.com/s/1DX8AEVBqepVDp3tiR06nBQ\" target=\"_blank\" rel=\"noopener\">《Linux/Unix 系统编程手册》（上册）- 第9章 进程凭证（提取码：wop8）</a></li>\n<li><a href=\"https://mudongliang.github.io/2020/09/17/ruid-euid-suid-usage-in-linux.html\" target=\"_blank\" rel=\"noopener\">ruid, euid, suid usage in Linux</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li>OS 版本：<code>Ubuntu 20.04.3 LTS</code></li>\n<li>kernel 版本：<code>5.15.0-57-generic</code></li>\n<li>Linux 中各类 UID 的联系与区别对于理解进程权限与 Audit 审计系统发挥至关重要的作用，这些 UID 作为进程凭证。</li>\n<li>✍ 可参考 <code>man 7 credentials</code> 手册中的说明加以理解。</li>\n</ul>\n<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>各类 UID 的解析</li>\n<li>ruid、euid 与 Saved set-user-ID 间的关系</li>\n<li>ruid 与 euid 的验证示例</li>\n<li>各类 UID 在 Audit 审计系统中的说明</li>\n<li>参考链接</li>\n</ul>\n<h3 id=\"各类-UID-的解析：\"><a href=\"#各类-UID-的解析：\" class=\"headerlink\" title=\"各类 UID 的解析：\"></a>各类 UID 的解析：</h3><ul>\n<li>user ID：  <ul>\n<li>常规 Linux 用户 ID，作为系统中用户的唯一识别符。</li>\n</ul>\n</li>\n<li>Real user ID（<code>ruid</code>）：  <ul>\n<li>真实用户 ID  </li>\n<li>🤘 ruid 为拥有当前进程的用户 ID，即调用该可执行文件的用户。  </li>\n<li>一般情况下，最初登录 Shell 的 user ID 与 ruid 相同，但是该登录用户有可能通过 su 或 sudo 提权为其他非特权用户或特权用户，此时的 ruid 与最初的登录 user ID 不同。</li>\n</ul>\n</li>\n<li><p>Effective user ID（<code>euid</code>）：  </p>\n<ul>\n<li>有效用户 ID  </li>\n<li>🤘 euid 被内核使用确定进程可访问资源的权限  </li>\n<li>进程的权限由保存在 euid 中的 UID 来决定  </li>\n<li>通常而言，进程的 ruid 与 euid 保持一致，ruid 与 euid 对进程而言。  </li>\n<li>euid 临时存储了另一个用户的 UID  </li>\n<li>🚀 euid 在使用系统调用与执行 set-user-ID 程序或 set-group-ID 程序时被修改。  </li>\n<li>也就是说，set-user-ID 程序或 set-group-ID 程序的可执行文件其本身也需要设置 set-user-ID 权限位（bit）后，euid 被更改为与可执行文件的所有者（owner）UID 相同，而未设置 set-user-ID 权限位（bit）的可执行文件，euid 依然与 ruid 保持一致，可参见下文 “ruid 与 euid 的验证示例” 部分。  </li>\n<li>set-user-ID 权限位指的是 Linux 中的特殊权限 suid</li>\n<li>privileged 在不同的上下文中需加以辨别，可能是特权用户 root，也可能是其他普通用户。</li>\n</ul>\n</li>\n<li><p>Saved set-user-ID：  </p>\n<ul>\n<li>保存设置用户 ID  </li>\n<li>🚀 该 ID 相当于一个 <code>buffer</code>，在进程启动后，它会从 euid 拷贝信息到自身。对于非 root 用户，可以在未来使用 <code>setuid()</code> 系统调用来将 euid 设置成为 ruid 和 saved set-user-ID 中的任何一个。但是非 root 用户是不允许用 setuid() 将 euid 设置成为任何第三个 user ID。</li>\n</ul>\n</li>\n<li>Audit user ID（<code>auid</code>）：  <ul>\n<li>审计用户 ID，用于记录 Linux Audit 审计系统中的用户标识。  </li>\n<li>auid 为最初登录 Shell 的的用户 ID</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"ruid、euid-与-Saved-set-user-ID-间的关系：\"><a href=\"#ruid、euid-与-Saved-set-user-ID-间的关系：\" class=\"headerlink\" title=\"ruid、euid 与 Saved set-user-ID 间的关系：\"></a>ruid、euid 与 Saved set-user-ID 间的关系：</h3><ul>\n<li>进程启动过程中三者的赋值关系，如下图所示：<img src=\"linux-process-uid-mapping.png\" alt>  <ul>\n<li>1️⃣2️⃣ 假定最初登录 Shell 的用户启动运行可执行文件，启动进程。  </li>\n<li>3️⃣ 设置进程的 <code>ruid/rgid</code> 为当前用户的 uid/gid  </li>\n<li>4️⃣ 设置进程的 <code>euid/egid</code>，根据可执行文件的 <code>set-user-ID</code> 与 <code>set-group-ID</code> 权限位进行设置，图中红色 0 表示关闭，紫色 1 表示开启。为 1 时，将进程的 euid/egid 设置为可执行文件的 uid/gid，否则从 ruid/rgid 拷贝。</li>\n</ul>\n</li>\n<li>以上过程可总结为下表：<img src=\"linux-process-uid-table.png\" alt></li>\n</ul>\n<h3 id=\"🚀-ruid-与-euid-的验证示例：\"><a href=\"#🚀-ruid-与-euid-的验证示例：\" class=\"headerlink\" title=\"🚀 ruid 与 euid 的验证示例：\"></a>🚀 ruid 与 euid 的验证示例：</h3><ul>\n<li><p>需要注意的是 Linux 系统中 set-user-ID 与 set-group-ID 权限位对 shell 脚本无效，如下 <a href=\"https://github.com/Alberthua-Perl/scripts-confs/blob/master/ruid-euid-suid-test/process-cred-sample.c\" target=\"_blank\" rel=\"noopener\">process-cred-sample.c</a> 程序所示：  </p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> _GNU_SOURCE</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;sys/types.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">uid_t</span> ruid, euid, suid;</span><br><span class=\"line\">    getresuid(&amp;ruid, &amp;euid, &amp;suid);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"RUID: %d, EUID: %d, SUID: %d\\n\"</span>, ruid, euid, suid);</span><br><span class=\"line\">    system(<span class=\"string\">\"cat file-read-only-by-sysadmin\"</span>);  <span class=\"comment\">// file-read-only-by-sysadmin: -r-------- sysadmin sysadmin</span></span><br><span class=\"line\">    setreuid(geteuid(), geteuid());  <span class=\"comment\">// use euid to set ruid</span></span><br><span class=\"line\">    getresuid(&amp;ruid, &amp;euid, &amp;suid);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"RUID: %d, EUID: %d, SUID: %d\\n\"</span>, ruid, euid, suid);</span><br><span class=\"line\">    system(<span class=\"string\">\"cat file-read-only-by-sysadmin\"</span>);  <span class=\"comment\">// file-read-only-by-sysadmin: -r-------- sysadmin sysadmin</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>以上程序中获取当前进程的 ruid、euid 与 suid，但是 <code>system()</code> 函数调用了 shell 脚本，即使将该可执行文件的 set-user-ID 权限位开启也无法使用此权限位：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ id</span><br><span class=\"line\">  uid=1000(godev) gid=1000(godev) groups=1000(godev)</span><br><span class=\"line\"><span class=\"comment\"># 笔者示例使用 godev 普通用户验证</span></span><br><span class=\"line\">$ id -u sysadmin</span><br><span class=\"line\">  1001</span><br><span class=\"line\">$ ls -lh file-read-only-by-sysadmin </span><br><span class=\"line\">  -r-------- 1 sysadmin sysadmin 5 Jan 24 17:08 file-read-only-by-sysadmin</span><br><span class=\"line\"><span class=\"comment\"># 当前目录中先创建该文件，其中 Test 作为文本内容。</span></span><br><span class=\"line\">$ gcc -o process-cred-sample process-cred-sample.c</span><br><span class=\"line\">$ sudo chown sysadmin:godev process-cred-sample</span><br><span class=\"line\"><span class=\"comment\"># 更改可执行程序的所有者，sysadmin 为系统上的另一个普通用户。</span></span><br><span class=\"line\">$ ./process-cred-sample</span><br><span class=\"line\">  RUID: 1000, EUID: 1000, SUID: 1000</span><br><span class=\"line\">  cat: file-read-only-by-sysadmin: Permission denied</span><br><span class=\"line\">  RUID: 1000, EUID: 1000, SUID: 1000</span><br><span class=\"line\">  cat: file-read-only-by-sysadmin: Permission denied</span><br><span class=\"line\"><span class=\"comment\"># 由于可执行文件不具有 set-user-ID 权限位而无法更改 euid</span></span><br><span class=\"line\">$ sudo chmod u+s process-cred-sample</span><br><span class=\"line\"><span class=\"comment\"># 添加可执行文件的 set-user-ID 权限位</span></span><br><span class=\"line\">$ ls -lh process-cred-sample</span><br><span class=\"line\">-rwsrwxr-x 1 sysadmin godev 17K Jan 25 23:19 process-cred-sample</span><br><span class=\"line\">$ ./process-cred-sample</span><br><span class=\"line\">  RUID: 1000, EUID: 1001, SUID: 1001</span><br><span class=\"line\">  cat: file-read-only-by-sysadmin: Permission denied  <span class=\"comment\"># 第一次输出</span></span><br><span class=\"line\">  RUID: 1001, EUID: 1001, SUID: 1001</span><br><span class=\"line\">  Test  <span class=\"comment\"># 第二次输出</span></span><br></pre></td></tr></table></figure>\n<p>以上命令第一次输出调用 shell 脚本而无法使用 set-user-ID 权限位返回 <code>Permission denied</code>。第二次输出使用 <code>setreuid()</code> 系统调用，将 euid 的值代替 ruid 的值作为参数传入，因此 ruid 也返回 1001，此时该进程可读取对应的文件内容，但请注意的是，此处的 ruid 是 setreuid() 系统调用的行为，从 kernel 的角度来看 ruid 依然是实际运行进程的 UID，即为 godev(1000)。</p>\n</li>\n<li><p>因此，若要实现 shell 脚本相同的效果，可使用 <code>fopen()</code> 与 <code>fread()</code> 函数将以上源码更改为名为 <a href=\"https://github.com/Alberthua-Perl/scripts-confs/blob/master/ruid-euid-suid-test/process-cred-sample-adv.c\" target=\"_blank\" rel=\"noopener\">process-cred-sample-adv.c</a> 程序：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> _GNU_SOURCE</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdlib.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;unistd.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;sys/types.h&gt;</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">define</span> BUFF_SIZE 100</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">read_file</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">    FILE *fp;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> buffer[BUFF_SIZE];</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">/* Open file for both reading and writing */</span></span><br><span class=\"line\">    fp = fopen(<span class=\"string\">\"file-read-only-by-sysadmin\"</span>, <span class=\"string\">\"r\"</span>);</span><br><span class=\"line\">    <span class=\"comment\">/* Read and display data */</span></span><br><span class=\"line\">    fread(buffer, BUFF_SIZE - <span class=\"number\">1</span>, <span class=\"keyword\">sizeof</span>(<span class=\"keyword\">char</span>), fp);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"%s\\n\"</span>, buffer);</span><br><span class=\"line\">    fclose(fp);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">()</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">uid_t</span> ruid, euid, suid;</span><br><span class=\"line\">    getresuid(&amp;ruid, &amp;euid, &amp;suid);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"RUID: %d, EUID: %d, SUID: %d\\n\"</span>, ruid, euid, suid);</span><br><span class=\"line\">    read_file();  <span class=\"comment\">// file-read-only-by-sysadmin: -r-------- sysadmin sysadmin</span></span><br><span class=\"line\">    setreuid(geteuid(), geteuid());</span><br><span class=\"line\">    getresuid(&amp;ruid, &amp;euid, &amp;suid);</span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"RUID: %d, EUID: %d, SUID: %d\\n\"</span>, ruid, euid, suid);</span><br><span class=\"line\">    read_file();  <span class=\"comment\">// file-read-only-by-sysadmin: -r-------- sysadmin sysadmin</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>同样编译程序，更改可执行文件所有者并添加 set-user-ID 权限位：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ gcc -o process-cred-sample-adv process-cred-sample-adv.c</span><br><span class=\"line\">$ sudo chown sysadmin:godev process-cred-sample-adv</span><br><span class=\"line\">$ sudo chmod u+s process-cred-sample-adv</span><br><span class=\"line\">$ ./process-cred-sample-adv</span><br><span class=\"line\">  RUID: 1000, EUID: 1001, SUID: 1001  <span class=\"comment\"># 第一次输出</span></span><br><span class=\"line\">  Test</span><br><span class=\"line\"></span><br><span class=\"line\">  RUID: 1001, EUID: 1001, SUID: 1001  <span class=\"comment\"># 第二次输出</span></span><br><span class=\"line\">  Test</span><br></pre></td></tr></table></figure>\n<p>第一次输出由于直接使用 fopen() 与 fread() 函数且 euid 更改为 1001，可读取对应文件的内容，而第二次输出通过 setreuid() 系统调用将 ruid 与 euid 都设置为 1001，也可读取对应文件的内容，因此对于系统资源的访问取决于 <code>euid</code>。</p>\n</li>\n<li>以上验证源码与文件的权限如下所示：<img src=\"linux-ruid-euid-test.png\" alt></li>\n</ul>\n<h3 id=\"各类-UID-在-Audit-审计系统中的说明：\"><a href=\"#各类-UID-在-Audit-审计系统中的说明：\" class=\"headerlink\" title=\"各类 UID 在 Audit 审计系统中的说明：\"></a>各类 UID 在 Audit 审计系统中的说明：</h3><ul>\n<li>使用 Audit 审计系统过程中对文件、目录或系统调用的审计结果以审计日志的方式呈现，在众多的 type=SYSCALL 类型审计日志中包含了大量的 auid、uid、euid、suid 等的信息。</li>\n<li><p>以下将审计上述 process-cred-sample-adv 可执行文件，进一步理解各类 UID 的作用：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install -y auditd</span><br><span class=\"line\"><span class=\"comment\"># 安装 auditd 软件包</span></span><br><span class=\"line\">$ sudo systemctl <span class=\"built_in\">enable</span> --now auditd.service</span><br><span class=\"line\"><span class=\"comment\"># 启动 auditd.service 守护进程</span></span><br><span class=\"line\">$ sudo auditctl -w ~/backup/ruid-euid-suid-test/process-cred-sample-adv \\</span><br><span class=\"line\">  -p x -k new-uid-adv</span><br><span class=\"line\"><span class=\"comment\"># 添加名为 new-uid-adv 搜索关键字的审计规则，监控可执行文件的执行权限属性，日志将写入</span></span><br><span class=\"line\"><span class=\"comment\"># /var/log/audit/audit.log 中</span></span><br><span class=\"line\">$ sudo auditctl -l</span><br><span class=\"line\">  -w /home/godev/backup/ruid-euid-suid-test/process-cred-sample-adv -p x -k new-uid-adv</span><br><span class=\"line\">$ ./process-cred-sample-adv</span><br><span class=\"line\">$ sudo ausearch -i -k new-uid-adv</span><br><span class=\"line\">  <span class=\"built_in\">type</span>=PROCTITLE msg=audit(01/26/2023 13:47:38.727:1185) : proctitle=./process-cred-sample-adv </span><br><span class=\"line\">  <span class=\"built_in\">type</span>=PATH msg=audit(01/26/2023 13:47:38.727:1185) : item=1 name=/lib64/ld-linux-x86-64.so.2 </span><br><span class=\"line\">  inode=403317285 dev=08:02 mode=file,755 ouid=root ogid=root rdev=00:00 nametype=NORMAL cap_fp=none </span><br><span class=\"line\">  cap_fi=none cap_fe=0 cap_fver=0 cap_frootid=0 </span><br><span class=\"line\">  <span class=\"built_in\">type</span>=PATH msg=audit(01/26/2023 13:47:38.727:1185) : item=0 name=./process-cred-sample-adv </span><br><span class=\"line\">  inode=137438286 dev=08:03 mode=file,suid,775 ouid=sysadmin ogid=godev rdev=00:00 nametype=NORMAL </span><br><span class=\"line\">  cap_fp=none cap_fi=none cap_fe=0 cap_fver=0 cap_frootid=0 </span><br><span class=\"line\">  <span class=\"built_in\">type</span>=CWD msg=audit(01/26/2023 13:47:38.727:1185) : cwd=/home/godev/backup/ruid-euid-suid-test </span><br><span class=\"line\">  <span class=\"built_in\">type</span>=EXECVE msg=audit(01/26/2023 13:47:38.727:1185) : argc=1 a0=./process-cred-sample-adv </span><br><span class=\"line\">  <span class=\"built_in\">type</span>=SYSCALL msg=audit(01/26/2023 13:47:38.727:1185) : arch=x86_64 syscall=execve success=yes </span><br><span class=\"line\">  <span class=\"built_in\">exit</span>=0 a0=0x55e64d0712b0 a1=0x55e64d1fab50 a2=0x55e64d1ed380 a3=0x8 items=2 ppid=22490 pid=41229 </span><br><span class=\"line\">  auid=godev uid=godev gid=godev euid=sysadmin suid=sysadmin fsuid=sysadmin egid=godev sgid=godev </span><br><span class=\"line\">  fsgid=godev tty=pts3 ses=4 comm=process-cred-sa exe=/home/godev/backup/ruid-euid-suid-test/process-cred-sample-adv </span><br><span class=\"line\">  subj=unconfined key=new-uid-adv</span><br></pre></td></tr></table></figure>\n<p>在执行 process-cred-sample-adv 可执行文件后，使用 <code>ausearch</code> 查找对应的执行日志，其中 <code>type=SYSCALL</code> 中 <code>uid=godev</code> 为 kernel 确定的 ruid 值 1000(godev)，虽然在 process-cred-sample-adv 进程返回中 ruid 为 1001，但该值为 setreuid() 系统调用重新设置的值，真实的 ruid 依然为 1000(godev)。<code>euid=sysadmin</code> 与 <code>suid=sysadmin</code> 的结果与进程返回的结果完全一致。</p>\n</li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://linux.die.net/man/7/credentials\" target=\"_blank\" rel=\"noopener\">credentials(7) - Linux man page</a></li>\n<li><a href=\"https://man7.org/linux/man-pages/man2/setregid.2.html\" target=\"_blank\" rel=\"noopener\">setreuid(2) - Linux manual page</a></li>\n<li><a href=\"https://stackoverflow.com/questions/32455684/difference-between-real-user-id-effective-user-id-and-saved-user-id\" target=\"_blank\" rel=\"noopener\">Difference between Real User ID, Effective User ID and Saved User ID</a></li>\n<li><a href=\"https://blog.csdn.net/fmeng23/article/details/23115989?spm=1001.2101.3001.6650.4&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-23115989-blog-40857821.pc_relevant_default&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-4-23115989-blog-40857821.pc_relevant_default&amp;utm_relevant_index=5\" target=\"_blank\" rel=\"noopener\">深刻理解 - real user id, effective user id, saved user id in Linux</a></li>\n<li><a href=\"https://pan.baidu.com/s/1DX8AEVBqepVDp3tiR06nBQ\" target=\"_blank\" rel=\"noopener\">《Linux/Unix 系统编程手册》（上册）- 第9章 进程凭证（提取码：wop8）</a></li>\n<li><a href=\"https://mudongliang.github.io/2020/09/17/ruid-euid-suid-usage-in-linux.html\" target=\"_blank\" rel=\"noopener\">ruid, euid, suid usage in Linux</a></li>\n</ul>\n"},{"title":"一文厘清 HTTPS 原理与应用","subtitle":"SSL/TLS handshake and HTTPS authentication","header-img":"https-bg.png","date":"2023-01-20T03:28:29.000Z","_content":"\n### 文档说明：\n- OS 版本：`CentOS Linux release 7.9.2009 (Core)`\n- Kernel 版本：`4.20.3-1.el7.elrepo.x86_64`\n- OpenSSL 版本：`openssl-1.0.2k-21.el7_9.x86_64.rpm`\n- Docker 版本：`20.10.8`\n- Nginx 版本：`1.22.1`\n- ✨ HTTPS 在常规 Web 服务器、中间件服务器及 `RESTful API` 等通信中广泛大量使用，因此理解 HTTPS 及相关概念显得尤为重要。\n- 该文档使用 openssl 工具创建与管理相关私钥与证书，当然也可使用 cfssl 或 certtool（来源于 gnutls-utils 软件包）工具创建与管理。\n\n### 文档目录：\n- 加密通信背景\n- 保证数据的机密性\n- 保证数据的真实性与完整性\n- 保证传输双方的身份验证\n- 数字签名原理\n- SSL/TLS 与 CA 相关术语\n- SSL/TLS 加密通信要点\n- 基于 SSL/TLS 加密连接的 HTTPS 单/双向认证\n- HTTPS 单向认证的 Wireshark 抓包分析\n- HTTPS 单向认证测试\n- HTTPS 双向认证的 Wireshark 抓包与测试\n- openssl 常用命令汇总\n- openssl 使用数字签名证书的单双向连接测试\n- 参考链接\n\n### 加密通信背景：\n- 网络安全问题：  \n  HTTP 不使用 SSL/TLS 进行加密通信，所有信息明文传播，带来了三大风险：  \n  - 窃听风险（eavesdropping）：第三方可以获知通信内容  \n  - 篡改风险（tampering）：第三方可以修改通信内容  \n  - 冒充风险（pretending）：第三方可以冒充他人身份参与通信\n- 网络安全问题的解决思路：`SSL/TLS` 协议  \n  - 所有信息都是加密传播，第三方无法窃听。  \n  - 具有校验机制，一旦被篡改，通信双方会立刻发现。  \n  - 配备身份证书，防止身份被冒充。\n\n### 保证数据的机密性：不被窃听\n- 🧬 实现方式：对称加密算法\n- 💥 单纯的数据加密只能保证数据不被泄露，但不能保证接收方收到的数据的真实性。\n\n### 保证数据的真实性与完整性：不被篡改\n- 数据的真实性：真实数据没有被篡改，数据是从真实发送者发来。\n- 🧬 实现方式：消息摘要算法（或称散列算法/单向散列函数）生成数据指纹（特征码）\n- 💥 利用提取数据指纹的方式，完成数据传输的完整性验证。\n- 🔒 实际的算法实现过程概要：  \n  - 给一段明文数据（plain text）加上数据信息指纹，这个指纹是通过结合数据信息进行相应算法获得的数据指纹。  \n  - 接收方当收到数据信息后，会利用相同的算法对获取的数据计算指纹，确认得到的指纹是否与传送过来的描述数据的指纹一致。  \n  - 如果一致，表示数据没有被篡改过；如果不一致，表示数据完整性遭到破坏，数据一概不予以接收处理。\n- 由于可能存在中间人攻击的可能性，因此可对传输过程中的数据指纹进行加密。\n- 发送方利用对称密钥方式对手中的指纹进行加密，接收方会利用相同的密钥对手中的指纹进行解密，从而确认指纹是否一致。\n- 如果中间人将新的指纹也进行了加密，发送给接收方，但接收方无法利用和发送方协商好的解密密钥对指纹进行解密，最终无法识别中间人发送过来的数据指纹信息。\n- 🤘 通过加密指纹可以保证真实数据没有被篡改。\n\n### 保证传输双方的身份验证：\n- 以上信息只是解决数据的交换获取问题，但是网络的身份验证问题依旧没有解决。\n- 🧬 实现方式：非对称加密\n- 利用非对称加密算法，可以有效解决网络中数据传输双方的安全身份验证问题。\n- 💥 非对称加密算法中，存在密钥对的概念，即拥有公钥（`public key`）与私钥（`private key`），其中公钥不是自行创建出来的而是从私钥中提取出来一部分作为公钥，因此可以说公钥是来自于私钥的，而私钥才决定密钥加密的安全性，并且私钥的长度可能会非常长，从最初的 1024、2048 到 4096 一直到更多的位数。增加私钥密钥位，从而提升密钥安全性。\n- 非对称加密算法遵循的基本原则：公钥加密的只能利用与之配对的私钥进行解密，反之亦然。\n- 非对称加密算法可以满足数据传输过程中对传输者身份验证的需求，因为接收者可以拥有相应的公钥，只有与之对应的发送者用相应的私钥进行加密信息，接收者用对应的公钥才可解密，否则可以确认发送者身份已经发生变化。\n\n### 🦄 数字签名原理：\n- **<font color=orange>公钥加密算法</font>** 解决通信双方身份验证问题，但无法确保公钥的真实性。\n- 因此，CA 数字签名使用证书授权中心（Certification Authority，简称 `CA`）解决通信双方交换的公钥的真实性，即数字证书的真实性（公钥包含于数字证书中）。\n- 数字签名证书的分类：  \n  - 自签名数字签名证书：    \n    不使用 `ca.key` 加密生成签名，使用自身的私钥加密生成签名，如 `GnuPG` 邮件加密传输。  \n  - CA 数字签名证书：    \n    使用 CA 证书授权中心的 `ca.key` 与 `ca.crt` 进行加密生成签名，如 `kube-apiserver`、Apache、Nginx、Tomcat 等，以下讨论该类型证书。\n- 🧬 实现方式：**<font color=orange>公钥非对称加密算法 + 消息摘要算法</font>**\n- 标准的 `X.509` 格式的 CA 数字签名证书组成：  \n  - 证书相关信息（C）：明文显示    \n    - 证书的版本信息（Version）    \n    - 证书的序列号（Serial Number，`srl`）：每个证书都有一个唯一的证书序列号    \n    - 证书所使用的签名算法：`sha256WithRSAEncryption`    \n    - 证书的发行机构名称：命名规则一般采用 `X.500` 格式（目录服务协议 X.500）    \n    - ⏱ 证书的有效期：现在通用的证书一般采用 UTC 时间格式，计时范围为 1950-2049。    \n    - 证书所有人的名称：命名规则一般采用 `X.500` 格式    \n    - 证书所有人的公钥信息    \n    - CA 数字签名校验码  \n  - 证书数字签名（S）：密文显示    \n    - 证书发行者（CA 证书授权中心）使用 CA 私钥加密生成签名\n- 🔥 CA 数字签名证书生成过程：  \n  - 该生成过程满足函数表达式：`S = F(Digest(C))`\n  - 其中 S 为证书数字签名，F 为签名算法，Digest 为消息摘要算法（MD5/SHA1/SHA256等），C 为证书相关信息。  \n  - 1️⃣ 服务端或客户端创建各自的私钥，并使用该私钥创建 `csr` 证书签名请求。  \n  - 2️⃣ 服务端或客户端的 `csr` 证书签名请求文件中包含证书相关信息 C 与相应的公钥信息。  \n  - 3️⃣ 使用消息摘要算法对证书相关信息 C 生成相应指纹（fingerprint），再使用 CA 私钥（ca.key）配合 CA 根证书（ca.crt）加密该指纹，最后生成服务端或客户端的 CA 数字签名证书。  \n  - 该 CA 数字签名只能被 CA 私钥（ca.key）对应位于 CA 根证书中的 CA 公钥解开。  \n  - 创建过程如下所示：也可参考该 [链接](https://github.com/Alberthua-Perl/scripts-confs/blob/master/shell-examples/create-ssl-certs.sh) 以获得以下过程的完整脚本\n    ```bash\n    $ openssl genrsa -out CA-center.key 2048\n    $ openssl req -key CA-center.key \\\n      -subj \"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=CA-center.lab.example.com\" \\\n      -new -x509 -days 3650 -out CA-center.crt\n    # 创建 CA 私钥与 CA 根证书（自签名）\n    $ openssl x509 -noout -text -in CA-center.crt\n      Certificate:\n        Data:\n            Version: 3 (0x2)\n            Serial Number:\n                fb:53:9c:3c:4d:81:f6:de\n        Signature Algorithm: sha256WithRSAEncryption\n            Issuer: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=CA-center.lab.example.com\n            Validity\n                Not Before: Jan  2 14:04:46 2023 GMT\n                Not After : Dec 30 14:04:46 2032 GMT\n            Subject: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=CA-center.lab.example.com\n            # 由于使用 CA 私钥自签名生成的 CA 根证书，其证书发行机构与所有人相同。\n            Subject Public Key Info:\n                Public Key Algorithm: rsaEncryption\n                    Public-Key: (2048 bit)\n                    Modulus:\n                        00:bf:9a:3d:48:8c:b9:21:cb:d4:e5:30:df:4a:0e:\n                        05:e1:29:fe:5c:1f:06:4d:fb:89:fe:f5:01:c7:37:\n                        c5:ee:f5:66:8f:2f:bd:48:82:a1:80:1e:00:9d:a0:\n                        ...\n    ```\n    ```bash\n    $ openssl genrsa -out server.key 2048\n    $ openssl req -key server.key \\\n      -subj \"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=cloud-ctl.lab.example.com\" \\\n      -new -out server.csr\n    $ openssl req -noout -text -in server.csr\n      Certificate Request:\n        Data:\n            Version: 0 (0x0)\n            Subject: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=cloud-ctl.lab.example.com \n            # 需签名服务端证书的所有人\n            Subject Public Key Info:  # csr 证书签名请求中的公钥信息\n                Public Key Algorithm: rsaEncryption  # 公钥加密算法：RSA（不对称加密）\n                    Public-Key: (2048 bit)\n                    Modulus:\n                        00:e0:bd:e9:ff:f5:16:e5:a9:94:9c:61:2f:27:c5:\n                        e9:76:a2:4b:e3:0f:1a:82:7d:7a:f1:bf:52:37:8d:\n                        54:ea:96:39:8c:c9:55:39:d6:5a:ac:03:2d:16:52:\n                        ...\n    # 创建与查看服务端私钥及 csr 证书签名请求文件\n    \n    $ openssl x509 -req -in server.csr \\\n      -CAkey CA-center.key -CA CA-center.crt -CAcreateserial \\\n      -days 3650 -out server.crt\n    # 使用 CA 私钥与 CA 根证书签发服务端 CA 数字签名证书\n    $ openssl x509 -noout -text -in server.crt\n      Certificate:\n        Data:\n            Version: 1 (0x0)\n            Serial Number:\n                a9:68:e7:c4:87:87:4e:03\n        Signature Algorithm: sha256WithRSAEncryption\n            Issuer: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=CA-center.lab.example.com \n            # 服务端 CA 数字签名证书的发行机构（CA 证书授权中心）\n            Validity\n                Not Before: Jan  2 14:04:46 2023 GMT\n                Not After : Dec 30 14:04:46 2032 GMT\n            Subject: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=cloud-ctl.lab.example.com\n            # 服务端 CA 数字签名证书的所有人：服务端信息\n            Subject Public Key Info:\n                Public Key Algorithm: rsaEncryption\n                    Public-Key: (2048 bit)\n                    Modulus:\n                        00:e0:bd:e9:ff:f5:16:e5:a9:94:9c:61:2f:27:c5:\n                        e9:76:a2:4b:e3:0f:1a:82:7d:7a:f1:bf:52:37:8d:\n                        54:ea:96:39:8c:c9:55:39:d6:5a:ac:03:2d:16:52:\n                        ...\n    # 该数字签名证书中的服务端公钥信息与其 csr 证书签名请求文件中的相同\n    ```\n- 客户端验证证书过程：  \n  - 验证服务端 CA 数字签名：    \n    - 客户端需具有 CA 根证书（ca.crt）    \n    - 客户端对服务端 CA 数字签名的验证满足表达式：`F'(S) = Digest(C)`\n    - 客户端将执行两种计算，并将计算结果进行比对：      \n      1️⃣ 由于证书相关信息（C）以明文显示，通过消息摘要算法计算 C 的哈希值。      \n      2️⃣ 使用 CA 公钥解密由服务端通过 CA 私钥加密的 CA 数字签名，获得原始证书相关信息（C）的哈希值。      \n      3️⃣ 若两者结果一致，说明证书有效且来自该 CA，未被篡改；若两者结果不一致，说明证书已被中间人篡改或不来自该 CA。  \n  - 提取服务端公钥：    \n    - CA 数字签名验证通过后，客户端就可以提取出服务端 CA 数字签名证书中的公钥进行通信。    \n    - 🤝 证书验证在 `SSL/TLS` 握手过程的 `Server Hello Done` 与 `Client Key Exchange` 之间。  \n  - 🚀 验证过程与原理，如下所示：![](ca-signed-certification-verify.jpg)\n\n### SSL/TLS 与 CA 相关术语：\n- 证书标准：`X.509`\n- 编码格式：  \n  - ✨ `PEM`：    \n    - privacy enhanced Mail    \n    - 纯文本形式的编码格式（Base64 编码），Apache 与 *nix 服务器偏向于使用该格式。  \n  - `DER`：    \n    - distinguished encoding Rules    \n    - 二进制形式的编码格式，Java 与 Windows 服务器偏向于使用该格式。\n- 证书（数字签名证书）：certificate（`CER` 或 `CRT`）\n- 私钥：private key\n- 👉 证书签名请求：  \n  - certificate signing request: `CSR`  \n  - 该文件使用私钥加密，包含公钥与签名申请者信息等。\n- CER 与 CRT 两者都为证书，CRT 在 Linux 上更常见。\n- CER、CRT、KEY、CSR 都可为 PEM 或 DER 编码格式！\n- 支持 SSL/TLS 协议的开源工具：`openssl`、`cfssl`、`gnutls`\n- 📚 man 查看以下命令：  \n  openssl、genrsa、rsa、req、x509、verify、s_client、s_server\n\n### SSL/TLS 加密通信要点：\n- 安全套接字层协议：Secure Socket Layer（SSL）\n- 传输层安全协议：Transport Layer Security（TLS）\n- SSL/TLS 历史背景：  \n  - 1994 年，NetScape 公司设计了 SSL 协议的 1.0 版，但未发布。  \n  - 1995 年，NetScape 公司发布 SSL 2.0 版，很快发现有严重漏洞。  \n  - 1996 年，SSL 3.0 版问世，得到大规模应用。  \n  - 1999 年，互联网标准化组织 ISOC 接替 NetScape 公司，发布了 SSL 的升级版 `TLS 1.0` 版。  \n  - 2006 年和 2008 年，TLS 进行了两次升级，分别为 TLS 1.1 版和 TLS 1.2 版。  \n  - 👉 最新的变动是 2011 年 `TLS 1.2` 的修订版。\n- TLS 与 SSL 之间的版本对应关系：  \n  - TLS 1.0 对应 SSL 3.1  \n  - TLS 1.1 对应 SSL 3.2  \n  - TLS 1.2 对应 SSL 3.3\n- 👉 一般主流浏览器都已经实现了 `TLS 1.2` 的支持。\n- SSL/TLS 协议在网络模型中的位置：![](ssl-tls-in-network-stack.png)\n- SSL/TLS 协议分为两部分：  \n  - Handshake Protocol：    \n    🤝 协商通信双方之后在本次会话中用于数据加密的会话密钥（`session key`），该过程为 \"握手阶段\"，其中会话密钥也称为协商密钥。  \n  - Record Protocol：    \n    定义使用会话密钥加密的数据的传输格式。\n- SSL 层：  \n  借助下层协议（TCP 层）的的信道安全地协商出一份会话密钥，并用此密钥来加密 HTTP 请求。\n- TCP 层：  \n  - 与 Web server 的 443 端口建立连接，传递由 SSL 处理后的数据。  \n  - SSL 在 TCP 之上建立一个加密通道，通过这一层的数据经过了加密，因此达到保密的效果。\n- 服务端本地与客户端本地的 SSL 套接字与 TCP 套接字的关系，如下所示：![](client-server-tcp-ssl-socket.png)\n\n### 🚀 基于 SSL/TLS 加密连接的 HTTPS 单/双向认证：\n- 以上关于服务端 CA 数字签名证书的验证只是 HTTPS 通信中的一部分，需通过其他步骤共同完成 HTTPS 加密通信。\n- HTTPS 加密通信认证分为两类：单向认证、双向认证\n- 单向认证中只需服务端提供服务端证书与私钥即可，而双向认证中服务端需提供证书与私钥外还需提供 CA 根证书（该证书用于客户端证书的签发），并且客户端需提供客户端证书与私钥。\n- 单向认证的过程，客户端从服务端下载服务端公钥证书进行验证，然后建立安全通信通道。\n- 双向认证的过程，客户端除了需要从服务端下载服务器的公钥证书进行验证外，还需要把客户端的公钥证书上传到服务端给服务端进行验证，等双方都认证通过了，才开始建立安全通信通道进行数据传输。\n- 👨‍🏫 **<font color=red>总结：</font>**  \n  无论 HTTPS 单向或双向认证都是客户端与服务端协商出 **<font color=red>会话密钥</font>** 与 **<font color=red>会话加密算法</font>** 的过程。\n- ✨ 以下从 HTTPS 抓包的角度说明 SSL/TLS 四次握手与 HTTPS 单/双向认证的详细过程：![](ssl-four-handshakes-https-single-and-mutual-authentication.png)上图中 **黑色箭头** 表示双向认证过程中多出的步骤，其余过程为单向认证过程。\n\n### 🧪 HTTPS 单向认证的 Wireshark 抓包分析：\n- 本例使用 `Nginx HTTPS` 服务测试 HTTPS（HTTP + SSL/TLS）加密通信。\n- 使用已配置服务端 CA 数字签名证书的 Nginx 容器测试 HTTPS 加密通信过程，并使用 `Wireshark` 抓包分析。\n- 构建 Nginx 容器使用的 [Dockerfile](https://github.com/Alberthua-Perl/dockerfile-s2i-demo/tree/master/nginx-ssl) 如下所示：  \n  ```dockerfile\n  # modified date: \n  #     - 2019-12-10: initial Dockerfile\n  #     - 2023-01-16: update nginx and add client ssl authentication\n  \n  FROM docker.io/library/centos:7.9.2009\n  MAINTAINER lhua \"hualongfeiyyy@163.com\"\n  \n  # install nginx dependent packages\n  RUN yum repolist && \\ \n      yum install -y gcc* && \\\n      yum install -y pcre-devel openssl openssl-devel && \\\n      yum clean all && \\\n      mkdir -p /application/nginx-1.22.1 && \\\n      useradd -u 1005 -M -s /sbin/nologin nginx\n      # create nginx user to run nginx worker processes\n  \n  # copy nginx source package to container rootfs\n  ADD nginx-1.22.1.tar.gz /tmp/\n  \n  # make install nginx \n  RUN cd /tmp/nginx-1.22.1 && \\\n      ./configure --user=nginx --group=nginx --prefix=/application/nginx-1.22.1 \\\n        --with-http_stub_status_module --with-http_ssl_module && \\\n      make && \\\n      make install && \\\n      ln -s /application/nginx-1.22.1 /application/nginx && \\\n      mkdir /application/nginx/conf/extra && \\\n      mkdir /application/nginx/html/www && \\\n      mkdir /application/nginx/key\n      # create virtual server, html and key directory.\n  \n  # copy nginx configuration file, virtual server configuration file and certification file.\n  ADD nginx.conf /application/nginx/conf/\n  ADD www.conf /application/nginx/conf/extra/\n  ADD index.html /application/nginx/html/www/\n  ADD certs/server.key /application/nginx/key/\n  ADD certs/server.crt /application/nginx/key/\n  ADD certs/CA-center.crt /application/nginx/key/\n  \n  EXPOSE 443\n  \n  # Note: Don't run nginx as backend daemon\n  CMD [\"/application/nginx/sbin/nginx\", \"-g\", \"daemon off;\"]\n  ```\n- Nginx 容器使用的 [配置文件](https://github.com/Alberthua-Perl/dockerfile-s2i-demo/blob/master/nginx-ssl/www.conf)，如下所示：  \n  ✨ 该配置文件启用 HTTPS 单向认证，若需开启双向认证过程，只需启用 `ssl_client_certificate` 与 `ssl_verify_client` 参数即可。  \n  ```nginx\n  # Web Service: domain-based virtual machine\n  server {\n      listen  443;\n      # alias for domain-based virtual machine\n      server_name  www.etiantian.org etiantian.org;\n  \n      ssl  on;  # Nginx 启用 SSL/TLS 验证：指定服务端 CA 数字签名证书与私钥\n      # enable openssl module to support SSL/TLS\n      ssl_certificate  /application/nginx/key/server.crt;\n      # server.crt 证书发送至客户端用于验证其身份，客户端使用其中的公钥加密\n      # pre-master 第三个随机数并发送至服务端协商会话密钥。\n      ssl_certificate_key  /application/nginx/key/server.key;\n      # server.key 用于解密从客户端发送来的已加密的 pre-master 第三个随机数\n      #ssl_client_certificate  /application/nginx/key/CA-center.crt;\n      #ssl_verify_client  on;\n      # 启用服务端对客户端 SSL/TLS 双向验证\n      # 若只需服务端单向验证，无需启用 ssl_client_certificate 与 ssl_verify_client。\n      ssl_session_timeout  5m;\n      ssl_protocols  TLSv1 TLSv1.1 TLSv1.2;\n      ssl_ciphers  ALL:!DH:!EXPORT:!RC4:+HIGH:+MEDIUM:-LOW:!aNULL:!eNULL;\n      ssl_prefer_server_ciphers  on; \n  \n      location / {\n          root   html/www;\n          index  index.html index.htm;\n      }\n  }\n  ```\n- 抓包 HTTPS 加密通信的三个过程：TCP 建立连接、SSL/TLS 握手、SSL/TLS 加密通信\n- HTTPS 加密通信 - 抓包整体示意：![](wireshark-https-single-progress.png)\n- 🤝 HTTPS 加密通信 - 4 次握手过程示意：![](ssl-tls-single-authentication-progress.png)👨‍💻 以下将握手过程分为 4 个阶段进行描述。\n- 1️⃣ HTTPS 加密通信 - 第 1 次握手过程：`Client Hello`  \n  - 客户端首先向服务端发送 Client Hello 的 SSL 握手信息。  \n  - Client Hello 握手信息中包含如下内容：    \n    - 客户端发起请求，以明文传输请求信息，包含版本信息、客户端随机数、加密套件候选列表、压缩算法候选列表、扩展字段等信息。    \n    - 支持的最高 TLS 协议版本，从低到高依次 SSLv2、SSLv3、TLSv1、TLSv1.1、TLSv1.2，当前基本不再使用低于 TLSv1 的版本。    \n    - ✨ 随机数 `random_C`，用于后续的会话密钥生成。    \n    - 客户端支持的加密套件 `Cipher Suites` 列表，每个加密套件对应 TLS 原理中的四个功能的组合：      \n      - 认证算法 `Au`：身份验证      \n      - 密钥交换算法 `KeyExchange`：（会话）密钥协商      \n      - 对称加密算法 `Enc`：信息加密      \n      - 信息摘要 `Mac`：完整性校验    \n    - 支持的压缩算法 `Compression Methods` 列表，用于后续的信息压缩传输。    \n    - 扩展字段 Extensions，支持协议与算法的相关参数以及其它辅助信息等，常见的 SNI 就属于扩展字段。![](client-hello-body-1.png)  \n  - 客户端支持的 17 种加密套件供服务端选择使用。![](client-hello-body-2.png)\n- 2️⃣ HTTPS 加密通信 - 第 2 次握手过程：服务端给客户端回复的 4 条 SSL 握手信息![](server-response-to-client-ssl.png)\n  - `Server Hello`：    \n    - 服务端返回协商的信息结果，包括选择使用的协议版本、选择的加密套件、选择的压缩算法、随机数 `random_S` 等，其中随机数用于后续的密钥协商。    \n    - 服务端选择 **<font color=orange>TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384</font>** 作为密钥交互的加密套件，该加密套件的名字在客户端发送给服务器的支持的 `17` 个列表中。    \n    - 该加密套件包含：      \n      - 非对称加密（密钥交换算法）：`ECDHE + RSA`      \n      - 对称加密算法：`AES + GCM`      \n      - 消息摘要算法：`SHA-384`  \n  - `Certificate`：该 SSL 握手信息中包含服务端 CA 数字签名证书![](server-ca-signed-certification.png)  \n  - `Server Key Exchange`：    \n    使用 `EC Diffie-Hellman` 算法（`ECDHE`）实现服务端与客户端的密钥交换算法协商。![](server-key-exchange.png)   \n    💥 对于使用 `DHE/ECDHE` 非对称密钥协商算法的 SSL 握手，将发送该类型握手。`RSA`、`DH`、`ECDH` 算法不会进行该 server key exchange 握手流程。 \n  - `Server Hello Done`：通知客户端 Server Hello 信息发送结束![](server-hello-done.jpg)\n- 3️⃣ HTTPS 加密通信 - 第 3 次握手过程：客户端给服务端回复 3 条 SSL 握手信息![](client-response-to-server-ssl.jpg)\n  - `Client Key Exchange`：    \n    - 服务端 CA 数字签名证书合法性验证通过后，客户端计算产生随机数字 `Pre-master`，并用服务端证书中的公钥加密，发送给服务端。      \n      💥 注意：服务端证书合法性验证失败，SSL 握手即停止！    \n    - 此时客户端已经获取全部的计算会话密钥需要的信息：      \n      🚀 两个明文随机数 `random_C` 和 `random_S` 与自己计算产生的 `Pre-master`，计算得到会话密钥。  \n  - `Change Cipher Spec`：    \n     🚀 客户端通知服务端后续的通信都采用协商的 **<font color=red>会话密钥</font>** 和 **<font color=red>会话加密算法</font>** 进行加密通信。  \n  - `Encrypted Handshake Message`：    \n    结合之前所有通信参数的哈希值生成一段数据，采用会话密钥与加密算法进行加密，然后发送给服务器用于数据与握手验证。\n- 4️⃣ HTTPS 加密通信 - 第 4 次握手过程：服务端给客户端回复 2 条 SSL 握手信息![](server-response-to-client-4-phase.png)\n  - `Change Cipher Spec`：    \n    - 服务端用私钥解密加密的 `Pre-master` 随机数，基于之前交换的两个明文随机数 random_C 和 random_S，计算得到会话密钥。    \n    - 计算之前所有接收信息的哈希值，然后解密客户端发送的 `Encrypted Handshake Message`，验证会话密钥和数据的准确性。    \n    - Change Cipher Spec 验证通过之后，服务端同样发送 Change Cipher Spec 以告知客户端后续的通信都采用协商的会话密钥与算法进行加密通信。  \n  - `Encrypted Handshake Message`：    \n    - 服务器也结合所有当前的通信参数信息生成一段数据并采用会话密钥与加密算法进行加密，并发送到客户端。\n- HTTPS 加密通信 - 握手结束：  \n  - 客户端计算所有接收信息的哈希值，并采用会话密钥解密 Encrypted Handshake Message，验证服务器发送的会话密钥和数据，验证通过则握手完成。  \n  - 开始使用会话密钥与加密算法进行加密通信。![](ssl-tls-handshake-end.png)\n\n### HTTPS 单向认证测试：\n- 服务端启用 HTTPS 单向认证后，可从浏览器客户端进行访问测试：![](https-single-auth-chrome-error-1.png)\n- 该服务端 CA 数字签名使用未经认证的 CA 签发，因此客户端浏览器无法验证其安全性而发出警告，可点击 \"高级\" 按钮接受该证书继续访问。若拒绝该证书，即断开此次认证连接，可在如下 Wireshark 抓包中显示安全告警信息：![](https-single-auth-chrome-error-2.png) \n\n### HTTPS 双向认证的 Wireshark 抓包与测试：\n- HTTPS 双向认证的 Wireshark 抓包过程如下所示，其中具体的步骤参见前文 \"SSL/TLS 四次握手与 HTTPS 单/双向认证的详细过程\" 与单向认证的过程。![](wireshark-https-single-progress.png)\n- HTTPS 双向认证过程的客户端测试：  \n  - 配置生成客户端所需的数字签名证书与私钥：    \n    ```bash\n    $ openssl genrsa -out client.key 2048\n    $ openssl req -key client.key \\\n      -subj \"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=firefox\" \\\n      -new -out client.csr\n    $ openssl x509 -req -in client.csr \\\n      -CAkey CA-center.key -CA CA-center.crt -CAcreateserial \\\n      -days 3650 -out client.crt\n    ```\n  - 若将客户端数字签名证书与私钥用于 `Firefox` 或 `Chrome` 浏览器访问服务端，可将其转换为 `p12` 格式：    \n    ```bash\n    $ openssl pkcs12 -export -clcerts \\\n      -in client.crt -inkey client.key -out client.p12\n    # 创建 client.p12 文件时将交互式输入加密密码\n    ```\n  - 将 p12 格式的文件导入 Firefox 浏览器客户端：![](firefox-import-pc12-certs-1.png)![](firefox-import-pc12-certs-2.png)![](firefox-import-pc12-certs-3.png)![](firefox-import-pc12-certs-4.png)\n  - 打开 Firefox 浏览器访问服务端，此时需接受客户端证书来标记自己：![](firefox-import-pc12-certs-5.png)  \n  - 💥 若双向认证客户端配置错误，将无法正常访问服务端，并且浏览器直接返回如下信息，且 Wireshark 抓包显示 `Encrypted Alert`：![](https-mutual-no-client-cert-error-1.png)![](https-mutual-no-client-cert-error-2.png)\n\n### openssl 常用命令汇总：\n- `openssl req` 命令选项：创建 `csr` 证书签名请求与数字签名证书（或自签名证书）  \n  ```bash\n  -key               指定用于创建 csr 证书签名请求的私钥            \n  -newkey alg:nbits  创建新的 csr 证书签名请求与私钥，指定加密算法与加密位数\n                    （通常为 rsa:2048）。             \n  -nodes             不使用密码为新创建的私钥加密\n  -keyout            指定新创建私钥的文件名\n  -sha256            使用 SHA-256 摘要（创建自签名数字证书时使用）\n  -subj              指定创建 csr 证书签名请求与数字签名证书所需的详细信息若未指定\n                     该选项，将进入交互模式。\n  -new               生成新的 csr 证书签名请求\n  -x509              生成数字签名证书（不生成证书签名请求）\n  -days              指定数字签名证书的合法时间（有效期），默认 30 天。\n  -out               指定输出的 csr 证书签名请求或数字签名证书的名称\n  ```\n- `openssl x509` 命令选项：创建与查看数字签名证书  \n  ```bash\n  -req             指定 csr 证书签名请求，与 -in 选项合用。                \n  -in              指定输入文件\n  -CAkey           指定用于签署证书的 CA 私钥\n  -CA              指定用于签署证书的 CA 根证书\n  -CAcreateserial  创建 CA 序列号文件，扩展名为 \".srl\"，该选项必须与 -CA 选项合用。\n  -days            指定数字签名证书的合法时间（有效期），默认 30 天，不与\n                   -preserve_dates 选项合用。\n  -out             指定输出的数字签名证书名称\n  ```\n- 创建自签名数字证书的 2 种方法：  \n  - 1️⃣ 先创建私钥再创建自签名数字证书  \n  - 2️⃣ 同时创建私钥与自签名数字证书    \n    ```bash\n    $ openssl req -newkey rsa:4096 -nodes -keyout server.key \\\n      -sha256 -subj \"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=cloud-ctl.lab.example.com\" \\\n      -x509 -days 3650 -out server.crt\n    ```\n- 创建 CA RSA 私钥与 CA 根证书（root-ca）：  \n  ```bash\n  $ openssl genrsa [-des3] -out ca.key [1024|2048|4096]\n  # 创建 CA RSA 私钥\n  # -des3 选项：交互输入密码为 RSA 私钥加密\n  \n  $ openssl req -key ca.key \\\n    -subj \"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=CA-center.lab.example.com\" \\\n    -new -x509 \\\n    -days 3650 -out ca.crt\n  # 创建 CA 自签名根证书\n  \n  $ openssl rsa -in ca.key -text -noout\n  # 查看 CA RSA 私钥的详细信息\n  \n  $ openssl x509 -in ca.crt -text -noout\n  # 查看 CA 根证书的详细信息\n  ```\n- 基于 CA 根证书创建 server 端数字签名证书：  \n  ```bash\n  $ openssl genrsa [-des3] -out server.key [1024|2048|4096]\n  # 创建 server 端 RSA 私钥\n  \n  $ openssl rsa -in server.key -pubout -out server.pub\n  # 提取 server 端 RSA 私钥对应的公钥（公钥由私钥中提取）\n  \n  $ openssl req -key server.key \\\n    -subj \"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=cloud-ctl.lab.example.com\" \\\n    -new -out server.csr\n  # 创建 server 端证书签名请求（certificate signing request）\n  # 注意：\n  #   1. 创建 csr 不使用 -x509 与 -days 选项\n  #   2. 在创建生成服务端与客户端证书签名请求时均要注意以下三点：\n  #      a. CA 根证书的 Common Name 填写 root 即可，所有服务端和客户端的证书该字段\n  #         需要填写 IP 或域名。\n  #      b. 一定要注意的是，CA 根证书的该字段和服务端证书、客户端证书不能一样。\n  #      c. 其他所有字段的填写，CA 根证书、服务端证书、客户端证书需保持一致，最后的密码\n  #         可直接回车跳过。\n  \n  $ openssl req -noout -text -in server.csr\n  # 查看 server 端证书签名请求的详细信息\n  \n  $ openssl x509 -req -in server.csr \\\n    -CAkey ca.key -CA ca.crt -CAcreateserial \\\n    -days 3650 -out server.crt\n  # 使用 server 端 csr 证书签名请求、CA RSA 私钥与 CA 根证书创建 server 端数字签名证书\n  \n  ### 查看 server 端数字签名证书的相关信息 ###\n  $ openssl x509 -noout -serial -in server.crt\n  # 查看 server 端数字签名证书的序列号\n  $ openssl x509 -noout -dates -in server.crt\n  # 查看 server 端数字签名证书的有效期\n  $ openssl x509 -noout -pubkey -in server.crt\n  # 查看 server 端数字签名证书中的公钥信息，该公钥与私钥中提取的公钥一致。\n  ```\n- 基于 CA 根证书创建 client 端数字签名证书：  \n  ```bash\n  $ openssl genrsa [-des3] -out client.key [1024|2048|4096]\n  # 创建 client 端 RSA 私钥\n  \n  $ openssl req -key client.key \\\n    -subj \"/C=CN/ST=Shanghai/L=Shanghai/CN=sec-srv.lab.example.com\" \\\n    -new -out client.csr\n  # 创建 client 端证书签名请求\n  \n  $ openssl x509 -req -in client.csr \\\n    -CAkey ca.key -CA ca.crt -CAcreateserial \\\n    -days 3650 -out client.crt\n  # 使用证书签名请求、CA RSA 私钥与 CA 根证书创建 client 端数字签名证书\n  ```\n\n### openssl 使用数字签名证书的单双向连接测试：\n- 使用 server 端数字签名证书进行单向连接测试：  \n  ```bash\n  $ openssl s_server -accept <port> -key server.key -cert server.crt    \n  # server 端：启动单向安全连接，启动后将等待 client 端发送信息并回显\n  $ openssl s_client -connect <host_ip>:<port>\n  # client 端：连接 server 端，若连接成功后将在任意一端输入信息后会在另一端显示该信息。\n  ```\n- 使用 server 端与 client 端数字签名证书进行双向连接测试：  \n  ```bash\n  $ openssl s_server -accept <port> \\\n    -key server.key -cert server.crt -Verify <depth>\n  # server 端：强制要求 client 端提供私钥与 client 端数字签名证书进行安全连接\n  $ openssl s_server -accept 10001 \\\n    -key server.key -cert server.crt -Verify 5\n  \n  $ openssl s_client -connect <host_ip>:<port> \\\n    -key client.key -cert client.crt\n  # client 端：连接 server 端，若连接成功后将在任意一端输入信息后会在另一端显示该信息。\n  $ openssl s_client \\\n    -connect 10.197.11.100:10001 -key client.key -cert client.crt\n  ```\n\n### 参考链接：\n- [HTTPS 加密协议详解 (四)：TLS/SSL 握手过程](https://www.wosign.com/FAQ/faq2016-0309-04.htm)\n- [TLS/SSL 协议详解(12) server key exchange](https://blog.csdn.net/mrpre/article/details/77867831)\n- [什么是 HTTPS 双向认证(MutualTLSauthentication)_API 网关 - 阿里云帮助中心](https://help.aliyun.com/document_detail/160093.html)\n- [HTTPS 双向证书认证](https://blog.xizhibei.me/2021/02/03/https-two-way-authentication-with-certificates/)\n- [NGINX 配置本地 HTTPS (双向认证)](https://www.cnblogs.com/xiao987334176/p/11041241.html)\n- [常见证书格式和转换](https://blog.csdn.net/justinjing0612/article/details/7770301)\n- [常见证书格式及相互转换](https://www.cnblogs.com/lzjsky/archive/2010/11/14/1877143.html)\n- [openssl 生成自签证书及查看证书细节](https://www.cnblogs.com/threegun/p/7130985.html)","source":"_posts/https-handshake-authentication.md","raw":"---\ntitle: 一文厘清 HTTPS 原理与应用\nsubtitle: SSL/TLS handshake and HTTPS authentication\nheader-img: https-bg.png\ndate: 2023-01-20 11:28:29\ntags:\n  - HTTPS\n---\n\n### 文档说明：\n- OS 版本：`CentOS Linux release 7.9.2009 (Core)`\n- Kernel 版本：`4.20.3-1.el7.elrepo.x86_64`\n- OpenSSL 版本：`openssl-1.0.2k-21.el7_9.x86_64.rpm`\n- Docker 版本：`20.10.8`\n- Nginx 版本：`1.22.1`\n- ✨ HTTPS 在常规 Web 服务器、中间件服务器及 `RESTful API` 等通信中广泛大量使用，因此理解 HTTPS 及相关概念显得尤为重要。\n- 该文档使用 openssl 工具创建与管理相关私钥与证书，当然也可使用 cfssl 或 certtool（来源于 gnutls-utils 软件包）工具创建与管理。\n\n### 文档目录：\n- 加密通信背景\n- 保证数据的机密性\n- 保证数据的真实性与完整性\n- 保证传输双方的身份验证\n- 数字签名原理\n- SSL/TLS 与 CA 相关术语\n- SSL/TLS 加密通信要点\n- 基于 SSL/TLS 加密连接的 HTTPS 单/双向认证\n- HTTPS 单向认证的 Wireshark 抓包分析\n- HTTPS 单向认证测试\n- HTTPS 双向认证的 Wireshark 抓包与测试\n- openssl 常用命令汇总\n- openssl 使用数字签名证书的单双向连接测试\n- 参考链接\n\n### 加密通信背景：\n- 网络安全问题：  \n  HTTP 不使用 SSL/TLS 进行加密通信，所有信息明文传播，带来了三大风险：  \n  - 窃听风险（eavesdropping）：第三方可以获知通信内容  \n  - 篡改风险（tampering）：第三方可以修改通信内容  \n  - 冒充风险（pretending）：第三方可以冒充他人身份参与通信\n- 网络安全问题的解决思路：`SSL/TLS` 协议  \n  - 所有信息都是加密传播，第三方无法窃听。  \n  - 具有校验机制，一旦被篡改，通信双方会立刻发现。  \n  - 配备身份证书，防止身份被冒充。\n\n### 保证数据的机密性：不被窃听\n- 🧬 实现方式：对称加密算法\n- 💥 单纯的数据加密只能保证数据不被泄露，但不能保证接收方收到的数据的真实性。\n\n### 保证数据的真实性与完整性：不被篡改\n- 数据的真实性：真实数据没有被篡改，数据是从真实发送者发来。\n- 🧬 实现方式：消息摘要算法（或称散列算法/单向散列函数）生成数据指纹（特征码）\n- 💥 利用提取数据指纹的方式，完成数据传输的完整性验证。\n- 🔒 实际的算法实现过程概要：  \n  - 给一段明文数据（plain text）加上数据信息指纹，这个指纹是通过结合数据信息进行相应算法获得的数据指纹。  \n  - 接收方当收到数据信息后，会利用相同的算法对获取的数据计算指纹，确认得到的指纹是否与传送过来的描述数据的指纹一致。  \n  - 如果一致，表示数据没有被篡改过；如果不一致，表示数据完整性遭到破坏，数据一概不予以接收处理。\n- 由于可能存在中间人攻击的可能性，因此可对传输过程中的数据指纹进行加密。\n- 发送方利用对称密钥方式对手中的指纹进行加密，接收方会利用相同的密钥对手中的指纹进行解密，从而确认指纹是否一致。\n- 如果中间人将新的指纹也进行了加密，发送给接收方，但接收方无法利用和发送方协商好的解密密钥对指纹进行解密，最终无法识别中间人发送过来的数据指纹信息。\n- 🤘 通过加密指纹可以保证真实数据没有被篡改。\n\n### 保证传输双方的身份验证：\n- 以上信息只是解决数据的交换获取问题，但是网络的身份验证问题依旧没有解决。\n- 🧬 实现方式：非对称加密\n- 利用非对称加密算法，可以有效解决网络中数据传输双方的安全身份验证问题。\n- 💥 非对称加密算法中，存在密钥对的概念，即拥有公钥（`public key`）与私钥（`private key`），其中公钥不是自行创建出来的而是从私钥中提取出来一部分作为公钥，因此可以说公钥是来自于私钥的，而私钥才决定密钥加密的安全性，并且私钥的长度可能会非常长，从最初的 1024、2048 到 4096 一直到更多的位数。增加私钥密钥位，从而提升密钥安全性。\n- 非对称加密算法遵循的基本原则：公钥加密的只能利用与之配对的私钥进行解密，反之亦然。\n- 非对称加密算法可以满足数据传输过程中对传输者身份验证的需求，因为接收者可以拥有相应的公钥，只有与之对应的发送者用相应的私钥进行加密信息，接收者用对应的公钥才可解密，否则可以确认发送者身份已经发生变化。\n\n### 🦄 数字签名原理：\n- **<font color=orange>公钥加密算法</font>** 解决通信双方身份验证问题，但无法确保公钥的真实性。\n- 因此，CA 数字签名使用证书授权中心（Certification Authority，简称 `CA`）解决通信双方交换的公钥的真实性，即数字证书的真实性（公钥包含于数字证书中）。\n- 数字签名证书的分类：  \n  - 自签名数字签名证书：    \n    不使用 `ca.key` 加密生成签名，使用自身的私钥加密生成签名，如 `GnuPG` 邮件加密传输。  \n  - CA 数字签名证书：    \n    使用 CA 证书授权中心的 `ca.key` 与 `ca.crt` 进行加密生成签名，如 `kube-apiserver`、Apache、Nginx、Tomcat 等，以下讨论该类型证书。\n- 🧬 实现方式：**<font color=orange>公钥非对称加密算法 + 消息摘要算法</font>**\n- 标准的 `X.509` 格式的 CA 数字签名证书组成：  \n  - 证书相关信息（C）：明文显示    \n    - 证书的版本信息（Version）    \n    - 证书的序列号（Serial Number，`srl`）：每个证书都有一个唯一的证书序列号    \n    - 证书所使用的签名算法：`sha256WithRSAEncryption`    \n    - 证书的发行机构名称：命名规则一般采用 `X.500` 格式（目录服务协议 X.500）    \n    - ⏱ 证书的有效期：现在通用的证书一般采用 UTC 时间格式，计时范围为 1950-2049。    \n    - 证书所有人的名称：命名规则一般采用 `X.500` 格式    \n    - 证书所有人的公钥信息    \n    - CA 数字签名校验码  \n  - 证书数字签名（S）：密文显示    \n    - 证书发行者（CA 证书授权中心）使用 CA 私钥加密生成签名\n- 🔥 CA 数字签名证书生成过程：  \n  - 该生成过程满足函数表达式：`S = F(Digest(C))`\n  - 其中 S 为证书数字签名，F 为签名算法，Digest 为消息摘要算法（MD5/SHA1/SHA256等），C 为证书相关信息。  \n  - 1️⃣ 服务端或客户端创建各自的私钥，并使用该私钥创建 `csr` 证书签名请求。  \n  - 2️⃣ 服务端或客户端的 `csr` 证书签名请求文件中包含证书相关信息 C 与相应的公钥信息。  \n  - 3️⃣ 使用消息摘要算法对证书相关信息 C 生成相应指纹（fingerprint），再使用 CA 私钥（ca.key）配合 CA 根证书（ca.crt）加密该指纹，最后生成服务端或客户端的 CA 数字签名证书。  \n  - 该 CA 数字签名只能被 CA 私钥（ca.key）对应位于 CA 根证书中的 CA 公钥解开。  \n  - 创建过程如下所示：也可参考该 [链接](https://github.com/Alberthua-Perl/scripts-confs/blob/master/shell-examples/create-ssl-certs.sh) 以获得以下过程的完整脚本\n    ```bash\n    $ openssl genrsa -out CA-center.key 2048\n    $ openssl req -key CA-center.key \\\n      -subj \"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=CA-center.lab.example.com\" \\\n      -new -x509 -days 3650 -out CA-center.crt\n    # 创建 CA 私钥与 CA 根证书（自签名）\n    $ openssl x509 -noout -text -in CA-center.crt\n      Certificate:\n        Data:\n            Version: 3 (0x2)\n            Serial Number:\n                fb:53:9c:3c:4d:81:f6:de\n        Signature Algorithm: sha256WithRSAEncryption\n            Issuer: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=CA-center.lab.example.com\n            Validity\n                Not Before: Jan  2 14:04:46 2023 GMT\n                Not After : Dec 30 14:04:46 2032 GMT\n            Subject: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=CA-center.lab.example.com\n            # 由于使用 CA 私钥自签名生成的 CA 根证书，其证书发行机构与所有人相同。\n            Subject Public Key Info:\n                Public Key Algorithm: rsaEncryption\n                    Public-Key: (2048 bit)\n                    Modulus:\n                        00:bf:9a:3d:48:8c:b9:21:cb:d4:e5:30:df:4a:0e:\n                        05:e1:29:fe:5c:1f:06:4d:fb:89:fe:f5:01:c7:37:\n                        c5:ee:f5:66:8f:2f:bd:48:82:a1:80:1e:00:9d:a0:\n                        ...\n    ```\n    ```bash\n    $ openssl genrsa -out server.key 2048\n    $ openssl req -key server.key \\\n      -subj \"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=cloud-ctl.lab.example.com\" \\\n      -new -out server.csr\n    $ openssl req -noout -text -in server.csr\n      Certificate Request:\n        Data:\n            Version: 0 (0x0)\n            Subject: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=cloud-ctl.lab.example.com \n            # 需签名服务端证书的所有人\n            Subject Public Key Info:  # csr 证书签名请求中的公钥信息\n                Public Key Algorithm: rsaEncryption  # 公钥加密算法：RSA（不对称加密）\n                    Public-Key: (2048 bit)\n                    Modulus:\n                        00:e0:bd:e9:ff:f5:16:e5:a9:94:9c:61:2f:27:c5:\n                        e9:76:a2:4b:e3:0f:1a:82:7d:7a:f1:bf:52:37:8d:\n                        54:ea:96:39:8c:c9:55:39:d6:5a:ac:03:2d:16:52:\n                        ...\n    # 创建与查看服务端私钥及 csr 证书签名请求文件\n    \n    $ openssl x509 -req -in server.csr \\\n      -CAkey CA-center.key -CA CA-center.crt -CAcreateserial \\\n      -days 3650 -out server.crt\n    # 使用 CA 私钥与 CA 根证书签发服务端 CA 数字签名证书\n    $ openssl x509 -noout -text -in server.crt\n      Certificate:\n        Data:\n            Version: 1 (0x0)\n            Serial Number:\n                a9:68:e7:c4:87:87:4e:03\n        Signature Algorithm: sha256WithRSAEncryption\n            Issuer: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=CA-center.lab.example.com \n            # 服务端 CA 数字签名证书的发行机构（CA 证书授权中心）\n            Validity\n                Not Before: Jan  2 14:04:46 2023 GMT\n                Not After : Dec 30 14:04:46 2032 GMT\n            Subject: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=cloud-ctl.lab.example.com\n            # 服务端 CA 数字签名证书的所有人：服务端信息\n            Subject Public Key Info:\n                Public Key Algorithm: rsaEncryption\n                    Public-Key: (2048 bit)\n                    Modulus:\n                        00:e0:bd:e9:ff:f5:16:e5:a9:94:9c:61:2f:27:c5:\n                        e9:76:a2:4b:e3:0f:1a:82:7d:7a:f1:bf:52:37:8d:\n                        54:ea:96:39:8c:c9:55:39:d6:5a:ac:03:2d:16:52:\n                        ...\n    # 该数字签名证书中的服务端公钥信息与其 csr 证书签名请求文件中的相同\n    ```\n- 客户端验证证书过程：  \n  - 验证服务端 CA 数字签名：    \n    - 客户端需具有 CA 根证书（ca.crt）    \n    - 客户端对服务端 CA 数字签名的验证满足表达式：`F'(S) = Digest(C)`\n    - 客户端将执行两种计算，并将计算结果进行比对：      \n      1️⃣ 由于证书相关信息（C）以明文显示，通过消息摘要算法计算 C 的哈希值。      \n      2️⃣ 使用 CA 公钥解密由服务端通过 CA 私钥加密的 CA 数字签名，获得原始证书相关信息（C）的哈希值。      \n      3️⃣ 若两者结果一致，说明证书有效且来自该 CA，未被篡改；若两者结果不一致，说明证书已被中间人篡改或不来自该 CA。  \n  - 提取服务端公钥：    \n    - CA 数字签名验证通过后，客户端就可以提取出服务端 CA 数字签名证书中的公钥进行通信。    \n    - 🤝 证书验证在 `SSL/TLS` 握手过程的 `Server Hello Done` 与 `Client Key Exchange` 之间。  \n  - 🚀 验证过程与原理，如下所示：![](ca-signed-certification-verify.jpg)\n\n### SSL/TLS 与 CA 相关术语：\n- 证书标准：`X.509`\n- 编码格式：  \n  - ✨ `PEM`：    \n    - privacy enhanced Mail    \n    - 纯文本形式的编码格式（Base64 编码），Apache 与 *nix 服务器偏向于使用该格式。  \n  - `DER`：    \n    - distinguished encoding Rules    \n    - 二进制形式的编码格式，Java 与 Windows 服务器偏向于使用该格式。\n- 证书（数字签名证书）：certificate（`CER` 或 `CRT`）\n- 私钥：private key\n- 👉 证书签名请求：  \n  - certificate signing request: `CSR`  \n  - 该文件使用私钥加密，包含公钥与签名申请者信息等。\n- CER 与 CRT 两者都为证书，CRT 在 Linux 上更常见。\n- CER、CRT、KEY、CSR 都可为 PEM 或 DER 编码格式！\n- 支持 SSL/TLS 协议的开源工具：`openssl`、`cfssl`、`gnutls`\n- 📚 man 查看以下命令：  \n  openssl、genrsa、rsa、req、x509、verify、s_client、s_server\n\n### SSL/TLS 加密通信要点：\n- 安全套接字层协议：Secure Socket Layer（SSL）\n- 传输层安全协议：Transport Layer Security（TLS）\n- SSL/TLS 历史背景：  \n  - 1994 年，NetScape 公司设计了 SSL 协议的 1.0 版，但未发布。  \n  - 1995 年，NetScape 公司发布 SSL 2.0 版，很快发现有严重漏洞。  \n  - 1996 年，SSL 3.0 版问世，得到大规模应用。  \n  - 1999 年，互联网标准化组织 ISOC 接替 NetScape 公司，发布了 SSL 的升级版 `TLS 1.0` 版。  \n  - 2006 年和 2008 年，TLS 进行了两次升级，分别为 TLS 1.1 版和 TLS 1.2 版。  \n  - 👉 最新的变动是 2011 年 `TLS 1.2` 的修订版。\n- TLS 与 SSL 之间的版本对应关系：  \n  - TLS 1.0 对应 SSL 3.1  \n  - TLS 1.1 对应 SSL 3.2  \n  - TLS 1.2 对应 SSL 3.3\n- 👉 一般主流浏览器都已经实现了 `TLS 1.2` 的支持。\n- SSL/TLS 协议在网络模型中的位置：![](ssl-tls-in-network-stack.png)\n- SSL/TLS 协议分为两部分：  \n  - Handshake Protocol：    \n    🤝 协商通信双方之后在本次会话中用于数据加密的会话密钥（`session key`），该过程为 \"握手阶段\"，其中会话密钥也称为协商密钥。  \n  - Record Protocol：    \n    定义使用会话密钥加密的数据的传输格式。\n- SSL 层：  \n  借助下层协议（TCP 层）的的信道安全地协商出一份会话密钥，并用此密钥来加密 HTTP 请求。\n- TCP 层：  \n  - 与 Web server 的 443 端口建立连接，传递由 SSL 处理后的数据。  \n  - SSL 在 TCP 之上建立一个加密通道，通过这一层的数据经过了加密，因此达到保密的效果。\n- 服务端本地与客户端本地的 SSL 套接字与 TCP 套接字的关系，如下所示：![](client-server-tcp-ssl-socket.png)\n\n### 🚀 基于 SSL/TLS 加密连接的 HTTPS 单/双向认证：\n- 以上关于服务端 CA 数字签名证书的验证只是 HTTPS 通信中的一部分，需通过其他步骤共同完成 HTTPS 加密通信。\n- HTTPS 加密通信认证分为两类：单向认证、双向认证\n- 单向认证中只需服务端提供服务端证书与私钥即可，而双向认证中服务端需提供证书与私钥外还需提供 CA 根证书（该证书用于客户端证书的签发），并且客户端需提供客户端证书与私钥。\n- 单向认证的过程，客户端从服务端下载服务端公钥证书进行验证，然后建立安全通信通道。\n- 双向认证的过程，客户端除了需要从服务端下载服务器的公钥证书进行验证外，还需要把客户端的公钥证书上传到服务端给服务端进行验证，等双方都认证通过了，才开始建立安全通信通道进行数据传输。\n- 👨‍🏫 **<font color=red>总结：</font>**  \n  无论 HTTPS 单向或双向认证都是客户端与服务端协商出 **<font color=red>会话密钥</font>** 与 **<font color=red>会话加密算法</font>** 的过程。\n- ✨ 以下从 HTTPS 抓包的角度说明 SSL/TLS 四次握手与 HTTPS 单/双向认证的详细过程：![](ssl-four-handshakes-https-single-and-mutual-authentication.png)上图中 **黑色箭头** 表示双向认证过程中多出的步骤，其余过程为单向认证过程。\n\n### 🧪 HTTPS 单向认证的 Wireshark 抓包分析：\n- 本例使用 `Nginx HTTPS` 服务测试 HTTPS（HTTP + SSL/TLS）加密通信。\n- 使用已配置服务端 CA 数字签名证书的 Nginx 容器测试 HTTPS 加密通信过程，并使用 `Wireshark` 抓包分析。\n- 构建 Nginx 容器使用的 [Dockerfile](https://github.com/Alberthua-Perl/dockerfile-s2i-demo/tree/master/nginx-ssl) 如下所示：  \n  ```dockerfile\n  # modified date: \n  #     - 2019-12-10: initial Dockerfile\n  #     - 2023-01-16: update nginx and add client ssl authentication\n  \n  FROM docker.io/library/centos:7.9.2009\n  MAINTAINER lhua \"hualongfeiyyy@163.com\"\n  \n  # install nginx dependent packages\n  RUN yum repolist && \\ \n      yum install -y gcc* && \\\n      yum install -y pcre-devel openssl openssl-devel && \\\n      yum clean all && \\\n      mkdir -p /application/nginx-1.22.1 && \\\n      useradd -u 1005 -M -s /sbin/nologin nginx\n      # create nginx user to run nginx worker processes\n  \n  # copy nginx source package to container rootfs\n  ADD nginx-1.22.1.tar.gz /tmp/\n  \n  # make install nginx \n  RUN cd /tmp/nginx-1.22.1 && \\\n      ./configure --user=nginx --group=nginx --prefix=/application/nginx-1.22.1 \\\n        --with-http_stub_status_module --with-http_ssl_module && \\\n      make && \\\n      make install && \\\n      ln -s /application/nginx-1.22.1 /application/nginx && \\\n      mkdir /application/nginx/conf/extra && \\\n      mkdir /application/nginx/html/www && \\\n      mkdir /application/nginx/key\n      # create virtual server, html and key directory.\n  \n  # copy nginx configuration file, virtual server configuration file and certification file.\n  ADD nginx.conf /application/nginx/conf/\n  ADD www.conf /application/nginx/conf/extra/\n  ADD index.html /application/nginx/html/www/\n  ADD certs/server.key /application/nginx/key/\n  ADD certs/server.crt /application/nginx/key/\n  ADD certs/CA-center.crt /application/nginx/key/\n  \n  EXPOSE 443\n  \n  # Note: Don't run nginx as backend daemon\n  CMD [\"/application/nginx/sbin/nginx\", \"-g\", \"daemon off;\"]\n  ```\n- Nginx 容器使用的 [配置文件](https://github.com/Alberthua-Perl/dockerfile-s2i-demo/blob/master/nginx-ssl/www.conf)，如下所示：  \n  ✨ 该配置文件启用 HTTPS 单向认证，若需开启双向认证过程，只需启用 `ssl_client_certificate` 与 `ssl_verify_client` 参数即可。  \n  ```nginx\n  # Web Service: domain-based virtual machine\n  server {\n      listen  443;\n      # alias for domain-based virtual machine\n      server_name  www.etiantian.org etiantian.org;\n  \n      ssl  on;  # Nginx 启用 SSL/TLS 验证：指定服务端 CA 数字签名证书与私钥\n      # enable openssl module to support SSL/TLS\n      ssl_certificate  /application/nginx/key/server.crt;\n      # server.crt 证书发送至客户端用于验证其身份，客户端使用其中的公钥加密\n      # pre-master 第三个随机数并发送至服务端协商会话密钥。\n      ssl_certificate_key  /application/nginx/key/server.key;\n      # server.key 用于解密从客户端发送来的已加密的 pre-master 第三个随机数\n      #ssl_client_certificate  /application/nginx/key/CA-center.crt;\n      #ssl_verify_client  on;\n      # 启用服务端对客户端 SSL/TLS 双向验证\n      # 若只需服务端单向验证，无需启用 ssl_client_certificate 与 ssl_verify_client。\n      ssl_session_timeout  5m;\n      ssl_protocols  TLSv1 TLSv1.1 TLSv1.2;\n      ssl_ciphers  ALL:!DH:!EXPORT:!RC4:+HIGH:+MEDIUM:-LOW:!aNULL:!eNULL;\n      ssl_prefer_server_ciphers  on; \n  \n      location / {\n          root   html/www;\n          index  index.html index.htm;\n      }\n  }\n  ```\n- 抓包 HTTPS 加密通信的三个过程：TCP 建立连接、SSL/TLS 握手、SSL/TLS 加密通信\n- HTTPS 加密通信 - 抓包整体示意：![](wireshark-https-single-progress.png)\n- 🤝 HTTPS 加密通信 - 4 次握手过程示意：![](ssl-tls-single-authentication-progress.png)👨‍💻 以下将握手过程分为 4 个阶段进行描述。\n- 1️⃣ HTTPS 加密通信 - 第 1 次握手过程：`Client Hello`  \n  - 客户端首先向服务端发送 Client Hello 的 SSL 握手信息。  \n  - Client Hello 握手信息中包含如下内容：    \n    - 客户端发起请求，以明文传输请求信息，包含版本信息、客户端随机数、加密套件候选列表、压缩算法候选列表、扩展字段等信息。    \n    - 支持的最高 TLS 协议版本，从低到高依次 SSLv2、SSLv3、TLSv1、TLSv1.1、TLSv1.2，当前基本不再使用低于 TLSv1 的版本。    \n    - ✨ 随机数 `random_C`，用于后续的会话密钥生成。    \n    - 客户端支持的加密套件 `Cipher Suites` 列表，每个加密套件对应 TLS 原理中的四个功能的组合：      \n      - 认证算法 `Au`：身份验证      \n      - 密钥交换算法 `KeyExchange`：（会话）密钥协商      \n      - 对称加密算法 `Enc`：信息加密      \n      - 信息摘要 `Mac`：完整性校验    \n    - 支持的压缩算法 `Compression Methods` 列表，用于后续的信息压缩传输。    \n    - 扩展字段 Extensions，支持协议与算法的相关参数以及其它辅助信息等，常见的 SNI 就属于扩展字段。![](client-hello-body-1.png)  \n  - 客户端支持的 17 种加密套件供服务端选择使用。![](client-hello-body-2.png)\n- 2️⃣ HTTPS 加密通信 - 第 2 次握手过程：服务端给客户端回复的 4 条 SSL 握手信息![](server-response-to-client-ssl.png)\n  - `Server Hello`：    \n    - 服务端返回协商的信息结果，包括选择使用的协议版本、选择的加密套件、选择的压缩算法、随机数 `random_S` 等，其中随机数用于后续的密钥协商。    \n    - 服务端选择 **<font color=orange>TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384</font>** 作为密钥交互的加密套件，该加密套件的名字在客户端发送给服务器的支持的 `17` 个列表中。    \n    - 该加密套件包含：      \n      - 非对称加密（密钥交换算法）：`ECDHE + RSA`      \n      - 对称加密算法：`AES + GCM`      \n      - 消息摘要算法：`SHA-384`  \n  - `Certificate`：该 SSL 握手信息中包含服务端 CA 数字签名证书![](server-ca-signed-certification.png)  \n  - `Server Key Exchange`：    \n    使用 `EC Diffie-Hellman` 算法（`ECDHE`）实现服务端与客户端的密钥交换算法协商。![](server-key-exchange.png)   \n    💥 对于使用 `DHE/ECDHE` 非对称密钥协商算法的 SSL 握手，将发送该类型握手。`RSA`、`DH`、`ECDH` 算法不会进行该 server key exchange 握手流程。 \n  - `Server Hello Done`：通知客户端 Server Hello 信息发送结束![](server-hello-done.jpg)\n- 3️⃣ HTTPS 加密通信 - 第 3 次握手过程：客户端给服务端回复 3 条 SSL 握手信息![](client-response-to-server-ssl.jpg)\n  - `Client Key Exchange`：    \n    - 服务端 CA 数字签名证书合法性验证通过后，客户端计算产生随机数字 `Pre-master`，并用服务端证书中的公钥加密，发送给服务端。      \n      💥 注意：服务端证书合法性验证失败，SSL 握手即停止！    \n    - 此时客户端已经获取全部的计算会话密钥需要的信息：      \n      🚀 两个明文随机数 `random_C` 和 `random_S` 与自己计算产生的 `Pre-master`，计算得到会话密钥。  \n  - `Change Cipher Spec`：    \n     🚀 客户端通知服务端后续的通信都采用协商的 **<font color=red>会话密钥</font>** 和 **<font color=red>会话加密算法</font>** 进行加密通信。  \n  - `Encrypted Handshake Message`：    \n    结合之前所有通信参数的哈希值生成一段数据，采用会话密钥与加密算法进行加密，然后发送给服务器用于数据与握手验证。\n- 4️⃣ HTTPS 加密通信 - 第 4 次握手过程：服务端给客户端回复 2 条 SSL 握手信息![](server-response-to-client-4-phase.png)\n  - `Change Cipher Spec`：    \n    - 服务端用私钥解密加密的 `Pre-master` 随机数，基于之前交换的两个明文随机数 random_C 和 random_S，计算得到会话密钥。    \n    - 计算之前所有接收信息的哈希值，然后解密客户端发送的 `Encrypted Handshake Message`，验证会话密钥和数据的准确性。    \n    - Change Cipher Spec 验证通过之后，服务端同样发送 Change Cipher Spec 以告知客户端后续的通信都采用协商的会话密钥与算法进行加密通信。  \n  - `Encrypted Handshake Message`：    \n    - 服务器也结合所有当前的通信参数信息生成一段数据并采用会话密钥与加密算法进行加密，并发送到客户端。\n- HTTPS 加密通信 - 握手结束：  \n  - 客户端计算所有接收信息的哈希值，并采用会话密钥解密 Encrypted Handshake Message，验证服务器发送的会话密钥和数据，验证通过则握手完成。  \n  - 开始使用会话密钥与加密算法进行加密通信。![](ssl-tls-handshake-end.png)\n\n### HTTPS 单向认证测试：\n- 服务端启用 HTTPS 单向认证后，可从浏览器客户端进行访问测试：![](https-single-auth-chrome-error-1.png)\n- 该服务端 CA 数字签名使用未经认证的 CA 签发，因此客户端浏览器无法验证其安全性而发出警告，可点击 \"高级\" 按钮接受该证书继续访问。若拒绝该证书，即断开此次认证连接，可在如下 Wireshark 抓包中显示安全告警信息：![](https-single-auth-chrome-error-2.png) \n\n### HTTPS 双向认证的 Wireshark 抓包与测试：\n- HTTPS 双向认证的 Wireshark 抓包过程如下所示，其中具体的步骤参见前文 \"SSL/TLS 四次握手与 HTTPS 单/双向认证的详细过程\" 与单向认证的过程。![](wireshark-https-single-progress.png)\n- HTTPS 双向认证过程的客户端测试：  \n  - 配置生成客户端所需的数字签名证书与私钥：    \n    ```bash\n    $ openssl genrsa -out client.key 2048\n    $ openssl req -key client.key \\\n      -subj \"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=firefox\" \\\n      -new -out client.csr\n    $ openssl x509 -req -in client.csr \\\n      -CAkey CA-center.key -CA CA-center.crt -CAcreateserial \\\n      -days 3650 -out client.crt\n    ```\n  - 若将客户端数字签名证书与私钥用于 `Firefox` 或 `Chrome` 浏览器访问服务端，可将其转换为 `p12` 格式：    \n    ```bash\n    $ openssl pkcs12 -export -clcerts \\\n      -in client.crt -inkey client.key -out client.p12\n    # 创建 client.p12 文件时将交互式输入加密密码\n    ```\n  - 将 p12 格式的文件导入 Firefox 浏览器客户端：![](firefox-import-pc12-certs-1.png)![](firefox-import-pc12-certs-2.png)![](firefox-import-pc12-certs-3.png)![](firefox-import-pc12-certs-4.png)\n  - 打开 Firefox 浏览器访问服务端，此时需接受客户端证书来标记自己：![](firefox-import-pc12-certs-5.png)  \n  - 💥 若双向认证客户端配置错误，将无法正常访问服务端，并且浏览器直接返回如下信息，且 Wireshark 抓包显示 `Encrypted Alert`：![](https-mutual-no-client-cert-error-1.png)![](https-mutual-no-client-cert-error-2.png)\n\n### openssl 常用命令汇总：\n- `openssl req` 命令选项：创建 `csr` 证书签名请求与数字签名证书（或自签名证书）  \n  ```bash\n  -key               指定用于创建 csr 证书签名请求的私钥            \n  -newkey alg:nbits  创建新的 csr 证书签名请求与私钥，指定加密算法与加密位数\n                    （通常为 rsa:2048）。             \n  -nodes             不使用密码为新创建的私钥加密\n  -keyout            指定新创建私钥的文件名\n  -sha256            使用 SHA-256 摘要（创建自签名数字证书时使用）\n  -subj              指定创建 csr 证书签名请求与数字签名证书所需的详细信息若未指定\n                     该选项，将进入交互模式。\n  -new               生成新的 csr 证书签名请求\n  -x509              生成数字签名证书（不生成证书签名请求）\n  -days              指定数字签名证书的合法时间（有效期），默认 30 天。\n  -out               指定输出的 csr 证书签名请求或数字签名证书的名称\n  ```\n- `openssl x509` 命令选项：创建与查看数字签名证书  \n  ```bash\n  -req             指定 csr 证书签名请求，与 -in 选项合用。                \n  -in              指定输入文件\n  -CAkey           指定用于签署证书的 CA 私钥\n  -CA              指定用于签署证书的 CA 根证书\n  -CAcreateserial  创建 CA 序列号文件，扩展名为 \".srl\"，该选项必须与 -CA 选项合用。\n  -days            指定数字签名证书的合法时间（有效期），默认 30 天，不与\n                   -preserve_dates 选项合用。\n  -out             指定输出的数字签名证书名称\n  ```\n- 创建自签名数字证书的 2 种方法：  \n  - 1️⃣ 先创建私钥再创建自签名数字证书  \n  - 2️⃣ 同时创建私钥与自签名数字证书    \n    ```bash\n    $ openssl req -newkey rsa:4096 -nodes -keyout server.key \\\n      -sha256 -subj \"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=cloud-ctl.lab.example.com\" \\\n      -x509 -days 3650 -out server.crt\n    ```\n- 创建 CA RSA 私钥与 CA 根证书（root-ca）：  \n  ```bash\n  $ openssl genrsa [-des3] -out ca.key [1024|2048|4096]\n  # 创建 CA RSA 私钥\n  # -des3 选项：交互输入密码为 RSA 私钥加密\n  \n  $ openssl req -key ca.key \\\n    -subj \"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=CA-center.lab.example.com\" \\\n    -new -x509 \\\n    -days 3650 -out ca.crt\n  # 创建 CA 自签名根证书\n  \n  $ openssl rsa -in ca.key -text -noout\n  # 查看 CA RSA 私钥的详细信息\n  \n  $ openssl x509 -in ca.crt -text -noout\n  # 查看 CA 根证书的详细信息\n  ```\n- 基于 CA 根证书创建 server 端数字签名证书：  \n  ```bash\n  $ openssl genrsa [-des3] -out server.key [1024|2048|4096]\n  # 创建 server 端 RSA 私钥\n  \n  $ openssl rsa -in server.key -pubout -out server.pub\n  # 提取 server 端 RSA 私钥对应的公钥（公钥由私钥中提取）\n  \n  $ openssl req -key server.key \\\n    -subj \"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=cloud-ctl.lab.example.com\" \\\n    -new -out server.csr\n  # 创建 server 端证书签名请求（certificate signing request）\n  # 注意：\n  #   1. 创建 csr 不使用 -x509 与 -days 选项\n  #   2. 在创建生成服务端与客户端证书签名请求时均要注意以下三点：\n  #      a. CA 根证书的 Common Name 填写 root 即可，所有服务端和客户端的证书该字段\n  #         需要填写 IP 或域名。\n  #      b. 一定要注意的是，CA 根证书的该字段和服务端证书、客户端证书不能一样。\n  #      c. 其他所有字段的填写，CA 根证书、服务端证书、客户端证书需保持一致，最后的密码\n  #         可直接回车跳过。\n  \n  $ openssl req -noout -text -in server.csr\n  # 查看 server 端证书签名请求的详细信息\n  \n  $ openssl x509 -req -in server.csr \\\n    -CAkey ca.key -CA ca.crt -CAcreateserial \\\n    -days 3650 -out server.crt\n  # 使用 server 端 csr 证书签名请求、CA RSA 私钥与 CA 根证书创建 server 端数字签名证书\n  \n  ### 查看 server 端数字签名证书的相关信息 ###\n  $ openssl x509 -noout -serial -in server.crt\n  # 查看 server 端数字签名证书的序列号\n  $ openssl x509 -noout -dates -in server.crt\n  # 查看 server 端数字签名证书的有效期\n  $ openssl x509 -noout -pubkey -in server.crt\n  # 查看 server 端数字签名证书中的公钥信息，该公钥与私钥中提取的公钥一致。\n  ```\n- 基于 CA 根证书创建 client 端数字签名证书：  \n  ```bash\n  $ openssl genrsa [-des3] -out client.key [1024|2048|4096]\n  # 创建 client 端 RSA 私钥\n  \n  $ openssl req -key client.key \\\n    -subj \"/C=CN/ST=Shanghai/L=Shanghai/CN=sec-srv.lab.example.com\" \\\n    -new -out client.csr\n  # 创建 client 端证书签名请求\n  \n  $ openssl x509 -req -in client.csr \\\n    -CAkey ca.key -CA ca.crt -CAcreateserial \\\n    -days 3650 -out client.crt\n  # 使用证书签名请求、CA RSA 私钥与 CA 根证书创建 client 端数字签名证书\n  ```\n\n### openssl 使用数字签名证书的单双向连接测试：\n- 使用 server 端数字签名证书进行单向连接测试：  \n  ```bash\n  $ openssl s_server -accept <port> -key server.key -cert server.crt    \n  # server 端：启动单向安全连接，启动后将等待 client 端发送信息并回显\n  $ openssl s_client -connect <host_ip>:<port>\n  # client 端：连接 server 端，若连接成功后将在任意一端输入信息后会在另一端显示该信息。\n  ```\n- 使用 server 端与 client 端数字签名证书进行双向连接测试：  \n  ```bash\n  $ openssl s_server -accept <port> \\\n    -key server.key -cert server.crt -Verify <depth>\n  # server 端：强制要求 client 端提供私钥与 client 端数字签名证书进行安全连接\n  $ openssl s_server -accept 10001 \\\n    -key server.key -cert server.crt -Verify 5\n  \n  $ openssl s_client -connect <host_ip>:<port> \\\n    -key client.key -cert client.crt\n  # client 端：连接 server 端，若连接成功后将在任意一端输入信息后会在另一端显示该信息。\n  $ openssl s_client \\\n    -connect 10.197.11.100:10001 -key client.key -cert client.crt\n  ```\n\n### 参考链接：\n- [HTTPS 加密协议详解 (四)：TLS/SSL 握手过程](https://www.wosign.com/FAQ/faq2016-0309-04.htm)\n- [TLS/SSL 协议详解(12) server key exchange](https://blog.csdn.net/mrpre/article/details/77867831)\n- [什么是 HTTPS 双向认证(MutualTLSauthentication)_API 网关 - 阿里云帮助中心](https://help.aliyun.com/document_detail/160093.html)\n- [HTTPS 双向证书认证](https://blog.xizhibei.me/2021/02/03/https-two-way-authentication-with-certificates/)\n- [NGINX 配置本地 HTTPS (双向认证)](https://www.cnblogs.com/xiao987334176/p/11041241.html)\n- [常见证书格式和转换](https://blog.csdn.net/justinjing0612/article/details/7770301)\n- [常见证书格式及相互转换](https://www.cnblogs.com/lzjsky/archive/2010/11/14/1877143.html)\n- [openssl 生成自签证书及查看证书细节](https://www.cnblogs.com/threegun/p/7130985.html)","slug":"https-handshake-authentication","published":1,"updated":"2023-01-20T06:02:32.409Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldfonol2000b16vdp2mvhc7i","content":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li>OS 版本：<code>CentOS Linux release 7.9.2009 (Core)</code></li>\n<li>Kernel 版本：<code>4.20.3-1.el7.elrepo.x86_64</code></li>\n<li>OpenSSL 版本：<code>openssl-1.0.2k-21.el7_9.x86_64.rpm</code></li>\n<li>Docker 版本：<code>20.10.8</code></li>\n<li>Nginx 版本：<code>1.22.1</code></li>\n<li>✨ HTTPS 在常规 Web 服务器、中间件服务器及 <code>RESTful API</code> 等通信中广泛大量使用，因此理解 HTTPS 及相关概念显得尤为重要。</li>\n<li>该文档使用 openssl 工具创建与管理相关私钥与证书，当然也可使用 cfssl 或 certtool（来源于 gnutls-utils 软件包）工具创建与管理。</li>\n</ul>\n<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>加密通信背景</li>\n<li>保证数据的机密性</li>\n<li>保证数据的真实性与完整性</li>\n<li>保证传输双方的身份验证</li>\n<li>数字签名原理</li>\n<li>SSL/TLS 与 CA 相关术语</li>\n<li>SSL/TLS 加密通信要点</li>\n<li>基于 SSL/TLS 加密连接的 HTTPS 单/双向认证</li>\n<li>HTTPS 单向认证的 Wireshark 抓包分析</li>\n<li>HTTPS 单向认证测试</li>\n<li>HTTPS 双向认证的 Wireshark 抓包与测试</li>\n<li>openssl 常用命令汇总</li>\n<li>openssl 使用数字签名证书的单双向连接测试</li>\n<li>参考链接</li>\n</ul>\n<h3 id=\"加密通信背景：\"><a href=\"#加密通信背景：\" class=\"headerlink\" title=\"加密通信背景：\"></a>加密通信背景：</h3><ul>\n<li>网络安全问题：<br>HTTP 不使用 SSL/TLS 进行加密通信，所有信息明文传播，带来了三大风险：  <ul>\n<li>窃听风险（eavesdropping）：第三方可以获知通信内容  </li>\n<li>篡改风险（tampering）：第三方可以修改通信内容  </li>\n<li>冒充风险（pretending）：第三方可以冒充他人身份参与通信</li>\n</ul>\n</li>\n<li>网络安全问题的解决思路：<code>SSL/TLS</code> 协议  <ul>\n<li>所有信息都是加密传播，第三方无法窃听。  </li>\n<li>具有校验机制，一旦被篡改，通信双方会立刻发现。  </li>\n<li>配备身份证书，防止身份被冒充。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"保证数据的机密性：不被窃听\"><a href=\"#保证数据的机密性：不被窃听\" class=\"headerlink\" title=\"保证数据的机密性：不被窃听\"></a>保证数据的机密性：不被窃听</h3><ul>\n<li>🧬 实现方式：对称加密算法</li>\n<li>💥 单纯的数据加密只能保证数据不被泄露，但不能保证接收方收到的数据的真实性。</li>\n</ul>\n<h3 id=\"保证数据的真实性与完整性：不被篡改\"><a href=\"#保证数据的真实性与完整性：不被篡改\" class=\"headerlink\" title=\"保证数据的真实性与完整性：不被篡改\"></a>保证数据的真实性与完整性：不被篡改</h3><ul>\n<li>数据的真实性：真实数据没有被篡改，数据是从真实发送者发来。</li>\n<li>🧬 实现方式：消息摘要算法（或称散列算法/单向散列函数）生成数据指纹（特征码）</li>\n<li>💥 利用提取数据指纹的方式，完成数据传输的完整性验证。</li>\n<li>🔒 实际的算法实现过程概要：  <ul>\n<li>给一段明文数据（plain text）加上数据信息指纹，这个指纹是通过结合数据信息进行相应算法获得的数据指纹。  </li>\n<li>接收方当收到数据信息后，会利用相同的算法对获取的数据计算指纹，确认得到的指纹是否与传送过来的描述数据的指纹一致。  </li>\n<li>如果一致，表示数据没有被篡改过；如果不一致，表示数据完整性遭到破坏，数据一概不予以接收处理。</li>\n</ul>\n</li>\n<li>由于可能存在中间人攻击的可能性，因此可对传输过程中的数据指纹进行加密。</li>\n<li>发送方利用对称密钥方式对手中的指纹进行加密，接收方会利用相同的密钥对手中的指纹进行解密，从而确认指纹是否一致。</li>\n<li>如果中间人将新的指纹也进行了加密，发送给接收方，但接收方无法利用和发送方协商好的解密密钥对指纹进行解密，最终无法识别中间人发送过来的数据指纹信息。</li>\n<li>🤘 通过加密指纹可以保证真实数据没有被篡改。</li>\n</ul>\n<h3 id=\"保证传输双方的身份验证：\"><a href=\"#保证传输双方的身份验证：\" class=\"headerlink\" title=\"保证传输双方的身份验证：\"></a>保证传输双方的身份验证：</h3><ul>\n<li>以上信息只是解决数据的交换获取问题，但是网络的身份验证问题依旧没有解决。</li>\n<li>🧬 实现方式：非对称加密</li>\n<li>利用非对称加密算法，可以有效解决网络中数据传输双方的安全身份验证问题。</li>\n<li>💥 非对称加密算法中，存在密钥对的概念，即拥有公钥（<code>public key</code>）与私钥（<code>private key</code>），其中公钥不是自行创建出来的而是从私钥中提取出来一部分作为公钥，因此可以说公钥是来自于私钥的，而私钥才决定密钥加密的安全性，并且私钥的长度可能会非常长，从最初的 1024、2048 到 4096 一直到更多的位数。增加私钥密钥位，从而提升密钥安全性。</li>\n<li>非对称加密算法遵循的基本原则：公钥加密的只能利用与之配对的私钥进行解密，反之亦然。</li>\n<li>非对称加密算法可以满足数据传输过程中对传输者身份验证的需求，因为接收者可以拥有相应的公钥，只有与之对应的发送者用相应的私钥进行加密信息，接收者用对应的公钥才可解密，否则可以确认发送者身份已经发生变化。</li>\n</ul>\n<h3 id=\"🦄-数字签名原理：\"><a href=\"#🦄-数字签名原理：\" class=\"headerlink\" title=\"🦄 数字签名原理：\"></a>🦄 数字签名原理：</h3><ul>\n<li><strong><font color=\"orange\">公钥加密算法</font></strong> 解决通信双方身份验证问题，但无法确保公钥的真实性。</li>\n<li>因此，CA 数字签名使用证书授权中心（Certification Authority，简称 <code>CA</code>）解决通信双方交换的公钥的真实性，即数字证书的真实性（公钥包含于数字证书中）。</li>\n<li>数字签名证书的分类：  <ul>\n<li>自签名数字签名证书：<br>不使用 <code>ca.key</code> 加密生成签名，使用自身的私钥加密生成签名，如 <code>GnuPG</code> 邮件加密传输。  </li>\n<li>CA 数字签名证书：<br>使用 CA 证书授权中心的 <code>ca.key</code> 与 <code>ca.crt</code> 进行加密生成签名，如 <code>kube-apiserver</code>、Apache、Nginx、Tomcat 等，以下讨论该类型证书。</li>\n</ul>\n</li>\n<li>🧬 实现方式：<strong><font color=\"orange\">公钥非对称加密算法 + 消息摘要算法</font></strong></li>\n<li>标准的 <code>X.509</code> 格式的 CA 数字签名证书组成：  <ul>\n<li>证书相关信息（C）：明文显示    <ul>\n<li>证书的版本信息（Version）    </li>\n<li>证书的序列号（Serial Number，<code>srl</code>）：每个证书都有一个唯一的证书序列号    </li>\n<li>证书所使用的签名算法：<code>sha256WithRSAEncryption</code>    </li>\n<li>证书的发行机构名称：命名规则一般采用 <code>X.500</code> 格式（目录服务协议 X.500）    </li>\n<li>⏱ 证书的有效期：现在通用的证书一般采用 UTC 时间格式，计时范围为 1950-2049。    </li>\n<li>证书所有人的名称：命名规则一般采用 <code>X.500</code> 格式    </li>\n<li>证书所有人的公钥信息    </li>\n<li>CA 数字签名校验码  </li>\n</ul>\n</li>\n<li>证书数字签名（S）：密文显示    <ul>\n<li>证书发行者（CA 证书授权中心）使用 CA 私钥加密生成签名</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>🔥 CA 数字签名证书生成过程：  </p>\n<ul>\n<li>该生成过程满足函数表达式：<code>S = F(Digest(C))</code></li>\n<li>其中 S 为证书数字签名，F 为签名算法，Digest 为消息摘要算法（MD5/SHA1/SHA256等），C 为证书相关信息。  </li>\n<li>1️⃣ 服务端或客户端创建各自的私钥，并使用该私钥创建 <code>csr</code> 证书签名请求。  </li>\n<li>2️⃣ 服务端或客户端的 <code>csr</code> 证书签名请求文件中包含证书相关信息 C 与相应的公钥信息。  </li>\n<li>3️⃣ 使用消息摘要算法对证书相关信息 C 生成相应指纹（fingerprint），再使用 CA 私钥（ca.key）配合 CA 根证书（ca.crt）加密该指纹，最后生成服务端或客户端的 CA 数字签名证书。  </li>\n<li>该 CA 数字签名只能被 CA 私钥（ca.key）对应位于 CA 根证书中的 CA 公钥解开。  </li>\n<li><p>创建过程如下所示：也可参考该 <a href=\"https://github.com/Alberthua-Perl/scripts-confs/blob/master/shell-examples/create-ssl-certs.sh\" target=\"_blank\" rel=\"noopener\">链接</a> 以获得以下过程的完整脚本</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl genrsa -out CA-center.key 2048</span><br><span class=\"line\">$ openssl req -key CA-center.key \\</span><br><span class=\"line\">  -subj <span class=\"string\">\"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=CA-center.lab.example.com\"</span> \\</span><br><span class=\"line\">  -new -x509 -days 3650 -out CA-center.crt</span><br><span class=\"line\"><span class=\"comment\"># 创建 CA 私钥与 CA 根证书（自签名）</span></span><br><span class=\"line\">$ openssl x509 -noout -text -<span class=\"keyword\">in</span> CA-center.crt</span><br><span class=\"line\">  Certificate:</span><br><span class=\"line\">    Data:</span><br><span class=\"line\">        Version: 3 (0x2)</span><br><span class=\"line\">        Serial Number:</span><br><span class=\"line\">            fb:53:9c:3c:4d:81:f6:de</span><br><span class=\"line\">    Signature Algorithm: sha256WithRSAEncryption</span><br><span class=\"line\">        Issuer: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=CA-center.lab.example.com</span><br><span class=\"line\">        Validity</span><br><span class=\"line\">            Not Before: Jan  2 14:04:46 2023 GMT</span><br><span class=\"line\">            Not After : Dec 30 14:04:46 2032 GMT</span><br><span class=\"line\">        Subject: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=CA-center.lab.example.com</span><br><span class=\"line\">        <span class=\"comment\"># 由于使用 CA 私钥自签名生成的 CA 根证书，其证书发行机构与所有人相同。</span></span><br><span class=\"line\">        Subject Public Key Info:</span><br><span class=\"line\">            Public Key Algorithm: rsaEncryption</span><br><span class=\"line\">                Public-Key: (2048 bit)</span><br><span class=\"line\">                Modulus:</span><br><span class=\"line\">                    00:bf:9a:3d:48:8c:b9:21:cb:d4:e5:30:df:4a:0e:</span><br><span class=\"line\">                    05:e1:29:fe:5c:1f:06:4d:fb:89:fe:f5:01:c7:37:</span><br><span class=\"line\">                    c5:ee:f5:66:8f:2f:bd:48:82:a1:80:1e:00:9d:a0:</span><br><span class=\"line\">                    ...</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl genrsa -out server.key 2048</span><br><span class=\"line\">$ openssl req -key server.key \\</span><br><span class=\"line\">  -subj <span class=\"string\">\"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=cloud-ctl.lab.example.com\"</span> \\</span><br><span class=\"line\">  -new -out server.csr</span><br><span class=\"line\">$ openssl req -noout -text -<span class=\"keyword\">in</span> server.csr</span><br><span class=\"line\">  Certificate Request:</span><br><span class=\"line\">    Data:</span><br><span class=\"line\">        Version: 0 (0x0)</span><br><span class=\"line\">        Subject: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=cloud-ctl.lab.example.com </span><br><span class=\"line\">        <span class=\"comment\"># 需签名服务端证书的所有人</span></span><br><span class=\"line\">        Subject Public Key Info:  <span class=\"comment\"># csr 证书签名请求中的公钥信息</span></span><br><span class=\"line\">            Public Key Algorithm: rsaEncryption  <span class=\"comment\"># 公钥加密算法：RSA（不对称加密）</span></span><br><span class=\"line\">                Public-Key: (2048 bit)</span><br><span class=\"line\">                Modulus:</span><br><span class=\"line\">                    00:e0:bd:e9:ff:f5:16:e5:a9:94:9c:61:2f:27:c5:</span><br><span class=\"line\">                    e9:76:a2:4b:e3:0f:1a:82:7d:7a:f1:bf:52:37:8d:</span><br><span class=\"line\">                    54:ea:96:39:8c:c9:55:39:d6:5a:ac:03:2d:16:52:</span><br><span class=\"line\">                    ...</span><br><span class=\"line\"><span class=\"comment\"># 创建与查看服务端私钥及 csr 证书签名请求文件</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl x509 -req -<span class=\"keyword\">in</span> server.csr \\</span><br><span class=\"line\">  -CAkey CA-center.key -CA CA-center.crt -CAcreateserial \\</span><br><span class=\"line\">  -days 3650 -out server.crt</span><br><span class=\"line\"><span class=\"comment\"># 使用 CA 私钥与 CA 根证书签发服务端 CA 数字签名证书</span></span><br><span class=\"line\">$ openssl x509 -noout -text -<span class=\"keyword\">in</span> server.crt</span><br><span class=\"line\">  Certificate:</span><br><span class=\"line\">    Data:</span><br><span class=\"line\">        Version: 1 (0x0)</span><br><span class=\"line\">        Serial Number:</span><br><span class=\"line\">            a9:68:e7:c4:87:87:4e:03</span><br><span class=\"line\">    Signature Algorithm: sha256WithRSAEncryption</span><br><span class=\"line\">        Issuer: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=CA-center.lab.example.com </span><br><span class=\"line\">        <span class=\"comment\"># 服务端 CA 数字签名证书的发行机构（CA 证书授权中心）</span></span><br><span class=\"line\">        Validity</span><br><span class=\"line\">            Not Before: Jan  2 14:04:46 2023 GMT</span><br><span class=\"line\">            Not After : Dec 30 14:04:46 2032 GMT</span><br><span class=\"line\">        Subject: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=cloud-ctl.lab.example.com</span><br><span class=\"line\">        <span class=\"comment\"># 服务端 CA 数字签名证书的所有人：服务端信息</span></span><br><span class=\"line\">        Subject Public Key Info:</span><br><span class=\"line\">            Public Key Algorithm: rsaEncryption</span><br><span class=\"line\">                Public-Key: (2048 bit)</span><br><span class=\"line\">                Modulus:</span><br><span class=\"line\">                    00:e0:bd:e9:ff:f5:16:e5:a9:94:9c:61:2f:27:c5:</span><br><span class=\"line\">                    e9:76:a2:4b:e3:0f:1a:82:7d:7a:f1:bf:52:37:8d:</span><br><span class=\"line\">                    54:ea:96:39:8c:c9:55:39:d6:5a:ac:03:2d:16:52:</span><br><span class=\"line\">                    ...</span><br><span class=\"line\"><span class=\"comment\"># 该数字签名证书中的服务端公钥信息与其 csr 证书签名请求文件中的相同</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>客户端验证证书过程：  </p>\n<ul>\n<li>验证服务端 CA 数字签名：    <ul>\n<li>客户端需具有 CA 根证书（ca.crt）    </li>\n<li>客户端对服务端 CA 数字签名的验证满足表达式：<code>F&#39;(S) = Digest(C)</code></li>\n<li>客户端将执行两种计算，并将计算结果进行比对：<br>1️⃣ 由于证书相关信息（C）以明文显示，通过消息摘要算法计算 C 的哈希值。<br>2️⃣ 使用 CA 公钥解密由服务端通过 CA 私钥加密的 CA 数字签名，获得原始证书相关信息（C）的哈希值。<br>3️⃣ 若两者结果一致，说明证书有效且来自该 CA，未被篡改；若两者结果不一致，说明证书已被中间人篡改或不来自该 CA。  </li>\n</ul>\n</li>\n<li>提取服务端公钥：    <ul>\n<li>CA 数字签名验证通过后，客户端就可以提取出服务端 CA 数字签名证书中的公钥进行通信。    </li>\n<li>🤝 证书验证在 <code>SSL/TLS</code> 握手过程的 <code>Server Hello Done</code> 与 <code>Client Key Exchange</code> 之间。  </li>\n</ul>\n</li>\n<li>🚀 验证过程与原理，如下所示：<img src=\"ca-signed-certification-verify.jpg\" alt></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"SSL-TLS-与-CA-相关术语：\"><a href=\"#SSL-TLS-与-CA-相关术语：\" class=\"headerlink\" title=\"SSL/TLS 与 CA 相关术语：\"></a>SSL/TLS 与 CA 相关术语：</h3><ul>\n<li>证书标准：<code>X.509</code></li>\n<li>编码格式：  <ul>\n<li>✨ <code>PEM</code>：    <ul>\n<li>privacy enhanced Mail    </li>\n<li>纯文本形式的编码格式（Base64 编码），Apache 与 *nix 服务器偏向于使用该格式。  </li>\n</ul>\n</li>\n<li><code>DER</code>：    <ul>\n<li>distinguished encoding Rules    </li>\n<li>二进制形式的编码格式，Java 与 Windows 服务器偏向于使用该格式。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>证书（数字签名证书）：certificate（<code>CER</code> 或 <code>CRT</code>）</li>\n<li>私钥：private key</li>\n<li>👉 证书签名请求：  <ul>\n<li>certificate signing request: <code>CSR</code>  </li>\n<li>该文件使用私钥加密，包含公钥与签名申请者信息等。</li>\n</ul>\n</li>\n<li>CER 与 CRT 两者都为证书，CRT 在 Linux 上更常见。</li>\n<li>CER、CRT、KEY、CSR 都可为 PEM 或 DER 编码格式！</li>\n<li>支持 SSL/TLS 协议的开源工具：<code>openssl</code>、<code>cfssl</code>、<code>gnutls</code></li>\n<li>📚 man 查看以下命令：<br>openssl、genrsa、rsa、req、x509、verify、s_client、s_server</li>\n</ul>\n<h3 id=\"SSL-TLS-加密通信要点：\"><a href=\"#SSL-TLS-加密通信要点：\" class=\"headerlink\" title=\"SSL/TLS 加密通信要点：\"></a>SSL/TLS 加密通信要点：</h3><ul>\n<li>安全套接字层协议：Secure Socket Layer（SSL）</li>\n<li>传输层安全协议：Transport Layer Security（TLS）</li>\n<li>SSL/TLS 历史背景：  <ul>\n<li>1994 年，NetScape 公司设计了 SSL 协议的 1.0 版，但未发布。  </li>\n<li>1995 年，NetScape 公司发布 SSL 2.0 版，很快发现有严重漏洞。  </li>\n<li>1996 年，SSL 3.0 版问世，得到大规模应用。  </li>\n<li>1999 年，互联网标准化组织 ISOC 接替 NetScape 公司，发布了 SSL 的升级版 <code>TLS 1.0</code> 版。  </li>\n<li>2006 年和 2008 年，TLS 进行了两次升级，分别为 TLS 1.1 版和 TLS 1.2 版。  </li>\n<li>👉 最新的变动是 2011 年 <code>TLS 1.2</code> 的修订版。</li>\n</ul>\n</li>\n<li>TLS 与 SSL 之间的版本对应关系：  <ul>\n<li>TLS 1.0 对应 SSL 3.1  </li>\n<li>TLS 1.1 对应 SSL 3.2  </li>\n<li>TLS 1.2 对应 SSL 3.3</li>\n</ul>\n</li>\n<li>👉 一般主流浏览器都已经实现了 <code>TLS 1.2</code> 的支持。</li>\n<li>SSL/TLS 协议在网络模型中的位置：<img src=\"ssl-tls-in-network-stack.png\" alt></li>\n<li>SSL/TLS 协议分为两部分：  <ul>\n<li>Handshake Protocol：<br>🤝 协商通信双方之后在本次会话中用于数据加密的会话密钥（<code>session key</code>），该过程为 “握手阶段”，其中会话密钥也称为协商密钥。  </li>\n<li>Record Protocol：<br>定义使用会话密钥加密的数据的传输格式。</li>\n</ul>\n</li>\n<li>SSL 层：<br>借助下层协议（TCP 层）的的信道安全地协商出一份会话密钥，并用此密钥来加密 HTTP 请求。</li>\n<li>TCP 层：  <ul>\n<li>与 Web server 的 443 端口建立连接，传递由 SSL 处理后的数据。  </li>\n<li>SSL 在 TCP 之上建立一个加密通道，通过这一层的数据经过了加密，因此达到保密的效果。</li>\n</ul>\n</li>\n<li>服务端本地与客户端本地的 SSL 套接字与 TCP 套接字的关系，如下所示：<img src=\"client-server-tcp-ssl-socket.png\" alt></li>\n</ul>\n<h3 id=\"🚀-基于-SSL-TLS-加密连接的-HTTPS-单-双向认证：\"><a href=\"#🚀-基于-SSL-TLS-加密连接的-HTTPS-单-双向认证：\" class=\"headerlink\" title=\"🚀 基于 SSL/TLS 加密连接的 HTTPS 单/双向认证：\"></a>🚀 基于 SSL/TLS 加密连接的 HTTPS 单/双向认证：</h3><ul>\n<li>以上关于服务端 CA 数字签名证书的验证只是 HTTPS 通信中的一部分，需通过其他步骤共同完成 HTTPS 加密通信。</li>\n<li>HTTPS 加密通信认证分为两类：单向认证、双向认证</li>\n<li>单向认证中只需服务端提供服务端证书与私钥即可，而双向认证中服务端需提供证书与私钥外还需提供 CA 根证书（该证书用于客户端证书的签发），并且客户端需提供客户端证书与私钥。</li>\n<li>单向认证的过程，客户端从服务端下载服务端公钥证书进行验证，然后建立安全通信通道。</li>\n<li>双向认证的过程，客户端除了需要从服务端下载服务器的公钥证书进行验证外，还需要把客户端的公钥证书上传到服务端给服务端进行验证，等双方都认证通过了，才开始建立安全通信通道进行数据传输。</li>\n<li>👨‍🏫 <strong><font color=\"red\">总结：</font></strong><br>无论 HTTPS 单向或双向认证都是客户端与服务端协商出 <strong><font color=\"red\">会话密钥</font></strong> 与 <strong><font color=\"red\">会话加密算法</font></strong> 的过程。</li>\n<li>✨ 以下从 HTTPS 抓包的角度说明 SSL/TLS 四次握手与 HTTPS 单/双向认证的详细过程：<img src=\"ssl-four-handshakes-https-single-and-mutual-authentication.png\" alt>上图中 <strong>黑色箭头</strong> 表示双向认证过程中多出的步骤，其余过程为单向认证过程。</li>\n</ul>\n<h3 id=\"🧪-HTTPS-单向认证的-Wireshark-抓包分析：\"><a href=\"#🧪-HTTPS-单向认证的-Wireshark-抓包分析：\" class=\"headerlink\" title=\"🧪 HTTPS 单向认证的 Wireshark 抓包分析：\"></a>🧪 HTTPS 单向认证的 Wireshark 抓包分析：</h3><ul>\n<li>本例使用 <code>Nginx HTTPS</code> 服务测试 HTTPS（HTTP + SSL/TLS）加密通信。</li>\n<li>使用已配置服务端 CA 数字签名证书的 Nginx 容器测试 HTTPS 加密通信过程，并使用 <code>Wireshark</code> 抓包分析。</li>\n<li><p>构建 Nginx 容器使用的 <a href=\"https://github.com/Alberthua-Perl/dockerfile-s2i-demo/tree/master/nginx-ssl\" target=\"_blank\" rel=\"noopener\">Dockerfile</a> 如下所示：  </p>\n<figure class=\"highlight dockerfile\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># modified date: </span></span><br><span class=\"line\"><span class=\"comment\">#     - 2019-12-10: initial Dockerfile</span></span><br><span class=\"line\"><span class=\"comment\">#     - 2023-01-16: update nginx and add client ssl authentication</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">FROM</span> docker.io/library/centos:<span class=\"number\">7.9</span>.<span class=\"number\">2009</span></span><br><span class=\"line\"><span class=\"keyword\">MAINTAINER</span> lhua <span class=\"string\">\"hualongfeiyyy@163.com\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># install nginx dependent packages</span></span><br><span class=\"line\"><span class=\"keyword\">RUN</span><span class=\"bash\"> yum repolist &amp;&amp; \\ </span></span><br><span class=\"line\">    yum install -y gcc* &amp;&amp; \\</span><br><span class=\"line\">    yum install -y pcre-devel openssl openssl-devel &amp;&amp; \\</span><br><span class=\"line\">    yum clean all &amp;&amp; \\</span><br><span class=\"line\">    mkdir -p /application/nginx-<span class=\"number\">1.22</span>.<span class=\"number\">1</span> &amp;&amp; \\</span><br><span class=\"line\">    useradd -u <span class=\"number\">1005</span> -M -s /sbin/nologin nginx</span><br><span class=\"line\">    <span class=\"comment\"># create nginx user to run nginx worker processes</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># copy nginx source package to container rootfs</span></span><br><span class=\"line\"><span class=\"keyword\">ADD</span><span class=\"bash\"> nginx-1.22.1.tar.gz /tmp/</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># make install nginx </span></span><br><span class=\"line\"><span class=\"keyword\">RUN</span><span class=\"bash\"> <span class=\"built_in\">cd</span> /tmp/nginx-1.22.1 &amp;&amp; \\</span></span><br><span class=\"line\"><span class=\"bash\">    ./configure --user=nginx --group=nginx --prefix=/application/nginx-1.22.1 \\</span></span><br><span class=\"line\"><span class=\"bash\">      --with-http_stub_status_module --with-http_ssl_module &amp;&amp; \\</span></span><br><span class=\"line\"><span class=\"bash\">    make &amp;&amp; \\</span></span><br><span class=\"line\"><span class=\"bash\">    make install &amp;&amp; \\</span></span><br><span class=\"line\"><span class=\"bash\">    ln -s /application/nginx-1.22.1 /application/nginx &amp;&amp; \\</span></span><br><span class=\"line\"><span class=\"bash\">    mkdir /application/nginx/conf/extra &amp;&amp; \\</span></span><br><span class=\"line\"><span class=\"bash\">    mkdir /application/nginx/html/www &amp;&amp; \\</span></span><br><span class=\"line\"><span class=\"bash\">    mkdir /application/nginx/key</span></span><br><span class=\"line\">    <span class=\"comment\"># create virtual server, html and key directory.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># copy nginx configuration file, virtual server configuration file and certification file.</span></span><br><span class=\"line\"><span class=\"keyword\">ADD</span><span class=\"bash\"> nginx.conf /application/nginx/conf/</span></span><br><span class=\"line\"><span class=\"keyword\">ADD</span><span class=\"bash\"> www.conf /application/nginx/conf/extra/</span></span><br><span class=\"line\"><span class=\"keyword\">ADD</span><span class=\"bash\"> index.html /application/nginx/html/www/</span></span><br><span class=\"line\"><span class=\"keyword\">ADD</span><span class=\"bash\"> certs/server.key /application/nginx/key/</span></span><br><span class=\"line\"><span class=\"keyword\">ADD</span><span class=\"bash\"> certs/server.crt /application/nginx/key/</span></span><br><span class=\"line\"><span class=\"keyword\">ADD</span><span class=\"bash\"> certs/CA-center.crt /application/nginx/key/</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">EXPOSE</span> <span class=\"number\">443</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># <span class=\"doctag\">Note:</span> Don't run nginx as backend daemon</span></span><br><span class=\"line\"><span class=\"keyword\">CMD</span><span class=\"bash\"> [<span class=\"string\">\"/application/nginx/sbin/nginx\"</span>, <span class=\"string\">\"-g\"</span>, <span class=\"string\">\"daemon off;\"</span>]</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Nginx 容器使用的 <a href=\"https://github.com/Alberthua-Perl/dockerfile-s2i-demo/blob/master/nginx-ssl/www.conf\" target=\"_blank\" rel=\"noopener\">配置文件</a>，如下所示：<br>✨ 该配置文件启用 HTTPS 单向认证，若需开启双向认证过程，只需启用 <code>ssl_client_certificate</code> 与 <code>ssl_verify_client</code> 参数即可。  </p>\n<figure class=\"highlight nginx\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Web Service: domain-based virtual machine</span></span><br><span class=\"line\"><span class=\"section\">server</span> &#123;</span><br><span class=\"line\">    <span class=\"attribute\">listen</span>  <span class=\"number\">443</span>;</span><br><span class=\"line\">    <span class=\"comment\"># alias for domain-based virtual machine</span></span><br><span class=\"line\">    <span class=\"attribute\">server_name</span>  www.etiantian.org etiantian.org;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attribute\">ssl</span>  <span class=\"literal\">on</span>;  <span class=\"comment\"># Nginx 启用 SSL/TLS 验证：指定服务端 CA 数字签名证书与私钥</span></span><br><span class=\"line\">    <span class=\"comment\"># enable openssl module to support SSL/TLS</span></span><br><span class=\"line\">    <span class=\"attribute\">ssl_certificate</span>  /application/nginx/key/server.crt;</span><br><span class=\"line\">    <span class=\"comment\"># server.crt 证书发送至客户端用于验证其身份，客户端使用其中的公钥加密</span></span><br><span class=\"line\">    <span class=\"comment\"># pre-master 第三个随机数并发送至服务端协商会话密钥。</span></span><br><span class=\"line\">    <span class=\"attribute\">ssl_certificate_key</span>  /application/nginx/key/server.key;</span><br><span class=\"line\">    <span class=\"comment\"># server.key 用于解密从客户端发送来的已加密的 pre-master 第三个随机数</span></span><br><span class=\"line\">    <span class=\"comment\">#ssl_client_certificate  /application/nginx/key/CA-center.crt;</span></span><br><span class=\"line\">    <span class=\"comment\">#ssl_verify_client  on;</span></span><br><span class=\"line\">    <span class=\"comment\"># 启用服务端对客户端 SSL/TLS 双向验证</span></span><br><span class=\"line\">    <span class=\"comment\"># 若只需服务端单向验证，无需启用 ssl_client_certificate 与 ssl_verify_client。</span></span><br><span class=\"line\">    <span class=\"attribute\">ssl_session_timeout</span>  <span class=\"number\">5m</span>;</span><br><span class=\"line\">    <span class=\"attribute\">ssl_protocols</span>  TLSv1 TLSv1.<span class=\"number\">1</span> TLSv1.<span class=\"number\">2</span>;</span><br><span class=\"line\">    <span class=\"attribute\">ssl_ciphers</span>  ALL:!DH:!EXPORT:!RC4:+HIGH:+MEDIUM:-LOW:!aNULL:!eNULL;</span><br><span class=\"line\">    <span class=\"attribute\">ssl_prefer_server_ciphers</span>  <span class=\"literal\">on</span>; </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attribute\">location</span> / &#123;</span><br><span class=\"line\">        <span class=\"attribute\">root</span>   html/www;</span><br><span class=\"line\">        <span class=\"attribute\">index</span>  index.html index.htm;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>抓包 HTTPS 加密通信的三个过程：TCP 建立连接、SSL/TLS 握手、SSL/TLS 加密通信</p>\n</li>\n<li>HTTPS 加密通信 - 抓包整体示意：<img src=\"wireshark-https-single-progress.png\" alt></li>\n<li>🤝 HTTPS 加密通信 - 4 次握手过程示意：<img src=\"ssl-tls-single-authentication-progress.png\" alt>👨‍💻 以下将握手过程分为 4 个阶段进行描述。</li>\n<li>1️⃣ HTTPS 加密通信 - 第 1 次握手过程：<code>Client Hello</code>  <ul>\n<li>客户端首先向服务端发送 Client Hello 的 SSL 握手信息。  </li>\n<li>Client Hello 握手信息中包含如下内容：    <ul>\n<li>客户端发起请求，以明文传输请求信息，包含版本信息、客户端随机数、加密套件候选列表、压缩算法候选列表、扩展字段等信息。    </li>\n<li>支持的最高 TLS 协议版本，从低到高依次 SSLv2、SSLv3、TLSv1、TLSv1.1、TLSv1.2，当前基本不再使用低于 TLSv1 的版本。    </li>\n<li>✨ 随机数 <code>random_C</code>，用于后续的会话密钥生成。    </li>\n<li>客户端支持的加密套件 <code>Cipher Suites</code> 列表，每个加密套件对应 TLS 原理中的四个功能的组合：      <ul>\n<li>认证算法 <code>Au</code>：身份验证      </li>\n<li>密钥交换算法 <code>KeyExchange</code>：（会话）密钥协商      </li>\n<li>对称加密算法 <code>Enc</code>：信息加密      </li>\n<li>信息摘要 <code>Mac</code>：完整性校验    </li>\n</ul>\n</li>\n<li>支持的压缩算法 <code>Compression Methods</code> 列表，用于后续的信息压缩传输。    </li>\n<li>扩展字段 Extensions，支持协议与算法的相关参数以及其它辅助信息等，常见的 SNI 就属于扩展字段。<img src=\"client-hello-body-1.png\" alt>  </li>\n</ul>\n</li>\n<li>客户端支持的 17 种加密套件供服务端选择使用。<img src=\"client-hello-body-2.png\" alt></li>\n</ul>\n</li>\n<li>2️⃣ HTTPS 加密通信 - 第 2 次握手过程：服务端给客户端回复的 4 条 SSL 握手信息<img src=\"server-response-to-client-ssl.png\" alt><ul>\n<li><code>Server Hello</code>：    <ul>\n<li>服务端返回协商的信息结果，包括选择使用的协议版本、选择的加密套件、选择的压缩算法、随机数 <code>random_S</code> 等，其中随机数用于后续的密钥协商。    </li>\n<li>服务端选择 <strong><font color=\"orange\">TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384</font></strong> 作为密钥交互的加密套件，该加密套件的名字在客户端发送给服务器的支持的 <code>17</code> 个列表中。    </li>\n<li>该加密套件包含：      <ul>\n<li>非对称加密（密钥交换算法）：<code>ECDHE + RSA</code>      </li>\n<li>对称加密算法：<code>AES + GCM</code>      </li>\n<li>消息摘要算法：<code>SHA-384</code>  </li>\n</ul>\n</li>\n</ul>\n</li>\n<li><code>Certificate</code>：该 SSL 握手信息中包含服务端 CA 数字签名证书<img src=\"server-ca-signed-certification.png\" alt>  </li>\n<li><code>Server Key Exchange</code>：<br>使用 <code>EC Diffie-Hellman</code> 算法（<code>ECDHE</code>）实现服务端与客户端的密钥交换算法协商。<img src=\"server-key-exchange.png\" alt><br>💥 对于使用 <code>DHE/ECDHE</code> 非对称密钥协商算法的 SSL 握手，将发送该类型握手。<code>RSA</code>、<code>DH</code>、<code>ECDH</code> 算法不会进行该 server key exchange 握手流程。 </li>\n<li><code>Server Hello Done</code>：通知客户端 Server Hello 信息发送结束<img src=\"server-hello-done.jpg\" alt></li>\n</ul>\n</li>\n<li>3️⃣ HTTPS 加密通信 - 第 3 次握手过程：客户端给服务端回复 3 条 SSL 握手信息<img src=\"client-response-to-server-ssl.jpg\" alt><ul>\n<li><code>Client Key Exchange</code>：    <ul>\n<li>服务端 CA 数字签名证书合法性验证通过后，客户端计算产生随机数字 <code>Pre-master</code>，并用服务端证书中的公钥加密，发送给服务端。<br>💥 注意：服务端证书合法性验证失败，SSL 握手即停止！    </li>\n<li>此时客户端已经获取全部的计算会话密钥需要的信息：<br>🚀 两个明文随机数 <code>random_C</code> 和 <code>random_S</code> 与自己计算产生的 <code>Pre-master</code>，计算得到会话密钥。  </li>\n</ul>\n</li>\n<li><code>Change Cipher Spec</code>：<br> 🚀 客户端通知服务端后续的通信都采用协商的 <strong><font color=\"red\">会话密钥</font></strong> 和 <strong><font color=\"red\">会话加密算法</font></strong> 进行加密通信。  </li>\n<li><code>Encrypted Handshake Message</code>：<br>结合之前所有通信参数的哈希值生成一段数据，采用会话密钥与加密算法进行加密，然后发送给服务器用于数据与握手验证。</li>\n</ul>\n</li>\n<li>4️⃣ HTTPS 加密通信 - 第 4 次握手过程：服务端给客户端回复 2 条 SSL 握手信息<img src=\"server-response-to-client-4-phase.png\" alt><ul>\n<li><code>Change Cipher Spec</code>：    <ul>\n<li>服务端用私钥解密加密的 <code>Pre-master</code> 随机数，基于之前交换的两个明文随机数 random_C 和 random_S，计算得到会话密钥。    </li>\n<li>计算之前所有接收信息的哈希值，然后解密客户端发送的 <code>Encrypted Handshake Message</code>，验证会话密钥和数据的准确性。    </li>\n<li>Change Cipher Spec 验证通过之后，服务端同样发送 Change Cipher Spec 以告知客户端后续的通信都采用协商的会话密钥与算法进行加密通信。  </li>\n</ul>\n</li>\n<li><code>Encrypted Handshake Message</code>：    <ul>\n<li>服务器也结合所有当前的通信参数信息生成一段数据并采用会话密钥与加密算法进行加密，并发送到客户端。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>HTTPS 加密通信 - 握手结束：  <ul>\n<li>客户端计算所有接收信息的哈希值，并采用会话密钥解密 Encrypted Handshake Message，验证服务器发送的会话密钥和数据，验证通过则握手完成。  </li>\n<li>开始使用会话密钥与加密算法进行加密通信。<img src=\"ssl-tls-handshake-end.png\" alt></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"HTTPS-单向认证测试：\"><a href=\"#HTTPS-单向认证测试：\" class=\"headerlink\" title=\"HTTPS 单向认证测试：\"></a>HTTPS 单向认证测试：</h3><ul>\n<li>服务端启用 HTTPS 单向认证后，可从浏览器客户端进行访问测试：<img src=\"https-single-auth-chrome-error-1.png\" alt></li>\n<li>该服务端 CA 数字签名使用未经认证的 CA 签发，因此客户端浏览器无法验证其安全性而发出警告，可点击 “高级” 按钮接受该证书继续访问。若拒绝该证书，即断开此次认证连接，可在如下 Wireshark 抓包中显示安全告警信息：<img src=\"https-single-auth-chrome-error-2.png\" alt> </li>\n</ul>\n<h3 id=\"HTTPS-双向认证的-Wireshark-抓包与测试：\"><a href=\"#HTTPS-双向认证的-Wireshark-抓包与测试：\" class=\"headerlink\" title=\"HTTPS 双向认证的 Wireshark 抓包与测试：\"></a>HTTPS 双向认证的 Wireshark 抓包与测试：</h3><ul>\n<li>HTTPS 双向认证的 Wireshark 抓包过程如下所示，其中具体的步骤参见前文 “SSL/TLS 四次握手与 HTTPS 单/双向认证的详细过程” 与单向认证的过程。<img src=\"wireshark-https-single-progress.png\" alt></li>\n<li><p>HTTPS 双向认证过程的客户端测试：  </p>\n<ul>\n<li><p>配置生成客户端所需的数字签名证书与私钥：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl genrsa -out client.key 2048</span><br><span class=\"line\">$ openssl req -key client.key \\</span><br><span class=\"line\">  -subj <span class=\"string\">\"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=firefox\"</span> \\</span><br><span class=\"line\">  -new -out client.csr</span><br><span class=\"line\">$ openssl x509 -req -<span class=\"keyword\">in</span> client.csr \\</span><br><span class=\"line\">  -CAkey CA-center.key -CA CA-center.crt -CAcreateserial \\</span><br><span class=\"line\">  -days 3650 -out client.crt</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>若将客户端数字签名证书与私钥用于 <code>Firefox</code> 或 <code>Chrome</code> 浏览器访问服务端，可将其转换为 <code>p12</code> 格式：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl pkcs12 -<span class=\"built_in\">export</span> -clcerts \\</span><br><span class=\"line\">  -<span class=\"keyword\">in</span> client.crt -inkey client.key -out client.p12</span><br><span class=\"line\"><span class=\"comment\"># 创建 client.p12 文件时将交互式输入加密密码</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>将 p12 格式的文件导入 Firefox 浏览器客户端：<img src=\"firefox-import-pc12-certs-1.png\" alt><img src=\"firefox-import-pc12-certs-2.png\" alt><img src=\"firefox-import-pc12-certs-3.png\" alt><img src=\"firefox-import-pc12-certs-4.png\" alt></p>\n</li>\n<li>打开 Firefox 浏览器访问服务端，此时需接受客户端证书来标记自己：<img src=\"firefox-import-pc12-certs-5.png\" alt>  </li>\n<li>💥 若双向认证客户端配置错误，将无法正常访问服务端，并且浏览器直接返回如下信息，且 Wireshark 抓包显示 <code>Encrypted Alert</code>：<img src=\"https-mutual-no-client-cert-error-1.png\" alt><img src=\"https-mutual-no-client-cert-error-2.png\" alt></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"openssl-常用命令汇总：\"><a href=\"#openssl-常用命令汇总：\" class=\"headerlink\" title=\"openssl 常用命令汇总：\"></a>openssl 常用命令汇总：</h3><ul>\n<li><p><code>openssl req</code> 命令选项：创建 <code>csr</code> 证书签名请求与数字签名证书（或自签名证书）  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-key               指定用于创建 csr 证书签名请求的私钥            </span><br><span class=\"line\">-newkey alg:nbits  创建新的 csr 证书签名请求与私钥，指定加密算法与加密位数</span><br><span class=\"line\">                  （通常为 rsa:2048）。             </span><br><span class=\"line\">-nodes             不使用密码为新创建的私钥加密</span><br><span class=\"line\">-keyout            指定新创建私钥的文件名</span><br><span class=\"line\">-sha256            使用 SHA-256 摘要（创建自签名数字证书时使用）</span><br><span class=\"line\">-subj              指定创建 csr 证书签名请求与数字签名证书所需的详细信息若未指定</span><br><span class=\"line\">                   该选项，将进入交互模式。</span><br><span class=\"line\">-new               生成新的 csr 证书签名请求</span><br><span class=\"line\">-x509              生成数字签名证书（不生成证书签名请求）</span><br><span class=\"line\">-days              指定数字签名证书的合法时间（有效期），默认 30 天。</span><br><span class=\"line\">-out               指定输出的 csr 证书签名请求或数字签名证书的名称</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>openssl x509</code> 命令选项：创建与查看数字签名证书  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-req             指定 csr 证书签名请求，与 -<span class=\"keyword\">in</span> 选项合用。                </span><br><span class=\"line\">-<span class=\"keyword\">in</span>              指定输入文件</span><br><span class=\"line\">-CAkey           指定用于签署证书的 CA 私钥</span><br><span class=\"line\">-CA              指定用于签署证书的 CA 根证书</span><br><span class=\"line\">-CAcreateserial  创建 CA 序列号文件，扩展名为 <span class=\"string\">\".srl\"</span>，该选项必须与 -CA 选项合用。</span><br><span class=\"line\">-days            指定数字签名证书的合法时间（有效期），默认 30 天，不与</span><br><span class=\"line\">                 -preserve_dates 选项合用。</span><br><span class=\"line\">-out             指定输出的数字签名证书名称</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>创建自签名数字证书的 2 种方法：  </p>\n<ul>\n<li>1️⃣ 先创建私钥再创建自签名数字证书  </li>\n<li>2️⃣ 同时创建私钥与自签名数字证书    <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl req -newkey rsa:4096 -nodes -keyout server.key \\</span><br><span class=\"line\">  -sha256 -subj <span class=\"string\">\"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=cloud-ctl.lab.example.com\"</span> \\</span><br><span class=\"line\">  -x509 -days 3650 -out server.crt</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>创建 CA RSA 私钥与 CA 根证书（root-ca）：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl genrsa [-des3] -out ca.key [1024|2048|4096]</span><br><span class=\"line\"><span class=\"comment\"># 创建 CA RSA 私钥</span></span><br><span class=\"line\"><span class=\"comment\"># -des3 选项：交互输入密码为 RSA 私钥加密</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl req -key ca.key \\</span><br><span class=\"line\">  -subj <span class=\"string\">\"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=CA-center.lab.example.com\"</span> \\</span><br><span class=\"line\">  -new -x509 \\</span><br><span class=\"line\">  -days 3650 -out ca.crt</span><br><span class=\"line\"><span class=\"comment\"># 创建 CA 自签名根证书</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl rsa -<span class=\"keyword\">in</span> ca.key -text -noout</span><br><span class=\"line\"><span class=\"comment\"># 查看 CA RSA 私钥的详细信息</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl x509 -<span class=\"keyword\">in</span> ca.crt -text -noout</span><br><span class=\"line\"><span class=\"comment\"># 查看 CA 根证书的详细信息</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>基于 CA 根证书创建 server 端数字签名证书：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl genrsa [-des3] -out server.key [1024|2048|4096]</span><br><span class=\"line\"><span class=\"comment\"># 创建 server 端 RSA 私钥</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl rsa -<span class=\"keyword\">in</span> server.key -pubout -out server.pub</span><br><span class=\"line\"><span class=\"comment\"># 提取 server 端 RSA 私钥对应的公钥（公钥由私钥中提取）</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl req -key server.key \\</span><br><span class=\"line\">  -subj <span class=\"string\">\"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=cloud-ctl.lab.example.com\"</span> \\</span><br><span class=\"line\">  -new -out server.csr</span><br><span class=\"line\"><span class=\"comment\"># 创建 server 端证书签名请求（certificate signing request）</span></span><br><span class=\"line\"><span class=\"comment\"># 注意：</span></span><br><span class=\"line\"><span class=\"comment\">#   1. 创建 csr 不使用 -x509 与 -days 选项</span></span><br><span class=\"line\"><span class=\"comment\">#   2. 在创建生成服务端与客户端证书签名请求时均要注意以下三点：</span></span><br><span class=\"line\"><span class=\"comment\">#      a. CA 根证书的 Common Name 填写 root 即可，所有服务端和客户端的证书该字段</span></span><br><span class=\"line\"><span class=\"comment\">#         需要填写 IP 或域名。</span></span><br><span class=\"line\"><span class=\"comment\">#      b. 一定要注意的是，CA 根证书的该字段和服务端证书、客户端证书不能一样。</span></span><br><span class=\"line\"><span class=\"comment\">#      c. 其他所有字段的填写，CA 根证书、服务端证书、客户端证书需保持一致，最后的密码</span></span><br><span class=\"line\"><span class=\"comment\">#         可直接回车跳过。</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl req -noout -text -<span class=\"keyword\">in</span> server.csr</span><br><span class=\"line\"><span class=\"comment\"># 查看 server 端证书签名请求的详细信息</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl x509 -req -<span class=\"keyword\">in</span> server.csr \\</span><br><span class=\"line\">  -CAkey ca.key -CA ca.crt -CAcreateserial \\</span><br><span class=\"line\">  -days 3650 -out server.crt</span><br><span class=\"line\"><span class=\"comment\"># 使用 server 端 csr 证书签名请求、CA RSA 私钥与 CA 根证书创建 server 端数字签名证书</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 查看 server 端数字签名证书的相关信息 ###</span></span><br><span class=\"line\">$ openssl x509 -noout -serial -<span class=\"keyword\">in</span> server.crt</span><br><span class=\"line\"><span class=\"comment\"># 查看 server 端数字签名证书的序列号</span></span><br><span class=\"line\">$ openssl x509 -noout -dates -<span class=\"keyword\">in</span> server.crt</span><br><span class=\"line\"><span class=\"comment\"># 查看 server 端数字签名证书的有效期</span></span><br><span class=\"line\">$ openssl x509 -noout -pubkey -<span class=\"keyword\">in</span> server.crt</span><br><span class=\"line\"><span class=\"comment\"># 查看 server 端数字签名证书中的公钥信息，该公钥与私钥中提取的公钥一致。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>基于 CA 根证书创建 client 端数字签名证书：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl genrsa [-des3] -out client.key [1024|2048|4096]</span><br><span class=\"line\"><span class=\"comment\"># 创建 client 端 RSA 私钥</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl req -key client.key \\</span><br><span class=\"line\">  -subj <span class=\"string\">\"/C=CN/ST=Shanghai/L=Shanghai/CN=sec-srv.lab.example.com\"</span> \\</span><br><span class=\"line\">  -new -out client.csr</span><br><span class=\"line\"><span class=\"comment\"># 创建 client 端证书签名请求</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl x509 -req -<span class=\"keyword\">in</span> client.csr \\</span><br><span class=\"line\">  -CAkey ca.key -CA ca.crt -CAcreateserial \\</span><br><span class=\"line\">  -days 3650 -out client.crt</span><br><span class=\"line\"><span class=\"comment\"># 使用证书签名请求、CA RSA 私钥与 CA 根证书创建 client 端数字签名证书</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"openssl-使用数字签名证书的单双向连接测试：\"><a href=\"#openssl-使用数字签名证书的单双向连接测试：\" class=\"headerlink\" title=\"openssl 使用数字签名证书的单双向连接测试：\"></a>openssl 使用数字签名证书的单双向连接测试：</h3><ul>\n<li><p>使用 server 端数字签名证书进行单向连接测试：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl s_server -accept &lt;port&gt; -key server.key -cert server.crt    </span><br><span class=\"line\"><span class=\"comment\"># server 端：启动单向安全连接，启动后将等待 client 端发送信息并回显</span></span><br><span class=\"line\">$ openssl s_client -connect &lt;host_ip&gt;:&lt;port&gt;</span><br><span class=\"line\"><span class=\"comment\"># client 端：连接 server 端，若连接成功后将在任意一端输入信息后会在另一端显示该信息。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用 server 端与 client 端数字签名证书进行双向连接测试：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl s_server -accept &lt;port&gt; \\</span><br><span class=\"line\">  -key server.key -cert server.crt -Verify &lt;depth&gt;</span><br><span class=\"line\"><span class=\"comment\"># server 端：强制要求 client 端提供私钥与 client 端数字签名证书进行安全连接</span></span><br><span class=\"line\">$ openssl s_server -accept 10001 \\</span><br><span class=\"line\">  -key server.key -cert server.crt -Verify 5</span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl s_client -connect &lt;host_ip&gt;:&lt;port&gt; \\</span><br><span class=\"line\">  -key client.key -cert client.crt</span><br><span class=\"line\"><span class=\"comment\"># client 端：连接 server 端，若连接成功后将在任意一端输入信息后会在另一端显示该信息。</span></span><br><span class=\"line\">$ openssl s_client \\</span><br><span class=\"line\">  -connect 10.197.11.100:10001 -key client.key -cert client.crt</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://www.wosign.com/FAQ/faq2016-0309-04.htm\" target=\"_blank\" rel=\"noopener\">HTTPS 加密协议详解 (四)：TLS/SSL 握手过程</a></li>\n<li><a href=\"https://blog.csdn.net/mrpre/article/details/77867831\" target=\"_blank\" rel=\"noopener\">TLS/SSL 协议详解(12) server key exchange</a></li>\n<li><a href=\"https://help.aliyun.com/document_detail/160093.html\" target=\"_blank\" rel=\"noopener\">什么是 HTTPS 双向认证(MutualTLSauthentication)_API 网关 - 阿里云帮助中心</a></li>\n<li><a href=\"https://blog.xizhibei.me/2021/02/03/https-two-way-authentication-with-certificates/\" target=\"_blank\" rel=\"noopener\">HTTPS 双向证书认证</a></li>\n<li><a href=\"https://www.cnblogs.com/xiao987334176/p/11041241.html\" target=\"_blank\" rel=\"noopener\">NGINX 配置本地 HTTPS (双向认证)</a></li>\n<li><a href=\"https://blog.csdn.net/justinjing0612/article/details/7770301\" target=\"_blank\" rel=\"noopener\">常见证书格式和转换</a></li>\n<li><a href=\"https://www.cnblogs.com/lzjsky/archive/2010/11/14/1877143.html\" target=\"_blank\" rel=\"noopener\">常见证书格式及相互转换</a></li>\n<li><a href=\"https://www.cnblogs.com/threegun/p/7130985.html\" target=\"_blank\" rel=\"noopener\">openssl 生成自签证书及查看证书细节</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li>OS 版本：<code>CentOS Linux release 7.9.2009 (Core)</code></li>\n<li>Kernel 版本：<code>4.20.3-1.el7.elrepo.x86_64</code></li>\n<li>OpenSSL 版本：<code>openssl-1.0.2k-21.el7_9.x86_64.rpm</code></li>\n<li>Docker 版本：<code>20.10.8</code></li>\n<li>Nginx 版本：<code>1.22.1</code></li>\n<li>✨ HTTPS 在常规 Web 服务器、中间件服务器及 <code>RESTful API</code> 等通信中广泛大量使用，因此理解 HTTPS 及相关概念显得尤为重要。</li>\n<li>该文档使用 openssl 工具创建与管理相关私钥与证书，当然也可使用 cfssl 或 certtool（来源于 gnutls-utils 软件包）工具创建与管理。</li>\n</ul>\n<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>加密通信背景</li>\n<li>保证数据的机密性</li>\n<li>保证数据的真实性与完整性</li>\n<li>保证传输双方的身份验证</li>\n<li>数字签名原理</li>\n<li>SSL/TLS 与 CA 相关术语</li>\n<li>SSL/TLS 加密通信要点</li>\n<li>基于 SSL/TLS 加密连接的 HTTPS 单/双向认证</li>\n<li>HTTPS 单向认证的 Wireshark 抓包分析</li>\n<li>HTTPS 单向认证测试</li>\n<li>HTTPS 双向认证的 Wireshark 抓包与测试</li>\n<li>openssl 常用命令汇总</li>\n<li>openssl 使用数字签名证书的单双向连接测试</li>\n<li>参考链接</li>\n</ul>\n<h3 id=\"加密通信背景：\"><a href=\"#加密通信背景：\" class=\"headerlink\" title=\"加密通信背景：\"></a>加密通信背景：</h3><ul>\n<li>网络安全问题：<br>HTTP 不使用 SSL/TLS 进行加密通信，所有信息明文传播，带来了三大风险：  <ul>\n<li>窃听风险（eavesdropping）：第三方可以获知通信内容  </li>\n<li>篡改风险（tampering）：第三方可以修改通信内容  </li>\n<li>冒充风险（pretending）：第三方可以冒充他人身份参与通信</li>\n</ul>\n</li>\n<li>网络安全问题的解决思路：<code>SSL/TLS</code> 协议  <ul>\n<li>所有信息都是加密传播，第三方无法窃听。  </li>\n<li>具有校验机制，一旦被篡改，通信双方会立刻发现。  </li>\n<li>配备身份证书，防止身份被冒充。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"保证数据的机密性：不被窃听\"><a href=\"#保证数据的机密性：不被窃听\" class=\"headerlink\" title=\"保证数据的机密性：不被窃听\"></a>保证数据的机密性：不被窃听</h3><ul>\n<li>🧬 实现方式：对称加密算法</li>\n<li>💥 单纯的数据加密只能保证数据不被泄露，但不能保证接收方收到的数据的真实性。</li>\n</ul>\n<h3 id=\"保证数据的真实性与完整性：不被篡改\"><a href=\"#保证数据的真实性与完整性：不被篡改\" class=\"headerlink\" title=\"保证数据的真实性与完整性：不被篡改\"></a>保证数据的真实性与完整性：不被篡改</h3><ul>\n<li>数据的真实性：真实数据没有被篡改，数据是从真实发送者发来。</li>\n<li>🧬 实现方式：消息摘要算法（或称散列算法/单向散列函数）生成数据指纹（特征码）</li>\n<li>💥 利用提取数据指纹的方式，完成数据传输的完整性验证。</li>\n<li>🔒 实际的算法实现过程概要：  <ul>\n<li>给一段明文数据（plain text）加上数据信息指纹，这个指纹是通过结合数据信息进行相应算法获得的数据指纹。  </li>\n<li>接收方当收到数据信息后，会利用相同的算法对获取的数据计算指纹，确认得到的指纹是否与传送过来的描述数据的指纹一致。  </li>\n<li>如果一致，表示数据没有被篡改过；如果不一致，表示数据完整性遭到破坏，数据一概不予以接收处理。</li>\n</ul>\n</li>\n<li>由于可能存在中间人攻击的可能性，因此可对传输过程中的数据指纹进行加密。</li>\n<li>发送方利用对称密钥方式对手中的指纹进行加密，接收方会利用相同的密钥对手中的指纹进行解密，从而确认指纹是否一致。</li>\n<li>如果中间人将新的指纹也进行了加密，发送给接收方，但接收方无法利用和发送方协商好的解密密钥对指纹进行解密，最终无法识别中间人发送过来的数据指纹信息。</li>\n<li>🤘 通过加密指纹可以保证真实数据没有被篡改。</li>\n</ul>\n<h3 id=\"保证传输双方的身份验证：\"><a href=\"#保证传输双方的身份验证：\" class=\"headerlink\" title=\"保证传输双方的身份验证：\"></a>保证传输双方的身份验证：</h3><ul>\n<li>以上信息只是解决数据的交换获取问题，但是网络的身份验证问题依旧没有解决。</li>\n<li>🧬 实现方式：非对称加密</li>\n<li>利用非对称加密算法，可以有效解决网络中数据传输双方的安全身份验证问题。</li>\n<li>💥 非对称加密算法中，存在密钥对的概念，即拥有公钥（<code>public key</code>）与私钥（<code>private key</code>），其中公钥不是自行创建出来的而是从私钥中提取出来一部分作为公钥，因此可以说公钥是来自于私钥的，而私钥才决定密钥加密的安全性，并且私钥的长度可能会非常长，从最初的 1024、2048 到 4096 一直到更多的位数。增加私钥密钥位，从而提升密钥安全性。</li>\n<li>非对称加密算法遵循的基本原则：公钥加密的只能利用与之配对的私钥进行解密，反之亦然。</li>\n<li>非对称加密算法可以满足数据传输过程中对传输者身份验证的需求，因为接收者可以拥有相应的公钥，只有与之对应的发送者用相应的私钥进行加密信息，接收者用对应的公钥才可解密，否则可以确认发送者身份已经发生变化。</li>\n</ul>\n<h3 id=\"🦄-数字签名原理：\"><a href=\"#🦄-数字签名原理：\" class=\"headerlink\" title=\"🦄 数字签名原理：\"></a>🦄 数字签名原理：</h3><ul>\n<li><strong><font color=\"orange\">公钥加密算法</font></strong> 解决通信双方身份验证问题，但无法确保公钥的真实性。</li>\n<li>因此，CA 数字签名使用证书授权中心（Certification Authority，简称 <code>CA</code>）解决通信双方交换的公钥的真实性，即数字证书的真实性（公钥包含于数字证书中）。</li>\n<li>数字签名证书的分类：  <ul>\n<li>自签名数字签名证书：<br>不使用 <code>ca.key</code> 加密生成签名，使用自身的私钥加密生成签名，如 <code>GnuPG</code> 邮件加密传输。  </li>\n<li>CA 数字签名证书：<br>使用 CA 证书授权中心的 <code>ca.key</code> 与 <code>ca.crt</code> 进行加密生成签名，如 <code>kube-apiserver</code>、Apache、Nginx、Tomcat 等，以下讨论该类型证书。</li>\n</ul>\n</li>\n<li>🧬 实现方式：<strong><font color=\"orange\">公钥非对称加密算法 + 消息摘要算法</font></strong></li>\n<li>标准的 <code>X.509</code> 格式的 CA 数字签名证书组成：  <ul>\n<li>证书相关信息（C）：明文显示    <ul>\n<li>证书的版本信息（Version）    </li>\n<li>证书的序列号（Serial Number，<code>srl</code>）：每个证书都有一个唯一的证书序列号    </li>\n<li>证书所使用的签名算法：<code>sha256WithRSAEncryption</code>    </li>\n<li>证书的发行机构名称：命名规则一般采用 <code>X.500</code> 格式（目录服务协议 X.500）    </li>\n<li>⏱ 证书的有效期：现在通用的证书一般采用 UTC 时间格式，计时范围为 1950-2049。    </li>\n<li>证书所有人的名称：命名规则一般采用 <code>X.500</code> 格式    </li>\n<li>证书所有人的公钥信息    </li>\n<li>CA 数字签名校验码  </li>\n</ul>\n</li>\n<li>证书数字签名（S）：密文显示    <ul>\n<li>证书发行者（CA 证书授权中心）使用 CA 私钥加密生成签名</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>🔥 CA 数字签名证书生成过程：  </p>\n<ul>\n<li>该生成过程满足函数表达式：<code>S = F(Digest(C))</code></li>\n<li>其中 S 为证书数字签名，F 为签名算法，Digest 为消息摘要算法（MD5/SHA1/SHA256等），C 为证书相关信息。  </li>\n<li>1️⃣ 服务端或客户端创建各自的私钥，并使用该私钥创建 <code>csr</code> 证书签名请求。  </li>\n<li>2️⃣ 服务端或客户端的 <code>csr</code> 证书签名请求文件中包含证书相关信息 C 与相应的公钥信息。  </li>\n<li>3️⃣ 使用消息摘要算法对证书相关信息 C 生成相应指纹（fingerprint），再使用 CA 私钥（ca.key）配合 CA 根证书（ca.crt）加密该指纹，最后生成服务端或客户端的 CA 数字签名证书。  </li>\n<li>该 CA 数字签名只能被 CA 私钥（ca.key）对应位于 CA 根证书中的 CA 公钥解开。  </li>\n<li><p>创建过程如下所示：也可参考该 <a href=\"https://github.com/Alberthua-Perl/scripts-confs/blob/master/shell-examples/create-ssl-certs.sh\" target=\"_blank\" rel=\"noopener\">链接</a> 以获得以下过程的完整脚本</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl genrsa -out CA-center.key 2048</span><br><span class=\"line\">$ openssl req -key CA-center.key \\</span><br><span class=\"line\">  -subj <span class=\"string\">\"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=CA-center.lab.example.com\"</span> \\</span><br><span class=\"line\">  -new -x509 -days 3650 -out CA-center.crt</span><br><span class=\"line\"><span class=\"comment\"># 创建 CA 私钥与 CA 根证书（自签名）</span></span><br><span class=\"line\">$ openssl x509 -noout -text -<span class=\"keyword\">in</span> CA-center.crt</span><br><span class=\"line\">  Certificate:</span><br><span class=\"line\">    Data:</span><br><span class=\"line\">        Version: 3 (0x2)</span><br><span class=\"line\">        Serial Number:</span><br><span class=\"line\">            fb:53:9c:3c:4d:81:f6:de</span><br><span class=\"line\">    Signature Algorithm: sha256WithRSAEncryption</span><br><span class=\"line\">        Issuer: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=CA-center.lab.example.com</span><br><span class=\"line\">        Validity</span><br><span class=\"line\">            Not Before: Jan  2 14:04:46 2023 GMT</span><br><span class=\"line\">            Not After : Dec 30 14:04:46 2032 GMT</span><br><span class=\"line\">        Subject: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=CA-center.lab.example.com</span><br><span class=\"line\">        <span class=\"comment\"># 由于使用 CA 私钥自签名生成的 CA 根证书，其证书发行机构与所有人相同。</span></span><br><span class=\"line\">        Subject Public Key Info:</span><br><span class=\"line\">            Public Key Algorithm: rsaEncryption</span><br><span class=\"line\">                Public-Key: (2048 bit)</span><br><span class=\"line\">                Modulus:</span><br><span class=\"line\">                    00:bf:9a:3d:48:8c:b9:21:cb:d4:e5:30:df:4a:0e:</span><br><span class=\"line\">                    05:e1:29:fe:5c:1f:06:4d:fb:89:fe:f5:01:c7:37:</span><br><span class=\"line\">                    c5:ee:f5:66:8f:2f:bd:48:82:a1:80:1e:00:9d:a0:</span><br><span class=\"line\">                    ...</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl genrsa -out server.key 2048</span><br><span class=\"line\">$ openssl req -key server.key \\</span><br><span class=\"line\">  -subj <span class=\"string\">\"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=cloud-ctl.lab.example.com\"</span> \\</span><br><span class=\"line\">  -new -out server.csr</span><br><span class=\"line\">$ openssl req -noout -text -<span class=\"keyword\">in</span> server.csr</span><br><span class=\"line\">  Certificate Request:</span><br><span class=\"line\">    Data:</span><br><span class=\"line\">        Version: 0 (0x0)</span><br><span class=\"line\">        Subject: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=cloud-ctl.lab.example.com </span><br><span class=\"line\">        <span class=\"comment\"># 需签名服务端证书的所有人</span></span><br><span class=\"line\">        Subject Public Key Info:  <span class=\"comment\"># csr 证书签名请求中的公钥信息</span></span><br><span class=\"line\">            Public Key Algorithm: rsaEncryption  <span class=\"comment\"># 公钥加密算法：RSA（不对称加密）</span></span><br><span class=\"line\">                Public-Key: (2048 bit)</span><br><span class=\"line\">                Modulus:</span><br><span class=\"line\">                    00:e0:bd:e9:ff:f5:16:e5:a9:94:9c:61:2f:27:c5:</span><br><span class=\"line\">                    e9:76:a2:4b:e3:0f:1a:82:7d:7a:f1:bf:52:37:8d:</span><br><span class=\"line\">                    54:ea:96:39:8c:c9:55:39:d6:5a:ac:03:2d:16:52:</span><br><span class=\"line\">                    ...</span><br><span class=\"line\"><span class=\"comment\"># 创建与查看服务端私钥及 csr 证书签名请求文件</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl x509 -req -<span class=\"keyword\">in</span> server.csr \\</span><br><span class=\"line\">  -CAkey CA-center.key -CA CA-center.crt -CAcreateserial \\</span><br><span class=\"line\">  -days 3650 -out server.crt</span><br><span class=\"line\"><span class=\"comment\"># 使用 CA 私钥与 CA 根证书签发服务端 CA 数字签名证书</span></span><br><span class=\"line\">$ openssl x509 -noout -text -<span class=\"keyword\">in</span> server.crt</span><br><span class=\"line\">  Certificate:</span><br><span class=\"line\">    Data:</span><br><span class=\"line\">        Version: 1 (0x0)</span><br><span class=\"line\">        Serial Number:</span><br><span class=\"line\">            a9:68:e7:c4:87:87:4e:03</span><br><span class=\"line\">    Signature Algorithm: sha256WithRSAEncryption</span><br><span class=\"line\">        Issuer: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=CA-center.lab.example.com </span><br><span class=\"line\">        <span class=\"comment\"># 服务端 CA 数字签名证书的发行机构（CA 证书授权中心）</span></span><br><span class=\"line\">        Validity</span><br><span class=\"line\">            Not Before: Jan  2 14:04:46 2023 GMT</span><br><span class=\"line\">            Not After : Dec 30 14:04:46 2032 GMT</span><br><span class=\"line\">        Subject: C=CN, ST=Shanghai, L=Shanghai, O=RedHat, OU=GLS, CN=cloud-ctl.lab.example.com</span><br><span class=\"line\">        <span class=\"comment\"># 服务端 CA 数字签名证书的所有人：服务端信息</span></span><br><span class=\"line\">        Subject Public Key Info:</span><br><span class=\"line\">            Public Key Algorithm: rsaEncryption</span><br><span class=\"line\">                Public-Key: (2048 bit)</span><br><span class=\"line\">                Modulus:</span><br><span class=\"line\">                    00:e0:bd:e9:ff:f5:16:e5:a9:94:9c:61:2f:27:c5:</span><br><span class=\"line\">                    e9:76:a2:4b:e3:0f:1a:82:7d:7a:f1:bf:52:37:8d:</span><br><span class=\"line\">                    54:ea:96:39:8c:c9:55:39:d6:5a:ac:03:2d:16:52:</span><br><span class=\"line\">                    ...</span><br><span class=\"line\"><span class=\"comment\"># 该数字签名证书中的服务端公钥信息与其 csr 证书签名请求文件中的相同</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>客户端验证证书过程：  </p>\n<ul>\n<li>验证服务端 CA 数字签名：    <ul>\n<li>客户端需具有 CA 根证书（ca.crt）    </li>\n<li>客户端对服务端 CA 数字签名的验证满足表达式：<code>F&#39;(S) = Digest(C)</code></li>\n<li>客户端将执行两种计算，并将计算结果进行比对：<br>1️⃣ 由于证书相关信息（C）以明文显示，通过消息摘要算法计算 C 的哈希值。<br>2️⃣ 使用 CA 公钥解密由服务端通过 CA 私钥加密的 CA 数字签名，获得原始证书相关信息（C）的哈希值。<br>3️⃣ 若两者结果一致，说明证书有效且来自该 CA，未被篡改；若两者结果不一致，说明证书已被中间人篡改或不来自该 CA。  </li>\n</ul>\n</li>\n<li>提取服务端公钥：    <ul>\n<li>CA 数字签名验证通过后，客户端就可以提取出服务端 CA 数字签名证书中的公钥进行通信。    </li>\n<li>🤝 证书验证在 <code>SSL/TLS</code> 握手过程的 <code>Server Hello Done</code> 与 <code>Client Key Exchange</code> 之间。  </li>\n</ul>\n</li>\n<li>🚀 验证过程与原理，如下所示：<img src=\"ca-signed-certification-verify.jpg\" alt></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"SSL-TLS-与-CA-相关术语：\"><a href=\"#SSL-TLS-与-CA-相关术语：\" class=\"headerlink\" title=\"SSL/TLS 与 CA 相关术语：\"></a>SSL/TLS 与 CA 相关术语：</h3><ul>\n<li>证书标准：<code>X.509</code></li>\n<li>编码格式：  <ul>\n<li>✨ <code>PEM</code>：    <ul>\n<li>privacy enhanced Mail    </li>\n<li>纯文本形式的编码格式（Base64 编码），Apache 与 *nix 服务器偏向于使用该格式。  </li>\n</ul>\n</li>\n<li><code>DER</code>：    <ul>\n<li>distinguished encoding Rules    </li>\n<li>二进制形式的编码格式，Java 与 Windows 服务器偏向于使用该格式。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>证书（数字签名证书）：certificate（<code>CER</code> 或 <code>CRT</code>）</li>\n<li>私钥：private key</li>\n<li>👉 证书签名请求：  <ul>\n<li>certificate signing request: <code>CSR</code>  </li>\n<li>该文件使用私钥加密，包含公钥与签名申请者信息等。</li>\n</ul>\n</li>\n<li>CER 与 CRT 两者都为证书，CRT 在 Linux 上更常见。</li>\n<li>CER、CRT、KEY、CSR 都可为 PEM 或 DER 编码格式！</li>\n<li>支持 SSL/TLS 协议的开源工具：<code>openssl</code>、<code>cfssl</code>、<code>gnutls</code></li>\n<li>📚 man 查看以下命令：<br>openssl、genrsa、rsa、req、x509、verify、s_client、s_server</li>\n</ul>\n<h3 id=\"SSL-TLS-加密通信要点：\"><a href=\"#SSL-TLS-加密通信要点：\" class=\"headerlink\" title=\"SSL/TLS 加密通信要点：\"></a>SSL/TLS 加密通信要点：</h3><ul>\n<li>安全套接字层协议：Secure Socket Layer（SSL）</li>\n<li>传输层安全协议：Transport Layer Security（TLS）</li>\n<li>SSL/TLS 历史背景：  <ul>\n<li>1994 年，NetScape 公司设计了 SSL 协议的 1.0 版，但未发布。  </li>\n<li>1995 年，NetScape 公司发布 SSL 2.0 版，很快发现有严重漏洞。  </li>\n<li>1996 年，SSL 3.0 版问世，得到大规模应用。  </li>\n<li>1999 年，互联网标准化组织 ISOC 接替 NetScape 公司，发布了 SSL 的升级版 <code>TLS 1.0</code> 版。  </li>\n<li>2006 年和 2008 年，TLS 进行了两次升级，分别为 TLS 1.1 版和 TLS 1.2 版。  </li>\n<li>👉 最新的变动是 2011 年 <code>TLS 1.2</code> 的修订版。</li>\n</ul>\n</li>\n<li>TLS 与 SSL 之间的版本对应关系：  <ul>\n<li>TLS 1.0 对应 SSL 3.1  </li>\n<li>TLS 1.1 对应 SSL 3.2  </li>\n<li>TLS 1.2 对应 SSL 3.3</li>\n</ul>\n</li>\n<li>👉 一般主流浏览器都已经实现了 <code>TLS 1.2</code> 的支持。</li>\n<li>SSL/TLS 协议在网络模型中的位置：<img src=\"ssl-tls-in-network-stack.png\" alt></li>\n<li>SSL/TLS 协议分为两部分：  <ul>\n<li>Handshake Protocol：<br>🤝 协商通信双方之后在本次会话中用于数据加密的会话密钥（<code>session key</code>），该过程为 “握手阶段”，其中会话密钥也称为协商密钥。  </li>\n<li>Record Protocol：<br>定义使用会话密钥加密的数据的传输格式。</li>\n</ul>\n</li>\n<li>SSL 层：<br>借助下层协议（TCP 层）的的信道安全地协商出一份会话密钥，并用此密钥来加密 HTTP 请求。</li>\n<li>TCP 层：  <ul>\n<li>与 Web server 的 443 端口建立连接，传递由 SSL 处理后的数据。  </li>\n<li>SSL 在 TCP 之上建立一个加密通道，通过这一层的数据经过了加密，因此达到保密的效果。</li>\n</ul>\n</li>\n<li>服务端本地与客户端本地的 SSL 套接字与 TCP 套接字的关系，如下所示：<img src=\"client-server-tcp-ssl-socket.png\" alt></li>\n</ul>\n<h3 id=\"🚀-基于-SSL-TLS-加密连接的-HTTPS-单-双向认证：\"><a href=\"#🚀-基于-SSL-TLS-加密连接的-HTTPS-单-双向认证：\" class=\"headerlink\" title=\"🚀 基于 SSL/TLS 加密连接的 HTTPS 单/双向认证：\"></a>🚀 基于 SSL/TLS 加密连接的 HTTPS 单/双向认证：</h3><ul>\n<li>以上关于服务端 CA 数字签名证书的验证只是 HTTPS 通信中的一部分，需通过其他步骤共同完成 HTTPS 加密通信。</li>\n<li>HTTPS 加密通信认证分为两类：单向认证、双向认证</li>\n<li>单向认证中只需服务端提供服务端证书与私钥即可，而双向认证中服务端需提供证书与私钥外还需提供 CA 根证书（该证书用于客户端证书的签发），并且客户端需提供客户端证书与私钥。</li>\n<li>单向认证的过程，客户端从服务端下载服务端公钥证书进行验证，然后建立安全通信通道。</li>\n<li>双向认证的过程，客户端除了需要从服务端下载服务器的公钥证书进行验证外，还需要把客户端的公钥证书上传到服务端给服务端进行验证，等双方都认证通过了，才开始建立安全通信通道进行数据传输。</li>\n<li>👨‍🏫 <strong><font color=\"red\">总结：</font></strong><br>无论 HTTPS 单向或双向认证都是客户端与服务端协商出 <strong><font color=\"red\">会话密钥</font></strong> 与 <strong><font color=\"red\">会话加密算法</font></strong> 的过程。</li>\n<li>✨ 以下从 HTTPS 抓包的角度说明 SSL/TLS 四次握手与 HTTPS 单/双向认证的详细过程：<img src=\"ssl-four-handshakes-https-single-and-mutual-authentication.png\" alt>上图中 <strong>黑色箭头</strong> 表示双向认证过程中多出的步骤，其余过程为单向认证过程。</li>\n</ul>\n<h3 id=\"🧪-HTTPS-单向认证的-Wireshark-抓包分析：\"><a href=\"#🧪-HTTPS-单向认证的-Wireshark-抓包分析：\" class=\"headerlink\" title=\"🧪 HTTPS 单向认证的 Wireshark 抓包分析：\"></a>🧪 HTTPS 单向认证的 Wireshark 抓包分析：</h3><ul>\n<li>本例使用 <code>Nginx HTTPS</code> 服务测试 HTTPS（HTTP + SSL/TLS）加密通信。</li>\n<li>使用已配置服务端 CA 数字签名证书的 Nginx 容器测试 HTTPS 加密通信过程，并使用 <code>Wireshark</code> 抓包分析。</li>\n<li><p>构建 Nginx 容器使用的 <a href=\"https://github.com/Alberthua-Perl/dockerfile-s2i-demo/tree/master/nginx-ssl\" target=\"_blank\" rel=\"noopener\">Dockerfile</a> 如下所示：  </p>\n<figure class=\"highlight dockerfile\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># modified date: </span></span><br><span class=\"line\"><span class=\"comment\">#     - 2019-12-10: initial Dockerfile</span></span><br><span class=\"line\"><span class=\"comment\">#     - 2023-01-16: update nginx and add client ssl authentication</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">FROM</span> docker.io/library/centos:<span class=\"number\">7.9</span>.<span class=\"number\">2009</span></span><br><span class=\"line\"><span class=\"keyword\">MAINTAINER</span> lhua <span class=\"string\">\"hualongfeiyyy@163.com\"</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># install nginx dependent packages</span></span><br><span class=\"line\"><span class=\"keyword\">RUN</span><span class=\"bash\"> yum repolist &amp;&amp; \\ </span></span><br><span class=\"line\">    yum install -y gcc* &amp;&amp; \\</span><br><span class=\"line\">    yum install -y pcre-devel openssl openssl-devel &amp;&amp; \\</span><br><span class=\"line\">    yum clean all &amp;&amp; \\</span><br><span class=\"line\">    mkdir -p /application/nginx-<span class=\"number\">1.22</span>.<span class=\"number\">1</span> &amp;&amp; \\</span><br><span class=\"line\">    useradd -u <span class=\"number\">1005</span> -M -s /sbin/nologin nginx</span><br><span class=\"line\">    <span class=\"comment\"># create nginx user to run nginx worker processes</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># copy nginx source package to container rootfs</span></span><br><span class=\"line\"><span class=\"keyword\">ADD</span><span class=\"bash\"> nginx-1.22.1.tar.gz /tmp/</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># make install nginx </span></span><br><span class=\"line\"><span class=\"keyword\">RUN</span><span class=\"bash\"> <span class=\"built_in\">cd</span> /tmp/nginx-1.22.1 &amp;&amp; \\</span></span><br><span class=\"line\"><span class=\"bash\">    ./configure --user=nginx --group=nginx --prefix=/application/nginx-1.22.1 \\</span></span><br><span class=\"line\"><span class=\"bash\">      --with-http_stub_status_module --with-http_ssl_module &amp;&amp; \\</span></span><br><span class=\"line\"><span class=\"bash\">    make &amp;&amp; \\</span></span><br><span class=\"line\"><span class=\"bash\">    make install &amp;&amp; \\</span></span><br><span class=\"line\"><span class=\"bash\">    ln -s /application/nginx-1.22.1 /application/nginx &amp;&amp; \\</span></span><br><span class=\"line\"><span class=\"bash\">    mkdir /application/nginx/conf/extra &amp;&amp; \\</span></span><br><span class=\"line\"><span class=\"bash\">    mkdir /application/nginx/html/www &amp;&amp; \\</span></span><br><span class=\"line\"><span class=\"bash\">    mkdir /application/nginx/key</span></span><br><span class=\"line\">    <span class=\"comment\"># create virtual server, html and key directory.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># copy nginx configuration file, virtual server configuration file and certification file.</span></span><br><span class=\"line\"><span class=\"keyword\">ADD</span><span class=\"bash\"> nginx.conf /application/nginx/conf/</span></span><br><span class=\"line\"><span class=\"keyword\">ADD</span><span class=\"bash\"> www.conf /application/nginx/conf/extra/</span></span><br><span class=\"line\"><span class=\"keyword\">ADD</span><span class=\"bash\"> index.html /application/nginx/html/www/</span></span><br><span class=\"line\"><span class=\"keyword\">ADD</span><span class=\"bash\"> certs/server.key /application/nginx/key/</span></span><br><span class=\"line\"><span class=\"keyword\">ADD</span><span class=\"bash\"> certs/server.crt /application/nginx/key/</span></span><br><span class=\"line\"><span class=\"keyword\">ADD</span><span class=\"bash\"> certs/CA-center.crt /application/nginx/key/</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">EXPOSE</span> <span class=\"number\">443</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># <span class=\"doctag\">Note:</span> Don't run nginx as backend daemon</span></span><br><span class=\"line\"><span class=\"keyword\">CMD</span><span class=\"bash\"> [<span class=\"string\">\"/application/nginx/sbin/nginx\"</span>, <span class=\"string\">\"-g\"</span>, <span class=\"string\">\"daemon off;\"</span>]</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Nginx 容器使用的 <a href=\"https://github.com/Alberthua-Perl/dockerfile-s2i-demo/blob/master/nginx-ssl/www.conf\" target=\"_blank\" rel=\"noopener\">配置文件</a>，如下所示：<br>✨ 该配置文件启用 HTTPS 单向认证，若需开启双向认证过程，只需启用 <code>ssl_client_certificate</code> 与 <code>ssl_verify_client</code> 参数即可。  </p>\n<figure class=\"highlight nginx\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Web Service: domain-based virtual machine</span></span><br><span class=\"line\"><span class=\"section\">server</span> &#123;</span><br><span class=\"line\">    <span class=\"attribute\">listen</span>  <span class=\"number\">443</span>;</span><br><span class=\"line\">    <span class=\"comment\"># alias for domain-based virtual machine</span></span><br><span class=\"line\">    <span class=\"attribute\">server_name</span>  www.etiantian.org etiantian.org;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attribute\">ssl</span>  <span class=\"literal\">on</span>;  <span class=\"comment\"># Nginx 启用 SSL/TLS 验证：指定服务端 CA 数字签名证书与私钥</span></span><br><span class=\"line\">    <span class=\"comment\"># enable openssl module to support SSL/TLS</span></span><br><span class=\"line\">    <span class=\"attribute\">ssl_certificate</span>  /application/nginx/key/server.crt;</span><br><span class=\"line\">    <span class=\"comment\"># server.crt 证书发送至客户端用于验证其身份，客户端使用其中的公钥加密</span></span><br><span class=\"line\">    <span class=\"comment\"># pre-master 第三个随机数并发送至服务端协商会话密钥。</span></span><br><span class=\"line\">    <span class=\"attribute\">ssl_certificate_key</span>  /application/nginx/key/server.key;</span><br><span class=\"line\">    <span class=\"comment\"># server.key 用于解密从客户端发送来的已加密的 pre-master 第三个随机数</span></span><br><span class=\"line\">    <span class=\"comment\">#ssl_client_certificate  /application/nginx/key/CA-center.crt;</span></span><br><span class=\"line\">    <span class=\"comment\">#ssl_verify_client  on;</span></span><br><span class=\"line\">    <span class=\"comment\"># 启用服务端对客户端 SSL/TLS 双向验证</span></span><br><span class=\"line\">    <span class=\"comment\"># 若只需服务端单向验证，无需启用 ssl_client_certificate 与 ssl_verify_client。</span></span><br><span class=\"line\">    <span class=\"attribute\">ssl_session_timeout</span>  <span class=\"number\">5m</span>;</span><br><span class=\"line\">    <span class=\"attribute\">ssl_protocols</span>  TLSv1 TLSv1.<span class=\"number\">1</span> TLSv1.<span class=\"number\">2</span>;</span><br><span class=\"line\">    <span class=\"attribute\">ssl_ciphers</span>  ALL:!DH:!EXPORT:!RC4:+HIGH:+MEDIUM:-LOW:!aNULL:!eNULL;</span><br><span class=\"line\">    <span class=\"attribute\">ssl_prefer_server_ciphers</span>  <span class=\"literal\">on</span>; </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"attribute\">location</span> / &#123;</span><br><span class=\"line\">        <span class=\"attribute\">root</span>   html/www;</span><br><span class=\"line\">        <span class=\"attribute\">index</span>  index.html index.htm;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>抓包 HTTPS 加密通信的三个过程：TCP 建立连接、SSL/TLS 握手、SSL/TLS 加密通信</p>\n</li>\n<li>HTTPS 加密通信 - 抓包整体示意：<img src=\"wireshark-https-single-progress.png\" alt></li>\n<li>🤝 HTTPS 加密通信 - 4 次握手过程示意：<img src=\"ssl-tls-single-authentication-progress.png\" alt>👨‍💻 以下将握手过程分为 4 个阶段进行描述。</li>\n<li>1️⃣ HTTPS 加密通信 - 第 1 次握手过程：<code>Client Hello</code>  <ul>\n<li>客户端首先向服务端发送 Client Hello 的 SSL 握手信息。  </li>\n<li>Client Hello 握手信息中包含如下内容：    <ul>\n<li>客户端发起请求，以明文传输请求信息，包含版本信息、客户端随机数、加密套件候选列表、压缩算法候选列表、扩展字段等信息。    </li>\n<li>支持的最高 TLS 协议版本，从低到高依次 SSLv2、SSLv3、TLSv1、TLSv1.1、TLSv1.2，当前基本不再使用低于 TLSv1 的版本。    </li>\n<li>✨ 随机数 <code>random_C</code>，用于后续的会话密钥生成。    </li>\n<li>客户端支持的加密套件 <code>Cipher Suites</code> 列表，每个加密套件对应 TLS 原理中的四个功能的组合：      <ul>\n<li>认证算法 <code>Au</code>：身份验证      </li>\n<li>密钥交换算法 <code>KeyExchange</code>：（会话）密钥协商      </li>\n<li>对称加密算法 <code>Enc</code>：信息加密      </li>\n<li>信息摘要 <code>Mac</code>：完整性校验    </li>\n</ul>\n</li>\n<li>支持的压缩算法 <code>Compression Methods</code> 列表，用于后续的信息压缩传输。    </li>\n<li>扩展字段 Extensions，支持协议与算法的相关参数以及其它辅助信息等，常见的 SNI 就属于扩展字段。<img src=\"client-hello-body-1.png\" alt>  </li>\n</ul>\n</li>\n<li>客户端支持的 17 种加密套件供服务端选择使用。<img src=\"client-hello-body-2.png\" alt></li>\n</ul>\n</li>\n<li>2️⃣ HTTPS 加密通信 - 第 2 次握手过程：服务端给客户端回复的 4 条 SSL 握手信息<img src=\"server-response-to-client-ssl.png\" alt><ul>\n<li><code>Server Hello</code>：    <ul>\n<li>服务端返回协商的信息结果，包括选择使用的协议版本、选择的加密套件、选择的压缩算法、随机数 <code>random_S</code> 等，其中随机数用于后续的密钥协商。    </li>\n<li>服务端选择 <strong><font color=\"orange\">TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384</font></strong> 作为密钥交互的加密套件，该加密套件的名字在客户端发送给服务器的支持的 <code>17</code> 个列表中。    </li>\n<li>该加密套件包含：      <ul>\n<li>非对称加密（密钥交换算法）：<code>ECDHE + RSA</code>      </li>\n<li>对称加密算法：<code>AES + GCM</code>      </li>\n<li>消息摘要算法：<code>SHA-384</code>  </li>\n</ul>\n</li>\n</ul>\n</li>\n<li><code>Certificate</code>：该 SSL 握手信息中包含服务端 CA 数字签名证书<img src=\"server-ca-signed-certification.png\" alt>  </li>\n<li><code>Server Key Exchange</code>：<br>使用 <code>EC Diffie-Hellman</code> 算法（<code>ECDHE</code>）实现服务端与客户端的密钥交换算法协商。<img src=\"server-key-exchange.png\" alt><br>💥 对于使用 <code>DHE/ECDHE</code> 非对称密钥协商算法的 SSL 握手，将发送该类型握手。<code>RSA</code>、<code>DH</code>、<code>ECDH</code> 算法不会进行该 server key exchange 握手流程。 </li>\n<li><code>Server Hello Done</code>：通知客户端 Server Hello 信息发送结束<img src=\"server-hello-done.jpg\" alt></li>\n</ul>\n</li>\n<li>3️⃣ HTTPS 加密通信 - 第 3 次握手过程：客户端给服务端回复 3 条 SSL 握手信息<img src=\"client-response-to-server-ssl.jpg\" alt><ul>\n<li><code>Client Key Exchange</code>：    <ul>\n<li>服务端 CA 数字签名证书合法性验证通过后，客户端计算产生随机数字 <code>Pre-master</code>，并用服务端证书中的公钥加密，发送给服务端。<br>💥 注意：服务端证书合法性验证失败，SSL 握手即停止！    </li>\n<li>此时客户端已经获取全部的计算会话密钥需要的信息：<br>🚀 两个明文随机数 <code>random_C</code> 和 <code>random_S</code> 与自己计算产生的 <code>Pre-master</code>，计算得到会话密钥。  </li>\n</ul>\n</li>\n<li><code>Change Cipher Spec</code>：<br> 🚀 客户端通知服务端后续的通信都采用协商的 <strong><font color=\"red\">会话密钥</font></strong> 和 <strong><font color=\"red\">会话加密算法</font></strong> 进行加密通信。  </li>\n<li><code>Encrypted Handshake Message</code>：<br>结合之前所有通信参数的哈希值生成一段数据，采用会话密钥与加密算法进行加密，然后发送给服务器用于数据与握手验证。</li>\n</ul>\n</li>\n<li>4️⃣ HTTPS 加密通信 - 第 4 次握手过程：服务端给客户端回复 2 条 SSL 握手信息<img src=\"server-response-to-client-4-phase.png\" alt><ul>\n<li><code>Change Cipher Spec</code>：    <ul>\n<li>服务端用私钥解密加密的 <code>Pre-master</code> 随机数，基于之前交换的两个明文随机数 random_C 和 random_S，计算得到会话密钥。    </li>\n<li>计算之前所有接收信息的哈希值，然后解密客户端发送的 <code>Encrypted Handshake Message</code>，验证会话密钥和数据的准确性。    </li>\n<li>Change Cipher Spec 验证通过之后，服务端同样发送 Change Cipher Spec 以告知客户端后续的通信都采用协商的会话密钥与算法进行加密通信。  </li>\n</ul>\n</li>\n<li><code>Encrypted Handshake Message</code>：    <ul>\n<li>服务器也结合所有当前的通信参数信息生成一段数据并采用会话密钥与加密算法进行加密，并发送到客户端。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>HTTPS 加密通信 - 握手结束：  <ul>\n<li>客户端计算所有接收信息的哈希值，并采用会话密钥解密 Encrypted Handshake Message，验证服务器发送的会话密钥和数据，验证通过则握手完成。  </li>\n<li>开始使用会话密钥与加密算法进行加密通信。<img src=\"ssl-tls-handshake-end.png\" alt></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"HTTPS-单向认证测试：\"><a href=\"#HTTPS-单向认证测试：\" class=\"headerlink\" title=\"HTTPS 单向认证测试：\"></a>HTTPS 单向认证测试：</h3><ul>\n<li>服务端启用 HTTPS 单向认证后，可从浏览器客户端进行访问测试：<img src=\"https-single-auth-chrome-error-1.png\" alt></li>\n<li>该服务端 CA 数字签名使用未经认证的 CA 签发，因此客户端浏览器无法验证其安全性而发出警告，可点击 “高级” 按钮接受该证书继续访问。若拒绝该证书，即断开此次认证连接，可在如下 Wireshark 抓包中显示安全告警信息：<img src=\"https-single-auth-chrome-error-2.png\" alt> </li>\n</ul>\n<h3 id=\"HTTPS-双向认证的-Wireshark-抓包与测试：\"><a href=\"#HTTPS-双向认证的-Wireshark-抓包与测试：\" class=\"headerlink\" title=\"HTTPS 双向认证的 Wireshark 抓包与测试：\"></a>HTTPS 双向认证的 Wireshark 抓包与测试：</h3><ul>\n<li>HTTPS 双向认证的 Wireshark 抓包过程如下所示，其中具体的步骤参见前文 “SSL/TLS 四次握手与 HTTPS 单/双向认证的详细过程” 与单向认证的过程。<img src=\"wireshark-https-single-progress.png\" alt></li>\n<li><p>HTTPS 双向认证过程的客户端测试：  </p>\n<ul>\n<li><p>配置生成客户端所需的数字签名证书与私钥：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl genrsa -out client.key 2048</span><br><span class=\"line\">$ openssl req -key client.key \\</span><br><span class=\"line\">  -subj <span class=\"string\">\"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=firefox\"</span> \\</span><br><span class=\"line\">  -new -out client.csr</span><br><span class=\"line\">$ openssl x509 -req -<span class=\"keyword\">in</span> client.csr \\</span><br><span class=\"line\">  -CAkey CA-center.key -CA CA-center.crt -CAcreateserial \\</span><br><span class=\"line\">  -days 3650 -out client.crt</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>若将客户端数字签名证书与私钥用于 <code>Firefox</code> 或 <code>Chrome</code> 浏览器访问服务端，可将其转换为 <code>p12</code> 格式：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl pkcs12 -<span class=\"built_in\">export</span> -clcerts \\</span><br><span class=\"line\">  -<span class=\"keyword\">in</span> client.crt -inkey client.key -out client.p12</span><br><span class=\"line\"><span class=\"comment\"># 创建 client.p12 文件时将交互式输入加密密码</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>将 p12 格式的文件导入 Firefox 浏览器客户端：<img src=\"firefox-import-pc12-certs-1.png\" alt><img src=\"firefox-import-pc12-certs-2.png\" alt><img src=\"firefox-import-pc12-certs-3.png\" alt><img src=\"firefox-import-pc12-certs-4.png\" alt></p>\n</li>\n<li>打开 Firefox 浏览器访问服务端，此时需接受客户端证书来标记自己：<img src=\"firefox-import-pc12-certs-5.png\" alt>  </li>\n<li>💥 若双向认证客户端配置错误，将无法正常访问服务端，并且浏览器直接返回如下信息，且 Wireshark 抓包显示 <code>Encrypted Alert</code>：<img src=\"https-mutual-no-client-cert-error-1.png\" alt><img src=\"https-mutual-no-client-cert-error-2.png\" alt></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"openssl-常用命令汇总：\"><a href=\"#openssl-常用命令汇总：\" class=\"headerlink\" title=\"openssl 常用命令汇总：\"></a>openssl 常用命令汇总：</h3><ul>\n<li><p><code>openssl req</code> 命令选项：创建 <code>csr</code> 证书签名请求与数字签名证书（或自签名证书）  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-key               指定用于创建 csr 证书签名请求的私钥            </span><br><span class=\"line\">-newkey alg:nbits  创建新的 csr 证书签名请求与私钥，指定加密算法与加密位数</span><br><span class=\"line\">                  （通常为 rsa:2048）。             </span><br><span class=\"line\">-nodes             不使用密码为新创建的私钥加密</span><br><span class=\"line\">-keyout            指定新创建私钥的文件名</span><br><span class=\"line\">-sha256            使用 SHA-256 摘要（创建自签名数字证书时使用）</span><br><span class=\"line\">-subj              指定创建 csr 证书签名请求与数字签名证书所需的详细信息若未指定</span><br><span class=\"line\">                   该选项，将进入交互模式。</span><br><span class=\"line\">-new               生成新的 csr 证书签名请求</span><br><span class=\"line\">-x509              生成数字签名证书（不生成证书签名请求）</span><br><span class=\"line\">-days              指定数字签名证书的合法时间（有效期），默认 30 天。</span><br><span class=\"line\">-out               指定输出的 csr 证书签名请求或数字签名证书的名称</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>openssl x509</code> 命令选项：创建与查看数字签名证书  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">-req             指定 csr 证书签名请求，与 -<span class=\"keyword\">in</span> 选项合用。                </span><br><span class=\"line\">-<span class=\"keyword\">in</span>              指定输入文件</span><br><span class=\"line\">-CAkey           指定用于签署证书的 CA 私钥</span><br><span class=\"line\">-CA              指定用于签署证书的 CA 根证书</span><br><span class=\"line\">-CAcreateserial  创建 CA 序列号文件，扩展名为 <span class=\"string\">\".srl\"</span>，该选项必须与 -CA 选项合用。</span><br><span class=\"line\">-days            指定数字签名证书的合法时间（有效期），默认 30 天，不与</span><br><span class=\"line\">                 -preserve_dates 选项合用。</span><br><span class=\"line\">-out             指定输出的数字签名证书名称</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>创建自签名数字证书的 2 种方法：  </p>\n<ul>\n<li>1️⃣ 先创建私钥再创建自签名数字证书  </li>\n<li>2️⃣ 同时创建私钥与自签名数字证书    <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl req -newkey rsa:4096 -nodes -keyout server.key \\</span><br><span class=\"line\">  -sha256 -subj <span class=\"string\">\"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=cloud-ctl.lab.example.com\"</span> \\</span><br><span class=\"line\">  -x509 -days 3650 -out server.crt</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n<li><p>创建 CA RSA 私钥与 CA 根证书（root-ca）：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl genrsa [-des3] -out ca.key [1024|2048|4096]</span><br><span class=\"line\"><span class=\"comment\"># 创建 CA RSA 私钥</span></span><br><span class=\"line\"><span class=\"comment\"># -des3 选项：交互输入密码为 RSA 私钥加密</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl req -key ca.key \\</span><br><span class=\"line\">  -subj <span class=\"string\">\"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=CA-center.lab.example.com\"</span> \\</span><br><span class=\"line\">  -new -x509 \\</span><br><span class=\"line\">  -days 3650 -out ca.crt</span><br><span class=\"line\"><span class=\"comment\"># 创建 CA 自签名根证书</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl rsa -<span class=\"keyword\">in</span> ca.key -text -noout</span><br><span class=\"line\"><span class=\"comment\"># 查看 CA RSA 私钥的详细信息</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl x509 -<span class=\"keyword\">in</span> ca.crt -text -noout</span><br><span class=\"line\"><span class=\"comment\"># 查看 CA 根证书的详细信息</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>基于 CA 根证书创建 server 端数字签名证书：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl genrsa [-des3] -out server.key [1024|2048|4096]</span><br><span class=\"line\"><span class=\"comment\"># 创建 server 端 RSA 私钥</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl rsa -<span class=\"keyword\">in</span> server.key -pubout -out server.pub</span><br><span class=\"line\"><span class=\"comment\"># 提取 server 端 RSA 私钥对应的公钥（公钥由私钥中提取）</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl req -key server.key \\</span><br><span class=\"line\">  -subj <span class=\"string\">\"/C=CN/ST=Shanghai/L=Shanghai/O=RedHat/OU=GLS/CN=cloud-ctl.lab.example.com\"</span> \\</span><br><span class=\"line\">  -new -out server.csr</span><br><span class=\"line\"><span class=\"comment\"># 创建 server 端证书签名请求（certificate signing request）</span></span><br><span class=\"line\"><span class=\"comment\"># 注意：</span></span><br><span class=\"line\"><span class=\"comment\">#   1. 创建 csr 不使用 -x509 与 -days 选项</span></span><br><span class=\"line\"><span class=\"comment\">#   2. 在创建生成服务端与客户端证书签名请求时均要注意以下三点：</span></span><br><span class=\"line\"><span class=\"comment\">#      a. CA 根证书的 Common Name 填写 root 即可，所有服务端和客户端的证书该字段</span></span><br><span class=\"line\"><span class=\"comment\">#         需要填写 IP 或域名。</span></span><br><span class=\"line\"><span class=\"comment\">#      b. 一定要注意的是，CA 根证书的该字段和服务端证书、客户端证书不能一样。</span></span><br><span class=\"line\"><span class=\"comment\">#      c. 其他所有字段的填写，CA 根证书、服务端证书、客户端证书需保持一致，最后的密码</span></span><br><span class=\"line\"><span class=\"comment\">#         可直接回车跳过。</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl req -noout -text -<span class=\"keyword\">in</span> server.csr</span><br><span class=\"line\"><span class=\"comment\"># 查看 server 端证书签名请求的详细信息</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl x509 -req -<span class=\"keyword\">in</span> server.csr \\</span><br><span class=\"line\">  -CAkey ca.key -CA ca.crt -CAcreateserial \\</span><br><span class=\"line\">  -days 3650 -out server.crt</span><br><span class=\"line\"><span class=\"comment\"># 使用 server 端 csr 证书签名请求、CA RSA 私钥与 CA 根证书创建 server 端数字签名证书</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### 查看 server 端数字签名证书的相关信息 ###</span></span><br><span class=\"line\">$ openssl x509 -noout -serial -<span class=\"keyword\">in</span> server.crt</span><br><span class=\"line\"><span class=\"comment\"># 查看 server 端数字签名证书的序列号</span></span><br><span class=\"line\">$ openssl x509 -noout -dates -<span class=\"keyword\">in</span> server.crt</span><br><span class=\"line\"><span class=\"comment\"># 查看 server 端数字签名证书的有效期</span></span><br><span class=\"line\">$ openssl x509 -noout -pubkey -<span class=\"keyword\">in</span> server.crt</span><br><span class=\"line\"><span class=\"comment\"># 查看 server 端数字签名证书中的公钥信息，该公钥与私钥中提取的公钥一致。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>基于 CA 根证书创建 client 端数字签名证书：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl genrsa [-des3] -out client.key [1024|2048|4096]</span><br><span class=\"line\"><span class=\"comment\"># 创建 client 端 RSA 私钥</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl req -key client.key \\</span><br><span class=\"line\">  -subj <span class=\"string\">\"/C=CN/ST=Shanghai/L=Shanghai/CN=sec-srv.lab.example.com\"</span> \\</span><br><span class=\"line\">  -new -out client.csr</span><br><span class=\"line\"><span class=\"comment\"># 创建 client 端证书签名请求</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl x509 -req -<span class=\"keyword\">in</span> client.csr \\</span><br><span class=\"line\">  -CAkey ca.key -CA ca.crt -CAcreateserial \\</span><br><span class=\"line\">  -days 3650 -out client.crt</span><br><span class=\"line\"><span class=\"comment\"># 使用证书签名请求、CA RSA 私钥与 CA 根证书创建 client 端数字签名证书</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"openssl-使用数字签名证书的单双向连接测试：\"><a href=\"#openssl-使用数字签名证书的单双向连接测试：\" class=\"headerlink\" title=\"openssl 使用数字签名证书的单双向连接测试：\"></a>openssl 使用数字签名证书的单双向连接测试：</h3><ul>\n<li><p>使用 server 端数字签名证书进行单向连接测试：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl s_server -accept &lt;port&gt; -key server.key -cert server.crt    </span><br><span class=\"line\"><span class=\"comment\"># server 端：启动单向安全连接，启动后将等待 client 端发送信息并回显</span></span><br><span class=\"line\">$ openssl s_client -connect &lt;host_ip&gt;:&lt;port&gt;</span><br><span class=\"line\"><span class=\"comment\"># client 端：连接 server 端，若连接成功后将在任意一端输入信息后会在另一端显示该信息。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用 server 端与 client 端数字签名证书进行双向连接测试：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ openssl s_server -accept &lt;port&gt; \\</span><br><span class=\"line\">  -key server.key -cert server.crt -Verify &lt;depth&gt;</span><br><span class=\"line\"><span class=\"comment\"># server 端：强制要求 client 端提供私钥与 client 端数字签名证书进行安全连接</span></span><br><span class=\"line\">$ openssl s_server -accept 10001 \\</span><br><span class=\"line\">  -key server.key -cert server.crt -Verify 5</span><br><span class=\"line\"></span><br><span class=\"line\">$ openssl s_client -connect &lt;host_ip&gt;:&lt;port&gt; \\</span><br><span class=\"line\">  -key client.key -cert client.crt</span><br><span class=\"line\"><span class=\"comment\"># client 端：连接 server 端，若连接成功后将在任意一端输入信息后会在另一端显示该信息。</span></span><br><span class=\"line\">$ openssl s_client \\</span><br><span class=\"line\">  -connect 10.197.11.100:10001 -key client.key -cert client.crt</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://www.wosign.com/FAQ/faq2016-0309-04.htm\" target=\"_blank\" rel=\"noopener\">HTTPS 加密协议详解 (四)：TLS/SSL 握手过程</a></li>\n<li><a href=\"https://blog.csdn.net/mrpre/article/details/77867831\" target=\"_blank\" rel=\"noopener\">TLS/SSL 协议详解(12) server key exchange</a></li>\n<li><a href=\"https://help.aliyun.com/document_detail/160093.html\" target=\"_blank\" rel=\"noopener\">什么是 HTTPS 双向认证(MutualTLSauthentication)_API 网关 - 阿里云帮助中心</a></li>\n<li><a href=\"https://blog.xizhibei.me/2021/02/03/https-two-way-authentication-with-certificates/\" target=\"_blank\" rel=\"noopener\">HTTPS 双向证书认证</a></li>\n<li><a href=\"https://www.cnblogs.com/xiao987334176/p/11041241.html\" target=\"_blank\" rel=\"noopener\">NGINX 配置本地 HTTPS (双向认证)</a></li>\n<li><a href=\"https://blog.csdn.net/justinjing0612/article/details/7770301\" target=\"_blank\" rel=\"noopener\">常见证书格式和转换</a></li>\n<li><a href=\"https://www.cnblogs.com/lzjsky/archive/2010/11/14/1877143.html\" target=\"_blank\" rel=\"noopener\">常见证书格式及相互转换</a></li>\n<li><a href=\"https://www.cnblogs.com/threegun/p/7130985.html\" target=\"_blank\" rel=\"noopener\">openssl 生成自签证书及查看证书细节</a></li>\n</ul>\n"},{"title":"Kani - Ansible 快速部署与管理 Kubernetes v1.22.1","subtitle":"Use Kani to Rapidly Deploy Kubernetes Cluster","header-img":"kani-ansible-k8s.svg","date":"2022-11-28T06:01:23.000Z","_content":"\n### 文档目录：\n- 项目目的\n- 实施环境\n- 需要更改的参数\n- 实施过程中遇到的问题与解决方法\n- Kani 的使用方法\n- 参考链接\n\n### 项目目的：\n- 虽然目前具有大量的 Kubernetes 集群自动化部署解决方案，其中官方的 `KubeSpray` 即为使用 Ansible 的方式部署，但想尝试自己手动造轮子，因此创建了 Kani 项目。\n- Kani 项目的目的在于使用 Ansible 快速部署与管理 Kubernetes 集群及其相关组件。\n- 当前版本中 Kani 支持：  \n  - `Containerd` runtime  \n  - `Calico` CNI  \n  - `Red Hat Quay v3 registry`\n- Kani 的可选功能包括部署与管理其他额外的云原生、DevOps 与 GitOps 组件，如下所示：  \n  - 容器镜像仓库：Red Hat Quay v3 registry  \n  - 代码仓库：GitLab\n- 可点击 [此处](https://github.com/Alberthua-Perl/kani) 获取 Kani 项目 👋\n\n### 实施环境：\n- OS 版本：`CentOS Linux release 7.9.2009` (Core)\n- kernel 版本：`5.13.12`\n> 可使用 `elrepo repository` 升级 Linux kernel。\n- Ansible 版本：`2.9.25`\n- Containerd 版本：`1.5.5`\n- Kubernetes 版本：`v1.22.1`\n- 准备一个节点作为 Ansible 控制节点用于运行 Kani，并安装 `ansible`、`rhel-system-roles` RPM 软件包。 \n- 使用普通用户克隆该项目，笔者环境中使用 `godev` 用户，该用户与项目目录中的 `vars/all.yml` 中的 `operator_user` 为同一用户。\n> 💥 使用 Kani 时，需注意将您的普通用户与 operator_user 保持一致！\n\n### 🤘 需要更改的参数：\n- 根据您的实际环境在以下文件中更改对应的参数：  \n  - `ansible.cfg` (Ansible config file):    \n    - remote_user：各个 Ansible 受管主机上的登录用户  \n  - `files/kubeadm-conf.yml` (kubeadm config file):    \n    - localAPIEndpoint.advertiseAddress：master 节点的 API 端点监听地址    \n    - localAPIEndpoint.bindPort：master 节点的 API 端点监听端口    \n    - nodeRegistration.criSocket：master 节点 containerd 的 Unix 套接字文件    \n    - nodeRegistration.name：master 节点的 FQDN    \n    - nodeRegistration.taints：为 master 节点添加不可调度的污点    \n    - mode：kube-proxy 的工作模式    \n    - imageRepository：指定容器镜像的仓库地址    \n    - KubernetesVersion：集群的安装版本    \n    - `networking.serviceSubnet`：集群的 Service Cluster IP 网段    \n    - `networking.podSubnet`：集群的 Pod IP 网段    \n    - cgroupDriver：指定控制组驱动类型    \n    - `clusterDNS`：集群的 CoreDNS 的 Service Cluster IP  \n  - `inventory-kubecluster` (Ansible inventory file):    \n    - 根据您所在的场景修改短主机名，此处为笔者所在的环境节点信息。  \n  - `vars/all.yml` (variables file):    \n    > 💥 根据您所在的环境修改 `!!! NEED TO EDIT !!!` 中的参数，其余参数可选择性地修改。    \n    - gateway：所有 Kubernetes 节点的的默认网关    \n    - nic：所有 Kubernetes 节点连接默认网关的网卡接口    \n    - operator_user：Ansible 控制节点与受管主机上远程连接的普通用户    \n    > 👉 operator_user 与 ansible.cfg 中的 remote_user 相同。    \n    - kube_master_node：master 节点的短主机名    \n    > 💥 该参数与 inventory-kubecluster 中的短主机名相同。\n\n### 实施过程中遇到的问题与解决方法：\n- Kubernetes 部署过程中的部分报错，如下所示：  \n  `kubeadm init` 初始化 master 节点失败，并且报错 `node not found`。由于所有的 `pause infra images` 未标识（tagged）`k8s.io/pause:3.5`，因此在 master 节点上的 `kubelet` 不能创建 `sandbox`。  \n  ![kubeadm-init-master-error-1.jpg](kubeadm-init-master-error-1.jpg)![kubeadm-init-master-error-2.jpg](kubeadm-init-master-error-2.jpg)\n- playbook 中的 `register` 注册变量不能在不同的 play 间引用。  \n  ![register-var-used-between-two-plays-error.jpg](register-var-used-between-two-plays-error.jpg)\n- 由于使用 `containerd` 来运行容器，因此 `ctr`、`crictl` 与 `nerdctl` 可被用来获取容器镜像与容器自身的状态。但是，仅仅 `crictl` 可直接使用 containerd 配置文件 `/etc/containerd/config.toml`。crictl 可加载配置有 quay registry endpoint、user 与 password 的配置文件。\n- 若使用自签名的 CA 证书，crictl 不能从 quay 容器镜像仓库拉取镜像，并且总是报错 `x509 cert file error`：  \n  ![crictl-ssl-ca-request-quay-error.jpg](crictl-ssl-ca-request-quay-error.jpg)\n- 通过配置在 containerd 配置文件中的 `insecure_skip_verify = true` 跳过 tls 验证才能拉取镜像。\n\n### 🚀 Kani 的使用方法：\n- Kani 项目的目录结构，如下所示：  \n  ```bash\n  ┌─[godev][paas-ctl][~/kani]\n  └─➞ tree .\n  .\n  ├── 00-general-prepare-kube.yml\n  ├── 01-containerd-kube-deploy.yml\n  ├── 02-kube-cluster-calio-deploy.yml\n  ├── 03-post-kube-deploy.yml\n  ├── ansible.cfg\n  ├── destroy-kube-cluster.yml\n  ├── files\n  │   ├── cni\n  │   │   └── calico-v3.21.yml\n  │   ├── containerd\n  │   │   ├── config.toml\n  │   │   ├── containerd-rootless-setuptool.sh\n  │   │   ├── containerd-rootless.sh\n  │   │   ├── cri-containerd-cni-1.5.5-linux-amd64.tar.gz  # 该文件可从下文百度网盘下载\n  │   │   └── nerdctl\n  │   ├── kube-utils\n  │   │   ├── k9s_Linux_x86_64.tar.gz\n  │   │   ├── kubeadm-conf.yml\n  │   │   ├── kube-dashboard-admin.yml\n  │   │   └── kube-dashboard-v2.3.1.yml\n  │   ├── quay\n  │   │   └── deploy-quay-registry.sh\n  │   ├── repos\n  │   │   ├── docker-ce.repo\n  │   │   └── kubernetes.repo\n  │   ├── rpms\n  │   │   ├── kubeadm-1.22.1-0.x86_64.rpm\n  │   │   ├── kubectl-1.22.1-0.x86_64.rpm\n  │   │   ├── kubelet-1.22.1-0.x86_64.rpm\n  │   │   └── kubernetes-cni-0.8.7-0.x86_64.rpm\n  │   └── vimrc\n  ├── inventory-kubecluster\n  ├── job-for-terminate-kube.yml\n  ├── kani\n  ├── kube-reverse\n  ├── provision-quay-registry.yml\n  ├── templates\n  │   └── hosts.j2\n  ├── terminate-kube-cluster.yml\n  └── vars\n      └── all.yml\n  \n  9 directories, 32 files\n  ```\n\n  > 1. 由于 GitHub 对于上传文件的大小限制（100 MiB），`files/containerd/cri-containerd-cni-1.5.5-linux-amd64.tar.gz` 可从 [百度网盘](https://pan.baidu.com/s/1ytxDjSN0u5Tewy5rcEGWNQ) 下载，下载密码为 apdl。\n  > 2. 💥 由于在 aliyun yum 源中的 kubeadm、kubectl、kubelet 与 kubernetes-cni 的 rpm 软件包可能存在无法获取的情况，因此已将软件包同项目一起上传！\n\n- 更改所有文件中的参数后，使用如下命令部署集群：  \n  ```bash\n  $ cd kani\n  $ chmod +x ./kani\n  $ ./kani --help\n  # 查看 kani 的使用方法\n  Rapid deploy kubernetes cluster and elements by ansible\n  \n  Usage:\n    kani [command]\n  \n  Available Commands:\n    deploy-kube     Deploy single master node kubernetes cluster with calico cni\n    terminate-kube  Terminate kubernetes master and worker nodes\n    destroy-kube    Destroy and prepare to re-install kubernetes cluster\n    config-quay     Config and run quay config container\n    deploy-quay     Deploy quay registry\n  \n  $ ./kani deploy-kube\n  # 部署 Kubernetes 集群\n  ```\n\n  > 🤘 注意：在 kubeadm init 初始化 master 节点后，由于还未将其他 node 节点加入至集群中，此时各个 node 节点上的 `kubelet` 守护进程启动失败，可能处于 `active (auto-restarting)` 状态，查看节点 /var/log/messages 中存在大量的 `/etc/kubernetes/pki/ca.crt not found` 的报错，这是由于 kubeadm join 还未将 node 节点加入集群以及还未同步 master 节点的 CA 证书所致，待 node 节点加入集群中后 kubelet 状态将恢复 `active` 状态。\n\n- Kubernetes 集群部署后的 node 与 pod 状态：![kubernetes-cluster-status.jpg](kubernetes-cluster-status.jpg)\n  \n  > 🤘 注意：Kubernetes 集群中 `coredns pod` 在 Calico CNI 未完全 ready 时将处于 `pending` 状态，直至所有 calico pod 处于 Running 状态时也将处于 Running 状态。\n\n- 停止 Kubernetes 集群：  \n  ```bash\n  $ ./kani terminate-kube\n  ```\n- 破坏与重装 Kubernetes 集群：  \n  ```bash\n  $ ./kani destroy-kube\n  ```\n- （可选操作）部署 `Red Hat Quay v3 registry` 并与 Kubernetes 集群集成：  \n  若需使用 `Red Hat Quay v3 registry` 作为容器镜像仓库，可使用如下命令：  \n  ```bash\n  $ ./kani config-quay\n  # 第一步：启动 Quay 的的 Web UI 配置界面\n  $ firefox &\n  # 第二步：使用 Web UI 配置 Quay\n  $ ./kani deploy-quay\n  # 第三步：部署 Quay\n  ```\n\n  - 可通过 [Red Hat Quay v3 registry 原理与实现](https://alberthua-perl.github.io/2022/12/05/redhat-quay-v3-registry/) 文档了解如何通过 Web UI 配置 Quay。\n\n  - 配置 Kubernetes 集群连接 Quay 与拉取镜像：    \n    - 若在集群规划时需将 Quay 与 Kubernetes 集群连接的话，需在运行 kani 命令前更改好 `files/containerd/config.toml` 文件，以保证集群部署完成后可与 Quay 对接。      \n      其中 `username` 与 `password` 为 Quay 中的登录用户名与密码，如下所示：      \n      ```ini\n      [plugins.\"io.containerd.grpc.v1.cri\".registry]\n            config_path = \"\"\n      \n            [plugins.\"io.containerd.grpc.v1.cri\".registry.auths]\n      \n            [plugins.\"io.containerd.grpc.v1.cri\".registry.configs]\n              [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"quay-registry.lab.example.com\".tls]\n                insecure_skip_verify = true\n                # 使用自签名 CA 证书也需配置为 true\n              [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"quay-registry.lab.example.com\".auth]\n                username = \"godev\"\n                password = \"redhat321\"\n                # Quay 中需配置的用户名与密码         \n      \n            [plugins.\"io.containerd.grpc.v1.cri\".registry.headers]\n      \n            [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors]\n            ### modified by hualf to configure registry mirror\n              [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"docker.io\"]\n                endpoint = [\"https://bqr1dr1n.mirror.aliyuncs.com\"]\n              [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"k8s.gcr.io\"]\n                endpoint = [\"https://registry.aliyuncs.com/k8sxio\"]\n              [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"quay-registry.lab.example.com\"]\n                endpoint = [\"https://quay-registry.lab.example.com\"]\n                # 内部私有的容器镜像仓库\n              # containerd 守护进程可访问的公共与私有容器镜像仓库 \n      ```\n    - 若在 Kubernetes 集群部署完成后再与 Quay 集成，需更改每个运行 Containerd 节点的配置文件，再重启每个节点上的 containerd 守护进程，才能保证与 Quay 的对接。   \n    - 在笔者的环境中，containerd 配置文件中已配置了 `godev` 用户与相应密码用于连接 Quay 与拉取镜像，因此，在 Quay 中需创建对应的用户。\n\n### 参考链接：\n- [Kubernetes Docs - 使用 Kubespray 安装 Kubernetes](https://kubernetes.io/zh/docs/setup/production-environment/tools/kubespray/)\n- [Kubernetes Docs - Bootstrapping clusters with kubeadm](https://v1-22.docs.kubernetes.io/docs/setup/production-environment/tools/kubeadm/)\n- [Install Calico](https://projectcalico.docs.tigera.io/getting-started/kubernetes/self-managed-onprem/onpremises)","source":"_posts/kani-deploy-k8s.md","raw":"---\ntitle: Kani - Ansible 快速部署与管理 Kubernetes v1.22.1\nsubtitle: Use Kani to Rapidly Deploy Kubernetes Cluster\nheader-img: kani-ansible-k8s.svg\ndate: 2022-11-28 14:01:23\ntags:\n  - Kubernetes\n  - 云原生\n  - Ansible\n---\n\n### 文档目录：\n- 项目目的\n- 实施环境\n- 需要更改的参数\n- 实施过程中遇到的问题与解决方法\n- Kani 的使用方法\n- 参考链接\n\n### 项目目的：\n- 虽然目前具有大量的 Kubernetes 集群自动化部署解决方案，其中官方的 `KubeSpray` 即为使用 Ansible 的方式部署，但想尝试自己手动造轮子，因此创建了 Kani 项目。\n- Kani 项目的目的在于使用 Ansible 快速部署与管理 Kubernetes 集群及其相关组件。\n- 当前版本中 Kani 支持：  \n  - `Containerd` runtime  \n  - `Calico` CNI  \n  - `Red Hat Quay v3 registry`\n- Kani 的可选功能包括部署与管理其他额外的云原生、DevOps 与 GitOps 组件，如下所示：  \n  - 容器镜像仓库：Red Hat Quay v3 registry  \n  - 代码仓库：GitLab\n- 可点击 [此处](https://github.com/Alberthua-Perl/kani) 获取 Kani 项目 👋\n\n### 实施环境：\n- OS 版本：`CentOS Linux release 7.9.2009` (Core)\n- kernel 版本：`5.13.12`\n> 可使用 `elrepo repository` 升级 Linux kernel。\n- Ansible 版本：`2.9.25`\n- Containerd 版本：`1.5.5`\n- Kubernetes 版本：`v1.22.1`\n- 准备一个节点作为 Ansible 控制节点用于运行 Kani，并安装 `ansible`、`rhel-system-roles` RPM 软件包。 \n- 使用普通用户克隆该项目，笔者环境中使用 `godev` 用户，该用户与项目目录中的 `vars/all.yml` 中的 `operator_user` 为同一用户。\n> 💥 使用 Kani 时，需注意将您的普通用户与 operator_user 保持一致！\n\n### 🤘 需要更改的参数：\n- 根据您的实际环境在以下文件中更改对应的参数：  \n  - `ansible.cfg` (Ansible config file):    \n    - remote_user：各个 Ansible 受管主机上的登录用户  \n  - `files/kubeadm-conf.yml` (kubeadm config file):    \n    - localAPIEndpoint.advertiseAddress：master 节点的 API 端点监听地址    \n    - localAPIEndpoint.bindPort：master 节点的 API 端点监听端口    \n    - nodeRegistration.criSocket：master 节点 containerd 的 Unix 套接字文件    \n    - nodeRegistration.name：master 节点的 FQDN    \n    - nodeRegistration.taints：为 master 节点添加不可调度的污点    \n    - mode：kube-proxy 的工作模式    \n    - imageRepository：指定容器镜像的仓库地址    \n    - KubernetesVersion：集群的安装版本    \n    - `networking.serviceSubnet`：集群的 Service Cluster IP 网段    \n    - `networking.podSubnet`：集群的 Pod IP 网段    \n    - cgroupDriver：指定控制组驱动类型    \n    - `clusterDNS`：集群的 CoreDNS 的 Service Cluster IP  \n  - `inventory-kubecluster` (Ansible inventory file):    \n    - 根据您所在的场景修改短主机名，此处为笔者所在的环境节点信息。  \n  - `vars/all.yml` (variables file):    \n    > 💥 根据您所在的环境修改 `!!! NEED TO EDIT !!!` 中的参数，其余参数可选择性地修改。    \n    - gateway：所有 Kubernetes 节点的的默认网关    \n    - nic：所有 Kubernetes 节点连接默认网关的网卡接口    \n    - operator_user：Ansible 控制节点与受管主机上远程连接的普通用户    \n    > 👉 operator_user 与 ansible.cfg 中的 remote_user 相同。    \n    - kube_master_node：master 节点的短主机名    \n    > 💥 该参数与 inventory-kubecluster 中的短主机名相同。\n\n### 实施过程中遇到的问题与解决方法：\n- Kubernetes 部署过程中的部分报错，如下所示：  \n  `kubeadm init` 初始化 master 节点失败，并且报错 `node not found`。由于所有的 `pause infra images` 未标识（tagged）`k8s.io/pause:3.5`，因此在 master 节点上的 `kubelet` 不能创建 `sandbox`。  \n  ![kubeadm-init-master-error-1.jpg](kubeadm-init-master-error-1.jpg)![kubeadm-init-master-error-2.jpg](kubeadm-init-master-error-2.jpg)\n- playbook 中的 `register` 注册变量不能在不同的 play 间引用。  \n  ![register-var-used-between-two-plays-error.jpg](register-var-used-between-two-plays-error.jpg)\n- 由于使用 `containerd` 来运行容器，因此 `ctr`、`crictl` 与 `nerdctl` 可被用来获取容器镜像与容器自身的状态。但是，仅仅 `crictl` 可直接使用 containerd 配置文件 `/etc/containerd/config.toml`。crictl 可加载配置有 quay registry endpoint、user 与 password 的配置文件。\n- 若使用自签名的 CA 证书，crictl 不能从 quay 容器镜像仓库拉取镜像，并且总是报错 `x509 cert file error`：  \n  ![crictl-ssl-ca-request-quay-error.jpg](crictl-ssl-ca-request-quay-error.jpg)\n- 通过配置在 containerd 配置文件中的 `insecure_skip_verify = true` 跳过 tls 验证才能拉取镜像。\n\n### 🚀 Kani 的使用方法：\n- Kani 项目的目录结构，如下所示：  \n  ```bash\n  ┌─[godev][paas-ctl][~/kani]\n  └─➞ tree .\n  .\n  ├── 00-general-prepare-kube.yml\n  ├── 01-containerd-kube-deploy.yml\n  ├── 02-kube-cluster-calio-deploy.yml\n  ├── 03-post-kube-deploy.yml\n  ├── ansible.cfg\n  ├── destroy-kube-cluster.yml\n  ├── files\n  │   ├── cni\n  │   │   └── calico-v3.21.yml\n  │   ├── containerd\n  │   │   ├── config.toml\n  │   │   ├── containerd-rootless-setuptool.sh\n  │   │   ├── containerd-rootless.sh\n  │   │   ├── cri-containerd-cni-1.5.5-linux-amd64.tar.gz  # 该文件可从下文百度网盘下载\n  │   │   └── nerdctl\n  │   ├── kube-utils\n  │   │   ├── k9s_Linux_x86_64.tar.gz\n  │   │   ├── kubeadm-conf.yml\n  │   │   ├── kube-dashboard-admin.yml\n  │   │   └── kube-dashboard-v2.3.1.yml\n  │   ├── quay\n  │   │   └── deploy-quay-registry.sh\n  │   ├── repos\n  │   │   ├── docker-ce.repo\n  │   │   └── kubernetes.repo\n  │   ├── rpms\n  │   │   ├── kubeadm-1.22.1-0.x86_64.rpm\n  │   │   ├── kubectl-1.22.1-0.x86_64.rpm\n  │   │   ├── kubelet-1.22.1-0.x86_64.rpm\n  │   │   └── kubernetes-cni-0.8.7-0.x86_64.rpm\n  │   └── vimrc\n  ├── inventory-kubecluster\n  ├── job-for-terminate-kube.yml\n  ├── kani\n  ├── kube-reverse\n  ├── provision-quay-registry.yml\n  ├── templates\n  │   └── hosts.j2\n  ├── terminate-kube-cluster.yml\n  └── vars\n      └── all.yml\n  \n  9 directories, 32 files\n  ```\n\n  > 1. 由于 GitHub 对于上传文件的大小限制（100 MiB），`files/containerd/cri-containerd-cni-1.5.5-linux-amd64.tar.gz` 可从 [百度网盘](https://pan.baidu.com/s/1ytxDjSN0u5Tewy5rcEGWNQ) 下载，下载密码为 apdl。\n  > 2. 💥 由于在 aliyun yum 源中的 kubeadm、kubectl、kubelet 与 kubernetes-cni 的 rpm 软件包可能存在无法获取的情况，因此已将软件包同项目一起上传！\n\n- 更改所有文件中的参数后，使用如下命令部署集群：  \n  ```bash\n  $ cd kani\n  $ chmod +x ./kani\n  $ ./kani --help\n  # 查看 kani 的使用方法\n  Rapid deploy kubernetes cluster and elements by ansible\n  \n  Usage:\n    kani [command]\n  \n  Available Commands:\n    deploy-kube     Deploy single master node kubernetes cluster with calico cni\n    terminate-kube  Terminate kubernetes master and worker nodes\n    destroy-kube    Destroy and prepare to re-install kubernetes cluster\n    config-quay     Config and run quay config container\n    deploy-quay     Deploy quay registry\n  \n  $ ./kani deploy-kube\n  # 部署 Kubernetes 集群\n  ```\n\n  > 🤘 注意：在 kubeadm init 初始化 master 节点后，由于还未将其他 node 节点加入至集群中，此时各个 node 节点上的 `kubelet` 守护进程启动失败，可能处于 `active (auto-restarting)` 状态，查看节点 /var/log/messages 中存在大量的 `/etc/kubernetes/pki/ca.crt not found` 的报错，这是由于 kubeadm join 还未将 node 节点加入集群以及还未同步 master 节点的 CA 证书所致，待 node 节点加入集群中后 kubelet 状态将恢复 `active` 状态。\n\n- Kubernetes 集群部署后的 node 与 pod 状态：![kubernetes-cluster-status.jpg](kubernetes-cluster-status.jpg)\n  \n  > 🤘 注意：Kubernetes 集群中 `coredns pod` 在 Calico CNI 未完全 ready 时将处于 `pending` 状态，直至所有 calico pod 处于 Running 状态时也将处于 Running 状态。\n\n- 停止 Kubernetes 集群：  \n  ```bash\n  $ ./kani terminate-kube\n  ```\n- 破坏与重装 Kubernetes 集群：  \n  ```bash\n  $ ./kani destroy-kube\n  ```\n- （可选操作）部署 `Red Hat Quay v3 registry` 并与 Kubernetes 集群集成：  \n  若需使用 `Red Hat Quay v3 registry` 作为容器镜像仓库，可使用如下命令：  \n  ```bash\n  $ ./kani config-quay\n  # 第一步：启动 Quay 的的 Web UI 配置界面\n  $ firefox &\n  # 第二步：使用 Web UI 配置 Quay\n  $ ./kani deploy-quay\n  # 第三步：部署 Quay\n  ```\n\n  - 可通过 [Red Hat Quay v3 registry 原理与实现](https://alberthua-perl.github.io/2022/12/05/redhat-quay-v3-registry/) 文档了解如何通过 Web UI 配置 Quay。\n\n  - 配置 Kubernetes 集群连接 Quay 与拉取镜像：    \n    - 若在集群规划时需将 Quay 与 Kubernetes 集群连接的话，需在运行 kani 命令前更改好 `files/containerd/config.toml` 文件，以保证集群部署完成后可与 Quay 对接。      \n      其中 `username` 与 `password` 为 Quay 中的登录用户名与密码，如下所示：      \n      ```ini\n      [plugins.\"io.containerd.grpc.v1.cri\".registry]\n            config_path = \"\"\n      \n            [plugins.\"io.containerd.grpc.v1.cri\".registry.auths]\n      \n            [plugins.\"io.containerd.grpc.v1.cri\".registry.configs]\n              [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"quay-registry.lab.example.com\".tls]\n                insecure_skip_verify = true\n                # 使用自签名 CA 证书也需配置为 true\n              [plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"quay-registry.lab.example.com\".auth]\n                username = \"godev\"\n                password = \"redhat321\"\n                # Quay 中需配置的用户名与密码         \n      \n            [plugins.\"io.containerd.grpc.v1.cri\".registry.headers]\n      \n            [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors]\n            ### modified by hualf to configure registry mirror\n              [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"docker.io\"]\n                endpoint = [\"https://bqr1dr1n.mirror.aliyuncs.com\"]\n              [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"k8s.gcr.io\"]\n                endpoint = [\"https://registry.aliyuncs.com/k8sxio\"]\n              [plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"quay-registry.lab.example.com\"]\n                endpoint = [\"https://quay-registry.lab.example.com\"]\n                # 内部私有的容器镜像仓库\n              # containerd 守护进程可访问的公共与私有容器镜像仓库 \n      ```\n    - 若在 Kubernetes 集群部署完成后再与 Quay 集成，需更改每个运行 Containerd 节点的配置文件，再重启每个节点上的 containerd 守护进程，才能保证与 Quay 的对接。   \n    - 在笔者的环境中，containerd 配置文件中已配置了 `godev` 用户与相应密码用于连接 Quay 与拉取镜像，因此，在 Quay 中需创建对应的用户。\n\n### 参考链接：\n- [Kubernetes Docs - 使用 Kubespray 安装 Kubernetes](https://kubernetes.io/zh/docs/setup/production-environment/tools/kubespray/)\n- [Kubernetes Docs - Bootstrapping clusters with kubeadm](https://v1-22.docs.kubernetes.io/docs/setup/production-environment/tools/kubeadm/)\n- [Install Calico](https://projectcalico.docs.tigera.io/getting-started/kubernetes/self-managed-onprem/onpremises)","slug":"kani-deploy-k8s","published":1,"updated":"2022-12-06T02:50:48.521Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldfonola000d16vdd44th76p","content":"<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>项目目的</li>\n<li>实施环境</li>\n<li>需要更改的参数</li>\n<li>实施过程中遇到的问题与解决方法</li>\n<li>Kani 的使用方法</li>\n<li>参考链接</li>\n</ul>\n<h3 id=\"项目目的：\"><a href=\"#项目目的：\" class=\"headerlink\" title=\"项目目的：\"></a>项目目的：</h3><ul>\n<li>虽然目前具有大量的 Kubernetes 集群自动化部署解决方案，其中官方的 <code>KubeSpray</code> 即为使用 Ansible 的方式部署，但想尝试自己手动造轮子，因此创建了 Kani 项目。</li>\n<li>Kani 项目的目的在于使用 Ansible 快速部署与管理 Kubernetes 集群及其相关组件。</li>\n<li>当前版本中 Kani 支持：  <ul>\n<li><code>Containerd</code> runtime  </li>\n<li><code>Calico</code> CNI  </li>\n<li><code>Red Hat Quay v3 registry</code></li>\n</ul>\n</li>\n<li>Kani 的可选功能包括部署与管理其他额外的云原生、DevOps 与 GitOps 组件，如下所示：  <ul>\n<li>容器镜像仓库：Red Hat Quay v3 registry  </li>\n<li>代码仓库：GitLab</li>\n</ul>\n</li>\n<li>可点击 <a href=\"https://github.com/Alberthua-Perl/kani\" target=\"_blank\" rel=\"noopener\">此处</a> 获取 Kani 项目 👋</li>\n</ul>\n<h3 id=\"实施环境：\"><a href=\"#实施环境：\" class=\"headerlink\" title=\"实施环境：\"></a>实施环境：</h3><ul>\n<li>OS 版本：<code>CentOS Linux release 7.9.2009</code> (Core)</li>\n<li>kernel 版本：<code>5.13.12</code><blockquote>\n<p>可使用 <code>elrepo repository</code> 升级 Linux kernel。</p>\n</blockquote>\n</li>\n<li>Ansible 版本：<code>2.9.25</code></li>\n<li>Containerd 版本：<code>1.5.5</code></li>\n<li>Kubernetes 版本：<code>v1.22.1</code></li>\n<li>准备一个节点作为 Ansible 控制节点用于运行 Kani，并安装 <code>ansible</code>、<code>rhel-system-roles</code> RPM 软件包。 </li>\n<li>使用普通用户克隆该项目，笔者环境中使用 <code>godev</code> 用户，该用户与项目目录中的 <code>vars/all.yml</code> 中的 <code>operator_user</code> 为同一用户。<blockquote>\n<p>💥 使用 Kani 时，需注意将您的普通用户与 operator_user 保持一致！</p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"🤘-需要更改的参数：\"><a href=\"#🤘-需要更改的参数：\" class=\"headerlink\" title=\"🤘 需要更改的参数：\"></a>🤘 需要更改的参数：</h3><ul>\n<li>根据您的实际环境在以下文件中更改对应的参数：  <ul>\n<li><code>ansible.cfg</code> (Ansible config file):    <ul>\n<li>remote_user：各个 Ansible 受管主机上的登录用户  </li>\n</ul>\n</li>\n<li><code>files/kubeadm-conf.yml</code> (kubeadm config file):    <ul>\n<li>localAPIEndpoint.advertiseAddress：master 节点的 API 端点监听地址    </li>\n<li>localAPIEndpoint.bindPort：master 节点的 API 端点监听端口    </li>\n<li>nodeRegistration.criSocket：master 节点 containerd 的 Unix 套接字文件    </li>\n<li>nodeRegistration.name：master 节点的 FQDN    </li>\n<li>nodeRegistration.taints：为 master 节点添加不可调度的污点    </li>\n<li>mode：kube-proxy 的工作模式    </li>\n<li>imageRepository：指定容器镜像的仓库地址    </li>\n<li>KubernetesVersion：集群的安装版本    </li>\n<li><code>networking.serviceSubnet</code>：集群的 Service Cluster IP 网段    </li>\n<li><code>networking.podSubnet</code>：集群的 Pod IP 网段    </li>\n<li>cgroupDriver：指定控制组驱动类型    </li>\n<li><code>clusterDNS</code>：集群的 CoreDNS 的 Service Cluster IP  </li>\n</ul>\n</li>\n<li><code>inventory-kubecluster</code> (Ansible inventory file):    <ul>\n<li>根据您所在的场景修改短主机名，此处为笔者所在的环境节点信息。  </li>\n</ul>\n</li>\n<li><code>vars/all.yml</code> (variables file):    <blockquote>\n<p>💥 根据您所在的环境修改 <code>!!! NEED TO EDIT !!!</code> 中的参数，其余参数可选择性地修改。    </p>\n<ul>\n<li>gateway：所有 Kubernetes 节点的的默认网关    </li>\n<li>nic：所有 Kubernetes 节点连接默认网关的网卡接口    </li>\n<li>operator_user：Ansible 控制节点与受管主机上远程连接的普通用户<br>👉 operator_user 与 ansible.cfg 中的 remote_user 相同。    </li>\n<li>kube_master_node：master 节点的短主机名<br>💥 该参数与 inventory-kubecluster 中的短主机名相同。</li>\n</ul>\n</blockquote>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"实施过程中遇到的问题与解决方法：\"><a href=\"#实施过程中遇到的问题与解决方法：\" class=\"headerlink\" title=\"实施过程中遇到的问题与解决方法：\"></a>实施过程中遇到的问题与解决方法：</h3><ul>\n<li>Kubernetes 部署过程中的部分报错，如下所示：<br><code>kubeadm init</code> 初始化 master 节点失败，并且报错 <code>node not found</code>。由于所有的 <code>pause infra images</code> 未标识（tagged）<code>k8s.io/pause:3.5</code>，因此在 master 节点上的 <code>kubelet</code> 不能创建 <code>sandbox</code>。<br><img src=\"kubeadm-init-master-error-1.jpg\" alt=\"kubeadm-init-master-error-1.jpg\"><img src=\"kubeadm-init-master-error-2.jpg\" alt=\"kubeadm-init-master-error-2.jpg\"></li>\n<li>playbook 中的 <code>register</code> 注册变量不能在不同的 play 间引用。<br><img src=\"register-var-used-between-two-plays-error.jpg\" alt=\"register-var-used-between-two-plays-error.jpg\"></li>\n<li>由于使用 <code>containerd</code> 来运行容器，因此 <code>ctr</code>、<code>crictl</code> 与 <code>nerdctl</code> 可被用来获取容器镜像与容器自身的状态。但是，仅仅 <code>crictl</code> 可直接使用 containerd 配置文件 <code>/etc/containerd/config.toml</code>。crictl 可加载配置有 quay registry endpoint、user 与 password 的配置文件。</li>\n<li>若使用自签名的 CA 证书，crictl 不能从 quay 容器镜像仓库拉取镜像，并且总是报错 <code>x509 cert file error</code>：<br><img src=\"crictl-ssl-ca-request-quay-error.jpg\" alt=\"crictl-ssl-ca-request-quay-error.jpg\"></li>\n<li>通过配置在 containerd 配置文件中的 <code>insecure_skip_verify = true</code> 跳过 tls 验证才能拉取镜像。</li>\n</ul>\n<h3 id=\"🚀-Kani-的使用方法：\"><a href=\"#🚀-Kani-的使用方法：\" class=\"headerlink\" title=\"🚀 Kani 的使用方法：\"></a>🚀 Kani 的使用方法：</h3><ul>\n<li><p>Kani 项目的目录结构，如下所示：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">┌─[godev][paas-ctl][~/kani]</span><br><span class=\"line\">└─➞ tree .</span><br><span class=\"line\">.</span><br><span class=\"line\">├── 00-general-prepare-kube.yml</span><br><span class=\"line\">├── 01-containerd-kube-deploy.yml</span><br><span class=\"line\">├── 02-kube-cluster-calio-deploy.yml</span><br><span class=\"line\">├── 03-post-kube-deploy.yml</span><br><span class=\"line\">├── ansible.cfg</span><br><span class=\"line\">├── destroy-kube-cluster.yml</span><br><span class=\"line\">├── files</span><br><span class=\"line\">│   ├── cni</span><br><span class=\"line\">│   │   └── calico-v3.21.yml</span><br><span class=\"line\">│   ├── containerd</span><br><span class=\"line\">│   │   ├── config.toml</span><br><span class=\"line\">│   │   ├── containerd-rootless-setuptool.sh</span><br><span class=\"line\">│   │   ├── containerd-rootless.sh</span><br><span class=\"line\">│   │   ├── cri-containerd-cni-1.5.5-linux-amd64.tar.gz  <span class=\"comment\"># 该文件可从下文百度网盘下载</span></span><br><span class=\"line\">│   │   └── nerdctl</span><br><span class=\"line\">│   ├── kube-utils</span><br><span class=\"line\">│   │   ├── k9s_Linux_x86_64.tar.gz</span><br><span class=\"line\">│   │   ├── kubeadm-conf.yml</span><br><span class=\"line\">│   │   ├── kube-dashboard-admin.yml</span><br><span class=\"line\">│   │   └── kube-dashboard-v2.3.1.yml</span><br><span class=\"line\">│   ├── quay</span><br><span class=\"line\">│   │   └── deploy-quay-registry.sh</span><br><span class=\"line\">│   ├── repos</span><br><span class=\"line\">│   │   ├── docker-ce.repo</span><br><span class=\"line\">│   │   └── kubernetes.repo</span><br><span class=\"line\">│   ├── rpms</span><br><span class=\"line\">│   │   ├── kubeadm-1.22.1-0.x86_64.rpm</span><br><span class=\"line\">│   │   ├── kubectl-1.22.1-0.x86_64.rpm</span><br><span class=\"line\">│   │   ├── kubelet-1.22.1-0.x86_64.rpm</span><br><span class=\"line\">│   │   └── kubernetes-cni-0.8.7-0.x86_64.rpm</span><br><span class=\"line\">│   └── vimrc</span><br><span class=\"line\">├── inventory-kubecluster</span><br><span class=\"line\">├── job-for-terminate-kube.yml</span><br><span class=\"line\">├── kani</span><br><span class=\"line\">├── kube-reverse</span><br><span class=\"line\">├── provision-quay-registry.yml</span><br><span class=\"line\">├── templates</span><br><span class=\"line\">│   └── hosts.j2</span><br><span class=\"line\">├── terminate-kube-cluster.yml</span><br><span class=\"line\">└── vars</span><br><span class=\"line\">    └── all.yml</span><br><span class=\"line\"></span><br><span class=\"line\">9 directories, 32 files</span><br></pre></td></tr></table></figure>\n<blockquote>\n<ol>\n<li>由于 GitHub 对于上传文件的大小限制（100 MiB），<code>files/containerd/cri-containerd-cni-1.5.5-linux-amd64.tar.gz</code> 可从 <a href=\"https://pan.baidu.com/s/1ytxDjSN0u5Tewy5rcEGWNQ\" target=\"_blank\" rel=\"noopener\">百度网盘</a> 下载，下载密码为 apdl。</li>\n<li>💥 由于在 aliyun yum 源中的 kubeadm、kubectl、kubelet 与 kubernetes-cni 的 rpm 软件包可能存在无法获取的情况，因此已将软件包同项目一起上传！</li>\n</ol>\n</blockquote>\n</li>\n<li><p>更改所有文件中的参数后，使用如下命令部署集群：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> kani</span><br><span class=\"line\">$ chmod +x ./kani</span><br><span class=\"line\">$ ./kani --<span class=\"built_in\">help</span></span><br><span class=\"line\"><span class=\"comment\"># 查看 kani 的使用方法</span></span><br><span class=\"line\">Rapid deploy kubernetes cluster and elements by ansible</span><br><span class=\"line\"></span><br><span class=\"line\">Usage:</span><br><span class=\"line\">  kani [<span class=\"built_in\">command</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">Available Commands:</span><br><span class=\"line\">  deploy-kube     Deploy single master node kubernetes cluster with calico cni</span><br><span class=\"line\">  terminate-kube  Terminate kubernetes master and worker nodes</span><br><span class=\"line\">  destroy-kube    Destroy and prepare to re-install kubernetes cluster</span><br><span class=\"line\">  config-quay     Config and run quay config container</span><br><span class=\"line\">  deploy-quay     Deploy quay registry</span><br><span class=\"line\"></span><br><span class=\"line\">$ ./kani deploy-kube</span><br><span class=\"line\"><span class=\"comment\"># 部署 Kubernetes 集群</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>🤘 注意：在 kubeadm init 初始化 master 节点后，由于还未将其他 node 节点加入至集群中，此时各个 node 节点上的 <code>kubelet</code> 守护进程启动失败，可能处于 <code>active (auto-restarting)</code> 状态，查看节点 /var/log/messages 中存在大量的 <code>/etc/kubernetes/pki/ca.crt not found</code> 的报错，这是由于 kubeadm join 还未将 node 节点加入集群以及还未同步 master 节点的 CA 证书所致，待 node 节点加入集群中后 kubelet 状态将恢复 <code>active</code> 状态。</p>\n</blockquote>\n</li>\n<li><p>Kubernetes 集群部署后的 node 与 pod 状态：<img src=\"kubernetes-cluster-status.jpg\" alt=\"kubernetes-cluster-status.jpg\"></p>\n<blockquote>\n<p>🤘 注意：Kubernetes 集群中 <code>coredns pod</code> 在 Calico CNI 未完全 ready 时将处于 <code>pending</code> 状态，直至所有 calico pod 处于 Running 状态时也将处于 Running 状态。</p>\n</blockquote>\n</li>\n<li><p>停止 Kubernetes 集群：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ./kani terminate-kube</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>破坏与重装 Kubernetes 集群：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ./kani destroy-kube</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>（可选操作）部署 <code>Red Hat Quay v3 registry</code> 并与 Kubernetes 集群集成：<br>若需使用 <code>Red Hat Quay v3 registry</code> 作为容器镜像仓库，可使用如下命令：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ./kani config-quay</span><br><span class=\"line\"><span class=\"comment\"># 第一步：启动 Quay 的的 Web UI 配置界面</span></span><br><span class=\"line\">$ firefox &amp;</span><br><span class=\"line\"><span class=\"comment\"># 第二步：使用 Web UI 配置 Quay</span></span><br><span class=\"line\">$ ./kani deploy-quay</span><br><span class=\"line\"><span class=\"comment\"># 第三步：部署 Quay</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>可通过 <a href=\"https://alberthua-perl.github.io/2022/12/05/redhat-quay-v3-registry/\">Red Hat Quay v3 registry 原理与实现</a> 文档了解如何通过 Web UI 配置 Quay。</p>\n</li>\n<li><p>配置 Kubernetes 集群连接 Quay 与拉取镜像：    </p>\n<ul>\n<li><p>若在集群规划时需将 Quay 与 Kubernetes 集群连接的话，需在运行 kani 命令前更改好 <code>files/containerd/config.toml</code> 文件，以保证集群部署完成后可与 Quay 对接。<br>其中 <code>username</code> 与 <code>password</code> 为 Quay 中的登录用户名与密码，如下所示：      </p>\n<figure class=\"highlight ini\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry]</span></span><br><span class=\"line\">      config_path = \"\"</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.auths]</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.configs]</span></span><br><span class=\"line\">        <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"quay-registry.lab.example.com\".tls]</span></span><br><span class=\"line\">          insecure_skip_verify = true</span><br><span class=\"line\">          <span class=\"comment\"># 使用自签名 CA 证书也需配置为 true</span></span><br><span class=\"line\">        <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"quay-registry.lab.example.com\".auth]</span></span><br><span class=\"line\">          username = \"godev\"</span><br><span class=\"line\">          password = \"redhat321\"</span><br><span class=\"line\">          <span class=\"comment\"># Quay 中需配置的用户名与密码         </span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.headers]</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors]</span></span><br><span class=\"line\">      <span class=\"comment\">### modified by hualf to configure registry mirror</span></span><br><span class=\"line\">        <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"docker.io\"]</span></span><br><span class=\"line\">          endpoint = [\"https://bqr1dr1n.mirror.aliyuncs.com\"]</span><br><span class=\"line\">        <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"k8s.gcr.io\"]</span></span><br><span class=\"line\">          endpoint = [\"https://registry.aliyuncs.com/k8sxio\"]</span><br><span class=\"line\">        <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"quay-registry.lab.example.com\"]</span></span><br><span class=\"line\">          endpoint = [\"https://quay-registry.lab.example.com\"]</span><br><span class=\"line\">          <span class=\"comment\"># 内部私有的容器镜像仓库</span></span><br><span class=\"line\">        <span class=\"comment\"># containerd 守护进程可访问的公共与私有容器镜像仓库</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>若在 Kubernetes 集群部署完成后再与 Quay 集成，需更改每个运行 Containerd 节点的配置文件，再重启每个节点上的 containerd 守护进程，才能保证与 Quay 的对接。   </p>\n</li>\n<li>在笔者的环境中，containerd 配置文件中已配置了 <code>godev</code> 用户与相应密码用于连接 Quay 与拉取镜像，因此，在 Quay 中需创建对应的用户。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://kubernetes.io/zh/docs/setup/production-environment/tools/kubespray/\" target=\"_blank\" rel=\"noopener\">Kubernetes Docs - 使用 Kubespray 安装 Kubernetes</a></li>\n<li><a href=\"https://v1-22.docs.kubernetes.io/docs/setup/production-environment/tools/kubeadm/\" target=\"_blank\" rel=\"noopener\">Kubernetes Docs - Bootstrapping clusters with kubeadm</a></li>\n<li><a href=\"https://projectcalico.docs.tigera.io/getting-started/kubernetes/self-managed-onprem/onpremises\" target=\"_blank\" rel=\"noopener\">Install Calico</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>项目目的</li>\n<li>实施环境</li>\n<li>需要更改的参数</li>\n<li>实施过程中遇到的问题与解决方法</li>\n<li>Kani 的使用方法</li>\n<li>参考链接</li>\n</ul>\n<h3 id=\"项目目的：\"><a href=\"#项目目的：\" class=\"headerlink\" title=\"项目目的：\"></a>项目目的：</h3><ul>\n<li>虽然目前具有大量的 Kubernetes 集群自动化部署解决方案，其中官方的 <code>KubeSpray</code> 即为使用 Ansible 的方式部署，但想尝试自己手动造轮子，因此创建了 Kani 项目。</li>\n<li>Kani 项目的目的在于使用 Ansible 快速部署与管理 Kubernetes 集群及其相关组件。</li>\n<li>当前版本中 Kani 支持：  <ul>\n<li><code>Containerd</code> runtime  </li>\n<li><code>Calico</code> CNI  </li>\n<li><code>Red Hat Quay v3 registry</code></li>\n</ul>\n</li>\n<li>Kani 的可选功能包括部署与管理其他额外的云原生、DevOps 与 GitOps 组件，如下所示：  <ul>\n<li>容器镜像仓库：Red Hat Quay v3 registry  </li>\n<li>代码仓库：GitLab</li>\n</ul>\n</li>\n<li>可点击 <a href=\"https://github.com/Alberthua-Perl/kani\" target=\"_blank\" rel=\"noopener\">此处</a> 获取 Kani 项目 👋</li>\n</ul>\n<h3 id=\"实施环境：\"><a href=\"#实施环境：\" class=\"headerlink\" title=\"实施环境：\"></a>实施环境：</h3><ul>\n<li>OS 版本：<code>CentOS Linux release 7.9.2009</code> (Core)</li>\n<li>kernel 版本：<code>5.13.12</code><blockquote>\n<p>可使用 <code>elrepo repository</code> 升级 Linux kernel。</p>\n</blockquote>\n</li>\n<li>Ansible 版本：<code>2.9.25</code></li>\n<li>Containerd 版本：<code>1.5.5</code></li>\n<li>Kubernetes 版本：<code>v1.22.1</code></li>\n<li>准备一个节点作为 Ansible 控制节点用于运行 Kani，并安装 <code>ansible</code>、<code>rhel-system-roles</code> RPM 软件包。 </li>\n<li>使用普通用户克隆该项目，笔者环境中使用 <code>godev</code> 用户，该用户与项目目录中的 <code>vars/all.yml</code> 中的 <code>operator_user</code> 为同一用户。<blockquote>\n<p>💥 使用 Kani 时，需注意将您的普通用户与 operator_user 保持一致！</p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"🤘-需要更改的参数：\"><a href=\"#🤘-需要更改的参数：\" class=\"headerlink\" title=\"🤘 需要更改的参数：\"></a>🤘 需要更改的参数：</h3><ul>\n<li>根据您的实际环境在以下文件中更改对应的参数：  <ul>\n<li><code>ansible.cfg</code> (Ansible config file):    <ul>\n<li>remote_user：各个 Ansible 受管主机上的登录用户  </li>\n</ul>\n</li>\n<li><code>files/kubeadm-conf.yml</code> (kubeadm config file):    <ul>\n<li>localAPIEndpoint.advertiseAddress：master 节点的 API 端点监听地址    </li>\n<li>localAPIEndpoint.bindPort：master 节点的 API 端点监听端口    </li>\n<li>nodeRegistration.criSocket：master 节点 containerd 的 Unix 套接字文件    </li>\n<li>nodeRegistration.name：master 节点的 FQDN    </li>\n<li>nodeRegistration.taints：为 master 节点添加不可调度的污点    </li>\n<li>mode：kube-proxy 的工作模式    </li>\n<li>imageRepository：指定容器镜像的仓库地址    </li>\n<li>KubernetesVersion：集群的安装版本    </li>\n<li><code>networking.serviceSubnet</code>：集群的 Service Cluster IP 网段    </li>\n<li><code>networking.podSubnet</code>：集群的 Pod IP 网段    </li>\n<li>cgroupDriver：指定控制组驱动类型    </li>\n<li><code>clusterDNS</code>：集群的 CoreDNS 的 Service Cluster IP  </li>\n</ul>\n</li>\n<li><code>inventory-kubecluster</code> (Ansible inventory file):    <ul>\n<li>根据您所在的场景修改短主机名，此处为笔者所在的环境节点信息。  </li>\n</ul>\n</li>\n<li><code>vars/all.yml</code> (variables file):    <blockquote>\n<p>💥 根据您所在的环境修改 <code>!!! NEED TO EDIT !!!</code> 中的参数，其余参数可选择性地修改。    </p>\n<ul>\n<li>gateway：所有 Kubernetes 节点的的默认网关    </li>\n<li>nic：所有 Kubernetes 节点连接默认网关的网卡接口    </li>\n<li>operator_user：Ansible 控制节点与受管主机上远程连接的普通用户<br>👉 operator_user 与 ansible.cfg 中的 remote_user 相同。    </li>\n<li>kube_master_node：master 节点的短主机名<br>💥 该参数与 inventory-kubecluster 中的短主机名相同。</li>\n</ul>\n</blockquote>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"实施过程中遇到的问题与解决方法：\"><a href=\"#实施过程中遇到的问题与解决方法：\" class=\"headerlink\" title=\"实施过程中遇到的问题与解决方法：\"></a>实施过程中遇到的问题与解决方法：</h3><ul>\n<li>Kubernetes 部署过程中的部分报错，如下所示：<br><code>kubeadm init</code> 初始化 master 节点失败，并且报错 <code>node not found</code>。由于所有的 <code>pause infra images</code> 未标识（tagged）<code>k8s.io/pause:3.5</code>，因此在 master 节点上的 <code>kubelet</code> 不能创建 <code>sandbox</code>。<br><img src=\"kubeadm-init-master-error-1.jpg\" alt=\"kubeadm-init-master-error-1.jpg\"><img src=\"kubeadm-init-master-error-2.jpg\" alt=\"kubeadm-init-master-error-2.jpg\"></li>\n<li>playbook 中的 <code>register</code> 注册变量不能在不同的 play 间引用。<br><img src=\"register-var-used-between-two-plays-error.jpg\" alt=\"register-var-used-between-two-plays-error.jpg\"></li>\n<li>由于使用 <code>containerd</code> 来运行容器，因此 <code>ctr</code>、<code>crictl</code> 与 <code>nerdctl</code> 可被用来获取容器镜像与容器自身的状态。但是，仅仅 <code>crictl</code> 可直接使用 containerd 配置文件 <code>/etc/containerd/config.toml</code>。crictl 可加载配置有 quay registry endpoint、user 与 password 的配置文件。</li>\n<li>若使用自签名的 CA 证书，crictl 不能从 quay 容器镜像仓库拉取镜像，并且总是报错 <code>x509 cert file error</code>：<br><img src=\"crictl-ssl-ca-request-quay-error.jpg\" alt=\"crictl-ssl-ca-request-quay-error.jpg\"></li>\n<li>通过配置在 containerd 配置文件中的 <code>insecure_skip_verify = true</code> 跳过 tls 验证才能拉取镜像。</li>\n</ul>\n<h3 id=\"🚀-Kani-的使用方法：\"><a href=\"#🚀-Kani-的使用方法：\" class=\"headerlink\" title=\"🚀 Kani 的使用方法：\"></a>🚀 Kani 的使用方法：</h3><ul>\n<li><p>Kani 项目的目录结构，如下所示：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">┌─[godev][paas-ctl][~/kani]</span><br><span class=\"line\">└─➞ tree .</span><br><span class=\"line\">.</span><br><span class=\"line\">├── 00-general-prepare-kube.yml</span><br><span class=\"line\">├── 01-containerd-kube-deploy.yml</span><br><span class=\"line\">├── 02-kube-cluster-calio-deploy.yml</span><br><span class=\"line\">├── 03-post-kube-deploy.yml</span><br><span class=\"line\">├── ansible.cfg</span><br><span class=\"line\">├── destroy-kube-cluster.yml</span><br><span class=\"line\">├── files</span><br><span class=\"line\">│   ├── cni</span><br><span class=\"line\">│   │   └── calico-v3.21.yml</span><br><span class=\"line\">│   ├── containerd</span><br><span class=\"line\">│   │   ├── config.toml</span><br><span class=\"line\">│   │   ├── containerd-rootless-setuptool.sh</span><br><span class=\"line\">│   │   ├── containerd-rootless.sh</span><br><span class=\"line\">│   │   ├── cri-containerd-cni-1.5.5-linux-amd64.tar.gz  <span class=\"comment\"># 该文件可从下文百度网盘下载</span></span><br><span class=\"line\">│   │   └── nerdctl</span><br><span class=\"line\">│   ├── kube-utils</span><br><span class=\"line\">│   │   ├── k9s_Linux_x86_64.tar.gz</span><br><span class=\"line\">│   │   ├── kubeadm-conf.yml</span><br><span class=\"line\">│   │   ├── kube-dashboard-admin.yml</span><br><span class=\"line\">│   │   └── kube-dashboard-v2.3.1.yml</span><br><span class=\"line\">│   ├── quay</span><br><span class=\"line\">│   │   └── deploy-quay-registry.sh</span><br><span class=\"line\">│   ├── repos</span><br><span class=\"line\">│   │   ├── docker-ce.repo</span><br><span class=\"line\">│   │   └── kubernetes.repo</span><br><span class=\"line\">│   ├── rpms</span><br><span class=\"line\">│   │   ├── kubeadm-1.22.1-0.x86_64.rpm</span><br><span class=\"line\">│   │   ├── kubectl-1.22.1-0.x86_64.rpm</span><br><span class=\"line\">│   │   ├── kubelet-1.22.1-0.x86_64.rpm</span><br><span class=\"line\">│   │   └── kubernetes-cni-0.8.7-0.x86_64.rpm</span><br><span class=\"line\">│   └── vimrc</span><br><span class=\"line\">├── inventory-kubecluster</span><br><span class=\"line\">├── job-for-terminate-kube.yml</span><br><span class=\"line\">├── kani</span><br><span class=\"line\">├── kube-reverse</span><br><span class=\"line\">├── provision-quay-registry.yml</span><br><span class=\"line\">├── templates</span><br><span class=\"line\">│   └── hosts.j2</span><br><span class=\"line\">├── terminate-kube-cluster.yml</span><br><span class=\"line\">└── vars</span><br><span class=\"line\">    └── all.yml</span><br><span class=\"line\"></span><br><span class=\"line\">9 directories, 32 files</span><br></pre></td></tr></table></figure>\n<blockquote>\n<ol>\n<li>由于 GitHub 对于上传文件的大小限制（100 MiB），<code>files/containerd/cri-containerd-cni-1.5.5-linux-amd64.tar.gz</code> 可从 <a href=\"https://pan.baidu.com/s/1ytxDjSN0u5Tewy5rcEGWNQ\" target=\"_blank\" rel=\"noopener\">百度网盘</a> 下载，下载密码为 apdl。</li>\n<li>💥 由于在 aliyun yum 源中的 kubeadm、kubectl、kubelet 与 kubernetes-cni 的 rpm 软件包可能存在无法获取的情况，因此已将软件包同项目一起上传！</li>\n</ol>\n</blockquote>\n</li>\n<li><p>更改所有文件中的参数后，使用如下命令部署集群：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> kani</span><br><span class=\"line\">$ chmod +x ./kani</span><br><span class=\"line\">$ ./kani --<span class=\"built_in\">help</span></span><br><span class=\"line\"><span class=\"comment\"># 查看 kani 的使用方法</span></span><br><span class=\"line\">Rapid deploy kubernetes cluster and elements by ansible</span><br><span class=\"line\"></span><br><span class=\"line\">Usage:</span><br><span class=\"line\">  kani [<span class=\"built_in\">command</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">Available Commands:</span><br><span class=\"line\">  deploy-kube     Deploy single master node kubernetes cluster with calico cni</span><br><span class=\"line\">  terminate-kube  Terminate kubernetes master and worker nodes</span><br><span class=\"line\">  destroy-kube    Destroy and prepare to re-install kubernetes cluster</span><br><span class=\"line\">  config-quay     Config and run quay config container</span><br><span class=\"line\">  deploy-quay     Deploy quay registry</span><br><span class=\"line\"></span><br><span class=\"line\">$ ./kani deploy-kube</span><br><span class=\"line\"><span class=\"comment\"># 部署 Kubernetes 集群</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>🤘 注意：在 kubeadm init 初始化 master 节点后，由于还未将其他 node 节点加入至集群中，此时各个 node 节点上的 <code>kubelet</code> 守护进程启动失败，可能处于 <code>active (auto-restarting)</code> 状态，查看节点 /var/log/messages 中存在大量的 <code>/etc/kubernetes/pki/ca.crt not found</code> 的报错，这是由于 kubeadm join 还未将 node 节点加入集群以及还未同步 master 节点的 CA 证书所致，待 node 节点加入集群中后 kubelet 状态将恢复 <code>active</code> 状态。</p>\n</blockquote>\n</li>\n<li><p>Kubernetes 集群部署后的 node 与 pod 状态：<img src=\"kubernetes-cluster-status.jpg\" alt=\"kubernetes-cluster-status.jpg\"></p>\n<blockquote>\n<p>🤘 注意：Kubernetes 集群中 <code>coredns pod</code> 在 Calico CNI 未完全 ready 时将处于 <code>pending</code> 状态，直至所有 calico pod 处于 Running 状态时也将处于 Running 状态。</p>\n</blockquote>\n</li>\n<li><p>停止 Kubernetes 集群：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ./kani terminate-kube</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>破坏与重装 Kubernetes 集群：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ./kani destroy-kube</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>（可选操作）部署 <code>Red Hat Quay v3 registry</code> 并与 Kubernetes 集群集成：<br>若需使用 <code>Red Hat Quay v3 registry</code> 作为容器镜像仓库，可使用如下命令：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ./kani config-quay</span><br><span class=\"line\"><span class=\"comment\"># 第一步：启动 Quay 的的 Web UI 配置界面</span></span><br><span class=\"line\">$ firefox &amp;</span><br><span class=\"line\"><span class=\"comment\"># 第二步：使用 Web UI 配置 Quay</span></span><br><span class=\"line\">$ ./kani deploy-quay</span><br><span class=\"line\"><span class=\"comment\"># 第三步：部署 Quay</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>可通过 <a href=\"https://alberthua-perl.github.io/2022/12/05/redhat-quay-v3-registry/\">Red Hat Quay v3 registry 原理与实现</a> 文档了解如何通过 Web UI 配置 Quay。</p>\n</li>\n<li><p>配置 Kubernetes 集群连接 Quay 与拉取镜像：    </p>\n<ul>\n<li><p>若在集群规划时需将 Quay 与 Kubernetes 集群连接的话，需在运行 kani 命令前更改好 <code>files/containerd/config.toml</code> 文件，以保证集群部署完成后可与 Quay 对接。<br>其中 <code>username</code> 与 <code>password</code> 为 Quay 中的登录用户名与密码，如下所示：      </p>\n<figure class=\"highlight ini\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry]</span></span><br><span class=\"line\">      config_path = \"\"</span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.auths]</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.configs]</span></span><br><span class=\"line\">        <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"quay-registry.lab.example.com\".tls]</span></span><br><span class=\"line\">          insecure_skip_verify = true</span><br><span class=\"line\">          <span class=\"comment\"># 使用自签名 CA 证书也需配置为 true</span></span><br><span class=\"line\">        <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.configs.\"quay-registry.lab.example.com\".auth]</span></span><br><span class=\"line\">          username = \"godev\"</span><br><span class=\"line\">          password = \"redhat321\"</span><br><span class=\"line\">          <span class=\"comment\"># Quay 中需配置的用户名与密码         </span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.headers]</span></span><br><span class=\"line\"></span><br><span class=\"line\">      <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors]</span></span><br><span class=\"line\">      <span class=\"comment\">### modified by hualf to configure registry mirror</span></span><br><span class=\"line\">        <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"docker.io\"]</span></span><br><span class=\"line\">          endpoint = [\"https://bqr1dr1n.mirror.aliyuncs.com\"]</span><br><span class=\"line\">        <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"k8s.gcr.io\"]</span></span><br><span class=\"line\">          endpoint = [\"https://registry.aliyuncs.com/k8sxio\"]</span><br><span class=\"line\">        <span class=\"section\">[plugins.\"io.containerd.grpc.v1.cri\".registry.mirrors.\"quay-registry.lab.example.com\"]</span></span><br><span class=\"line\">          endpoint = [\"https://quay-registry.lab.example.com\"]</span><br><span class=\"line\">          <span class=\"comment\"># 内部私有的容器镜像仓库</span></span><br><span class=\"line\">        <span class=\"comment\"># containerd 守护进程可访问的公共与私有容器镜像仓库</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>若在 Kubernetes 集群部署完成后再与 Quay 集成，需更改每个运行 Containerd 节点的配置文件，再重启每个节点上的 containerd 守护进程，才能保证与 Quay 的对接。   </p>\n</li>\n<li>在笔者的环境中，containerd 配置文件中已配置了 <code>godev</code> 用户与相应密码用于连接 Quay 与拉取镜像，因此，在 Quay 中需创建对应的用户。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://kubernetes.io/zh/docs/setup/production-environment/tools/kubespray/\" target=\"_blank\" rel=\"noopener\">Kubernetes Docs - 使用 Kubespray 安装 Kubernetes</a></li>\n<li><a href=\"https://v1-22.docs.kubernetes.io/docs/setup/production-environment/tools/kubeadm/\" target=\"_blank\" rel=\"noopener\">Kubernetes Docs - Bootstrapping clusters with kubeadm</a></li>\n<li><a href=\"https://projectcalico.docs.tigera.io/getting-started/kubernetes/self-managed-onprem/onpremises\" target=\"_blank\" rel=\"noopener\">Install Calico</a></li>\n</ul>\n"},{"title":"部署 loganalyzer 管理集中式日志","subtitle":"Deploy loganalyzer to Manage Centralized Logs","header-img":"hello-world-dark-bg.jpg","date":"2022-12-05T08:12:20.000Z","_content":"\n### 文档说明：\n- OS 版本：Red Hat Enterprise Linux 8.2 (Ootpa)\n- Podman 版本：podman-1.9.3-2.module+el8.2.1+6867+366c07d6.x86_64\n- loganalyzer 版本：loganalyzer-4.1.11.tar.gz\n- 该示例中使用 yum 安装的软件包若未指定特定版本均为系统自带软件包。\n\n### 架构示例：\n![loganalyzer-mysql-rsyslogserver.jpg](loganalyzer-mysql-rsyslogserver.jpg)\n如图所示，`rsyslog-server` 服务端收集来自 `rsyslog-client` 客户端发送的指定系统日志数据，并且 Apache httpd server 与 MySQL 数据库均以容器的方式一同部署于服务端。\n\n### loganalyzer 与 MySQL 的容器化部署要点：\n- 部署用 `Shell` 脚本可参考 [此链接](https://github.com/Alberthua-Perl/scripts-confs/blob/master/deploy-rsyslog-viewer/deploy-rsyslog-viewer.sh)。\n- 部署用节点：\n  - serverb.lab.example.com (RH294v8.0 course)：2 vCPU，4GiB RAM\n  - firewalld 服务已禁用   \n  - SELinux 为 enforcing 模式   \n- 此次使用 **`podman runtime`** 容器运行时运行所有容器。\n- 该部署环境中已预配置 `Red Hat Quay 3.3.0`，并且已将 `mysql-57-rhel7:latest` 上传至该容器镜像仓库中的 `rhscl organization` 中。\n- 将容器镜像上传至 Quay 中，需提前创建相应的 organizaion，否则将上传失败报错！\n  ![quay-push-error-1..jpg](quay-push-error-1.jpg)![quay-push-error-2.jpg](quay-push-error-2.jpg)\n- 务必关闭并禁用节点 `firewalld` 服务，该服务与 `iptables NAT` 规则冲突，在启用的情况下将无法实现容器的端口映射，iptables NAT 规则无法建立！\n- 由于 loganalyzer 容器与 MySQL 容器均位于同一节点上，且容器通过 `CNI bridge` (cni-podman0) 连接，因此 loganalyzer 连接 MySQL 时应使用节点的 IP 地址，但 MySQL 对指定用户的授权语句应使用 `CNI Gateway` 的 IP 地址，否则在前端 Web 上无法建立连接。\n   ```sql\n   grant all on Syslog.* to '${SYSLOG_USER}'@'${CNI_GATEWAY}' identified by '${SYSLOG_PASS}';\n   ```\n- loganalyzer 容器镜像基于 `Apache httpd server` 构建，可参考 [此链接](https://github.com/Alberthua-Perl/Dockerfile-examples/tree/master/loganalyzer-viewer)。\n- loganalyzer 项目基于 PHP，可作为 MySQL 数据库检索日志数据的 Web 前端。\n- MySQL 容器使用持久化存储（卷映射）时，由于使用 Red Hat 官方镜像，启动容器时不使用 root 用户运行 mysql 守护进程，而使用 **UID 27** (mysql) 运行，需设置宿主机映射目录的所有者与所属组，不更改将无法运行容器。    \n- 容器中报错日志如下所示：![mysql-container-run-error.jpg](mysql-container-run-error.jpg)\n- loganalyzer 容器与 MySQL 容器部署成功且正常运行后，需访问 loganalyzer 容器所在节点以完成两者的对接，如下所示：![loganalyzer-web-1.jpg](loganalyzer-web-1.jpg)![loganalyzer-web-2.jpg](loganalyzer-web-2.jpg)![loganalyzer-web-3.jpg](loganalyzer-web-3.jpg)![loganalyzer-web-4.jpg](loganalyzer-web-4.jpg)![loganalyzer-web-5.jpg](loganalyzer-web-5.jpg)![loganalyzer-web-6.jpg](loganalyzer-web-6.jpg)![loganalyzer-web-7.jpg](loganalyzer-web-7.jpg)![loganalyzer-web-8.jpg](loganalyzer-web-8.jpg)![loganalyzer-web-9.jpg](loganalyzer-web-9.jpg)![loganalyzer-web-10.jpg](loganalyzer-web-10.jpg)\n\n### loganalyzer 的常规部署要点：\n- loganalyzer 也可直接使用解压的压缩包（PHP 源码）实现安装，方法位于部署脚本的最后注释部分。\n- SELinux 为 `enforcing` 模式时，loganalyzer 无法与 MySQL 容器连接，需打开 PHP 与 MySQL的网络连接布尔值以支持。![selinux-php-mysql-connection.jpg](selinux-php-mysql-connection.jpg)\n","source":"_posts/loganalyzer-rsyslog-mysql.md","raw":"---\ntitle: 部署 loganalyzer 管理集中式日志\nsubtitle: Deploy loganalyzer to Manage Centralized Logs\nheader-img: hello-world-dark-bg.jpg \ndate: 2022-12-05 16:12:20\ntags:\n  - Linux\n  - 容器\n---\n\n### 文档说明：\n- OS 版本：Red Hat Enterprise Linux 8.2 (Ootpa)\n- Podman 版本：podman-1.9.3-2.module+el8.2.1+6867+366c07d6.x86_64\n- loganalyzer 版本：loganalyzer-4.1.11.tar.gz\n- 该示例中使用 yum 安装的软件包若未指定特定版本均为系统自带软件包。\n\n### 架构示例：\n![loganalyzer-mysql-rsyslogserver.jpg](loganalyzer-mysql-rsyslogserver.jpg)\n如图所示，`rsyslog-server` 服务端收集来自 `rsyslog-client` 客户端发送的指定系统日志数据，并且 Apache httpd server 与 MySQL 数据库均以容器的方式一同部署于服务端。\n\n### loganalyzer 与 MySQL 的容器化部署要点：\n- 部署用 `Shell` 脚本可参考 [此链接](https://github.com/Alberthua-Perl/scripts-confs/blob/master/deploy-rsyslog-viewer/deploy-rsyslog-viewer.sh)。\n- 部署用节点：\n  - serverb.lab.example.com (RH294v8.0 course)：2 vCPU，4GiB RAM\n  - firewalld 服务已禁用   \n  - SELinux 为 enforcing 模式   \n- 此次使用 **`podman runtime`** 容器运行时运行所有容器。\n- 该部署环境中已预配置 `Red Hat Quay 3.3.0`，并且已将 `mysql-57-rhel7:latest` 上传至该容器镜像仓库中的 `rhscl organization` 中。\n- 将容器镜像上传至 Quay 中，需提前创建相应的 organizaion，否则将上传失败报错！\n  ![quay-push-error-1..jpg](quay-push-error-1.jpg)![quay-push-error-2.jpg](quay-push-error-2.jpg)\n- 务必关闭并禁用节点 `firewalld` 服务，该服务与 `iptables NAT` 规则冲突，在启用的情况下将无法实现容器的端口映射，iptables NAT 规则无法建立！\n- 由于 loganalyzer 容器与 MySQL 容器均位于同一节点上，且容器通过 `CNI bridge` (cni-podman0) 连接，因此 loganalyzer 连接 MySQL 时应使用节点的 IP 地址，但 MySQL 对指定用户的授权语句应使用 `CNI Gateway` 的 IP 地址，否则在前端 Web 上无法建立连接。\n   ```sql\n   grant all on Syslog.* to '${SYSLOG_USER}'@'${CNI_GATEWAY}' identified by '${SYSLOG_PASS}';\n   ```\n- loganalyzer 容器镜像基于 `Apache httpd server` 构建，可参考 [此链接](https://github.com/Alberthua-Perl/Dockerfile-examples/tree/master/loganalyzer-viewer)。\n- loganalyzer 项目基于 PHP，可作为 MySQL 数据库检索日志数据的 Web 前端。\n- MySQL 容器使用持久化存储（卷映射）时，由于使用 Red Hat 官方镜像，启动容器时不使用 root 用户运行 mysql 守护进程，而使用 **UID 27** (mysql) 运行，需设置宿主机映射目录的所有者与所属组，不更改将无法运行容器。    \n- 容器中报错日志如下所示：![mysql-container-run-error.jpg](mysql-container-run-error.jpg)\n- loganalyzer 容器与 MySQL 容器部署成功且正常运行后，需访问 loganalyzer 容器所在节点以完成两者的对接，如下所示：![loganalyzer-web-1.jpg](loganalyzer-web-1.jpg)![loganalyzer-web-2.jpg](loganalyzer-web-2.jpg)![loganalyzer-web-3.jpg](loganalyzer-web-3.jpg)![loganalyzer-web-4.jpg](loganalyzer-web-4.jpg)![loganalyzer-web-5.jpg](loganalyzer-web-5.jpg)![loganalyzer-web-6.jpg](loganalyzer-web-6.jpg)![loganalyzer-web-7.jpg](loganalyzer-web-7.jpg)![loganalyzer-web-8.jpg](loganalyzer-web-8.jpg)![loganalyzer-web-9.jpg](loganalyzer-web-9.jpg)![loganalyzer-web-10.jpg](loganalyzer-web-10.jpg)\n\n### loganalyzer 的常规部署要点：\n- loganalyzer 也可直接使用解压的压缩包（PHP 源码）实现安装，方法位于部署脚本的最后注释部分。\n- SELinux 为 `enforcing` 模式时，loganalyzer 无法与 MySQL 容器连接，需打开 PHP 与 MySQL的网络连接布尔值以支持。![selinux-php-mysql-connection.jpg](selinux-php-mysql-connection.jpg)\n","slug":"loganalyzer-rsyslog-mysql","published":1,"updated":"2022-12-05T08:59:29.210Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldfonoll000e16vdvqcp5vmt","content":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li>OS 版本：Red Hat Enterprise Linux 8.2 (Ootpa)</li>\n<li>Podman 版本：podman-1.9.3-2.module+el8.2.1+6867+366c07d6.x86_64</li>\n<li>loganalyzer 版本：loganalyzer-4.1.11.tar.gz</li>\n<li>该示例中使用 yum 安装的软件包若未指定特定版本均为系统自带软件包。</li>\n</ul>\n<h3 id=\"架构示例：\"><a href=\"#架构示例：\" class=\"headerlink\" title=\"架构示例：\"></a>架构示例：</h3><p><img src=\"loganalyzer-mysql-rsyslogserver.jpg\" alt=\"loganalyzer-mysql-rsyslogserver.jpg\"><br>如图所示，<code>rsyslog-server</code> 服务端收集来自 <code>rsyslog-client</code> 客户端发送的指定系统日志数据，并且 Apache httpd server 与 MySQL 数据库均以容器的方式一同部署于服务端。</p>\n<h3 id=\"loganalyzer-与-MySQL-的容器化部署要点：\"><a href=\"#loganalyzer-与-MySQL-的容器化部署要点：\" class=\"headerlink\" title=\"loganalyzer 与 MySQL 的容器化部署要点：\"></a>loganalyzer 与 MySQL 的容器化部署要点：</h3><ul>\n<li>部署用 <code>Shell</code> 脚本可参考 <a href=\"https://github.com/Alberthua-Perl/scripts-confs/blob/master/deploy-rsyslog-viewer/deploy-rsyslog-viewer.sh\" target=\"_blank\" rel=\"noopener\">此链接</a>。</li>\n<li>部署用节点：<ul>\n<li>serverb.lab.example.com (RH294v8.0 course)：2 vCPU，4GiB RAM</li>\n<li>firewalld 服务已禁用   </li>\n<li>SELinux 为 enforcing 模式   </li>\n</ul>\n</li>\n<li>此次使用 <strong><code>podman runtime</code></strong> 容器运行时运行所有容器。</li>\n<li>该部署环境中已预配置 <code>Red Hat Quay 3.3.0</code>，并且已将 <code>mysql-57-rhel7:latest</code> 上传至该容器镜像仓库中的 <code>rhscl organization</code> 中。</li>\n<li>将容器镜像上传至 Quay 中，需提前创建相应的 organizaion，否则将上传失败报错！<br><img src=\"quay-push-error-1.jpg\" alt=\"quay-push-error-1..jpg\"><img src=\"quay-push-error-2.jpg\" alt=\"quay-push-error-2.jpg\"></li>\n<li>务必关闭并禁用节点 <code>firewalld</code> 服务，该服务与 <code>iptables NAT</code> 规则冲突，在启用的情况下将无法实现容器的端口映射，iptables NAT 规则无法建立！</li>\n<li><p>由于 loganalyzer 容器与 MySQL 容器均位于同一节点上，且容器通过 <code>CNI bridge</code> (cni-podman0) 连接，因此 loganalyzer 连接 MySQL 时应使用节点的 IP 地址，但 MySQL 对指定用户的授权语句应使用 <code>CNI Gateway</code> 的 IP 地址，否则在前端 Web 上无法建立连接。</p>\n <figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">grant</span> <span class=\"keyword\">all</span> <span class=\"keyword\">on</span> Syslog.* <span class=\"keyword\">to</span> <span class=\"string\">'$&#123;SYSLOG_USER&#125;'</span>@<span class=\"string\">'$&#123;CNI_GATEWAY&#125;'</span> <span class=\"keyword\">identified</span> <span class=\"keyword\">by</span> <span class=\"string\">'$&#123;SYSLOG_PASS&#125;'</span>;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>loganalyzer 容器镜像基于 <code>Apache httpd server</code> 构建，可参考 <a href=\"https://github.com/Alberthua-Perl/Dockerfile-examples/tree/master/loganalyzer-viewer\" target=\"_blank\" rel=\"noopener\">此链接</a>。</p>\n</li>\n<li>loganalyzer 项目基于 PHP，可作为 MySQL 数据库检索日志数据的 Web 前端。</li>\n<li>MySQL 容器使用持久化存储（卷映射）时，由于使用 Red Hat 官方镜像，启动容器时不使用 root 用户运行 mysql 守护进程，而使用 <strong>UID 27</strong> (mysql) 运行，需设置宿主机映射目录的所有者与所属组，不更改将无法运行容器。    </li>\n<li>容器中报错日志如下所示：<img src=\"mysql-container-run-error.jpg\" alt=\"mysql-container-run-error.jpg\"></li>\n<li>loganalyzer 容器与 MySQL 容器部署成功且正常运行后，需访问 loganalyzer 容器所在节点以完成两者的对接，如下所示：<img src=\"loganalyzer-web-1.jpg\" alt=\"loganalyzer-web-1.jpg\"><img src=\"loganalyzer-web-2.jpg\" alt=\"loganalyzer-web-2.jpg\"><img src=\"loganalyzer-web-3.jpg\" alt=\"loganalyzer-web-3.jpg\"><img src=\"loganalyzer-web-4.jpg\" alt=\"loganalyzer-web-4.jpg\"><img src=\"loganalyzer-web-5.jpg\" alt=\"loganalyzer-web-5.jpg\"><img src=\"loganalyzer-web-6.jpg\" alt=\"loganalyzer-web-6.jpg\"><img src=\"loganalyzer-web-7.jpg\" alt=\"loganalyzer-web-7.jpg\"><img src=\"loganalyzer-web-8.jpg\" alt=\"loganalyzer-web-8.jpg\"><img src=\"loganalyzer-web-9.jpg\" alt=\"loganalyzer-web-9.jpg\"><img src=\"loganalyzer-web-10.jpg\" alt=\"loganalyzer-web-10.jpg\"></li>\n</ul>\n<h3 id=\"loganalyzer-的常规部署要点：\"><a href=\"#loganalyzer-的常规部署要点：\" class=\"headerlink\" title=\"loganalyzer 的常规部署要点：\"></a>loganalyzer 的常规部署要点：</h3><ul>\n<li>loganalyzer 也可直接使用解压的压缩包（PHP 源码）实现安装，方法位于部署脚本的最后注释部分。</li>\n<li>SELinux 为 <code>enforcing</code> 模式时，loganalyzer 无法与 MySQL 容器连接，需打开 PHP 与 MySQL的网络连接布尔值以支持。<img src=\"selinux-php-mysql-connection.jpg\" alt=\"selinux-php-mysql-connection.jpg\"></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li>OS 版本：Red Hat Enterprise Linux 8.2 (Ootpa)</li>\n<li>Podman 版本：podman-1.9.3-2.module+el8.2.1+6867+366c07d6.x86_64</li>\n<li>loganalyzer 版本：loganalyzer-4.1.11.tar.gz</li>\n<li>该示例中使用 yum 安装的软件包若未指定特定版本均为系统自带软件包。</li>\n</ul>\n<h3 id=\"架构示例：\"><a href=\"#架构示例：\" class=\"headerlink\" title=\"架构示例：\"></a>架构示例：</h3><p><img src=\"loganalyzer-mysql-rsyslogserver.jpg\" alt=\"loganalyzer-mysql-rsyslogserver.jpg\"><br>如图所示，<code>rsyslog-server</code> 服务端收集来自 <code>rsyslog-client</code> 客户端发送的指定系统日志数据，并且 Apache httpd server 与 MySQL 数据库均以容器的方式一同部署于服务端。</p>\n<h3 id=\"loganalyzer-与-MySQL-的容器化部署要点：\"><a href=\"#loganalyzer-与-MySQL-的容器化部署要点：\" class=\"headerlink\" title=\"loganalyzer 与 MySQL 的容器化部署要点：\"></a>loganalyzer 与 MySQL 的容器化部署要点：</h3><ul>\n<li>部署用 <code>Shell</code> 脚本可参考 <a href=\"https://github.com/Alberthua-Perl/scripts-confs/blob/master/deploy-rsyslog-viewer/deploy-rsyslog-viewer.sh\" target=\"_blank\" rel=\"noopener\">此链接</a>。</li>\n<li>部署用节点：<ul>\n<li>serverb.lab.example.com (RH294v8.0 course)：2 vCPU，4GiB RAM</li>\n<li>firewalld 服务已禁用   </li>\n<li>SELinux 为 enforcing 模式   </li>\n</ul>\n</li>\n<li>此次使用 <strong><code>podman runtime</code></strong> 容器运行时运行所有容器。</li>\n<li>该部署环境中已预配置 <code>Red Hat Quay 3.3.0</code>，并且已将 <code>mysql-57-rhel7:latest</code> 上传至该容器镜像仓库中的 <code>rhscl organization</code> 中。</li>\n<li>将容器镜像上传至 Quay 中，需提前创建相应的 organizaion，否则将上传失败报错！<br><img src=\"quay-push-error-1.jpg\" alt=\"quay-push-error-1..jpg\"><img src=\"quay-push-error-2.jpg\" alt=\"quay-push-error-2.jpg\"></li>\n<li>务必关闭并禁用节点 <code>firewalld</code> 服务，该服务与 <code>iptables NAT</code> 规则冲突，在启用的情况下将无法实现容器的端口映射，iptables NAT 规则无法建立！</li>\n<li><p>由于 loganalyzer 容器与 MySQL 容器均位于同一节点上，且容器通过 <code>CNI bridge</code> (cni-podman0) 连接，因此 loganalyzer 连接 MySQL 时应使用节点的 IP 地址，但 MySQL 对指定用户的授权语句应使用 <code>CNI Gateway</code> 的 IP 地址，否则在前端 Web 上无法建立连接。</p>\n <figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">grant</span> <span class=\"keyword\">all</span> <span class=\"keyword\">on</span> Syslog.* <span class=\"keyword\">to</span> <span class=\"string\">'$&#123;SYSLOG_USER&#125;'</span>@<span class=\"string\">'$&#123;CNI_GATEWAY&#125;'</span> <span class=\"keyword\">identified</span> <span class=\"keyword\">by</span> <span class=\"string\">'$&#123;SYSLOG_PASS&#125;'</span>;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>loganalyzer 容器镜像基于 <code>Apache httpd server</code> 构建，可参考 <a href=\"https://github.com/Alberthua-Perl/Dockerfile-examples/tree/master/loganalyzer-viewer\" target=\"_blank\" rel=\"noopener\">此链接</a>。</p>\n</li>\n<li>loganalyzer 项目基于 PHP，可作为 MySQL 数据库检索日志数据的 Web 前端。</li>\n<li>MySQL 容器使用持久化存储（卷映射）时，由于使用 Red Hat 官方镜像，启动容器时不使用 root 用户运行 mysql 守护进程，而使用 <strong>UID 27</strong> (mysql) 运行，需设置宿主机映射目录的所有者与所属组，不更改将无法运行容器。    </li>\n<li>容器中报错日志如下所示：<img src=\"mysql-container-run-error.jpg\" alt=\"mysql-container-run-error.jpg\"></li>\n<li>loganalyzer 容器与 MySQL 容器部署成功且正常运行后，需访问 loganalyzer 容器所在节点以完成两者的对接，如下所示：<img src=\"loganalyzer-web-1.jpg\" alt=\"loganalyzer-web-1.jpg\"><img src=\"loganalyzer-web-2.jpg\" alt=\"loganalyzer-web-2.jpg\"><img src=\"loganalyzer-web-3.jpg\" alt=\"loganalyzer-web-3.jpg\"><img src=\"loganalyzer-web-4.jpg\" alt=\"loganalyzer-web-4.jpg\"><img src=\"loganalyzer-web-5.jpg\" alt=\"loganalyzer-web-5.jpg\"><img src=\"loganalyzer-web-6.jpg\" alt=\"loganalyzer-web-6.jpg\"><img src=\"loganalyzer-web-7.jpg\" alt=\"loganalyzer-web-7.jpg\"><img src=\"loganalyzer-web-8.jpg\" alt=\"loganalyzer-web-8.jpg\"><img src=\"loganalyzer-web-9.jpg\" alt=\"loganalyzer-web-9.jpg\"><img src=\"loganalyzer-web-10.jpg\" alt=\"loganalyzer-web-10.jpg\"></li>\n</ul>\n<h3 id=\"loganalyzer-的常规部署要点：\"><a href=\"#loganalyzer-的常规部署要点：\" class=\"headerlink\" title=\"loganalyzer 的常规部署要点：\"></a>loganalyzer 的常规部署要点：</h3><ul>\n<li>loganalyzer 也可直接使用解压的压缩包（PHP 源码）实现安装，方法位于部署脚本的最后注释部分。</li>\n<li>SELinux 为 <code>enforcing</code> 模式时，loganalyzer 无法与 MySQL 容器连接，需打开 PHP 与 MySQL的网络连接布尔值以支持。<img src=\"selinux-php-mysql-connection.jpg\" alt=\"selinux-php-mysql-connection.jpg\"></li>\n</ul>\n"},{"title":"Podman 容器原理与使用（1）","subtitle":"Podman Architecture and Usage (1)","header-img":"podman-bg.webp","date":"2022-12-05T05:01:29.000Z","_content":"\n### 文档说明：\n- 实验用 OS 版本：  \n  - CentOS 7.9、RHEL 8.0、RHEL 8.2、Ubuntu 20.04.3 LTS\n- 实验用 kernel 版本：  \n  - 3.10.0-1160.41.1.el7.x86_64  \n  - 4.18.0-193.el8.x86_64  \n  - 5.14.0-1.el7.elrepo.x86_64\n- 实验用 Podman 版本：1.6.4、3.2.3、3.3.1\n- 实验用 podman-compose 版本：0.1.8\n- 实验用 Docker 版本：20.10.8\n- 若未做特殊说明，以下示例均于 `RHEL 8.2`（`4.18.0-193.el8.x86_64`）上执行，Podman 版本为 `3.2.3`。\n- 该文档中未涉及 podman 命令的基础使用方法，可参阅 [该文档](https://mp.weixin.qq.com/s/MDi4RB5V60EGl3ii9usD0Q) 加以熟悉。\n- 💥 重要提示：Podman 项目正在不断演进与完善中，请以自身使用的版本为准进行测试与使用！\n\n### 文档目录：\n- Podman 的特性概述\n- Podman 版本兼容性比较\n- Podman 的扩展功能\n- Podman 在不同 OS 版本中的安装\n- Docker 与 Podman 进程管理方式比较\n- Podman 的网络实现原理（rootfull 与 rootless）\n- Podman 的 macvlan 网络实现\n- Podman rootless 容器用户映射实现方式\n- 参考链接\n\n### Podman 的特性概述：\n- LXC、`LXD`（Go 语言开发）、`systemd-nspawn` 均可作为 Linux 容器，但缺少容器跨主机运行与应用打包的能力。\n- Docker 与 Podman 可使用容器镜像实现应用打包发布，快速且轻量。\n- Docker 与 Podman 都使用 `runC`（Go 语言开发）作为底层 `oci-runtime`。\n- Docker 与 Podman 都支持 `OCI Image Format`（Go 语言开发），都能使用 DockerHub 上的容器镜像，而 systemd-nspawn 无法使用它们的镜像。\n- 👉 Podman 使用 `CNI`（Go 语言开发）作为 rootfull 容器网络底层，实现比 Docker 网络层略微简单但原理相同。\n- 相对于 LXD 与 systemd-nspawn，CNI 可以避免编写大量的网络规则。\n- 🚀 为了实现普通用户 rootless 容器网络，Podman 可以使用 `slirp4netns` 程序，避免 `kernel space` 中的大量 `veth pair` 虚拟接口的出现, 并且性能更好。\n- Docker 运行容器必须使用守护进程且使用 root 权限，存在系统安全问题，而 Podman 针对此问题使用以下两个特性加以解决，如下所示：  \n  - Podman 支持无守护进程（`no-daemon`）运行容器。  \n  - Podman 支持普通用户运行 `rootless` 容器，即，普通用户直接运行容器无需提权具有 root 权限。\n- 虽然 Docker 与 Podman 的实现原理不同，但对于使用者而言其 CLI 十分相似，可平滑地从 Docker 过渡至 Podman。\n- Podman 的目标不是容器的编排，编排可以使用更加专业的 Kubernetes、Open Shift、Rancher 等，使用 Podman 可以更轻量的运行容器且不受 root 权限的安全问题，即便是 root 用户也无法查看其它普通用户空间下的容器，Podman 通过 `user namespace` 进行隔离。\n- 👉 Podman 可使用 `systemd service` 单元文件直接管理容器，实现容器服务随系统启动而启动。\n- 👉 Podman 里集成了 `CRIU`，因此 Podman 中的容器可以在单机上热迁移。\n- 由于 Kubernetes 将从 `v1.24.x` 版本后放弃使用 `dockershim` 接口层，容器运行时可选择使用 `Containerd` 或者 `CRI-O`，两者虽然均支持 OCI image 规范，但它们不是面向使用者或开发者直接管理容器或镜像的工具，而 Podman 可直接面向使用者或开发者操作容器或镜像。\n- Podman 命令的子进程创建 pod 与容器。\n\n### Podman 版本兼容性比较：\n- Podman 版本、kernel 版本与 OS 版本的兼容性将直接影响普通用户使用 rootless 容器。\n- 如下所示，kernel 不支持 rootless 容器：  \n  ![centos79-kernel-not-support-podman-rootless.jpg](centos79-kernel-not-support-podman-rootless.jpg)\n\n- 普通用户 rootless 容器兼容性比较：\n  ![podman-version-compare.png](podman-version-compare.png)\n\n  > 📌**注意：**\n  > \n  > rootless 容器特性取决于 kernel 的版本，不取决于 OS 与 Podman 的版本。\n\n  - 由于 `user namespace` 特性在 kernel `4.9.0` 之后出现，因此升级 kernel 即可解决 rootless 问题。\n  - 关于 rootless 特性在 RHEL 8 中的设置，可 [点击此处](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/building_running_and_managing_containers/assembly_starting-with-containers_building-running-and-managing-containers#proc_setting-up-rootless-containers_assembly_starting-with-containers) 参考 Red Hat 的官方配置说明。\n\n### Podman 的扩展功能：\n- `cockpit-podman` 软件包作为 cockpit 插件可集成于 `Web UI` 中，实现 Web UI 管理容器。  \n  - cockpit-podman 服务安装与启用：    \n    ```bash\n    $ sudo yum install -y cockpit-podman\n    $ sudo systemctl enable --now cockpit.socket\n    $ sudo systemctl status cockpit.service\n    # 安装 cockpit-podman 软件包，并启用 cockpit 服务。\n    $ sudo netstat -tunlp | grep 9090\n    # 查看 systemd 监听的 9090 端口是否启用\n    ```\n  - 在 Web UI 中可查看并管理 podman 容器与镜像：    \n    ![podman-arch-usage/cockpit-podman-1.jpg](cockpit-podman-1.jpg)![cockpit-podman-2.jpg](cockpit-podman-2.jpg)\n- `podman-compose` 旨在使用更轻量的方式实现`单机容器编排`，以用于替换 `docker-compose`，这种方式将不再依赖守护进程与 root 权限，同时可使用 rootless 容器，详细示例见下文。\n- podman-compose 使用 `Python` 开发，因此可直接使用 `pip3` 安装该组件，或使用 rpm 软件包方式安装。\n- 由于 podman-compose 依然处于 `dev` 阶段，仅作为功能测试使用，暂未受到 GA 环境支持。\n\n### Podman 在不同 OS 版本中的安装：\n- CentOS 7.x/8.x 或 RHEL 7.x/8.x 中：yum 命令使用 podman `rpm` 软件包安装  \n  ```bash\n  $ sudo yum install -y podman-3.2.3-0.11.module_el8.4.0+942+d25aada8.x86_64\n  # 安装 podman 最新版本，低版本 podman 存在较多 bug。\n  # 注意：\n  #   1. 需配置 CentOS 8 的 yum 软件源以安装最新版的 podman 及其依赖软件包\n  #   2. yum 安装 podman 时也将安装 containernetworking-plugins 软件包\n  ```\n- 🤘 Ubuntu 20.04.2 LTS 中：apt-get 命令使用 podman `deb` 软件包安装  \n  ```bash\n$ . /etc/os-release\n# 查看当前的系统发行版\n$ echo \"deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_${VERSION_ID}/ /\" | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list\n$ curl -L \"https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_${VERSION_ID}/Release.key\" | sudo apt-key add -\n# 添加 podman 软件源与 apt 公钥\n$ sudo apt-get update -y\n$ sudo apt-get upgrade -y\n# 更新系统软件源并升级系统软件包\n$ sudo apt-get install -y podman\n  Reading package lists... Done\n  Building dependency tree       \n  Reading state information... Done\n  ...\n  The following NEW packages will be installed:\n    catatonit conmon containernetworking-plugins containers-common criu crun fuse-overlayfs fuse3 libfuse3-3 libnet1 libprotobuf-c1\n    podman podman-machine-cni podman-plugins\n  ...\n# 安装 podman 与相关的软件包，包括 conmon、containernetworking-plugins、crun 等。  \n  ```\n  安装参考链接：  \n  - [Podman Doc - installation](https://podman.io/getting-started/installation)\n  - [Easy to Install Podman on Ubuntu 20.04](https://www.hostnextra.com/kb/easy-to-install-podman-on-ubuntu-20-04/)\n  - [podman from devel:kubic:libcontainers:stable project](https://software.opensuse.org//download.html?project=devel%3Akubic%3Alibcontainers%3Astable&package=podman)\n\n### 🤘 Docker 与 Podman 进程管理方式比较：\n- Docker v20.10.8 使用 `dockerd` 与 `containerd` 守护进程管理容器与镜像的生命周期，运行状态如下所示： \n  ```bash\n  $ sudo systemctl status docker.service\n  ● docker.service - Docker Application Container Engine\n     Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled)\n     Active: active (running) since Wed 2022-10-19 10:53:04 CST; 6min ago\n       Docs: https://docs.docker.com\n   Main PID: 79556 (dockerd)\n      Tasks: 21\n     Memory: 42.6M\n     CGroup: /system.slice/docker.service\n             ├─79556 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock\n             ├─79677 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 4000 -container-ip 172.17.0.2 -container-port 4000\n             └─79683 /usr/bin/docker-proxy -proto tcp -host-ip :: -host-port 4000 -container-ip 172.17.0.2 -container-port 4000\n  \n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.197803867+08:00\" level=info msg=\"scheme \\\"unix\\\" not registered, fallback to default scheme\" module=grpc\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.197837924+08:00\" level=info msg=\"ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}\" module=grpc\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.197860326+08:00\" level=info msg=\"ClientConn switching balancer to \\\"pick_first\\\"\" module=grpc\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.220416627+08:00\" level=info msg=\"Loading containers: start.\"\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.347884960+08:00\" level=info msg=\"Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address\"\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.725361851+08:00\" level=info msg=\"Loading containers: done.\"\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.755449128+08:00\" level=info msg=\"Docker daemon\" commit=75249d8 graphdriver(s)=overlay2 version=20.10.8\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.755527994+08:00\" level=info msg=\"Daemon has completed initialization\"\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com systemd[1]: Started Docker Application Container Engine.\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.776865058+08:00\" level=info msg=\"API listen on /var/run/docker.sock\"\n  # dockerd 守护进程的运行状态\n  \n  $ sudo systemctl status containerd\n  ● containerd.service - containerd container runtime\n     Loaded: loaded (/usr/lib/systemd/system/containerd.service; enabled; vendor preset: disabled)\n     Active: active (running) since Tue 2022-10-18 15:08:06 CST; 20h ago\n       Docs: https://containerd.io\n   Main PID: 1892 (containerd)\n      Tasks: 20\n     Memory: 103.4M\n     CGroup: /system.slice/containerd.service\n             ├─ 1892 /usr/bin/containerd\n             └─79696 /usr/bin/containerd-shim-runc-v2 -namespace moby -id 3ea752c1cce6a65b39af7f68c971186e020992514b663ab7a917f47da70450fa -address /run/containerd/containerd.sock\n  # containerd 通过调用 containerd-shim-runc-v2 运行指定容器\n  $ sudo ps -ef | grep -E \"dockerd|containerd|containerd-shim-runc-v2\"\n    root       1892      1  0 Oct18 ?        00:05:01 /usr/bin/containerd\n    root      79556      1  0 10:53 ?        00:00:03 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock\n    root      79696      1  0 10:53 ?        00:00:01 /usr/bin/containerd-shim-runc-v2 -namespace moby -id 3ea752c1cce6a65b39af7f68c971186e020992514b663ab7a917f47da70450fa -address /run/containerd/containerd.sock\n  # PID 79696 为实际的容器运行进程\n  ```\n- Podman 不使用守护进程的方式运行或管理容器，对于 rootfull 容器或 rootless 容器的运行方式存在差异：  \n  - rootfull 容器的进程：    \n    👉 以交互式方式运行的容器进程状态如下所示：    \n    ```bash\n    $ sudo ps -ef | egrep \"podman|slirp4netns|conmon\"\n      root        3879    3476  1 06:31 pts/3    00:00:00 podman run -it --name=mydebian docker.io/library/debian:latest /bin/sh\n      root        3945       1  0 06:31 ?        00:00:00 /usr/bin/conmon --api-version 1 -c 29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba -u 29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba -r /usr/bin/crun -b /var/lib/containers/storage/overlay-containers/29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba/userdata -p /run/containers/storage/overlay-containers/29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba/userdata/pidfile -n mydebian --exit-dir /run/libpod/exits --full-attach -s -l journald --log-level warning --runtime-arg --log-format=json --runtime-arg --log --runtime-arg=/run/containers/storage/overlay-containers/29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba/userdata/oci-log -t --conmon-pidfile /run/containers/storage/overlay-containers/29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba/userdata/conmon.pid --exit-command /usr/bin/podman --exit-command-arg --root --exit-command-arg /var/lib/containers/storage --exit-command-arg --runroot --exit-command-arg /run/containers/storage --exit-command-arg --log-level --exit-command-arg warning --exit-command-arg --cgroup-manager --exit-command-arg systemd --exit-command-arg --tmpdir --exit-command-arg /run/libpod --exit-command-arg --network-config-dir --exit-command-arg  --exit-command-arg --network-backend --exit-command-arg cni --exit-command-arg --volumepath --exit-command-arg /var/lib/containers/storage/volumes --exit-command-arg --runtime --exit-command-arg crun --exit-command-arg --storage-driver --exit-command-arg overlay --exit-command-arg --storage-opt --exit-command-arg overlay.mountopt=nodev,metacopy=on --exit-command-arg --events-backend --exit-command-arg journald --exit-command-arg container --exit-command-arg cleanup --exit-command-arg 29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba\n    # 由于具有交互式命令行运行依然保留 podman 进程\n    ```\n    👉 以 `detach` 方式（后台）运行的容器进程状态如下所示：    \n    ```bash\n    $ sudo ps -ef | egrep \"podman|slirp4netns|conmon\"\n      root        3744       1  0 06:25 ?        00:00:00 /usr/bin/conmon --api-version 1 -c b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272 -u b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272 -r /usr/bin/crun -b /var/lib/containers/storage/overlay-containers/b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272/userdata -p /run/containers/storage/overlay-containers/b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272/userdata/pidfile -n apache-rhce8.2-alpine --exit-dir /run/libpod/exits --full-attach -s -l journald --log-level warning --runtime-arg --log-format=json --runtime-arg --log --runtime-arg=/run/containers/storage/overlay-containers/b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272/userdata/oci-log --conmon-pidfile /run/containers/storage/overlay-containers/b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272/userdata/conmon.pid --exit-command /usr/bin/podman --exit-command-arg --root --exit-command-arg /var/lib/containers/storage --exit-command-arg --runroot --exit-command-arg /run/containers/storage --exit-command-arg --log-level --exit-command-arg warning --exit-command-arg --cgroup-manager --exit-command-arg systemd --exit-command-arg --tmpdir --exit-command-arg /run/libpod --exit-command-arg --network-config-dir --exit-command-arg  --exit-command-arg --network-backend --exit-command-arg cni --exit-command-arg --volumepath --exit-command-arg /var/lib/containers/storage/volumes --exit-command-arg --runtime --exit-command-arg crun --exit-command-arg --storage-driver --exit-command-arg overlay --exit-command-arg --storage-opt --exit-command-arg overlay.mountopt=nodev,metacopy=on --exit-command-arg --events-backend --exit-command-arg journald --exit-command-arg container --exit-command-arg cleanup --exit-command-arg b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272\n    # podman 在调用 conmon 程序创建并运行容器后退出，而 rootfull 容器的 CNI 插件\n    # 可直接使用 iptables 的方式实现。\n    ```\n  - rootless 容器的进程：    \n    👉 以交互式方式运行的容器进程状态如下所示：\n    ```bash\n    $ ps -ef | egrep \"podman|slirp4netns|conmon\"\n      core        3418    2762  0 06:17 pts/2    00:00:05 podman run -it --name=mybusybox docker.io/library/busybox:latest /bin/sh\n      core        3430    3418  0 06:17 pts/2    00:00:00 /usr/bin/slirp4netns --disable-host-loopback --mtu=65520 --enable-sandbox --enable-seccomp --enable-ipv6 -c -e 3 -r 4 --netns-type=path /run/user/1000/netns/netns-19eb5630-c0a8-4ea9-8790-76ecdcdf2dbc tap0\n      core        3433       1  0 06:17 ?        00:00:00 /usr/bin/conmon --api-version 1 -c 5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160 -u 5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160 -r /usr/bin/crun -b /var/home/core/.local/share/containers/storage/overlay-containers/5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160/userdata -p /run/user/1000/containers/overlay-containers/5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160/userdata/pidfile -n mybusybox --exit-dir /run/user/1000/libpod/tmp/exits --full-attach -s -l journald --log-level warning --runtime-arg --log-format=json --runtime-arg --log --runtime-arg=/run/user/1000/containers/overlay-containers/5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160/userdata/oci-log -t --conmon-pidfile /run/user/1000/containers/overlay-containers/5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160/userdata/conmon.pid --exit-command /usr/bin/podman --exit-command-arg --root --exit-command-arg /var/home/core/.local/share/containers/storage --exit-command-arg --runroot --exit-command-arg /run/user/1000/containers --exit-command-arg --log-level --exit-command-arg warning --exit-command-arg --cgroup-manager --exit-command-arg systemd --exit-command-arg --tmpdir --exit-command-arg /run/user/1000/libpod/tmp --exit-command-arg --network-config-dir --exit-command-arg  --exit-command-arg --network-backend --exit-command-arg netavark --exit-command-arg --volumepath --exit-command-arg /var/home/core/.local/share/containers/storage/volumes --exit-command-arg --runtime --exit-command-arg crun --exit-command-arg --storage-driver --exit-command-arg overlay --exit-command-arg --events-backend --exit-command-arg journald --exit-command-arg container --exit-command-arg cleanup --exit-command-arg 5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160\n    # 由于具有交互式命令行运行依然保留 podman 进程，并且由 podman 进程创建 slirp4netns 子进程\n    # 用于 rootless 容器的网络命名空间之间的通信。\n    ``` \n    👉 以 `detach` 方式（后台）运行的容器进程状态如下所示：   \n    ```bash\n    $ ps -ef | egrep \"podman|slirp4netns|conmon\"\n      core        3308       1  0 06:15 pts/2    00:00:00 /usr/bin/slirp4netns --disable-host-loopback --mtu=65520 --enable-sandbox --enable-seccomp --enable-ipv6 -c -e 3 -r 4 --netns-type=path /run/user/1000/netns/netns-f9f6f9dd-bf80-f6ca-6f39-7c9d9cd6beea tap0\n      core        3325       1  0 06:15 ?        00:00:00 /usr/bin/conmon --api-version 1 -c 91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab -u 91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab -r /usr/bin/crun -b /var/home/core/.local/share/containers/storage/overlay-containers/91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab/userdata -p /run/user/1000/containers/overlay-containers/91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab/userdata/pidfile -n apache-rhce8.2-alpine --exit-dir /run/user/1000/libpod/tmp/exits --full-attach -s -l journald --log-level warning --runtime-arg --log-format=json --runtime-arg --log --runtime-arg=/run/user/1000/containers/overlay-containers/91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab/userdata/oci-log --conmon-pidfile /run/user/1000/containers/overlay-containers/91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab/userdata/conmon.pid --exit-command /usr/bin/podman --exit-command-arg --root --exit-command-arg /var/home/core/.local/share/containers/storage --exit-command-arg --runroot --exit-command-arg /run/user/1000/containers --exit-command-arg --log-level --exit-command-arg warning --exit-command-arg --cgroup-manager --exit-command-arg systemd --exit-command-arg --tmpdir --exit-command-arg /run/user/1000/libpod/tmp --exit-command-arg --network-config-dir --exit-command-arg  --exit-command-arg --network-backend --exit-command-arg netavark --exit-command-arg --volumepath --exit-command-arg /var/home/core/.local/share/containers/storage/volumes --exit-command-arg --runtime --exit-command-arg crun --exit-command-arg --storage-driver --exit-command-arg overlay --exit-command-arg --events-backend --exit-command-arg journald --exit-command-arg container --exit-command-arg cleanup --exit-command-arg 91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab\n    # podman 在调用 conmon 程序创建并运行容器后退出，并且由 podman 进程创建 slirp4netns 子进程\n    # 用于 rootless 容器的网络命名空间之间的通信。\n    ```\n\n### Podman 的网络实现原理（rootfull 与 rootless）：\n- Podman 支持的容器网络模式如下所示：  \n  ![podman-network-mode.jpg](podman-network-mode.jpg)\n- root 用户运行 rootfull 容器网络分析：  \n  - 默认情况下，rootfull 容器使用 bridge 网络模式，并且在未创建任何容器前系统上不会自动创建 `cni-podman0 `网桥，只有创建容器后自动生成。  \n  - root 用户使用全局范围内的 CNI 插件，podman 默认使用 `bridge`、`portmap` 插件，其配置文件如下：    \n    ```bash\n    $ cat /etc/cni/net.d/87-podman-bridge.conflist\n    {\n      \"cniVersion\": \"0.4.0\",\n      \"name\": \"podman\",\n      \"plugins\": [\n        {\n          \"type\": \"bridge\",\n          \"bridge\": \"cni-podman0\",\n          \"isGateway\": true,\n          \"ipMasq\": true,\n          \"hairpinMode\": true,\n          \"ipam\": {\n            \"type\": \"host-local\",\n            \"routes\": [{ \"dst\": \"0.0.0.0/0\" }],\n            \"ranges\": [\n              [\n                {\n                  \"subnet\": \"10.88.0.0/16\",\n                  \"gateway\": \"10.88.0.1\"\n                }\n              ]\n            ]\n          }\n        },\n        {\n          \"type\": \"portmap\",\n          \"capabilities\": {\n            \"portMappings\": true\n          }\n        },\n        {\n          \"type\": \"firewall\"\n        },\n        {\n          \"type\": \"tuning\"\n        }\n      ]\n    # 该配置文件位于 Podman 源码 cni/87-podman-bridge.conflist\n    # Podman 可调用 bridge、portmap 等 CNI 插件\n    \n    $ sudo podman inspect <container_name> | jq .[0].HostConfig.NetworkMode\n      \"bridge\"\n    # root 用户创建的容器网络模式\n    ```\n  - root 用户创建具有端口映射的容器时，iptables filter 表与 nat 表规则将相应增加：    \n    ```bash\n    # ----- filter 表中创建新容器后的新增规则 -----\n    *filter\n    -A FORWARD -m comment --comment \"CNI firewall plugin rules\" -j CNI-FORWARD\n    -A CNI-FORWARD -m comment --comment \"CNI firewall plugin admin overrides\" -j CNI-ADMIN\n    -A CNI-FORWARD -d 10.88.0.3/32 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT\n    # 新增规则：允许 3 层转发目标地址为 10.88.0.3 的流量（进入容器的流量），conntrack 模块进行连接状态追踪。\n    # 当容器通过 MASQUERADE 对外访问，回包再次进入容器宿主机时不再通过 DNAT 转发，而通过 conntrack \n    # 记录的连接状态直接转发至该规则并通过 cni-podman0 网桥进入容器。\n    -A CNI-FORWARD -s 10.88.0.3/32 -j ACCEPT\n    # 新增规则：允许 3 层转发源地址为 10.88.0.3 的流量（出容器的流量）。\n    \n    # ----- nat 表中创建新容器后的新增规则 -----\n    *nat\n    -A PREROUTING -m addrtype --dst-type LOCAL -j CNI-HOSTPORT-DNAT\n    -A POSTROUTING -m comment --comment \"CNI portfwd requiring masquerade\" -j CNI-HOSTPORT-MASQ\n    -A POSTROUTING -s 10.88.0.3/32 -m comment --comment \"name: \\\"podman\\\" id: \\\"2d2b3521457cb1d9b7ae6657304d05789a854e7a48916276a40da543df9aa217\\\"\" -j CNI-b6c5fb6c593e895d843cb5bd\n    # 新增规则：来自于 10.88.0.3 容器的流量转发至 CNI-b6c5fb6c593e895d843cb5bd 链\n    -A OUTPUT -m addrtype --dst-type LOCAL -j CNI-HOSTPORT-DNAT\n    # 启用 CNI 后即创建的规则，该规则接收来自本地应用的流量并转发至 CNI-HOSTPORT-DNAT 链\n    -A CNI-HOSTPORT-SETMARK -m comment --comment \"CNI portfwd masquerade mark\" -j MARK --set-xmark 0x2000/0x2000\n    -A CNI-HOSTPORT-MASQ -m mark --mark 0x2000/0x2000 -j MASQUERADE\n    ### 以下 6 条在创建新容器时同时创建 \n    -A CNI-HOSTPORT-DNAT -p tcp -m comment --comment \"dnat name: \\\"podman\\\" id: \\\"2d2b3521457cb1d9b7ae6657304d05789a854e7a48916276a40da543df9aa217\\\"\" -m multiport --dports 8843 -j CNI-DN-b6c5fb6c593e895d843cb\n    # 自定义 DNAT 链，发送至本地 8843 端口的流量转发至 CNI-DN-b6c5fb6c593e895d843cb 链。\n    -A CNI-b6c5fb6c593e895d843cb5bd -d 10.88.0.0/16 -m comment --comment \"name: \\\"podman\\\" id: \\\"2d2b3521457cb1d9b7ae6657304d05789a854e7a48916276a40da543df9aa217\\\"\" -j ACCEPT\n    # 允许转发目标网段为 10.88.0.0/16 的流量（进入容器的流量），该网段为容器所在的网络。\n    -A CNI-b6c5fb6c593e895d843cb5bd ! -d 224.0.0.0/4 -m comment --comment \"name: \\\"podman\\\" id: \\\"2d2b3521457cb1d9b7ae6657304d05789a854e7a48916276a40da543df9aa217\\\"\" -j MASQUERADE\n    # MASQUERADE 出容器流量\n    -A CNI-DN-b6c5fb6c593e895d843cb -s 10.88.0.0/16 -p tcp -m tcp --dport 8843 -j CNI-HOSTPORT-SETMARK\n    -A CNI-DN-b6c5fb6c593e895d843cb -s 127.0.0.1/32 -p tcp -m tcp --dport 8843 -j CNI-HOSTPORT-SETMARK\n    -A CNI-DN-b6c5fb6c593e895d843cb -p tcp -m tcp --dport 8843 -j DNAT --to-destination 10.88.0.3:443\n    # 自定义 DNAT 链实现容器宿主机至容器的端口映射\n    ```\n  - 🚀 示例：外部访问容器内 Web 服务时，涉及的宿主机 iptables：\n    ![external-access-container-web-service-iptables.jpg](external-access-container-web-service-iptables.jpg)从外部访问容器内 Web 服务时，流量将通过 PREROUTING 链及自定义链（`CNI-HOSTPORT-DNAT`、`CNI-DN-xxxx`、`DNAT`），经由 FORWARD 链及自定义链（`CNI-FORWARD`）的三层转发与 `cni-podman0` 网桥的二层转发进入容器，容器对外响应的流量将经过 cni-podman0 网桥转发，并经过 CNI-FORWARD 链与 POSTROUTING 链及自定义链（`CNI-HOSTPORT-MASQ`）出容器宿主机。  \n  - 🚀 示例：直接从容器内访问外部时，返回容器的回包将直接使用 conntrack 模块追踪的连接状态，流量通过 `CNI-FORWARD` 链的三层转发与 cni-podman0 的二层转发至容器中，即，回包进入容器宿主机不再通过`CNI-HOSTPORT-DNAT`链。    \n    如下所示，相关的 DNAT 链无流量通过（蓝框），CNI-FORWARD 链均有流量通过（蓝框）。    \n    ![container-access-external-iptables.jpg](container-access-external-iptables.jpg)\n    \n    > 📌 **Kubernetes 相关问题提示：**\n    > \n    > 1. 容器或 pod 通过 cni 网桥桥接的方式在 Kubernetes 或 OpenShift3 中需在计算节点（worker node）上配置 `net.bridge.bridge-nf-call-iptables` 与 `net.bridge.bridge-nf-call-iptables6` 内核参数，使 cni 二层网桥可调用 iptables 的 conntrack 模块，以解决前后端 pod 在同一节点上时，由于 pod 直连 cni 二层网桥，而二层网桥只实现二层转发，无法追踪前后端的连接状态，造成后端 pod 向前端 pod 回包时无法处于同一连接链路的问题，可 [点击此处](https://imroc.cc/k8s/faq/why-enable-bridge-nf-call-iptables/) 获得更多帮助。\n    > 2. 使用以上内核参数时，需加载 `br_netfilter` 内核模块方能生效。\n  \n  - 使用 `iperf3` 工具的容器测试不同 rootfull 容器之间的网络性能，如下所示：    \n    ![rootfull-container-to-container-bandwidth.jpg](rootfull-container-to-container-bandwidth.jpg)\n- 普通用户运行 rootless 容器网络分析：  \n  - `slirp4netns` 程序支持 user rootless network namespace，而非通过 `iptables` 与 CNI 实现。  \n  - 👉 普通用户使用端口映射运行 rootless 容器时，默认情况下只能使用宿主机 1024 以上的端口实现映射，但可使用 `net.ipv4.ip_unprivileged_port_start` 内核参数实现低于 1024 的端口开始映射，如下所示：    \n    ```bash\n### 方式 1：###\n$ sysctl -w net.ipv4.ip_unprivileged_port_start=80\n# 临时配置：允许普通用户从 80 端口开始的端口映射运行 rootless 容器\n    \n### 方式 2：###\n$ echo \"net.ipv4.ip_unprivileged_port_start=80\" >> /etc/sysctl.d/rootless.conf\n# 永久配置：将该内核参数写入内核参数配置文件，使其开机永久生效。\n$ sysctl -p\n# 使配置的内核参数生效\n\n - 普通用户创建的容器网络模式为 `slirp4netns`（slirp4netns 软件包实现）。    \n    ```bash\n    $ podman inspect <container_name> | jq .[0].HostConfig.NetworkMode\n      \"slirp4netns\"\n    # 普通用户创建的 rootless 容器网络模式\n    ```\n  - 每个普通用户运行 rootless 容器都将生成 slirp4netns 进程用于隔离该用户的 `network namespace`，以下分别使用 godev 与 hualf 用户运行 rootless 容器：    \n    ![godev-rootless-container.jpg](godev-rootless-container.jpg)![hualf-rootless-container.jpg](hualf-rootless-container.jpg) \n  - slirp4netns 实现的网络模式与带宽比较：    \n    ![rootless-slirp4netns-networking.jpg](rootless-slirp4netns-networking.jpg) \n  - 使用 `iperf3` 工具的容器测试不同 rootless 容器之间的网络性能，如下所示：\n    ![rootless-container-to-container-bandwidth.jpg](rootless-container-to-container-bandwidth.jpg)对比 rootfull 容器之间的网络性能来看，slirp4netns 实现的 rootless 容器在不同的网络命名空间内的通信性能损耗较大，而 rootfull 容器之间的网络性能相比前者在此次测试中高出近 5 倍。 \n  - 关于 slirp4netns 更加详细的内容，请参考 [Github 项目](https://github.com/rootless-containers/slirp4netns)。\n\n### Podman 的 macvlan 网络实现：\n- `macvlan` 作为 CNI 在 Kubernetes 与 OpenShift v4 中作为 `Multus CNI` 支持的额外插件类型使用愈加广泛，集群中除了常规使用的 Flannel、Calico 等作为 `slow path` 的插件外，要求高性能的业务流量可使用 macvlan 直连 pod 宿主机物理网口实现 `fast path`。\n- 为后续熟悉以上场景的实现，因此在 Podman `rootfull` 容器中使用 macvlan 网络模式。\n- 关于 macvlan 的基础知识可参考 [Linux 虚拟网卡技术：Macvlan](https://mp.weixin.qq.com/s?__biz=MzU1MzY4NzQ1OA==&mid=2247484064&idx=1&sn=ffd745069b6c4aeac0589de00467b2f2&chksm=fbee426dcc99cb7bdf26f5e6a21bbeaebba7ccd384a02f850d4461ea92331ed140edf98ffaec&mpshare=1&scene=1&srcid=03049MKwF55OVgEZ4OCH39wd&sharer_sharetime=1583337046541&sharer_shareid=8eaca72194dae7b3d51d5c708436eee4#rd) 与 [linux 网络虚拟化：macvlan](https://cizixs.com/2017/02/14/network-virtualization-macvlan/)\n- macvlan 特性由 `Linux kernel` 支持，笔者的实验环境满足 macvlan 的要求，请使用如下命令确定：  \n  ```bash\n  $ sudo lsmod | grep macvlan\n  # 若无任何返回，说明还未加载 macvlan 内核模块。\n  $ sudo modprobe macvlan\n  # 加载 macvlan 内核模块，若执行报错，说明 kernel 不支持该特性。\n  ```\n- podman 与 macvlan 类型网络的集成，如下所示：  \n  ```bash\n  $ sudo podman network create -d macvlan -o parent=ens33 <network_name>\n    /etc/cni/net.d/<network_name>.conflist\n  # 创建 macvlan 类型网络  \n  $ sudo podman network ls\n  $ sudo /opt/cni/bin/dhcp daemon\n  # 在另一个窗口中启动 dhcp 守护进程供 macvlan 插件调用，为容器网口分配 IP 地址。\n  $ sudo podman run -it --rm \\\n    --name <container_name> --network=<network_name> \\\n    <container_image>:<tag> /bin/sh\n  # 创建支持 macvlan 类型网络的 rootfull 容器  \n  ```\n- 从与 rootfull 容器在同一广播域的其他节点上 ping 该容器，可正常通信：  \n  ![podman-macvlan-network.png](podman-macvlan-network.png)\n  \n  > 🤔 以上示例的容器中运行 Web 服务（可暴露 443 端口），使用 macvlan 网络模式可打通与同一广播域中外部节点的通信，但无法访问其中的服务，可采取何种方法解决该问题？  \n\n### Podman rootless 容器用户映射实现方式：\n- Podman rootless 容器的实现核心在于解决 network namespace（NetNS） 与 user namespace（UserNS） 的问题，前文已介绍 NetNS 的实现方式，后文将介绍 UserNS 的实现方式。\n- 若要使用 rootless 容器，需确认 OS 是否开启 user namespace 功能：  \n  ```bash\n  $ sudo sysctl -a | grep user\\.max_user_namespaces\n    user.max_user_namespaces = 47494\n  ```\n- 系统上每创建一个用户就会在 `/etc/subuid` 与 `/etc/subgid` 中生成对应用户在其用户命名空间中的映射规则，以 /etc/subuid 为例，参数以冒号分隔，每个参数含义如下所示：  \n  - 第一个参数（uid）：用户名称  \n  - 第二个参数（loweruid）：用户命名空间中起始的映射 uid\n- 第三个参数（count）：用户命名空间内部与外部可映射 uid 数量（可理解为所有容器普通用户的 uid 数量和）  \n  ![rootless-user-namespace-mapping.jpg](rootless-user-namespace-mapping.jpg)\n- 以上两个文件允许运行进程的 uid 映射范围，在 `/proc/<pid>/uid_map` 中定义。\n- 可过滤容器 `conmon` 进程的 pid 确认每个容器中的 uid 映射情况，参见以下示例。\n- 关于以上两个文件的具体说明可参考 `newuidmap` 与 `newgidmap` 命令的 man 手册。\n- 可参考 Podman 官方推荐的命令创建 uid 的映射，如下所示：  \n  ```bash\n  $ sudo usermod --add-subuids 10000-75535 $(whoami)\n  \n  # ----- 示例 -----\n  $ sudo cat /etc/subuid\n    appuser:10000:500\n  $ sudo cat /etc/subgid\n    appuser:500:50\n  # 该用户创建的 user namespace 中可以使用从 10000 开始的 500 个 UID 和从 500 开始的 50 个 GID 的映射。\n  ```\n- 🚀 示例：  \n  普通用户 hualf 在 /etc/subuid 中映射为 hualf:165536:65536，说明在该用户的用户命名空间中可嵌套一个或多个用户命名空间（或容器），每个容器中的 root 用户 uid 0 都映射为 hualf 用户的 uid 1001（运行容器进程的用户），而容器中普通用户的 uid 映射至宿主机的 subuid 范围中，对于此例 subuid 范围为 165536~231071，容器中的 uid 1 用户映射为宿主机 uid 165536，因此容器中 admin 用户 uid 1000 映射为宿主机 uid 166535（165536+999）。  \n  通过容器宿主机上每个普通用户的用户命名空间的 subuid 映射范围，可分配众多 uid 在 rootless 容器中运行应用进程。  \n  ![user-namespace-subuid-mapping-1-edited.png](user-namespace-subuid-mapping-1-edited.png)![user-namespace-subuid-mapping-2-edited.png](user-namespace-subuid-mapping-2-edited.png)\n\n### 参考链接：\n- [Reintroduction of Podman](https://projectatomic.io/blog/2018/02/reintroduction-podman/)\n- [Using pods with Podman on Fedora](https://fedoramagazine.org/podman-pods-fedora-containers/)\n- [Configuring container networking with Podman](https://www.redhat.com/sysadmin/container-networking-podman)\n- [RedHat docs - Building, running, and managing Linux containers on Red Hat Enterprise Linux 8](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/building_running_and_managing_containers/index)\n- [容器安全拾遗 - Rootless Container初探](https://developer.aliyun.com/article/700923)\n- [Documentation for /proc/sys/user/](https://www.kernel.org/doc/html/latest/admin-guide/sysctl/user.html)\n- [docker docs - Overview of Docker Compose](https://docs.docker.com/compose/)\n- [CNI docs - firewall plugin](https://www.cni.dev/plugins/current/meta/firewall/)\n- [CNI docs - Port-mapping plugin](https://www.cni.dev/plugins/current/meta/firewall/)\n- https://fossies.org/linux/podman/docs/tutorials/basic_networking.md\n","source":"_posts/podman-arch-usage.md","raw":"---\ntitle: Podman 容器原理与使用（1）\nsubtitle: Podman Architecture and Usage (1)\nheader-img: podman-bg.webp\ndate: 2022-12-05 13:01:29\ntags:\n  - 容器\n  - 云原生\n---\n\n### 文档说明：\n- 实验用 OS 版本：  \n  - CentOS 7.9、RHEL 8.0、RHEL 8.2、Ubuntu 20.04.3 LTS\n- 实验用 kernel 版本：  \n  - 3.10.0-1160.41.1.el7.x86_64  \n  - 4.18.0-193.el8.x86_64  \n  - 5.14.0-1.el7.elrepo.x86_64\n- 实验用 Podman 版本：1.6.4、3.2.3、3.3.1\n- 实验用 podman-compose 版本：0.1.8\n- 实验用 Docker 版本：20.10.8\n- 若未做特殊说明，以下示例均于 `RHEL 8.2`（`4.18.0-193.el8.x86_64`）上执行，Podman 版本为 `3.2.3`。\n- 该文档中未涉及 podman 命令的基础使用方法，可参阅 [该文档](https://mp.weixin.qq.com/s/MDi4RB5V60EGl3ii9usD0Q) 加以熟悉。\n- 💥 重要提示：Podman 项目正在不断演进与完善中，请以自身使用的版本为准进行测试与使用！\n\n### 文档目录：\n- Podman 的特性概述\n- Podman 版本兼容性比较\n- Podman 的扩展功能\n- Podman 在不同 OS 版本中的安装\n- Docker 与 Podman 进程管理方式比较\n- Podman 的网络实现原理（rootfull 与 rootless）\n- Podman 的 macvlan 网络实现\n- Podman rootless 容器用户映射实现方式\n- 参考链接\n\n### Podman 的特性概述：\n- LXC、`LXD`（Go 语言开发）、`systemd-nspawn` 均可作为 Linux 容器，但缺少容器跨主机运行与应用打包的能力。\n- Docker 与 Podman 可使用容器镜像实现应用打包发布，快速且轻量。\n- Docker 与 Podman 都使用 `runC`（Go 语言开发）作为底层 `oci-runtime`。\n- Docker 与 Podman 都支持 `OCI Image Format`（Go 语言开发），都能使用 DockerHub 上的容器镜像，而 systemd-nspawn 无法使用它们的镜像。\n- 👉 Podman 使用 `CNI`（Go 语言开发）作为 rootfull 容器网络底层，实现比 Docker 网络层略微简单但原理相同。\n- 相对于 LXD 与 systemd-nspawn，CNI 可以避免编写大量的网络规则。\n- 🚀 为了实现普通用户 rootless 容器网络，Podman 可以使用 `slirp4netns` 程序，避免 `kernel space` 中的大量 `veth pair` 虚拟接口的出现, 并且性能更好。\n- Docker 运行容器必须使用守护进程且使用 root 权限，存在系统安全问题，而 Podman 针对此问题使用以下两个特性加以解决，如下所示：  \n  - Podman 支持无守护进程（`no-daemon`）运行容器。  \n  - Podman 支持普通用户运行 `rootless` 容器，即，普通用户直接运行容器无需提权具有 root 权限。\n- 虽然 Docker 与 Podman 的实现原理不同，但对于使用者而言其 CLI 十分相似，可平滑地从 Docker 过渡至 Podman。\n- Podman 的目标不是容器的编排，编排可以使用更加专业的 Kubernetes、Open Shift、Rancher 等，使用 Podman 可以更轻量的运行容器且不受 root 权限的安全问题，即便是 root 用户也无法查看其它普通用户空间下的容器，Podman 通过 `user namespace` 进行隔离。\n- 👉 Podman 可使用 `systemd service` 单元文件直接管理容器，实现容器服务随系统启动而启动。\n- 👉 Podman 里集成了 `CRIU`，因此 Podman 中的容器可以在单机上热迁移。\n- 由于 Kubernetes 将从 `v1.24.x` 版本后放弃使用 `dockershim` 接口层，容器运行时可选择使用 `Containerd` 或者 `CRI-O`，两者虽然均支持 OCI image 规范，但它们不是面向使用者或开发者直接管理容器或镜像的工具，而 Podman 可直接面向使用者或开发者操作容器或镜像。\n- Podman 命令的子进程创建 pod 与容器。\n\n### Podman 版本兼容性比较：\n- Podman 版本、kernel 版本与 OS 版本的兼容性将直接影响普通用户使用 rootless 容器。\n- 如下所示，kernel 不支持 rootless 容器：  \n  ![centos79-kernel-not-support-podman-rootless.jpg](centos79-kernel-not-support-podman-rootless.jpg)\n\n- 普通用户 rootless 容器兼容性比较：\n  ![podman-version-compare.png](podman-version-compare.png)\n\n  > 📌**注意：**\n  > \n  > rootless 容器特性取决于 kernel 的版本，不取决于 OS 与 Podman 的版本。\n\n  - 由于 `user namespace` 特性在 kernel `4.9.0` 之后出现，因此升级 kernel 即可解决 rootless 问题。\n  - 关于 rootless 特性在 RHEL 8 中的设置，可 [点击此处](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/building_running_and_managing_containers/assembly_starting-with-containers_building-running-and-managing-containers#proc_setting-up-rootless-containers_assembly_starting-with-containers) 参考 Red Hat 的官方配置说明。\n\n### Podman 的扩展功能：\n- `cockpit-podman` 软件包作为 cockpit 插件可集成于 `Web UI` 中，实现 Web UI 管理容器。  \n  - cockpit-podman 服务安装与启用：    \n    ```bash\n    $ sudo yum install -y cockpit-podman\n    $ sudo systemctl enable --now cockpit.socket\n    $ sudo systemctl status cockpit.service\n    # 安装 cockpit-podman 软件包，并启用 cockpit 服务。\n    $ sudo netstat -tunlp | grep 9090\n    # 查看 systemd 监听的 9090 端口是否启用\n    ```\n  - 在 Web UI 中可查看并管理 podman 容器与镜像：    \n    ![podman-arch-usage/cockpit-podman-1.jpg](cockpit-podman-1.jpg)![cockpit-podman-2.jpg](cockpit-podman-2.jpg)\n- `podman-compose` 旨在使用更轻量的方式实现`单机容器编排`，以用于替换 `docker-compose`，这种方式将不再依赖守护进程与 root 权限，同时可使用 rootless 容器，详细示例见下文。\n- podman-compose 使用 `Python` 开发，因此可直接使用 `pip3` 安装该组件，或使用 rpm 软件包方式安装。\n- 由于 podman-compose 依然处于 `dev` 阶段，仅作为功能测试使用，暂未受到 GA 环境支持。\n\n### Podman 在不同 OS 版本中的安装：\n- CentOS 7.x/8.x 或 RHEL 7.x/8.x 中：yum 命令使用 podman `rpm` 软件包安装  \n  ```bash\n  $ sudo yum install -y podman-3.2.3-0.11.module_el8.4.0+942+d25aada8.x86_64\n  # 安装 podman 最新版本，低版本 podman 存在较多 bug。\n  # 注意：\n  #   1. 需配置 CentOS 8 的 yum 软件源以安装最新版的 podman 及其依赖软件包\n  #   2. yum 安装 podman 时也将安装 containernetworking-plugins 软件包\n  ```\n- 🤘 Ubuntu 20.04.2 LTS 中：apt-get 命令使用 podman `deb` 软件包安装  \n  ```bash\n$ . /etc/os-release\n# 查看当前的系统发行版\n$ echo \"deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_${VERSION_ID}/ /\" | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list\n$ curl -L \"https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_${VERSION_ID}/Release.key\" | sudo apt-key add -\n# 添加 podman 软件源与 apt 公钥\n$ sudo apt-get update -y\n$ sudo apt-get upgrade -y\n# 更新系统软件源并升级系统软件包\n$ sudo apt-get install -y podman\n  Reading package lists... Done\n  Building dependency tree       \n  Reading state information... Done\n  ...\n  The following NEW packages will be installed:\n    catatonit conmon containernetworking-plugins containers-common criu crun fuse-overlayfs fuse3 libfuse3-3 libnet1 libprotobuf-c1\n    podman podman-machine-cni podman-plugins\n  ...\n# 安装 podman 与相关的软件包，包括 conmon、containernetworking-plugins、crun 等。  \n  ```\n  安装参考链接：  \n  - [Podman Doc - installation](https://podman.io/getting-started/installation)\n  - [Easy to Install Podman on Ubuntu 20.04](https://www.hostnextra.com/kb/easy-to-install-podman-on-ubuntu-20-04/)\n  - [podman from devel:kubic:libcontainers:stable project](https://software.opensuse.org//download.html?project=devel%3Akubic%3Alibcontainers%3Astable&package=podman)\n\n### 🤘 Docker 与 Podman 进程管理方式比较：\n- Docker v20.10.8 使用 `dockerd` 与 `containerd` 守护进程管理容器与镜像的生命周期，运行状态如下所示： \n  ```bash\n  $ sudo systemctl status docker.service\n  ● docker.service - Docker Application Container Engine\n     Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled)\n     Active: active (running) since Wed 2022-10-19 10:53:04 CST; 6min ago\n       Docs: https://docs.docker.com\n   Main PID: 79556 (dockerd)\n      Tasks: 21\n     Memory: 42.6M\n     CGroup: /system.slice/docker.service\n             ├─79556 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock\n             ├─79677 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 4000 -container-ip 172.17.0.2 -container-port 4000\n             └─79683 /usr/bin/docker-proxy -proto tcp -host-ip :: -host-port 4000 -container-ip 172.17.0.2 -container-port 4000\n  \n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.197803867+08:00\" level=info msg=\"scheme \\\"unix\\\" not registered, fallback to default scheme\" module=grpc\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.197837924+08:00\" level=info msg=\"ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}\" module=grpc\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.197860326+08:00\" level=info msg=\"ClientConn switching balancer to \\\"pick_first\\\"\" module=grpc\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.220416627+08:00\" level=info msg=\"Loading containers: start.\"\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.347884960+08:00\" level=info msg=\"Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address\"\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.725361851+08:00\" level=info msg=\"Loading containers: done.\"\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.755449128+08:00\" level=info msg=\"Docker daemon\" commit=75249d8 graphdriver(s)=overlay2 version=20.10.8\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.755527994+08:00\" level=info msg=\"Daemon has completed initialization\"\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com systemd[1]: Started Docker Application Container Engine.\n  Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=\"2022-10-19T10:53:04.776865058+08:00\" level=info msg=\"API listen on /var/run/docker.sock\"\n  # dockerd 守护进程的运行状态\n  \n  $ sudo systemctl status containerd\n  ● containerd.service - containerd container runtime\n     Loaded: loaded (/usr/lib/systemd/system/containerd.service; enabled; vendor preset: disabled)\n     Active: active (running) since Tue 2022-10-18 15:08:06 CST; 20h ago\n       Docs: https://containerd.io\n   Main PID: 1892 (containerd)\n      Tasks: 20\n     Memory: 103.4M\n     CGroup: /system.slice/containerd.service\n             ├─ 1892 /usr/bin/containerd\n             └─79696 /usr/bin/containerd-shim-runc-v2 -namespace moby -id 3ea752c1cce6a65b39af7f68c971186e020992514b663ab7a917f47da70450fa -address /run/containerd/containerd.sock\n  # containerd 通过调用 containerd-shim-runc-v2 运行指定容器\n  $ sudo ps -ef | grep -E \"dockerd|containerd|containerd-shim-runc-v2\"\n    root       1892      1  0 Oct18 ?        00:05:01 /usr/bin/containerd\n    root      79556      1  0 10:53 ?        00:00:03 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock\n    root      79696      1  0 10:53 ?        00:00:01 /usr/bin/containerd-shim-runc-v2 -namespace moby -id 3ea752c1cce6a65b39af7f68c971186e020992514b663ab7a917f47da70450fa -address /run/containerd/containerd.sock\n  # PID 79696 为实际的容器运行进程\n  ```\n- Podman 不使用守护进程的方式运行或管理容器，对于 rootfull 容器或 rootless 容器的运行方式存在差异：  \n  - rootfull 容器的进程：    \n    👉 以交互式方式运行的容器进程状态如下所示：    \n    ```bash\n    $ sudo ps -ef | egrep \"podman|slirp4netns|conmon\"\n      root        3879    3476  1 06:31 pts/3    00:00:00 podman run -it --name=mydebian docker.io/library/debian:latest /bin/sh\n      root        3945       1  0 06:31 ?        00:00:00 /usr/bin/conmon --api-version 1 -c 29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba -u 29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba -r /usr/bin/crun -b /var/lib/containers/storage/overlay-containers/29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba/userdata -p /run/containers/storage/overlay-containers/29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba/userdata/pidfile -n mydebian --exit-dir /run/libpod/exits --full-attach -s -l journald --log-level warning --runtime-arg --log-format=json --runtime-arg --log --runtime-arg=/run/containers/storage/overlay-containers/29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba/userdata/oci-log -t --conmon-pidfile /run/containers/storage/overlay-containers/29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba/userdata/conmon.pid --exit-command /usr/bin/podman --exit-command-arg --root --exit-command-arg /var/lib/containers/storage --exit-command-arg --runroot --exit-command-arg /run/containers/storage --exit-command-arg --log-level --exit-command-arg warning --exit-command-arg --cgroup-manager --exit-command-arg systemd --exit-command-arg --tmpdir --exit-command-arg /run/libpod --exit-command-arg --network-config-dir --exit-command-arg  --exit-command-arg --network-backend --exit-command-arg cni --exit-command-arg --volumepath --exit-command-arg /var/lib/containers/storage/volumes --exit-command-arg --runtime --exit-command-arg crun --exit-command-arg --storage-driver --exit-command-arg overlay --exit-command-arg --storage-opt --exit-command-arg overlay.mountopt=nodev,metacopy=on --exit-command-arg --events-backend --exit-command-arg journald --exit-command-arg container --exit-command-arg cleanup --exit-command-arg 29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba\n    # 由于具有交互式命令行运行依然保留 podman 进程\n    ```\n    👉 以 `detach` 方式（后台）运行的容器进程状态如下所示：    \n    ```bash\n    $ sudo ps -ef | egrep \"podman|slirp4netns|conmon\"\n      root        3744       1  0 06:25 ?        00:00:00 /usr/bin/conmon --api-version 1 -c b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272 -u b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272 -r /usr/bin/crun -b /var/lib/containers/storage/overlay-containers/b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272/userdata -p /run/containers/storage/overlay-containers/b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272/userdata/pidfile -n apache-rhce8.2-alpine --exit-dir /run/libpod/exits --full-attach -s -l journald --log-level warning --runtime-arg --log-format=json --runtime-arg --log --runtime-arg=/run/containers/storage/overlay-containers/b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272/userdata/oci-log --conmon-pidfile /run/containers/storage/overlay-containers/b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272/userdata/conmon.pid --exit-command /usr/bin/podman --exit-command-arg --root --exit-command-arg /var/lib/containers/storage --exit-command-arg --runroot --exit-command-arg /run/containers/storage --exit-command-arg --log-level --exit-command-arg warning --exit-command-arg --cgroup-manager --exit-command-arg systemd --exit-command-arg --tmpdir --exit-command-arg /run/libpod --exit-command-arg --network-config-dir --exit-command-arg  --exit-command-arg --network-backend --exit-command-arg cni --exit-command-arg --volumepath --exit-command-arg /var/lib/containers/storage/volumes --exit-command-arg --runtime --exit-command-arg crun --exit-command-arg --storage-driver --exit-command-arg overlay --exit-command-arg --storage-opt --exit-command-arg overlay.mountopt=nodev,metacopy=on --exit-command-arg --events-backend --exit-command-arg journald --exit-command-arg container --exit-command-arg cleanup --exit-command-arg b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272\n    # podman 在调用 conmon 程序创建并运行容器后退出，而 rootfull 容器的 CNI 插件\n    # 可直接使用 iptables 的方式实现。\n    ```\n  - rootless 容器的进程：    \n    👉 以交互式方式运行的容器进程状态如下所示：\n    ```bash\n    $ ps -ef | egrep \"podman|slirp4netns|conmon\"\n      core        3418    2762  0 06:17 pts/2    00:00:05 podman run -it --name=mybusybox docker.io/library/busybox:latest /bin/sh\n      core        3430    3418  0 06:17 pts/2    00:00:00 /usr/bin/slirp4netns --disable-host-loopback --mtu=65520 --enable-sandbox --enable-seccomp --enable-ipv6 -c -e 3 -r 4 --netns-type=path /run/user/1000/netns/netns-19eb5630-c0a8-4ea9-8790-76ecdcdf2dbc tap0\n      core        3433       1  0 06:17 ?        00:00:00 /usr/bin/conmon --api-version 1 -c 5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160 -u 5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160 -r /usr/bin/crun -b /var/home/core/.local/share/containers/storage/overlay-containers/5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160/userdata -p /run/user/1000/containers/overlay-containers/5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160/userdata/pidfile -n mybusybox --exit-dir /run/user/1000/libpod/tmp/exits --full-attach -s -l journald --log-level warning --runtime-arg --log-format=json --runtime-arg --log --runtime-arg=/run/user/1000/containers/overlay-containers/5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160/userdata/oci-log -t --conmon-pidfile /run/user/1000/containers/overlay-containers/5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160/userdata/conmon.pid --exit-command /usr/bin/podman --exit-command-arg --root --exit-command-arg /var/home/core/.local/share/containers/storage --exit-command-arg --runroot --exit-command-arg /run/user/1000/containers --exit-command-arg --log-level --exit-command-arg warning --exit-command-arg --cgroup-manager --exit-command-arg systemd --exit-command-arg --tmpdir --exit-command-arg /run/user/1000/libpod/tmp --exit-command-arg --network-config-dir --exit-command-arg  --exit-command-arg --network-backend --exit-command-arg netavark --exit-command-arg --volumepath --exit-command-arg /var/home/core/.local/share/containers/storage/volumes --exit-command-arg --runtime --exit-command-arg crun --exit-command-arg --storage-driver --exit-command-arg overlay --exit-command-arg --events-backend --exit-command-arg journald --exit-command-arg container --exit-command-arg cleanup --exit-command-arg 5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160\n    # 由于具有交互式命令行运行依然保留 podman 进程，并且由 podman 进程创建 slirp4netns 子进程\n    # 用于 rootless 容器的网络命名空间之间的通信。\n    ``` \n    👉 以 `detach` 方式（后台）运行的容器进程状态如下所示：   \n    ```bash\n    $ ps -ef | egrep \"podman|slirp4netns|conmon\"\n      core        3308       1  0 06:15 pts/2    00:00:00 /usr/bin/slirp4netns --disable-host-loopback --mtu=65520 --enable-sandbox --enable-seccomp --enable-ipv6 -c -e 3 -r 4 --netns-type=path /run/user/1000/netns/netns-f9f6f9dd-bf80-f6ca-6f39-7c9d9cd6beea tap0\n      core        3325       1  0 06:15 ?        00:00:00 /usr/bin/conmon --api-version 1 -c 91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab -u 91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab -r /usr/bin/crun -b /var/home/core/.local/share/containers/storage/overlay-containers/91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab/userdata -p /run/user/1000/containers/overlay-containers/91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab/userdata/pidfile -n apache-rhce8.2-alpine --exit-dir /run/user/1000/libpod/tmp/exits --full-attach -s -l journald --log-level warning --runtime-arg --log-format=json --runtime-arg --log --runtime-arg=/run/user/1000/containers/overlay-containers/91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab/userdata/oci-log --conmon-pidfile /run/user/1000/containers/overlay-containers/91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab/userdata/conmon.pid --exit-command /usr/bin/podman --exit-command-arg --root --exit-command-arg /var/home/core/.local/share/containers/storage --exit-command-arg --runroot --exit-command-arg /run/user/1000/containers --exit-command-arg --log-level --exit-command-arg warning --exit-command-arg --cgroup-manager --exit-command-arg systemd --exit-command-arg --tmpdir --exit-command-arg /run/user/1000/libpod/tmp --exit-command-arg --network-config-dir --exit-command-arg  --exit-command-arg --network-backend --exit-command-arg netavark --exit-command-arg --volumepath --exit-command-arg /var/home/core/.local/share/containers/storage/volumes --exit-command-arg --runtime --exit-command-arg crun --exit-command-arg --storage-driver --exit-command-arg overlay --exit-command-arg --events-backend --exit-command-arg journald --exit-command-arg container --exit-command-arg cleanup --exit-command-arg 91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab\n    # podman 在调用 conmon 程序创建并运行容器后退出，并且由 podman 进程创建 slirp4netns 子进程\n    # 用于 rootless 容器的网络命名空间之间的通信。\n    ```\n\n### Podman 的网络实现原理（rootfull 与 rootless）：\n- Podman 支持的容器网络模式如下所示：  \n  ![podman-network-mode.jpg](podman-network-mode.jpg)\n- root 用户运行 rootfull 容器网络分析：  \n  - 默认情况下，rootfull 容器使用 bridge 网络模式，并且在未创建任何容器前系统上不会自动创建 `cni-podman0 `网桥，只有创建容器后自动生成。  \n  - root 用户使用全局范围内的 CNI 插件，podman 默认使用 `bridge`、`portmap` 插件，其配置文件如下：    \n    ```bash\n    $ cat /etc/cni/net.d/87-podman-bridge.conflist\n    {\n      \"cniVersion\": \"0.4.0\",\n      \"name\": \"podman\",\n      \"plugins\": [\n        {\n          \"type\": \"bridge\",\n          \"bridge\": \"cni-podman0\",\n          \"isGateway\": true,\n          \"ipMasq\": true,\n          \"hairpinMode\": true,\n          \"ipam\": {\n            \"type\": \"host-local\",\n            \"routes\": [{ \"dst\": \"0.0.0.0/0\" }],\n            \"ranges\": [\n              [\n                {\n                  \"subnet\": \"10.88.0.0/16\",\n                  \"gateway\": \"10.88.0.1\"\n                }\n              ]\n            ]\n          }\n        },\n        {\n          \"type\": \"portmap\",\n          \"capabilities\": {\n            \"portMappings\": true\n          }\n        },\n        {\n          \"type\": \"firewall\"\n        },\n        {\n          \"type\": \"tuning\"\n        }\n      ]\n    # 该配置文件位于 Podman 源码 cni/87-podman-bridge.conflist\n    # Podman 可调用 bridge、portmap 等 CNI 插件\n    \n    $ sudo podman inspect <container_name> | jq .[0].HostConfig.NetworkMode\n      \"bridge\"\n    # root 用户创建的容器网络模式\n    ```\n  - root 用户创建具有端口映射的容器时，iptables filter 表与 nat 表规则将相应增加：    \n    ```bash\n    # ----- filter 表中创建新容器后的新增规则 -----\n    *filter\n    -A FORWARD -m comment --comment \"CNI firewall plugin rules\" -j CNI-FORWARD\n    -A CNI-FORWARD -m comment --comment \"CNI firewall plugin admin overrides\" -j CNI-ADMIN\n    -A CNI-FORWARD -d 10.88.0.3/32 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT\n    # 新增规则：允许 3 层转发目标地址为 10.88.0.3 的流量（进入容器的流量），conntrack 模块进行连接状态追踪。\n    # 当容器通过 MASQUERADE 对外访问，回包再次进入容器宿主机时不再通过 DNAT 转发，而通过 conntrack \n    # 记录的连接状态直接转发至该规则并通过 cni-podman0 网桥进入容器。\n    -A CNI-FORWARD -s 10.88.0.3/32 -j ACCEPT\n    # 新增规则：允许 3 层转发源地址为 10.88.0.3 的流量（出容器的流量）。\n    \n    # ----- nat 表中创建新容器后的新增规则 -----\n    *nat\n    -A PREROUTING -m addrtype --dst-type LOCAL -j CNI-HOSTPORT-DNAT\n    -A POSTROUTING -m comment --comment \"CNI portfwd requiring masquerade\" -j CNI-HOSTPORT-MASQ\n    -A POSTROUTING -s 10.88.0.3/32 -m comment --comment \"name: \\\"podman\\\" id: \\\"2d2b3521457cb1d9b7ae6657304d05789a854e7a48916276a40da543df9aa217\\\"\" -j CNI-b6c5fb6c593e895d843cb5bd\n    # 新增规则：来自于 10.88.0.3 容器的流量转发至 CNI-b6c5fb6c593e895d843cb5bd 链\n    -A OUTPUT -m addrtype --dst-type LOCAL -j CNI-HOSTPORT-DNAT\n    # 启用 CNI 后即创建的规则，该规则接收来自本地应用的流量并转发至 CNI-HOSTPORT-DNAT 链\n    -A CNI-HOSTPORT-SETMARK -m comment --comment \"CNI portfwd masquerade mark\" -j MARK --set-xmark 0x2000/0x2000\n    -A CNI-HOSTPORT-MASQ -m mark --mark 0x2000/0x2000 -j MASQUERADE\n    ### 以下 6 条在创建新容器时同时创建 \n    -A CNI-HOSTPORT-DNAT -p tcp -m comment --comment \"dnat name: \\\"podman\\\" id: \\\"2d2b3521457cb1d9b7ae6657304d05789a854e7a48916276a40da543df9aa217\\\"\" -m multiport --dports 8843 -j CNI-DN-b6c5fb6c593e895d843cb\n    # 自定义 DNAT 链，发送至本地 8843 端口的流量转发至 CNI-DN-b6c5fb6c593e895d843cb 链。\n    -A CNI-b6c5fb6c593e895d843cb5bd -d 10.88.0.0/16 -m comment --comment \"name: \\\"podman\\\" id: \\\"2d2b3521457cb1d9b7ae6657304d05789a854e7a48916276a40da543df9aa217\\\"\" -j ACCEPT\n    # 允许转发目标网段为 10.88.0.0/16 的流量（进入容器的流量），该网段为容器所在的网络。\n    -A CNI-b6c5fb6c593e895d843cb5bd ! -d 224.0.0.0/4 -m comment --comment \"name: \\\"podman\\\" id: \\\"2d2b3521457cb1d9b7ae6657304d05789a854e7a48916276a40da543df9aa217\\\"\" -j MASQUERADE\n    # MASQUERADE 出容器流量\n    -A CNI-DN-b6c5fb6c593e895d843cb -s 10.88.0.0/16 -p tcp -m tcp --dport 8843 -j CNI-HOSTPORT-SETMARK\n    -A CNI-DN-b6c5fb6c593e895d843cb -s 127.0.0.1/32 -p tcp -m tcp --dport 8843 -j CNI-HOSTPORT-SETMARK\n    -A CNI-DN-b6c5fb6c593e895d843cb -p tcp -m tcp --dport 8843 -j DNAT --to-destination 10.88.0.3:443\n    # 自定义 DNAT 链实现容器宿主机至容器的端口映射\n    ```\n  - 🚀 示例：外部访问容器内 Web 服务时，涉及的宿主机 iptables：\n    ![external-access-container-web-service-iptables.jpg](external-access-container-web-service-iptables.jpg)从外部访问容器内 Web 服务时，流量将通过 PREROUTING 链及自定义链（`CNI-HOSTPORT-DNAT`、`CNI-DN-xxxx`、`DNAT`），经由 FORWARD 链及自定义链（`CNI-FORWARD`）的三层转发与 `cni-podman0` 网桥的二层转发进入容器，容器对外响应的流量将经过 cni-podman0 网桥转发，并经过 CNI-FORWARD 链与 POSTROUTING 链及自定义链（`CNI-HOSTPORT-MASQ`）出容器宿主机。  \n  - 🚀 示例：直接从容器内访问外部时，返回容器的回包将直接使用 conntrack 模块追踪的连接状态，流量通过 `CNI-FORWARD` 链的三层转发与 cni-podman0 的二层转发至容器中，即，回包进入容器宿主机不再通过`CNI-HOSTPORT-DNAT`链。    \n    如下所示，相关的 DNAT 链无流量通过（蓝框），CNI-FORWARD 链均有流量通过（蓝框）。    \n    ![container-access-external-iptables.jpg](container-access-external-iptables.jpg)\n    \n    > 📌 **Kubernetes 相关问题提示：**\n    > \n    > 1. 容器或 pod 通过 cni 网桥桥接的方式在 Kubernetes 或 OpenShift3 中需在计算节点（worker node）上配置 `net.bridge.bridge-nf-call-iptables` 与 `net.bridge.bridge-nf-call-iptables6` 内核参数，使 cni 二层网桥可调用 iptables 的 conntrack 模块，以解决前后端 pod 在同一节点上时，由于 pod 直连 cni 二层网桥，而二层网桥只实现二层转发，无法追踪前后端的连接状态，造成后端 pod 向前端 pod 回包时无法处于同一连接链路的问题，可 [点击此处](https://imroc.cc/k8s/faq/why-enable-bridge-nf-call-iptables/) 获得更多帮助。\n    > 2. 使用以上内核参数时，需加载 `br_netfilter` 内核模块方能生效。\n  \n  - 使用 `iperf3` 工具的容器测试不同 rootfull 容器之间的网络性能，如下所示：    \n    ![rootfull-container-to-container-bandwidth.jpg](rootfull-container-to-container-bandwidth.jpg)\n- 普通用户运行 rootless 容器网络分析：  \n  - `slirp4netns` 程序支持 user rootless network namespace，而非通过 `iptables` 与 CNI 实现。  \n  - 👉 普通用户使用端口映射运行 rootless 容器时，默认情况下只能使用宿主机 1024 以上的端口实现映射，但可使用 `net.ipv4.ip_unprivileged_port_start` 内核参数实现低于 1024 的端口开始映射，如下所示：    \n    ```bash\n### 方式 1：###\n$ sysctl -w net.ipv4.ip_unprivileged_port_start=80\n# 临时配置：允许普通用户从 80 端口开始的端口映射运行 rootless 容器\n    \n### 方式 2：###\n$ echo \"net.ipv4.ip_unprivileged_port_start=80\" >> /etc/sysctl.d/rootless.conf\n# 永久配置：将该内核参数写入内核参数配置文件，使其开机永久生效。\n$ sysctl -p\n# 使配置的内核参数生效\n\n - 普通用户创建的容器网络模式为 `slirp4netns`（slirp4netns 软件包实现）。    \n    ```bash\n    $ podman inspect <container_name> | jq .[0].HostConfig.NetworkMode\n      \"slirp4netns\"\n    # 普通用户创建的 rootless 容器网络模式\n    ```\n  - 每个普通用户运行 rootless 容器都将生成 slirp4netns 进程用于隔离该用户的 `network namespace`，以下分别使用 godev 与 hualf 用户运行 rootless 容器：    \n    ![godev-rootless-container.jpg](godev-rootless-container.jpg)![hualf-rootless-container.jpg](hualf-rootless-container.jpg) \n  - slirp4netns 实现的网络模式与带宽比较：    \n    ![rootless-slirp4netns-networking.jpg](rootless-slirp4netns-networking.jpg) \n  - 使用 `iperf3` 工具的容器测试不同 rootless 容器之间的网络性能，如下所示：\n    ![rootless-container-to-container-bandwidth.jpg](rootless-container-to-container-bandwidth.jpg)对比 rootfull 容器之间的网络性能来看，slirp4netns 实现的 rootless 容器在不同的网络命名空间内的通信性能损耗较大，而 rootfull 容器之间的网络性能相比前者在此次测试中高出近 5 倍。 \n  - 关于 slirp4netns 更加详细的内容，请参考 [Github 项目](https://github.com/rootless-containers/slirp4netns)。\n\n### Podman 的 macvlan 网络实现：\n- `macvlan` 作为 CNI 在 Kubernetes 与 OpenShift v4 中作为 `Multus CNI` 支持的额外插件类型使用愈加广泛，集群中除了常规使用的 Flannel、Calico 等作为 `slow path` 的插件外，要求高性能的业务流量可使用 macvlan 直连 pod 宿主机物理网口实现 `fast path`。\n- 为后续熟悉以上场景的实现，因此在 Podman `rootfull` 容器中使用 macvlan 网络模式。\n- 关于 macvlan 的基础知识可参考 [Linux 虚拟网卡技术：Macvlan](https://mp.weixin.qq.com/s?__biz=MzU1MzY4NzQ1OA==&mid=2247484064&idx=1&sn=ffd745069b6c4aeac0589de00467b2f2&chksm=fbee426dcc99cb7bdf26f5e6a21bbeaebba7ccd384a02f850d4461ea92331ed140edf98ffaec&mpshare=1&scene=1&srcid=03049MKwF55OVgEZ4OCH39wd&sharer_sharetime=1583337046541&sharer_shareid=8eaca72194dae7b3d51d5c708436eee4#rd) 与 [linux 网络虚拟化：macvlan](https://cizixs.com/2017/02/14/network-virtualization-macvlan/)\n- macvlan 特性由 `Linux kernel` 支持，笔者的实验环境满足 macvlan 的要求，请使用如下命令确定：  \n  ```bash\n  $ sudo lsmod | grep macvlan\n  # 若无任何返回，说明还未加载 macvlan 内核模块。\n  $ sudo modprobe macvlan\n  # 加载 macvlan 内核模块，若执行报错，说明 kernel 不支持该特性。\n  ```\n- podman 与 macvlan 类型网络的集成，如下所示：  \n  ```bash\n  $ sudo podman network create -d macvlan -o parent=ens33 <network_name>\n    /etc/cni/net.d/<network_name>.conflist\n  # 创建 macvlan 类型网络  \n  $ sudo podman network ls\n  $ sudo /opt/cni/bin/dhcp daemon\n  # 在另一个窗口中启动 dhcp 守护进程供 macvlan 插件调用，为容器网口分配 IP 地址。\n  $ sudo podman run -it --rm \\\n    --name <container_name> --network=<network_name> \\\n    <container_image>:<tag> /bin/sh\n  # 创建支持 macvlan 类型网络的 rootfull 容器  \n  ```\n- 从与 rootfull 容器在同一广播域的其他节点上 ping 该容器，可正常通信：  \n  ![podman-macvlan-network.png](podman-macvlan-network.png)\n  \n  > 🤔 以上示例的容器中运行 Web 服务（可暴露 443 端口），使用 macvlan 网络模式可打通与同一广播域中外部节点的通信，但无法访问其中的服务，可采取何种方法解决该问题？  \n\n### Podman rootless 容器用户映射实现方式：\n- Podman rootless 容器的实现核心在于解决 network namespace（NetNS） 与 user namespace（UserNS） 的问题，前文已介绍 NetNS 的实现方式，后文将介绍 UserNS 的实现方式。\n- 若要使用 rootless 容器，需确认 OS 是否开启 user namespace 功能：  \n  ```bash\n  $ sudo sysctl -a | grep user\\.max_user_namespaces\n    user.max_user_namespaces = 47494\n  ```\n- 系统上每创建一个用户就会在 `/etc/subuid` 与 `/etc/subgid` 中生成对应用户在其用户命名空间中的映射规则，以 /etc/subuid 为例，参数以冒号分隔，每个参数含义如下所示：  \n  - 第一个参数（uid）：用户名称  \n  - 第二个参数（loweruid）：用户命名空间中起始的映射 uid\n- 第三个参数（count）：用户命名空间内部与外部可映射 uid 数量（可理解为所有容器普通用户的 uid 数量和）  \n  ![rootless-user-namespace-mapping.jpg](rootless-user-namespace-mapping.jpg)\n- 以上两个文件允许运行进程的 uid 映射范围，在 `/proc/<pid>/uid_map` 中定义。\n- 可过滤容器 `conmon` 进程的 pid 确认每个容器中的 uid 映射情况，参见以下示例。\n- 关于以上两个文件的具体说明可参考 `newuidmap` 与 `newgidmap` 命令的 man 手册。\n- 可参考 Podman 官方推荐的命令创建 uid 的映射，如下所示：  \n  ```bash\n  $ sudo usermod --add-subuids 10000-75535 $(whoami)\n  \n  # ----- 示例 -----\n  $ sudo cat /etc/subuid\n    appuser:10000:500\n  $ sudo cat /etc/subgid\n    appuser:500:50\n  # 该用户创建的 user namespace 中可以使用从 10000 开始的 500 个 UID 和从 500 开始的 50 个 GID 的映射。\n  ```\n- 🚀 示例：  \n  普通用户 hualf 在 /etc/subuid 中映射为 hualf:165536:65536，说明在该用户的用户命名空间中可嵌套一个或多个用户命名空间（或容器），每个容器中的 root 用户 uid 0 都映射为 hualf 用户的 uid 1001（运行容器进程的用户），而容器中普通用户的 uid 映射至宿主机的 subuid 范围中，对于此例 subuid 范围为 165536~231071，容器中的 uid 1 用户映射为宿主机 uid 165536，因此容器中 admin 用户 uid 1000 映射为宿主机 uid 166535（165536+999）。  \n  通过容器宿主机上每个普通用户的用户命名空间的 subuid 映射范围，可分配众多 uid 在 rootless 容器中运行应用进程。  \n  ![user-namespace-subuid-mapping-1-edited.png](user-namespace-subuid-mapping-1-edited.png)![user-namespace-subuid-mapping-2-edited.png](user-namespace-subuid-mapping-2-edited.png)\n\n### 参考链接：\n- [Reintroduction of Podman](https://projectatomic.io/blog/2018/02/reintroduction-podman/)\n- [Using pods with Podman on Fedora](https://fedoramagazine.org/podman-pods-fedora-containers/)\n- [Configuring container networking with Podman](https://www.redhat.com/sysadmin/container-networking-podman)\n- [RedHat docs - Building, running, and managing Linux containers on Red Hat Enterprise Linux 8](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/building_running_and_managing_containers/index)\n- [容器安全拾遗 - Rootless Container初探](https://developer.aliyun.com/article/700923)\n- [Documentation for /proc/sys/user/](https://www.kernel.org/doc/html/latest/admin-guide/sysctl/user.html)\n- [docker docs - Overview of Docker Compose](https://docs.docker.com/compose/)\n- [CNI docs - firewall plugin](https://www.cni.dev/plugins/current/meta/firewall/)\n- [CNI docs - Port-mapping plugin](https://www.cni.dev/plugins/current/meta/firewall/)\n- https://fossies.org/linux/podman/docs/tutorials/basic_networking.md\n","slug":"podman-arch-usage","published":1,"updated":"2022-12-05T07:11:38.946Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldfonols000g16vdrnw9xusi","content":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li>实验用 OS 版本：  <ul>\n<li>CentOS 7.9、RHEL 8.0、RHEL 8.2、Ubuntu 20.04.3 LTS</li>\n</ul>\n</li>\n<li>实验用 kernel 版本：  <ul>\n<li>3.10.0-1160.41.1.el7.x86_64  </li>\n<li>4.18.0-193.el8.x86_64  </li>\n<li>5.14.0-1.el7.elrepo.x86_64</li>\n</ul>\n</li>\n<li>实验用 Podman 版本：1.6.4、3.2.3、3.3.1</li>\n<li>实验用 podman-compose 版本：0.1.8</li>\n<li>实验用 Docker 版本：20.10.8</li>\n<li>若未做特殊说明，以下示例均于 <code>RHEL 8.2</code>（<code>4.18.0-193.el8.x86_64</code>）上执行，Podman 版本为 <code>3.2.3</code>。</li>\n<li>该文档中未涉及 podman 命令的基础使用方法，可参阅 <a href=\"https://mp.weixin.qq.com/s/MDi4RB5V60EGl3ii9usD0Q\" target=\"_blank\" rel=\"noopener\">该文档</a> 加以熟悉。</li>\n<li>💥 重要提示：Podman 项目正在不断演进与完善中，请以自身使用的版本为准进行测试与使用！</li>\n</ul>\n<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>Podman 的特性概述</li>\n<li>Podman 版本兼容性比较</li>\n<li>Podman 的扩展功能</li>\n<li>Podman 在不同 OS 版本中的安装</li>\n<li>Docker 与 Podman 进程管理方式比较</li>\n<li>Podman 的网络实现原理（rootfull 与 rootless）</li>\n<li>Podman 的 macvlan 网络实现</li>\n<li>Podman rootless 容器用户映射实现方式</li>\n<li>参考链接</li>\n</ul>\n<h3 id=\"Podman-的特性概述：\"><a href=\"#Podman-的特性概述：\" class=\"headerlink\" title=\"Podman 的特性概述：\"></a>Podman 的特性概述：</h3><ul>\n<li>LXC、<code>LXD</code>（Go 语言开发）、<code>systemd-nspawn</code> 均可作为 Linux 容器，但缺少容器跨主机运行与应用打包的能力。</li>\n<li>Docker 与 Podman 可使用容器镜像实现应用打包发布，快速且轻量。</li>\n<li>Docker 与 Podman 都使用 <code>runC</code>（Go 语言开发）作为底层 <code>oci-runtime</code>。</li>\n<li>Docker 与 Podman 都支持 <code>OCI Image Format</code>（Go 语言开发），都能使用 DockerHub 上的容器镜像，而 systemd-nspawn 无法使用它们的镜像。</li>\n<li>👉 Podman 使用 <code>CNI</code>（Go 语言开发）作为 rootfull 容器网络底层，实现比 Docker 网络层略微简单但原理相同。</li>\n<li>相对于 LXD 与 systemd-nspawn，CNI 可以避免编写大量的网络规则。</li>\n<li>🚀 为了实现普通用户 rootless 容器网络，Podman 可以使用 <code>slirp4netns</code> 程序，避免 <code>kernel space</code> 中的大量 <code>veth pair</code> 虚拟接口的出现, 并且性能更好。</li>\n<li>Docker 运行容器必须使用守护进程且使用 root 权限，存在系统安全问题，而 Podman 针对此问题使用以下两个特性加以解决，如下所示：  <ul>\n<li>Podman 支持无守护进程（<code>no-daemon</code>）运行容器。  </li>\n<li>Podman 支持普通用户运行 <code>rootless</code> 容器，即，普通用户直接运行容器无需提权具有 root 权限。</li>\n</ul>\n</li>\n<li>虽然 Docker 与 Podman 的实现原理不同，但对于使用者而言其 CLI 十分相似，可平滑地从 Docker 过渡至 Podman。</li>\n<li>Podman 的目标不是容器的编排，编排可以使用更加专业的 Kubernetes、Open Shift、Rancher 等，使用 Podman 可以更轻量的运行容器且不受 root 权限的安全问题，即便是 root 用户也无法查看其它普通用户空间下的容器，Podman 通过 <code>user namespace</code> 进行隔离。</li>\n<li>👉 Podman 可使用 <code>systemd service</code> 单元文件直接管理容器，实现容器服务随系统启动而启动。</li>\n<li>👉 Podman 里集成了 <code>CRIU</code>，因此 Podman 中的容器可以在单机上热迁移。</li>\n<li>由于 Kubernetes 将从 <code>v1.24.x</code> 版本后放弃使用 <code>dockershim</code> 接口层，容器运行时可选择使用 <code>Containerd</code> 或者 <code>CRI-O</code>，两者虽然均支持 OCI image 规范，但它们不是面向使用者或开发者直接管理容器或镜像的工具，而 Podman 可直接面向使用者或开发者操作容器或镜像。</li>\n<li>Podman 命令的子进程创建 pod 与容器。</li>\n</ul>\n<h3 id=\"Podman-版本兼容性比较：\"><a href=\"#Podman-版本兼容性比较：\" class=\"headerlink\" title=\"Podman 版本兼容性比较：\"></a>Podman 版本兼容性比较：</h3><ul>\n<li>Podman 版本、kernel 版本与 OS 版本的兼容性将直接影响普通用户使用 rootless 容器。</li>\n<li><p>如下所示，kernel 不支持 rootless 容器：<br><img src=\"centos79-kernel-not-support-podman-rootless.jpg\" alt=\"centos79-kernel-not-support-podman-rootless.jpg\"></p>\n</li>\n<li><p>普通用户 rootless 容器兼容性比较：<br><img src=\"podman-version-compare.png\" alt=\"podman-version-compare.png\"></p>\n<blockquote>\n<p>📌<strong>注意：</strong></p>\n<p>rootless 容器特性取决于 kernel 的版本，不取决于 OS 与 Podman 的版本。</p>\n</blockquote>\n<ul>\n<li>由于 <code>user namespace</code> 特性在 kernel <code>4.9.0</code> 之后出现，因此升级 kernel 即可解决 rootless 问题。</li>\n<li>关于 rootless 特性在 RHEL 8 中的设置，可 <a href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/building_running_and_managing_containers/assembly_starting-with-containers_building-running-and-managing-containers#proc_setting-up-rootless-containers_assembly_starting-with-containers\" target=\"_blank\" rel=\"noopener\">点击此处</a> 参考 Red Hat 的官方配置说明。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Podman-的扩展功能：\"><a href=\"#Podman-的扩展功能：\" class=\"headerlink\" title=\"Podman 的扩展功能：\"></a>Podman 的扩展功能：</h3><ul>\n<li><p><code>cockpit-podman</code> 软件包作为 cockpit 插件可集成于 <code>Web UI</code> 中，实现 Web UI 管理容器。  </p>\n<ul>\n<li><p>cockpit-podman 服务安装与启用：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo yum install -y cockpit-podman</span><br><span class=\"line\">$ sudo systemctl <span class=\"built_in\">enable</span> --now cockpit.socket</span><br><span class=\"line\">$ sudo systemctl status cockpit.service</span><br><span class=\"line\"><span class=\"comment\"># 安装 cockpit-podman 软件包，并启用 cockpit 服务。</span></span><br><span class=\"line\">$ sudo netstat -tunlp | grep 9090</span><br><span class=\"line\"><span class=\"comment\"># 查看 systemd 监听的 9090 端口是否启用</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>在 Web UI 中可查看并管理 podman 容器与镜像：<br><img src=\"cockpit-podman-1.jpg\" alt=\"podman-arch-usage/cockpit-podman-1.jpg\"><img src=\"cockpit-podman-2.jpg\" alt=\"cockpit-podman-2.jpg\"></p>\n</li>\n</ul>\n</li>\n<li><code>podman-compose</code> 旨在使用更轻量的方式实现<code>单机容器编排</code>，以用于替换 <code>docker-compose</code>，这种方式将不再依赖守护进程与 root 权限，同时可使用 rootless 容器，详细示例见下文。</li>\n<li>podman-compose 使用 <code>Python</code> 开发，因此可直接使用 <code>pip3</code> 安装该组件，或使用 rpm 软件包方式安装。</li>\n<li>由于 podman-compose 依然处于 <code>dev</code> 阶段，仅作为功能测试使用，暂未受到 GA 环境支持。</li>\n</ul>\n<h3 id=\"Podman-在不同-OS-版本中的安装：\"><a href=\"#Podman-在不同-OS-版本中的安装：\" class=\"headerlink\" title=\"Podman 在不同 OS 版本中的安装：\"></a>Podman 在不同 OS 版本中的安装：</h3><ul>\n<li><p>CentOS 7.x/8.x 或 RHEL 7.x/8.x 中：yum 命令使用 podman <code>rpm</code> 软件包安装  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo yum install -y podman-3.2.3-0.11.module_el8.4.0+942+d25aada8.x86_64</span><br><span class=\"line\"><span class=\"comment\"># 安装 podman 最新版本，低版本 podman 存在较多 bug。</span></span><br><span class=\"line\"><span class=\"comment\"># 注意：</span></span><br><span class=\"line\"><span class=\"comment\">#   1. 需配置 CentOS 8 的 yum 软件源以安装最新版的 podman 及其依赖软件包</span></span><br><span class=\"line\"><span class=\"comment\">#   2. yum 安装 podman 时也将安装 containernetworking-plugins 软件包</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>🤘 Ubuntu 20.04.2 LTS 中：apt-get 命令使用 podman <code>deb</code> 软件包安装  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ . /etc/os-release</span><br><span class=\"line\"><span class=\"comment\"># 查看当前的系统发行版</span></span><br><span class=\"line\">$ <span class=\"built_in\">echo</span> <span class=\"string\">\"deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_<span class=\"variable\">$&#123;VERSION_ID&#125;</span>/ /\"</span> | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list</span><br><span class=\"line\">$ curl -L <span class=\"string\">\"https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_<span class=\"variable\">$&#123;VERSION_ID&#125;</span>/Release.key\"</span> | sudo apt-key add -</span><br><span class=\"line\"><span class=\"comment\"># 添加 podman 软件源与 apt 公钥</span></span><br><span class=\"line\">$ sudo apt-get update -y</span><br><span class=\"line\">$ sudo apt-get upgrade -y</span><br><span class=\"line\"><span class=\"comment\"># 更新系统软件源并升级系统软件包</span></span><br><span class=\"line\">$ sudo apt-get install -y podman</span><br><span class=\"line\">  Reading package lists... Done</span><br><span class=\"line\">  Building dependency tree       </span><br><span class=\"line\">  Reading state information... Done</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  The following NEW packages will be installed:</span><br><span class=\"line\">    catatonit conmon containernetworking-plugins containers-common criu crun fuse-overlayfs fuse3 libfuse3-3 libnet1 libprotobuf-c1</span><br><span class=\"line\">    podman podman-machine-cni podman-plugins</span><br><span class=\"line\">  ...</span><br><span class=\"line\"><span class=\"comment\"># 安装 podman 与相关的软件包，包括 conmon、containernetworking-plugins、crun 等。</span></span><br></pre></td></tr></table></figure>\n<p>安装参考链接：  </p>\n<ul>\n<li><a href=\"https://podman.io/getting-started/installation\" target=\"_blank\" rel=\"noopener\">Podman Doc - installation</a></li>\n<li><a href=\"https://www.hostnextra.com/kb/easy-to-install-podman-on-ubuntu-20-04/\" target=\"_blank\" rel=\"noopener\">Easy to Install Podman on Ubuntu 20.04</a></li>\n<li><a href=\"https://software.opensuse.org//download.html?project=devel%3Akubic%3Alibcontainers%3Astable&amp;package=podman\" target=\"_blank\" rel=\"noopener\">podman from devel:kubic:libcontainers:stable project</a></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"🤘-Docker-与-Podman-进程管理方式比较：\"><a href=\"#🤘-Docker-与-Podman-进程管理方式比较：\" class=\"headerlink\" title=\"🤘 Docker 与 Podman 进程管理方式比较：\"></a>🤘 Docker 与 Podman 进程管理方式比较：</h3><ul>\n<li><p>Docker v20.10.8 使用 <code>dockerd</code> 与 <code>containerd</code> 守护进程管理容器与镜像的生命周期，运行状态如下所示： </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo systemctl status docker.service</span><br><span class=\"line\">● docker.service - Docker Application Container Engine</span><br><span class=\"line\">   Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled)</span><br><span class=\"line\">   Active: active (running) since Wed 2022-10-19 10:53:04 CST; 6min ago</span><br><span class=\"line\">     Docs: https://docs.docker.com</span><br><span class=\"line\"> Main PID: 79556 (dockerd)</span><br><span class=\"line\">    Tasks: 21</span><br><span class=\"line\">   Memory: 42.6M</span><br><span class=\"line\">   CGroup: /system.slice/docker.service</span><br><span class=\"line\">           ├─79556 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock</span><br><span class=\"line\">           ├─79677 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 4000 -container-ip 172.17.0.2 -container-port 4000</span><br><span class=\"line\">           └─79683 /usr/bin/docker-proxy -proto tcp -host-ip :: -host-port 4000 -container-ip 172.17.0.2 -container-port 4000</span><br><span class=\"line\"></span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.197803867+08:00\"</span> level=info msg=<span class=\"string\">\"scheme \\\"unix\\\" not registered, fallback to default scheme\"</span> module=grpc</span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.197837924+08:00\"</span> level=info msg=<span class=\"string\">\"ccResolverWrapper: sending update to cc: &#123;[&#123;unix:///run/containerd/containerd.sock  &lt;nil&gt; 0 &lt;nil&gt;&#125;] &lt;nil&gt; &lt;nil&gt;&#125;\"</span> module=grpc</span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.197860326+08:00\"</span> level=info msg=<span class=\"string\">\"ClientConn switching balancer to \\\"pick_first\\\"\"</span> module=grpc</span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.220416627+08:00\"</span> level=info msg=<span class=\"string\">\"Loading containers: start.\"</span></span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.347884960+08:00\"</span> level=info msg=<span class=\"string\">\"Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address\"</span></span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.725361851+08:00\"</span> level=info msg=<span class=\"string\">\"Loading containers: done.\"</span></span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.755449128+08:00\"</span> level=info msg=<span class=\"string\">\"Docker daemon\"</span> commit=75249d8 graphdriver(s)=overlay2 version=20.10.8</span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.755527994+08:00\"</span> level=info msg=<span class=\"string\">\"Daemon has completed initialization\"</span></span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com systemd[1]: Started Docker Application Container Engine.</span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.776865058+08:00\"</span> level=info msg=<span class=\"string\">\"API listen on /var/run/docker.sock\"</span></span><br><span class=\"line\"><span class=\"comment\"># dockerd 守护进程的运行状态</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ sudo systemctl status containerd</span><br><span class=\"line\">● containerd.service - containerd container runtime</span><br><span class=\"line\">   Loaded: loaded (/usr/lib/systemd/system/containerd.service; enabled; vendor preset: disabled)</span><br><span class=\"line\">   Active: active (running) since Tue 2022-10-18 15:08:06 CST; 20h ago</span><br><span class=\"line\">     Docs: https://containerd.io</span><br><span class=\"line\"> Main PID: 1892 (containerd)</span><br><span class=\"line\">    Tasks: 20</span><br><span class=\"line\">   Memory: 103.4M</span><br><span class=\"line\">   CGroup: /system.slice/containerd.service</span><br><span class=\"line\">           ├─ 1892 /usr/bin/containerd</span><br><span class=\"line\">           └─79696 /usr/bin/containerd-shim-runc-v2 -namespace moby -id 3ea752c1cce6a65b39af7f68c971186e020992514b663ab7a917f47da70450fa -address /run/containerd/containerd.sock</span><br><span class=\"line\"><span class=\"comment\"># containerd 通过调用 containerd-shim-runc-v2 运行指定容器</span></span><br><span class=\"line\">$ sudo ps -ef | grep -E <span class=\"string\">\"dockerd|containerd|containerd-shim-runc-v2\"</span></span><br><span class=\"line\">  root       1892      1  0 Oct18 ?        00:05:01 /usr/bin/containerd</span><br><span class=\"line\">  root      79556      1  0 10:53 ?        00:00:03 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock</span><br><span class=\"line\">  root      79696      1  0 10:53 ?        00:00:01 /usr/bin/containerd-shim-runc-v2 -namespace moby -id 3ea752c1cce6a65b39af7f68c971186e020992514b663ab7a917f47da70450fa -address /run/containerd/containerd.sock</span><br><span class=\"line\"><span class=\"comment\"># PID 79696 为实际的容器运行进程</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Podman 不使用守护进程的方式运行或管理容器，对于 rootfull 容器或 rootless 容器的运行方式存在差异：  </p>\n<ul>\n<li><p>rootfull 容器的进程：<br>👉 以交互式方式运行的容器进程状态如下所示：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo ps -ef | egrep <span class=\"string\">\"podman|slirp4netns|conmon\"</span></span><br><span class=\"line\">  root        3879    3476  1 06:31 pts/3    00:00:00 podman run -it --name=mydebian docker.io/library/debian:latest /bin/sh</span><br><span class=\"line\">  root        3945       1  0 06:31 ?        00:00:00 /usr/bin/conmon --api-version 1 -c 29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba -u 29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba -r /usr/bin/crun -b /var/lib/containers/storage/overlay-containers/29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba/userdata -p /run/containers/storage/overlay-containers/29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba/userdata/pidfile -n mydebian --<span class=\"built_in\">exit</span>-dir /run/libpod/exits --full-attach -s -l journald --<span class=\"built_in\">log</span>-level warning --runtime-arg --<span class=\"built_in\">log</span>-format=json --runtime-arg --<span class=\"built_in\">log</span> --runtime-arg=/run/containers/storage/overlay-containers/29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba/userdata/oci-log -t --conmon-pidfile /run/containers/storage/overlay-containers/29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba/userdata/conmon.pid --<span class=\"built_in\">exit</span>-command /usr/bin/podman --<span class=\"built_in\">exit</span>-command-arg --root --<span class=\"built_in\">exit</span>-command-arg /var/lib/containers/storage --<span class=\"built_in\">exit</span>-command-arg --runroot --<span class=\"built_in\">exit</span>-command-arg /run/containers/storage --<span class=\"built_in\">exit</span>-command-arg --<span class=\"built_in\">log</span>-level --<span class=\"built_in\">exit</span>-command-arg warning --<span class=\"built_in\">exit</span>-command-arg --cgroup-manager --<span class=\"built_in\">exit</span>-command-arg systemd --<span class=\"built_in\">exit</span>-command-arg --tmpdir --<span class=\"built_in\">exit</span>-command-arg /run/libpod --<span class=\"built_in\">exit</span>-command-arg --network-config-dir --<span class=\"built_in\">exit</span>-command-arg  --<span class=\"built_in\">exit</span>-command-arg --network-backend --<span class=\"built_in\">exit</span>-command-arg cni --<span class=\"built_in\">exit</span>-command-arg --volumepath --<span class=\"built_in\">exit</span>-command-arg /var/lib/containers/storage/volumes --<span class=\"built_in\">exit</span>-command-arg --runtime --<span class=\"built_in\">exit</span>-command-arg crun --<span class=\"built_in\">exit</span>-command-arg --storage-driver --<span class=\"built_in\">exit</span>-command-arg overlay --<span class=\"built_in\">exit</span>-command-arg --storage-opt --<span class=\"built_in\">exit</span>-command-arg overlay.mountopt=nodev,metacopy=on --<span class=\"built_in\">exit</span>-command-arg --events-backend --<span class=\"built_in\">exit</span>-command-arg journald --<span class=\"built_in\">exit</span>-command-arg container --<span class=\"built_in\">exit</span>-command-arg cleanup --<span class=\"built_in\">exit</span>-command-arg 29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba</span><br><span class=\"line\"><span class=\"comment\"># 由于具有交互式命令行运行依然保留 podman 进程</span></span><br></pre></td></tr></table></figure>\n<p>👉 以 <code>detach</code> 方式（后台）运行的容器进程状态如下所示：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo ps -ef | egrep <span class=\"string\">\"podman|slirp4netns|conmon\"</span></span><br><span class=\"line\">  root        3744       1  0 06:25 ?        00:00:00 /usr/bin/conmon --api-version 1 -c b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272 -u b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272 -r /usr/bin/crun -b /var/lib/containers/storage/overlay-containers/b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272/userdata -p /run/containers/storage/overlay-containers/b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272/userdata/pidfile -n apache-rhce8.2-alpine --<span class=\"built_in\">exit</span>-dir /run/libpod/exits --full-attach -s -l journald --<span class=\"built_in\">log</span>-level warning --runtime-arg --<span class=\"built_in\">log</span>-format=json --runtime-arg --<span class=\"built_in\">log</span> --runtime-arg=/run/containers/storage/overlay-containers/b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272/userdata/oci-log --conmon-pidfile /run/containers/storage/overlay-containers/b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272/userdata/conmon.pid --<span class=\"built_in\">exit</span>-command /usr/bin/podman --<span class=\"built_in\">exit</span>-command-arg --root --<span class=\"built_in\">exit</span>-command-arg /var/lib/containers/storage --<span class=\"built_in\">exit</span>-command-arg --runroot --<span class=\"built_in\">exit</span>-command-arg /run/containers/storage --<span class=\"built_in\">exit</span>-command-arg --<span class=\"built_in\">log</span>-level --<span class=\"built_in\">exit</span>-command-arg warning --<span class=\"built_in\">exit</span>-command-arg --cgroup-manager --<span class=\"built_in\">exit</span>-command-arg systemd --<span class=\"built_in\">exit</span>-command-arg --tmpdir --<span class=\"built_in\">exit</span>-command-arg /run/libpod --<span class=\"built_in\">exit</span>-command-arg --network-config-dir --<span class=\"built_in\">exit</span>-command-arg  --<span class=\"built_in\">exit</span>-command-arg --network-backend --<span class=\"built_in\">exit</span>-command-arg cni --<span class=\"built_in\">exit</span>-command-arg --volumepath --<span class=\"built_in\">exit</span>-command-arg /var/lib/containers/storage/volumes --<span class=\"built_in\">exit</span>-command-arg --runtime --<span class=\"built_in\">exit</span>-command-arg crun --<span class=\"built_in\">exit</span>-command-arg --storage-driver --<span class=\"built_in\">exit</span>-command-arg overlay --<span class=\"built_in\">exit</span>-command-arg --storage-opt --<span class=\"built_in\">exit</span>-command-arg overlay.mountopt=nodev,metacopy=on --<span class=\"built_in\">exit</span>-command-arg --events-backend --<span class=\"built_in\">exit</span>-command-arg journald --<span class=\"built_in\">exit</span>-command-arg container --<span class=\"built_in\">exit</span>-command-arg cleanup --<span class=\"built_in\">exit</span>-command-arg b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272</span><br><span class=\"line\"><span class=\"comment\"># podman 在调用 conmon 程序创建并运行容器后退出，而 rootfull 容器的 CNI 插件</span></span><br><span class=\"line\"><span class=\"comment\"># 可直接使用 iptables 的方式实现。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>rootless 容器的进程：<br>👉 以交互式方式运行的容器进程状态如下所示：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ps -ef | egrep <span class=\"string\">\"podman|slirp4netns|conmon\"</span></span><br><span class=\"line\">  core        3418    2762  0 06:17 pts/2    00:00:05 podman run -it --name=mybusybox docker.io/library/busybox:latest /bin/sh</span><br><span class=\"line\">  core        3430    3418  0 06:17 pts/2    00:00:00 /usr/bin/slirp4netns --<span class=\"built_in\">disable</span>-host-loopback --mtu=65520 --<span class=\"built_in\">enable</span>-sandbox --<span class=\"built_in\">enable</span>-seccomp --<span class=\"built_in\">enable</span>-ipv6 -c -e 3 -r 4 --netns-type=path /run/user/1000/netns/netns-19eb5630-c0a8-4ea9-8790-76ecdcdf2dbc tap0</span><br><span class=\"line\">  core        3433       1  0 06:17 ?        00:00:00 /usr/bin/conmon --api-version 1 -c 5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160 -u 5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160 -r /usr/bin/crun -b /var/home/core/.<span class=\"built_in\">local</span>/share/containers/storage/overlay-containers/5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160/userdata -p /run/user/1000/containers/overlay-containers/5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160/userdata/pidfile -n mybusybox --<span class=\"built_in\">exit</span>-dir /run/user/1000/libpod/tmp/exits --full-attach -s -l journald --<span class=\"built_in\">log</span>-level warning --runtime-arg --<span class=\"built_in\">log</span>-format=json --runtime-arg --<span class=\"built_in\">log</span> --runtime-arg=/run/user/1000/containers/overlay-containers/5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160/userdata/oci-log -t --conmon-pidfile /run/user/1000/containers/overlay-containers/5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160/userdata/conmon.pid --<span class=\"built_in\">exit</span>-command /usr/bin/podman --<span class=\"built_in\">exit</span>-command-arg --root --<span class=\"built_in\">exit</span>-command-arg /var/home/core/.<span class=\"built_in\">local</span>/share/containers/storage --<span class=\"built_in\">exit</span>-command-arg --runroot --<span class=\"built_in\">exit</span>-command-arg /run/user/1000/containers --<span class=\"built_in\">exit</span>-command-arg --<span class=\"built_in\">log</span>-level --<span class=\"built_in\">exit</span>-command-arg warning --<span class=\"built_in\">exit</span>-command-arg --cgroup-manager --<span class=\"built_in\">exit</span>-command-arg systemd --<span class=\"built_in\">exit</span>-command-arg --tmpdir --<span class=\"built_in\">exit</span>-command-arg /run/user/1000/libpod/tmp --<span class=\"built_in\">exit</span>-command-arg --network-config-dir --<span class=\"built_in\">exit</span>-command-arg  --<span class=\"built_in\">exit</span>-command-arg --network-backend --<span class=\"built_in\">exit</span>-command-arg netavark --<span class=\"built_in\">exit</span>-command-arg --volumepath --<span class=\"built_in\">exit</span>-command-arg /var/home/core/.<span class=\"built_in\">local</span>/share/containers/storage/volumes --<span class=\"built_in\">exit</span>-command-arg --runtime --<span class=\"built_in\">exit</span>-command-arg crun --<span class=\"built_in\">exit</span>-command-arg --storage-driver --<span class=\"built_in\">exit</span>-command-arg overlay --<span class=\"built_in\">exit</span>-command-arg --events-backend --<span class=\"built_in\">exit</span>-command-arg journald --<span class=\"built_in\">exit</span>-command-arg container --<span class=\"built_in\">exit</span>-command-arg cleanup --<span class=\"built_in\">exit</span>-command-arg 5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160</span><br><span class=\"line\"><span class=\"comment\"># 由于具有交互式命令行运行依然保留 podman 进程，并且由 podman 进程创建 slirp4netns 子进程</span></span><br><span class=\"line\"><span class=\"comment\"># 用于 rootless 容器的网络命名空间之间的通信。</span></span><br><span class=\"line\">``` </span><br><span class=\"line\">👉 以 `detach` 方式（后台）运行的容器进程状态如下所示：   </span><br><span class=\"line\">```bash</span><br><span class=\"line\">$ ps -ef | egrep <span class=\"string\">\"podman|slirp4netns|conmon\"</span></span><br><span class=\"line\">  core        3308       1  0 06:15 pts/2    00:00:00 /usr/bin/slirp4netns --<span class=\"built_in\">disable</span>-host-loopback --mtu=65520 --<span class=\"built_in\">enable</span>-sandbox --<span class=\"built_in\">enable</span>-seccomp --<span class=\"built_in\">enable</span>-ipv6 -c -e 3 -r 4 --netns-type=path /run/user/1000/netns/netns-f9f6f9dd-bf80-f6ca-6f39-7c9d9cd6beea tap0</span><br><span class=\"line\">  core        3325       1  0 06:15 ?        00:00:00 /usr/bin/conmon --api-version 1 -c 91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab -u 91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab -r /usr/bin/crun -b /var/home/core/.<span class=\"built_in\">local</span>/share/containers/storage/overlay-containers/91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab/userdata -p /run/user/1000/containers/overlay-containers/91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab/userdata/pidfile -n apache-rhce8.2-alpine --<span class=\"built_in\">exit</span>-dir /run/user/1000/libpod/tmp/exits --full-attach -s -l journald --<span class=\"built_in\">log</span>-level warning --runtime-arg --<span class=\"built_in\">log</span>-format=json --runtime-arg --<span class=\"built_in\">log</span> --runtime-arg=/run/user/1000/containers/overlay-containers/91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab/userdata/oci-log --conmon-pidfile /run/user/1000/containers/overlay-containers/91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab/userdata/conmon.pid --<span class=\"built_in\">exit</span>-command /usr/bin/podman --<span class=\"built_in\">exit</span>-command-arg --root --<span class=\"built_in\">exit</span>-command-arg /var/home/core/.<span class=\"built_in\">local</span>/share/containers/storage --<span class=\"built_in\">exit</span>-command-arg --runroot --<span class=\"built_in\">exit</span>-command-arg /run/user/1000/containers --<span class=\"built_in\">exit</span>-command-arg --<span class=\"built_in\">log</span>-level --<span class=\"built_in\">exit</span>-command-arg warning --<span class=\"built_in\">exit</span>-command-arg --cgroup-manager --<span class=\"built_in\">exit</span>-command-arg systemd --<span class=\"built_in\">exit</span>-command-arg --tmpdir --<span class=\"built_in\">exit</span>-command-arg /run/user/1000/libpod/tmp --<span class=\"built_in\">exit</span>-command-arg --network-config-dir --<span class=\"built_in\">exit</span>-command-arg  --<span class=\"built_in\">exit</span>-command-arg --network-backend --<span class=\"built_in\">exit</span>-command-arg netavark --<span class=\"built_in\">exit</span>-command-arg --volumepath --<span class=\"built_in\">exit</span>-command-arg /var/home/core/.<span class=\"built_in\">local</span>/share/containers/storage/volumes --<span class=\"built_in\">exit</span>-command-arg --runtime --<span class=\"built_in\">exit</span>-command-arg crun --<span class=\"built_in\">exit</span>-command-arg --storage-driver --<span class=\"built_in\">exit</span>-command-arg overlay --<span class=\"built_in\">exit</span>-command-arg --events-backend --<span class=\"built_in\">exit</span>-command-arg journald --<span class=\"built_in\">exit</span>-command-arg container --<span class=\"built_in\">exit</span>-command-arg cleanup --<span class=\"built_in\">exit</span>-command-arg 91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab</span><br><span class=\"line\"><span class=\"comment\"># podman 在调用 conmon 程序创建并运行容器后退出，并且由 podman 进程创建 slirp4netns 子进程</span></span><br><span class=\"line\"><span class=\"comment\"># 用于 rootless 容器的网络命名空间之间的通信。</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Podman-的网络实现原理（rootfull-与-rootless）：\"><a href=\"#Podman-的网络实现原理（rootfull-与-rootless）：\" class=\"headerlink\" title=\"Podman 的网络实现原理（rootfull 与 rootless）：\"></a>Podman 的网络实现原理（rootfull 与 rootless）：</h3><ul>\n<li>Podman 支持的容器网络模式如下所示：<br><img src=\"podman-network-mode.jpg\" alt=\"podman-network-mode.jpg\"></li>\n<li><p>root 用户运行 rootfull 容器网络分析：  </p>\n<ul>\n<li>默认情况下，rootfull 容器使用 bridge 网络模式，并且在未创建任何容器前系统上不会自动创建 <code>cni-podman0</code>网桥，只有创建容器后自动生成。  </li>\n<li><p>root 用户使用全局范围内的 CNI 插件，podman 默认使用 <code>bridge</code>、<code>portmap</code> 插件，其配置文件如下：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cat /etc/cni/net.d/87-podman-bridge.conflist</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"cniVersion\"</span>: <span class=\"string\">\"0.4.0\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"name\"</span>: <span class=\"string\">\"podman\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"plugins\"</span>: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"type\"</span>: <span class=\"string\">\"bridge\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"bridge\"</span>: <span class=\"string\">\"cni-podman0\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"isGateway\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">      <span class=\"string\">\"ipMasq\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">      <span class=\"string\">\"hairpinMode\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">      <span class=\"string\">\"ipam\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">\"type\"</span>: <span class=\"string\">\"host-local\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"routes\"</span>: [&#123; <span class=\"string\">\"dst\"</span>: <span class=\"string\">\"0.0.0.0/0\"</span> &#125;],</span><br><span class=\"line\">        <span class=\"string\">\"ranges\"</span>: [</span><br><span class=\"line\">          [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">              <span class=\"string\">\"subnet\"</span>: <span class=\"string\">\"10.88.0.0/16\"</span>,</span><br><span class=\"line\">              <span class=\"string\">\"gateway\"</span>: <span class=\"string\">\"10.88.0.1\"</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">          ]</span><br><span class=\"line\">        ]</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"type\"</span>: <span class=\"string\">\"portmap\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"capabilities\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">\"portMappings\"</span>: <span class=\"literal\">true</span></span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"type\"</span>: <span class=\"string\">\"firewall\"</span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"type\"</span>: <span class=\"string\">\"tuning\"</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\"><span class=\"comment\"># 该配置文件位于 Podman 源码 cni/87-podman-bridge.conflist</span></span><br><span class=\"line\"><span class=\"comment\"># Podman 可调用 bridge、portmap 等 CNI 插件</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ sudo podman inspect &lt;container_name&gt; | jq .[0].HostConfig.NetworkMode</span><br><span class=\"line\">  <span class=\"string\">\"bridge\"</span></span><br><span class=\"line\"><span class=\"comment\"># root 用户创建的容器网络模式</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>root 用户创建具有端口映射的容器时，iptables filter 表与 nat 表规则将相应增加：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># ----- filter 表中创建新容器后的新增规则 -----</span></span><br><span class=\"line\">*filter</span><br><span class=\"line\">-A FORWARD -m comment --comment <span class=\"string\">\"CNI firewall plugin rules\"</span> -j CNI-FORWARD</span><br><span class=\"line\">-A CNI-FORWARD -m comment --comment <span class=\"string\">\"CNI firewall plugin admin overrides\"</span> -j CNI-ADMIN</span><br><span class=\"line\">-A CNI-FORWARD -d 10.88.0.3/32 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT</span><br><span class=\"line\"><span class=\"comment\"># 新增规则：允许 3 层转发目标地址为 10.88.0.3 的流量（进入容器的流量），conntrack 模块进行连接状态追踪。</span></span><br><span class=\"line\"><span class=\"comment\"># 当容器通过 MASQUERADE 对外访问，回包再次进入容器宿主机时不再通过 DNAT 转发，而通过 conntrack </span></span><br><span class=\"line\"><span class=\"comment\"># 记录的连接状态直接转发至该规则并通过 cni-podman0 网桥进入容器。</span></span><br><span class=\"line\">-A CNI-FORWARD -s 10.88.0.3/32 -j ACCEPT</span><br><span class=\"line\"><span class=\"comment\"># 新增规则：允许 3 层转发源地址为 10.88.0.3 的流量（出容器的流量）。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ----- nat 表中创建新容器后的新增规则 -----</span></span><br><span class=\"line\">*nat</span><br><span class=\"line\">-A PREROUTING -m addrtype --dst-type LOCAL -j CNI-HOSTPORT-DNAT</span><br><span class=\"line\">-A POSTROUTING -m comment --comment <span class=\"string\">\"CNI portfwd requiring masquerade\"</span> -j CNI-HOSTPORT-MASQ</span><br><span class=\"line\">-A POSTROUTING -s 10.88.0.3/32 -m comment --comment <span class=\"string\">\"name: \\\"podman\\\" id: \\\"2d2b3521457cb1d9b7ae6657304d05789a854e7a48916276a40da543df9aa217\\\"\"</span> -j CNI-b6c5fb6c593e895d843cb5bd</span><br><span class=\"line\"><span class=\"comment\"># 新增规则：来自于 10.88.0.3 容器的流量转发至 CNI-b6c5fb6c593e895d843cb5bd 链</span></span><br><span class=\"line\">-A OUTPUT -m addrtype --dst-type LOCAL -j CNI-HOSTPORT-DNAT</span><br><span class=\"line\"><span class=\"comment\"># 启用 CNI 后即创建的规则，该规则接收来自本地应用的流量并转发至 CNI-HOSTPORT-DNAT 链</span></span><br><span class=\"line\">-A CNI-HOSTPORT-SETMARK -m comment --comment <span class=\"string\">\"CNI portfwd masquerade mark\"</span> -j MARK --<span class=\"built_in\">set</span>-xmark 0x2000/0x2000</span><br><span class=\"line\">-A CNI-HOSTPORT-MASQ -m mark --mark 0x2000/0x2000 -j MASQUERADE</span><br><span class=\"line\"><span class=\"comment\">### 以下 6 条在创建新容器时同时创建 </span></span><br><span class=\"line\">-A CNI-HOSTPORT-DNAT -p tcp -m comment --comment <span class=\"string\">\"dnat name: \\\"podman\\\" id: \\\"2d2b3521457cb1d9b7ae6657304d05789a854e7a48916276a40da543df9aa217\\\"\"</span> -m multiport --dports 8843 -j CNI-DN-b6c5fb6c593e895d843cb</span><br><span class=\"line\"><span class=\"comment\"># 自定义 DNAT 链，发送至本地 8843 端口的流量转发至 CNI-DN-b6c5fb6c593e895d843cb 链。</span></span><br><span class=\"line\">-A CNI-b6c5fb6c593e895d843cb5bd -d 10.88.0.0/16 -m comment --comment <span class=\"string\">\"name: \\\"podman\\\" id: \\\"2d2b3521457cb1d9b7ae6657304d05789a854e7a48916276a40da543df9aa217\\\"\"</span> -j ACCEPT</span><br><span class=\"line\"><span class=\"comment\"># 允许转发目标网段为 10.88.0.0/16 的流量（进入容器的流量），该网段为容器所在的网络。</span></span><br><span class=\"line\">-A CNI-b6c5fb6c593e895d843cb5bd ! -d 224.0.0.0/4 -m comment --comment <span class=\"string\">\"name: \\\"podman\\\" id: \\\"2d2b3521457cb1d9b7ae6657304d05789a854e7a48916276a40da543df9aa217\\\"\"</span> -j MASQUERADE</span><br><span class=\"line\"><span class=\"comment\"># MASQUERADE 出容器流量</span></span><br><span class=\"line\">-A CNI-DN-b6c5fb6c593e895d843cb -s 10.88.0.0/16 -p tcp -m tcp --dport 8843 -j CNI-HOSTPORT-SETMARK</span><br><span class=\"line\">-A CNI-DN-b6c5fb6c593e895d843cb -s 127.0.0.1/32 -p tcp -m tcp --dport 8843 -j CNI-HOSTPORT-SETMARK</span><br><span class=\"line\">-A CNI-DN-b6c5fb6c593e895d843cb -p tcp -m tcp --dport 8843 -j DNAT --to-destination 10.88.0.3:443</span><br><span class=\"line\"><span class=\"comment\"># 自定义 DNAT 链实现容器宿主机至容器的端口映射</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>🚀 示例：外部访问容器内 Web 服务时，涉及的宿主机 iptables：<br><img src=\"external-access-container-web-service-iptables.jpg\" alt=\"external-access-container-web-service-iptables.jpg\">从外部访问容器内 Web 服务时，流量将通过 PREROUTING 链及自定义链（<code>CNI-HOSTPORT-DNAT</code>、<code>CNI-DN-xxxx</code>、<code>DNAT</code>），经由 FORWARD 链及自定义链（<code>CNI-FORWARD</code>）的三层转发与 <code>cni-podman0</code> 网桥的二层转发进入容器，容器对外响应的流量将经过 cni-podman0 网桥转发，并经过 CNI-FORWARD 链与 POSTROUTING 链及自定义链（<code>CNI-HOSTPORT-MASQ</code>）出容器宿主机。  </p>\n</li>\n<li><p>🚀 示例：直接从容器内访问外部时，返回容器的回包将直接使用 conntrack 模块追踪的连接状态，流量通过 <code>CNI-FORWARD</code> 链的三层转发与 cni-podman0 的二层转发至容器中，即，回包进入容器宿主机不再通过<code>CNI-HOSTPORT-DNAT</code>链。<br>如下所示，相关的 DNAT 链无流量通过（蓝框），CNI-FORWARD 链均有流量通过（蓝框）。<br><img src=\"container-access-external-iptables.jpg\" alt=\"container-access-external-iptables.jpg\"></p>\n<blockquote>\n<p>📌 <strong>Kubernetes 相关问题提示：</strong></p>\n<ol>\n<li>容器或 pod 通过 cni 网桥桥接的方式在 Kubernetes 或 OpenShift3 中需在计算节点（worker node）上配置 <code>net.bridge.bridge-nf-call-iptables</code> 与 <code>net.bridge.bridge-nf-call-iptables6</code> 内核参数，使 cni 二层网桥可调用 iptables 的 conntrack 模块，以解决前后端 pod 在同一节点上时，由于 pod 直连 cni 二层网桥，而二层网桥只实现二层转发，无法追踪前后端的连接状态，造成后端 pod 向前端 pod 回包时无法处于同一连接链路的问题，可 <a href=\"https://imroc.cc/k8s/faq/why-enable-bridge-nf-call-iptables/\" target=\"_blank\" rel=\"noopener\">点击此处</a> 获得更多帮助。</li>\n<li>使用以上内核参数时，需加载 <code>br_netfilter</code> 内核模块方能生效。</li>\n</ol>\n</blockquote>\n</li>\n<li><p>使用 <code>iperf3</code> 工具的容器测试不同 rootfull 容器之间的网络性能，如下所示：<br><img src=\"rootfull-container-to-container-bandwidth.jpg\" alt=\"rootfull-container-to-container-bandwidth.jpg\"></p>\n</li>\n</ul>\n</li>\n<li><p>普通用户运行 rootless 容器网络分析：  </p>\n<ul>\n<li><code>slirp4netns</code> 程序支持 user rootless network namespace，而非通过 <code>iptables</code> 与 CNI 实现。  </li>\n<li><p>👉 普通用户使用端口映射运行 rootless 容器时，默认情况下只能使用宿主机 1024 以上的端口实现映射，但可使用 <code>net.ipv4.ip_unprivileged_port_start</code> 内核参数实现低于 1024 的端口开始映射，如下所示：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">### 方式 1：###</span></span><br><span class=\"line\">$ sysctl -w net.ipv4.ip_unprivileged_port_start=80</span><br><span class=\"line\"><span class=\"comment\"># 临时配置：允许普通用户从 80 端口开始的端口映射运行 rootless 容器</span></span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\">### 方式 2：###</span></span><br><span class=\"line\">$ <span class=\"built_in\">echo</span> <span class=\"string\">\"net.ipv4.ip_unprivileged_port_start=80\"</span> &gt;&gt; /etc/sysctl.d/rootless.conf</span><br><span class=\"line\"><span class=\"comment\"># 永久配置：将该内核参数写入内核参数配置文件，使其开机永久生效。</span></span><br><span class=\"line\">$ sysctl -p</span><br><span class=\"line\"><span class=\"comment\"># 使配置的内核参数生效</span></span><br><span class=\"line\"></span><br><span class=\"line\"> - 普通用户创建的容器网络模式为 `slirp4netns`（slirp4netns 软件包实现）。    </span><br><span class=\"line\">    ```bash</span><br><span class=\"line\">    $ podman inspect &lt;container_name&gt; | jq .[0].HostConfig.NetworkMode</span><br><span class=\"line\">      <span class=\"string\">\"slirp4netns\"</span></span><br><span class=\"line\">    <span class=\"comment\"># 普通用户创建的 rootless 容器网络模式</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>每个普通用户运行 rootless 容器都将生成 slirp4netns 进程用于隔离该用户的 <code>network namespace</code>，以下分别使用 godev 与 hualf 用户运行 rootless 容器：<br><img src=\"godev-rootless-container.jpg\" alt=\"godev-rootless-container.jpg\"><img src=\"hualf-rootless-container.jpg\" alt=\"hualf-rootless-container.jpg\"> </p>\n</li>\n<li>slirp4netns 实现的网络模式与带宽比较：<br><img src=\"rootless-slirp4netns-networking.jpg\" alt=\"rootless-slirp4netns-networking.jpg\"> </li>\n<li>使用 <code>iperf3</code> 工具的容器测试不同 rootless 容器之间的网络性能，如下所示：<br><img src=\"rootless-container-to-container-bandwidth.jpg\" alt=\"rootless-container-to-container-bandwidth.jpg\">对比 rootfull 容器之间的网络性能来看，slirp4netns 实现的 rootless 容器在不同的网络命名空间内的通信性能损耗较大，而 rootfull 容器之间的网络性能相比前者在此次测试中高出近 5 倍。 </li>\n<li>关于 slirp4netns 更加详细的内容，请参考 <a href=\"https://github.com/rootless-containers/slirp4netns\" target=\"_blank\" rel=\"noopener\">Github 项目</a>。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Podman-的-macvlan-网络实现：\"><a href=\"#Podman-的-macvlan-网络实现：\" class=\"headerlink\" title=\"Podman 的 macvlan 网络实现：\"></a>Podman 的 macvlan 网络实现：</h3><ul>\n<li><code>macvlan</code> 作为 CNI 在 Kubernetes 与 OpenShift v4 中作为 <code>Multus CNI</code> 支持的额外插件类型使用愈加广泛，集群中除了常规使用的 Flannel、Calico 等作为 <code>slow path</code> 的插件外，要求高性能的业务流量可使用 macvlan 直连 pod 宿主机物理网口实现 <code>fast path</code>。</li>\n<li>为后续熟悉以上场景的实现，因此在 Podman <code>rootfull</code> 容器中使用 macvlan 网络模式。</li>\n<li>关于 macvlan 的基础知识可参考 <a href=\"https://mp.weixin.qq.com/s?__biz=MzU1MzY4NzQ1OA==&amp;mid=2247484064&amp;idx=1&amp;sn=ffd745069b6c4aeac0589de00467b2f2&amp;chksm=fbee426dcc99cb7bdf26f5e6a21bbeaebba7ccd384a02f850d4461ea92331ed140edf98ffaec&amp;mpshare=1&amp;scene=1&amp;srcid=03049MKwF55OVgEZ4OCH39wd&amp;sharer_sharetime=1583337046541&amp;sharer_shareid=8eaca72194dae7b3d51d5c708436eee4#rd\" target=\"_blank\" rel=\"noopener\">Linux 虚拟网卡技术：Macvlan</a> 与 <a href=\"https://cizixs.com/2017/02/14/network-virtualization-macvlan/\" target=\"_blank\" rel=\"noopener\">linux 网络虚拟化：macvlan</a></li>\n<li><p>macvlan 特性由 <code>Linux kernel</code> 支持，笔者的实验环境满足 macvlan 的要求，请使用如下命令确定：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo lsmod | grep macvlan</span><br><span class=\"line\"><span class=\"comment\"># 若无任何返回，说明还未加载 macvlan 内核模块。</span></span><br><span class=\"line\">$ sudo modprobe macvlan</span><br><span class=\"line\"><span class=\"comment\"># 加载 macvlan 内核模块，若执行报错，说明 kernel 不支持该特性。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>podman 与 macvlan 类型网络的集成，如下所示：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo podman network create -d macvlan -o parent=ens33 &lt;network_name&gt;</span><br><span class=\"line\">  /etc/cni/net.d/&lt;network_name&gt;.conflist</span><br><span class=\"line\"><span class=\"comment\"># 创建 macvlan 类型网络  </span></span><br><span class=\"line\">$ sudo podman network ls</span><br><span class=\"line\">$ sudo /opt/cni/bin/dhcp daemon</span><br><span class=\"line\"><span class=\"comment\"># 在另一个窗口中启动 dhcp 守护进程供 macvlan 插件调用，为容器网口分配 IP 地址。</span></span><br><span class=\"line\">$ sudo podman run -it --rm \\</span><br><span class=\"line\">  --name &lt;container_name&gt; --network=&lt;network_name&gt; \\</span><br><span class=\"line\">  &lt;container_image&gt;:&lt;tag&gt; /bin/sh</span><br><span class=\"line\"><span class=\"comment\"># 创建支持 macvlan 类型网络的 rootfull 容器</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>从与 rootfull 容器在同一广播域的其他节点上 ping 该容器，可正常通信：<br><img src=\"podman-macvlan-network.png\" alt=\"podman-macvlan-network.png\"></p>\n<blockquote>\n<p>🤔 以上示例的容器中运行 Web 服务（可暴露 443 端口），使用 macvlan 网络模式可打通与同一广播域中外部节点的通信，但无法访问其中的服务，可采取何种方法解决该问题？  </p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"Podman-rootless-容器用户映射实现方式：\"><a href=\"#Podman-rootless-容器用户映射实现方式：\" class=\"headerlink\" title=\"Podman rootless 容器用户映射实现方式：\"></a>Podman rootless 容器用户映射实现方式：</h3><ul>\n<li>Podman rootless 容器的实现核心在于解决 network namespace（NetNS） 与 user namespace（UserNS） 的问题，前文已介绍 NetNS 的实现方式，后文将介绍 UserNS 的实现方式。</li>\n<li><p>若要使用 rootless 容器，需确认 OS 是否开启 user namespace 功能：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo sysctl -a | grep user\\.max_user_namespaces</span><br><span class=\"line\">  user.max_user_namespaces = 47494</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>系统上每创建一个用户就会在 <code>/etc/subuid</code> 与 <code>/etc/subgid</code> 中生成对应用户在其用户命名空间中的映射规则，以 /etc/subuid 为例，参数以冒号分隔，每个参数含义如下所示：  </p>\n<ul>\n<li>第一个参数（uid）：用户名称  </li>\n<li>第二个参数（loweruid）：用户命名空间中起始的映射 uid</li>\n</ul>\n</li>\n<li>第三个参数（count）：用户命名空间内部与外部可映射 uid 数量（可理解为所有容器普通用户的 uid 数量和）<br><img src=\"rootless-user-namespace-mapping.jpg\" alt=\"rootless-user-namespace-mapping.jpg\"></li>\n<li>以上两个文件允许运行进程的 uid 映射范围，在 <code>/proc/&lt;pid&gt;/uid_map</code> 中定义。</li>\n<li>可过滤容器 <code>conmon</code> 进程的 pid 确认每个容器中的 uid 映射情况，参见以下示例。</li>\n<li>关于以上两个文件的具体说明可参考 <code>newuidmap</code> 与 <code>newgidmap</code> 命令的 man 手册。</li>\n<li><p>可参考 Podman 官方推荐的命令创建 uid 的映射，如下所示：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo usermod --add-subuids 10000-75535 $(whoami)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ----- 示例 -----</span></span><br><span class=\"line\">$ sudo cat /etc/subuid</span><br><span class=\"line\">  appuser:10000:500</span><br><span class=\"line\">$ sudo cat /etc/subgid</span><br><span class=\"line\">  appuser:500:50</span><br><span class=\"line\"><span class=\"comment\"># 该用户创建的 user namespace 中可以使用从 10000 开始的 500 个 UID 和从 500 开始的 50 个 GID 的映射。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>🚀 示例：<br>普通用户 hualf 在 /etc/subuid 中映射为 hualf:165536:65536，说明在该用户的用户命名空间中可嵌套一个或多个用户命名空间（或容器），每个容器中的 root 用户 uid 0 都映射为 hualf 用户的 uid 1001（运行容器进程的用户），而容器中普通用户的 uid 映射至宿主机的 subuid 范围中，对于此例 subuid 范围为 165536~231071，容器中的 uid 1 用户映射为宿主机 uid 165536，因此容器中 admin 用户 uid 1000 映射为宿主机 uid 166535（165536+999）。<br>通过容器宿主机上每个普通用户的用户命名空间的 subuid 映射范围，可分配众多 uid 在 rootless 容器中运行应用进程。<br><img src=\"user-namespace-subuid-mapping-1-edited.png\" alt=\"user-namespace-subuid-mapping-1-edited.png\"><img src=\"user-namespace-subuid-mapping-2-edited.png\" alt=\"user-namespace-subuid-mapping-2-edited.png\"></p>\n</li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://projectatomic.io/blog/2018/02/reintroduction-podman/\" target=\"_blank\" rel=\"noopener\">Reintroduction of Podman</a></li>\n<li><a href=\"https://fedoramagazine.org/podman-pods-fedora-containers/\" target=\"_blank\" rel=\"noopener\">Using pods with Podman on Fedora</a></li>\n<li><a href=\"https://www.redhat.com/sysadmin/container-networking-podman\" target=\"_blank\" rel=\"noopener\">Configuring container networking with Podman</a></li>\n<li><a href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/building_running_and_managing_containers/index\" target=\"_blank\" rel=\"noopener\">RedHat docs - Building, running, and managing Linux containers on Red Hat Enterprise Linux 8</a></li>\n<li><a href=\"https://developer.aliyun.com/article/700923\" target=\"_blank\" rel=\"noopener\">容器安全拾遗 - Rootless Container初探</a></li>\n<li><a href=\"https://www.kernel.org/doc/html/latest/admin-guide/sysctl/user.html\" target=\"_blank\" rel=\"noopener\">Documentation for /proc/sys/user/</a></li>\n<li><a href=\"https://docs.docker.com/compose/\" target=\"_blank\" rel=\"noopener\">docker docs - Overview of Docker Compose</a></li>\n<li><a href=\"https://www.cni.dev/plugins/current/meta/firewall/\" target=\"_blank\" rel=\"noopener\">CNI docs - firewall plugin</a></li>\n<li><a href=\"https://www.cni.dev/plugins/current/meta/firewall/\" target=\"_blank\" rel=\"noopener\">CNI docs - Port-mapping plugin</a></li>\n<li><a href=\"https://fossies.org/linux/podman/docs/tutorials/basic_networking.md\" target=\"_blank\" rel=\"noopener\">https://fossies.org/linux/podman/docs/tutorials/basic_networking.md</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li>实验用 OS 版本：  <ul>\n<li>CentOS 7.9、RHEL 8.0、RHEL 8.2、Ubuntu 20.04.3 LTS</li>\n</ul>\n</li>\n<li>实验用 kernel 版本：  <ul>\n<li>3.10.0-1160.41.1.el7.x86_64  </li>\n<li>4.18.0-193.el8.x86_64  </li>\n<li>5.14.0-1.el7.elrepo.x86_64</li>\n</ul>\n</li>\n<li>实验用 Podman 版本：1.6.4、3.2.3、3.3.1</li>\n<li>实验用 podman-compose 版本：0.1.8</li>\n<li>实验用 Docker 版本：20.10.8</li>\n<li>若未做特殊说明，以下示例均于 <code>RHEL 8.2</code>（<code>4.18.0-193.el8.x86_64</code>）上执行，Podman 版本为 <code>3.2.3</code>。</li>\n<li>该文档中未涉及 podman 命令的基础使用方法，可参阅 <a href=\"https://mp.weixin.qq.com/s/MDi4RB5V60EGl3ii9usD0Q\" target=\"_blank\" rel=\"noopener\">该文档</a> 加以熟悉。</li>\n<li>💥 重要提示：Podman 项目正在不断演进与完善中，请以自身使用的版本为准进行测试与使用！</li>\n</ul>\n<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>Podman 的特性概述</li>\n<li>Podman 版本兼容性比较</li>\n<li>Podman 的扩展功能</li>\n<li>Podman 在不同 OS 版本中的安装</li>\n<li>Docker 与 Podman 进程管理方式比较</li>\n<li>Podman 的网络实现原理（rootfull 与 rootless）</li>\n<li>Podman 的 macvlan 网络实现</li>\n<li>Podman rootless 容器用户映射实现方式</li>\n<li>参考链接</li>\n</ul>\n<h3 id=\"Podman-的特性概述：\"><a href=\"#Podman-的特性概述：\" class=\"headerlink\" title=\"Podman 的特性概述：\"></a>Podman 的特性概述：</h3><ul>\n<li>LXC、<code>LXD</code>（Go 语言开发）、<code>systemd-nspawn</code> 均可作为 Linux 容器，但缺少容器跨主机运行与应用打包的能力。</li>\n<li>Docker 与 Podman 可使用容器镜像实现应用打包发布，快速且轻量。</li>\n<li>Docker 与 Podman 都使用 <code>runC</code>（Go 语言开发）作为底层 <code>oci-runtime</code>。</li>\n<li>Docker 与 Podman 都支持 <code>OCI Image Format</code>（Go 语言开发），都能使用 DockerHub 上的容器镜像，而 systemd-nspawn 无法使用它们的镜像。</li>\n<li>👉 Podman 使用 <code>CNI</code>（Go 语言开发）作为 rootfull 容器网络底层，实现比 Docker 网络层略微简单但原理相同。</li>\n<li>相对于 LXD 与 systemd-nspawn，CNI 可以避免编写大量的网络规则。</li>\n<li>🚀 为了实现普通用户 rootless 容器网络，Podman 可以使用 <code>slirp4netns</code> 程序，避免 <code>kernel space</code> 中的大量 <code>veth pair</code> 虚拟接口的出现, 并且性能更好。</li>\n<li>Docker 运行容器必须使用守护进程且使用 root 权限，存在系统安全问题，而 Podman 针对此问题使用以下两个特性加以解决，如下所示：  <ul>\n<li>Podman 支持无守护进程（<code>no-daemon</code>）运行容器。  </li>\n<li>Podman 支持普通用户运行 <code>rootless</code> 容器，即，普通用户直接运行容器无需提权具有 root 权限。</li>\n</ul>\n</li>\n<li>虽然 Docker 与 Podman 的实现原理不同，但对于使用者而言其 CLI 十分相似，可平滑地从 Docker 过渡至 Podman。</li>\n<li>Podman 的目标不是容器的编排，编排可以使用更加专业的 Kubernetes、Open Shift、Rancher 等，使用 Podman 可以更轻量的运行容器且不受 root 权限的安全问题，即便是 root 用户也无法查看其它普通用户空间下的容器，Podman 通过 <code>user namespace</code> 进行隔离。</li>\n<li>👉 Podman 可使用 <code>systemd service</code> 单元文件直接管理容器，实现容器服务随系统启动而启动。</li>\n<li>👉 Podman 里集成了 <code>CRIU</code>，因此 Podman 中的容器可以在单机上热迁移。</li>\n<li>由于 Kubernetes 将从 <code>v1.24.x</code> 版本后放弃使用 <code>dockershim</code> 接口层，容器运行时可选择使用 <code>Containerd</code> 或者 <code>CRI-O</code>，两者虽然均支持 OCI image 规范，但它们不是面向使用者或开发者直接管理容器或镜像的工具，而 Podman 可直接面向使用者或开发者操作容器或镜像。</li>\n<li>Podman 命令的子进程创建 pod 与容器。</li>\n</ul>\n<h3 id=\"Podman-版本兼容性比较：\"><a href=\"#Podman-版本兼容性比较：\" class=\"headerlink\" title=\"Podman 版本兼容性比较：\"></a>Podman 版本兼容性比较：</h3><ul>\n<li>Podman 版本、kernel 版本与 OS 版本的兼容性将直接影响普通用户使用 rootless 容器。</li>\n<li><p>如下所示，kernel 不支持 rootless 容器：<br><img src=\"centos79-kernel-not-support-podman-rootless.jpg\" alt=\"centos79-kernel-not-support-podman-rootless.jpg\"></p>\n</li>\n<li><p>普通用户 rootless 容器兼容性比较：<br><img src=\"podman-version-compare.png\" alt=\"podman-version-compare.png\"></p>\n<blockquote>\n<p>📌<strong>注意：</strong></p>\n<p>rootless 容器特性取决于 kernel 的版本，不取决于 OS 与 Podman 的版本。</p>\n</blockquote>\n<ul>\n<li>由于 <code>user namespace</code> 特性在 kernel <code>4.9.0</code> 之后出现，因此升级 kernel 即可解决 rootless 问题。</li>\n<li>关于 rootless 特性在 RHEL 8 中的设置，可 <a href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/building_running_and_managing_containers/assembly_starting-with-containers_building-running-and-managing-containers#proc_setting-up-rootless-containers_assembly_starting-with-containers\" target=\"_blank\" rel=\"noopener\">点击此处</a> 参考 Red Hat 的官方配置说明。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Podman-的扩展功能：\"><a href=\"#Podman-的扩展功能：\" class=\"headerlink\" title=\"Podman 的扩展功能：\"></a>Podman 的扩展功能：</h3><ul>\n<li><p><code>cockpit-podman</code> 软件包作为 cockpit 插件可集成于 <code>Web UI</code> 中，实现 Web UI 管理容器。  </p>\n<ul>\n<li><p>cockpit-podman 服务安装与启用：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo yum install -y cockpit-podman</span><br><span class=\"line\">$ sudo systemctl <span class=\"built_in\">enable</span> --now cockpit.socket</span><br><span class=\"line\">$ sudo systemctl status cockpit.service</span><br><span class=\"line\"><span class=\"comment\"># 安装 cockpit-podman 软件包，并启用 cockpit 服务。</span></span><br><span class=\"line\">$ sudo netstat -tunlp | grep 9090</span><br><span class=\"line\"><span class=\"comment\"># 查看 systemd 监听的 9090 端口是否启用</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>在 Web UI 中可查看并管理 podman 容器与镜像：<br><img src=\"cockpit-podman-1.jpg\" alt=\"podman-arch-usage/cockpit-podman-1.jpg\"><img src=\"cockpit-podman-2.jpg\" alt=\"cockpit-podman-2.jpg\"></p>\n</li>\n</ul>\n</li>\n<li><code>podman-compose</code> 旨在使用更轻量的方式实现<code>单机容器编排</code>，以用于替换 <code>docker-compose</code>，这种方式将不再依赖守护进程与 root 权限，同时可使用 rootless 容器，详细示例见下文。</li>\n<li>podman-compose 使用 <code>Python</code> 开发，因此可直接使用 <code>pip3</code> 安装该组件，或使用 rpm 软件包方式安装。</li>\n<li>由于 podman-compose 依然处于 <code>dev</code> 阶段，仅作为功能测试使用，暂未受到 GA 环境支持。</li>\n</ul>\n<h3 id=\"Podman-在不同-OS-版本中的安装：\"><a href=\"#Podman-在不同-OS-版本中的安装：\" class=\"headerlink\" title=\"Podman 在不同 OS 版本中的安装：\"></a>Podman 在不同 OS 版本中的安装：</h3><ul>\n<li><p>CentOS 7.x/8.x 或 RHEL 7.x/8.x 中：yum 命令使用 podman <code>rpm</code> 软件包安装  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo yum install -y podman-3.2.3-0.11.module_el8.4.0+942+d25aada8.x86_64</span><br><span class=\"line\"><span class=\"comment\"># 安装 podman 最新版本，低版本 podman 存在较多 bug。</span></span><br><span class=\"line\"><span class=\"comment\"># 注意：</span></span><br><span class=\"line\"><span class=\"comment\">#   1. 需配置 CentOS 8 的 yum 软件源以安装最新版的 podman 及其依赖软件包</span></span><br><span class=\"line\"><span class=\"comment\">#   2. yum 安装 podman 时也将安装 containernetworking-plugins 软件包</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>🤘 Ubuntu 20.04.2 LTS 中：apt-get 命令使用 podman <code>deb</code> 软件包安装  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ . /etc/os-release</span><br><span class=\"line\"><span class=\"comment\"># 查看当前的系统发行版</span></span><br><span class=\"line\">$ <span class=\"built_in\">echo</span> <span class=\"string\">\"deb https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_<span class=\"variable\">$&#123;VERSION_ID&#125;</span>/ /\"</span> | sudo tee /etc/apt/sources.list.d/devel:kubic:libcontainers:stable.list</span><br><span class=\"line\">$ curl -L <span class=\"string\">\"https://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_<span class=\"variable\">$&#123;VERSION_ID&#125;</span>/Release.key\"</span> | sudo apt-key add -</span><br><span class=\"line\"><span class=\"comment\"># 添加 podman 软件源与 apt 公钥</span></span><br><span class=\"line\">$ sudo apt-get update -y</span><br><span class=\"line\">$ sudo apt-get upgrade -y</span><br><span class=\"line\"><span class=\"comment\"># 更新系统软件源并升级系统软件包</span></span><br><span class=\"line\">$ sudo apt-get install -y podman</span><br><span class=\"line\">  Reading package lists... Done</span><br><span class=\"line\">  Building dependency tree       </span><br><span class=\"line\">  Reading state information... Done</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  The following NEW packages will be installed:</span><br><span class=\"line\">    catatonit conmon containernetworking-plugins containers-common criu crun fuse-overlayfs fuse3 libfuse3-3 libnet1 libprotobuf-c1</span><br><span class=\"line\">    podman podman-machine-cni podman-plugins</span><br><span class=\"line\">  ...</span><br><span class=\"line\"><span class=\"comment\"># 安装 podman 与相关的软件包，包括 conmon、containernetworking-plugins、crun 等。</span></span><br></pre></td></tr></table></figure>\n<p>安装参考链接：  </p>\n<ul>\n<li><a href=\"https://podman.io/getting-started/installation\" target=\"_blank\" rel=\"noopener\">Podman Doc - installation</a></li>\n<li><a href=\"https://www.hostnextra.com/kb/easy-to-install-podman-on-ubuntu-20-04/\" target=\"_blank\" rel=\"noopener\">Easy to Install Podman on Ubuntu 20.04</a></li>\n<li><a href=\"https://software.opensuse.org//download.html?project=devel%3Akubic%3Alibcontainers%3Astable&amp;package=podman\" target=\"_blank\" rel=\"noopener\">podman from devel:kubic:libcontainers:stable project</a></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"🤘-Docker-与-Podman-进程管理方式比较：\"><a href=\"#🤘-Docker-与-Podman-进程管理方式比较：\" class=\"headerlink\" title=\"🤘 Docker 与 Podman 进程管理方式比较：\"></a>🤘 Docker 与 Podman 进程管理方式比较：</h3><ul>\n<li><p>Docker v20.10.8 使用 <code>dockerd</code> 与 <code>containerd</code> 守护进程管理容器与镜像的生命周期，运行状态如下所示： </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo systemctl status docker.service</span><br><span class=\"line\">● docker.service - Docker Application Container Engine</span><br><span class=\"line\">   Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled)</span><br><span class=\"line\">   Active: active (running) since Wed 2022-10-19 10:53:04 CST; 6min ago</span><br><span class=\"line\">     Docs: https://docs.docker.com</span><br><span class=\"line\"> Main PID: 79556 (dockerd)</span><br><span class=\"line\">    Tasks: 21</span><br><span class=\"line\">   Memory: 42.6M</span><br><span class=\"line\">   CGroup: /system.slice/docker.service</span><br><span class=\"line\">           ├─79556 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock</span><br><span class=\"line\">           ├─79677 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 4000 -container-ip 172.17.0.2 -container-port 4000</span><br><span class=\"line\">           └─79683 /usr/bin/docker-proxy -proto tcp -host-ip :: -host-port 4000 -container-ip 172.17.0.2 -container-port 4000</span><br><span class=\"line\"></span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.197803867+08:00\"</span> level=info msg=<span class=\"string\">\"scheme \\\"unix\\\" not registered, fallback to default scheme\"</span> module=grpc</span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.197837924+08:00\"</span> level=info msg=<span class=\"string\">\"ccResolverWrapper: sending update to cc: &#123;[&#123;unix:///run/containerd/containerd.sock  &lt;nil&gt; 0 &lt;nil&gt;&#125;] &lt;nil&gt; &lt;nil&gt;&#125;\"</span> module=grpc</span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.197860326+08:00\"</span> level=info msg=<span class=\"string\">\"ClientConn switching balancer to \\\"pick_first\\\"\"</span> module=grpc</span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.220416627+08:00\"</span> level=info msg=<span class=\"string\">\"Loading containers: start.\"</span></span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.347884960+08:00\"</span> level=info msg=<span class=\"string\">\"Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address\"</span></span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.725361851+08:00\"</span> level=info msg=<span class=\"string\">\"Loading containers: done.\"</span></span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.755449128+08:00\"</span> level=info msg=<span class=\"string\">\"Docker daemon\"</span> commit=75249d8 graphdriver(s)=overlay2 version=20.10.8</span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.755527994+08:00\"</span> level=info msg=<span class=\"string\">\"Daemon has completed initialization\"</span></span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com systemd[1]: Started Docker Application Container Engine.</span><br><span class=\"line\">Oct 19 10:53:04 cloud-ctl.domain12.example.com dockerd[79556]: time=<span class=\"string\">\"2022-10-19T10:53:04.776865058+08:00\"</span> level=info msg=<span class=\"string\">\"API listen on /var/run/docker.sock\"</span></span><br><span class=\"line\"><span class=\"comment\"># dockerd 守护进程的运行状态</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ sudo systemctl status containerd</span><br><span class=\"line\">● containerd.service - containerd container runtime</span><br><span class=\"line\">   Loaded: loaded (/usr/lib/systemd/system/containerd.service; enabled; vendor preset: disabled)</span><br><span class=\"line\">   Active: active (running) since Tue 2022-10-18 15:08:06 CST; 20h ago</span><br><span class=\"line\">     Docs: https://containerd.io</span><br><span class=\"line\"> Main PID: 1892 (containerd)</span><br><span class=\"line\">    Tasks: 20</span><br><span class=\"line\">   Memory: 103.4M</span><br><span class=\"line\">   CGroup: /system.slice/containerd.service</span><br><span class=\"line\">           ├─ 1892 /usr/bin/containerd</span><br><span class=\"line\">           └─79696 /usr/bin/containerd-shim-runc-v2 -namespace moby -id 3ea752c1cce6a65b39af7f68c971186e020992514b663ab7a917f47da70450fa -address /run/containerd/containerd.sock</span><br><span class=\"line\"><span class=\"comment\"># containerd 通过调用 containerd-shim-runc-v2 运行指定容器</span></span><br><span class=\"line\">$ sudo ps -ef | grep -E <span class=\"string\">\"dockerd|containerd|containerd-shim-runc-v2\"</span></span><br><span class=\"line\">  root       1892      1  0 Oct18 ?        00:05:01 /usr/bin/containerd</span><br><span class=\"line\">  root      79556      1  0 10:53 ?        00:00:03 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock</span><br><span class=\"line\">  root      79696      1  0 10:53 ?        00:00:01 /usr/bin/containerd-shim-runc-v2 -namespace moby -id 3ea752c1cce6a65b39af7f68c971186e020992514b663ab7a917f47da70450fa -address /run/containerd/containerd.sock</span><br><span class=\"line\"><span class=\"comment\"># PID 79696 为实际的容器运行进程</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Podman 不使用守护进程的方式运行或管理容器，对于 rootfull 容器或 rootless 容器的运行方式存在差异：  </p>\n<ul>\n<li><p>rootfull 容器的进程：<br>👉 以交互式方式运行的容器进程状态如下所示：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo ps -ef | egrep <span class=\"string\">\"podman|slirp4netns|conmon\"</span></span><br><span class=\"line\">  root        3879    3476  1 06:31 pts/3    00:00:00 podman run -it --name=mydebian docker.io/library/debian:latest /bin/sh</span><br><span class=\"line\">  root        3945       1  0 06:31 ?        00:00:00 /usr/bin/conmon --api-version 1 -c 29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba -u 29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba -r /usr/bin/crun -b /var/lib/containers/storage/overlay-containers/29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba/userdata -p /run/containers/storage/overlay-containers/29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba/userdata/pidfile -n mydebian --<span class=\"built_in\">exit</span>-dir /run/libpod/exits --full-attach -s -l journald --<span class=\"built_in\">log</span>-level warning --runtime-arg --<span class=\"built_in\">log</span>-format=json --runtime-arg --<span class=\"built_in\">log</span> --runtime-arg=/run/containers/storage/overlay-containers/29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba/userdata/oci-log -t --conmon-pidfile /run/containers/storage/overlay-containers/29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba/userdata/conmon.pid --<span class=\"built_in\">exit</span>-command /usr/bin/podman --<span class=\"built_in\">exit</span>-command-arg --root --<span class=\"built_in\">exit</span>-command-arg /var/lib/containers/storage --<span class=\"built_in\">exit</span>-command-arg --runroot --<span class=\"built_in\">exit</span>-command-arg /run/containers/storage --<span class=\"built_in\">exit</span>-command-arg --<span class=\"built_in\">log</span>-level --<span class=\"built_in\">exit</span>-command-arg warning --<span class=\"built_in\">exit</span>-command-arg --cgroup-manager --<span class=\"built_in\">exit</span>-command-arg systemd --<span class=\"built_in\">exit</span>-command-arg --tmpdir --<span class=\"built_in\">exit</span>-command-arg /run/libpod --<span class=\"built_in\">exit</span>-command-arg --network-config-dir --<span class=\"built_in\">exit</span>-command-arg  --<span class=\"built_in\">exit</span>-command-arg --network-backend --<span class=\"built_in\">exit</span>-command-arg cni --<span class=\"built_in\">exit</span>-command-arg --volumepath --<span class=\"built_in\">exit</span>-command-arg /var/lib/containers/storage/volumes --<span class=\"built_in\">exit</span>-command-arg --runtime --<span class=\"built_in\">exit</span>-command-arg crun --<span class=\"built_in\">exit</span>-command-arg --storage-driver --<span class=\"built_in\">exit</span>-command-arg overlay --<span class=\"built_in\">exit</span>-command-arg --storage-opt --<span class=\"built_in\">exit</span>-command-arg overlay.mountopt=nodev,metacopy=on --<span class=\"built_in\">exit</span>-command-arg --events-backend --<span class=\"built_in\">exit</span>-command-arg journald --<span class=\"built_in\">exit</span>-command-arg container --<span class=\"built_in\">exit</span>-command-arg cleanup --<span class=\"built_in\">exit</span>-command-arg 29260258303cef76f1191c8b83f16eb7ba70c5424bb17a729e2d3b051680adba</span><br><span class=\"line\"><span class=\"comment\"># 由于具有交互式命令行运行依然保留 podman 进程</span></span><br></pre></td></tr></table></figure>\n<p>👉 以 <code>detach</code> 方式（后台）运行的容器进程状态如下所示：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo ps -ef | egrep <span class=\"string\">\"podman|slirp4netns|conmon\"</span></span><br><span class=\"line\">  root        3744       1  0 06:25 ?        00:00:00 /usr/bin/conmon --api-version 1 -c b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272 -u b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272 -r /usr/bin/crun -b /var/lib/containers/storage/overlay-containers/b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272/userdata -p /run/containers/storage/overlay-containers/b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272/userdata/pidfile -n apache-rhce8.2-alpine --<span class=\"built_in\">exit</span>-dir /run/libpod/exits --full-attach -s -l journald --<span class=\"built_in\">log</span>-level warning --runtime-arg --<span class=\"built_in\">log</span>-format=json --runtime-arg --<span class=\"built_in\">log</span> --runtime-arg=/run/containers/storage/overlay-containers/b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272/userdata/oci-log --conmon-pidfile /run/containers/storage/overlay-containers/b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272/userdata/conmon.pid --<span class=\"built_in\">exit</span>-command /usr/bin/podman --<span class=\"built_in\">exit</span>-command-arg --root --<span class=\"built_in\">exit</span>-command-arg /var/lib/containers/storage --<span class=\"built_in\">exit</span>-command-arg --runroot --<span class=\"built_in\">exit</span>-command-arg /run/containers/storage --<span class=\"built_in\">exit</span>-command-arg --<span class=\"built_in\">log</span>-level --<span class=\"built_in\">exit</span>-command-arg warning --<span class=\"built_in\">exit</span>-command-arg --cgroup-manager --<span class=\"built_in\">exit</span>-command-arg systemd --<span class=\"built_in\">exit</span>-command-arg --tmpdir --<span class=\"built_in\">exit</span>-command-arg /run/libpod --<span class=\"built_in\">exit</span>-command-arg --network-config-dir --<span class=\"built_in\">exit</span>-command-arg  --<span class=\"built_in\">exit</span>-command-arg --network-backend --<span class=\"built_in\">exit</span>-command-arg cni --<span class=\"built_in\">exit</span>-command-arg --volumepath --<span class=\"built_in\">exit</span>-command-arg /var/lib/containers/storage/volumes --<span class=\"built_in\">exit</span>-command-arg --runtime --<span class=\"built_in\">exit</span>-command-arg crun --<span class=\"built_in\">exit</span>-command-arg --storage-driver --<span class=\"built_in\">exit</span>-command-arg overlay --<span class=\"built_in\">exit</span>-command-arg --storage-opt --<span class=\"built_in\">exit</span>-command-arg overlay.mountopt=nodev,metacopy=on --<span class=\"built_in\">exit</span>-command-arg --events-backend --<span class=\"built_in\">exit</span>-command-arg journald --<span class=\"built_in\">exit</span>-command-arg container --<span class=\"built_in\">exit</span>-command-arg cleanup --<span class=\"built_in\">exit</span>-command-arg b8ad3fce848ef26197a1d8bd43be5a2a72c66211e05cd90ccfaa55e1515ed272</span><br><span class=\"line\"><span class=\"comment\"># podman 在调用 conmon 程序创建并运行容器后退出，而 rootfull 容器的 CNI 插件</span></span><br><span class=\"line\"><span class=\"comment\"># 可直接使用 iptables 的方式实现。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>rootless 容器的进程：<br>👉 以交互式方式运行的容器进程状态如下所示：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ps -ef | egrep <span class=\"string\">\"podman|slirp4netns|conmon\"</span></span><br><span class=\"line\">  core        3418    2762  0 06:17 pts/2    00:00:05 podman run -it --name=mybusybox docker.io/library/busybox:latest /bin/sh</span><br><span class=\"line\">  core        3430    3418  0 06:17 pts/2    00:00:00 /usr/bin/slirp4netns --<span class=\"built_in\">disable</span>-host-loopback --mtu=65520 --<span class=\"built_in\">enable</span>-sandbox --<span class=\"built_in\">enable</span>-seccomp --<span class=\"built_in\">enable</span>-ipv6 -c -e 3 -r 4 --netns-type=path /run/user/1000/netns/netns-19eb5630-c0a8-4ea9-8790-76ecdcdf2dbc tap0</span><br><span class=\"line\">  core        3433       1  0 06:17 ?        00:00:00 /usr/bin/conmon --api-version 1 -c 5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160 -u 5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160 -r /usr/bin/crun -b /var/home/core/.<span class=\"built_in\">local</span>/share/containers/storage/overlay-containers/5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160/userdata -p /run/user/1000/containers/overlay-containers/5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160/userdata/pidfile -n mybusybox --<span class=\"built_in\">exit</span>-dir /run/user/1000/libpod/tmp/exits --full-attach -s -l journald --<span class=\"built_in\">log</span>-level warning --runtime-arg --<span class=\"built_in\">log</span>-format=json --runtime-arg --<span class=\"built_in\">log</span> --runtime-arg=/run/user/1000/containers/overlay-containers/5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160/userdata/oci-log -t --conmon-pidfile /run/user/1000/containers/overlay-containers/5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160/userdata/conmon.pid --<span class=\"built_in\">exit</span>-command /usr/bin/podman --<span class=\"built_in\">exit</span>-command-arg --root --<span class=\"built_in\">exit</span>-command-arg /var/home/core/.<span class=\"built_in\">local</span>/share/containers/storage --<span class=\"built_in\">exit</span>-command-arg --runroot --<span class=\"built_in\">exit</span>-command-arg /run/user/1000/containers --<span class=\"built_in\">exit</span>-command-arg --<span class=\"built_in\">log</span>-level --<span class=\"built_in\">exit</span>-command-arg warning --<span class=\"built_in\">exit</span>-command-arg --cgroup-manager --<span class=\"built_in\">exit</span>-command-arg systemd --<span class=\"built_in\">exit</span>-command-arg --tmpdir --<span class=\"built_in\">exit</span>-command-arg /run/user/1000/libpod/tmp --<span class=\"built_in\">exit</span>-command-arg --network-config-dir --<span class=\"built_in\">exit</span>-command-arg  --<span class=\"built_in\">exit</span>-command-arg --network-backend --<span class=\"built_in\">exit</span>-command-arg netavark --<span class=\"built_in\">exit</span>-command-arg --volumepath --<span class=\"built_in\">exit</span>-command-arg /var/home/core/.<span class=\"built_in\">local</span>/share/containers/storage/volumes --<span class=\"built_in\">exit</span>-command-arg --runtime --<span class=\"built_in\">exit</span>-command-arg crun --<span class=\"built_in\">exit</span>-command-arg --storage-driver --<span class=\"built_in\">exit</span>-command-arg overlay --<span class=\"built_in\">exit</span>-command-arg --events-backend --<span class=\"built_in\">exit</span>-command-arg journald --<span class=\"built_in\">exit</span>-command-arg container --<span class=\"built_in\">exit</span>-command-arg cleanup --<span class=\"built_in\">exit</span>-command-arg 5acc7fc4127d5492866b966d6c0c04dce880995c49eddb8421c11e7efc661160</span><br><span class=\"line\"><span class=\"comment\"># 由于具有交互式命令行运行依然保留 podman 进程，并且由 podman 进程创建 slirp4netns 子进程</span></span><br><span class=\"line\"><span class=\"comment\"># 用于 rootless 容器的网络命名空间之间的通信。</span></span><br><span class=\"line\">``` </span><br><span class=\"line\">👉 以 `detach` 方式（后台）运行的容器进程状态如下所示：   </span><br><span class=\"line\">```bash</span><br><span class=\"line\">$ ps -ef | egrep <span class=\"string\">\"podman|slirp4netns|conmon\"</span></span><br><span class=\"line\">  core        3308       1  0 06:15 pts/2    00:00:00 /usr/bin/slirp4netns --<span class=\"built_in\">disable</span>-host-loopback --mtu=65520 --<span class=\"built_in\">enable</span>-sandbox --<span class=\"built_in\">enable</span>-seccomp --<span class=\"built_in\">enable</span>-ipv6 -c -e 3 -r 4 --netns-type=path /run/user/1000/netns/netns-f9f6f9dd-bf80-f6ca-6f39-7c9d9cd6beea tap0</span><br><span class=\"line\">  core        3325       1  0 06:15 ?        00:00:00 /usr/bin/conmon --api-version 1 -c 91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab -u 91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab -r /usr/bin/crun -b /var/home/core/.<span class=\"built_in\">local</span>/share/containers/storage/overlay-containers/91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab/userdata -p /run/user/1000/containers/overlay-containers/91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab/userdata/pidfile -n apache-rhce8.2-alpine --<span class=\"built_in\">exit</span>-dir /run/user/1000/libpod/tmp/exits --full-attach -s -l journald --<span class=\"built_in\">log</span>-level warning --runtime-arg --<span class=\"built_in\">log</span>-format=json --runtime-arg --<span class=\"built_in\">log</span> --runtime-arg=/run/user/1000/containers/overlay-containers/91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab/userdata/oci-log --conmon-pidfile /run/user/1000/containers/overlay-containers/91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab/userdata/conmon.pid --<span class=\"built_in\">exit</span>-command /usr/bin/podman --<span class=\"built_in\">exit</span>-command-arg --root --<span class=\"built_in\">exit</span>-command-arg /var/home/core/.<span class=\"built_in\">local</span>/share/containers/storage --<span class=\"built_in\">exit</span>-command-arg --runroot --<span class=\"built_in\">exit</span>-command-arg /run/user/1000/containers --<span class=\"built_in\">exit</span>-command-arg --<span class=\"built_in\">log</span>-level --<span class=\"built_in\">exit</span>-command-arg warning --<span class=\"built_in\">exit</span>-command-arg --cgroup-manager --<span class=\"built_in\">exit</span>-command-arg systemd --<span class=\"built_in\">exit</span>-command-arg --tmpdir --<span class=\"built_in\">exit</span>-command-arg /run/user/1000/libpod/tmp --<span class=\"built_in\">exit</span>-command-arg --network-config-dir --<span class=\"built_in\">exit</span>-command-arg  --<span class=\"built_in\">exit</span>-command-arg --network-backend --<span class=\"built_in\">exit</span>-command-arg netavark --<span class=\"built_in\">exit</span>-command-arg --volumepath --<span class=\"built_in\">exit</span>-command-arg /var/home/core/.<span class=\"built_in\">local</span>/share/containers/storage/volumes --<span class=\"built_in\">exit</span>-command-arg --runtime --<span class=\"built_in\">exit</span>-command-arg crun --<span class=\"built_in\">exit</span>-command-arg --storage-driver --<span class=\"built_in\">exit</span>-command-arg overlay --<span class=\"built_in\">exit</span>-command-arg --events-backend --<span class=\"built_in\">exit</span>-command-arg journald --<span class=\"built_in\">exit</span>-command-arg container --<span class=\"built_in\">exit</span>-command-arg cleanup --<span class=\"built_in\">exit</span>-command-arg 91b49d5726023b9ca1c4e30a6665fc21c9b3c3182a1accddb0adb259d0ba20ab</span><br><span class=\"line\"><span class=\"comment\"># podman 在调用 conmon 程序创建并运行容器后退出，并且由 podman 进程创建 slirp4netns 子进程</span></span><br><span class=\"line\"><span class=\"comment\"># 用于 rootless 容器的网络命名空间之间的通信。</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Podman-的网络实现原理（rootfull-与-rootless）：\"><a href=\"#Podman-的网络实现原理（rootfull-与-rootless）：\" class=\"headerlink\" title=\"Podman 的网络实现原理（rootfull 与 rootless）：\"></a>Podman 的网络实现原理（rootfull 与 rootless）：</h3><ul>\n<li>Podman 支持的容器网络模式如下所示：<br><img src=\"podman-network-mode.jpg\" alt=\"podman-network-mode.jpg\"></li>\n<li><p>root 用户运行 rootfull 容器网络分析：  </p>\n<ul>\n<li>默认情况下，rootfull 容器使用 bridge 网络模式，并且在未创建任何容器前系统上不会自动创建 <code>cni-podman0</code>网桥，只有创建容器后自动生成。  </li>\n<li><p>root 用户使用全局范围内的 CNI 插件，podman 默认使用 <code>bridge</code>、<code>portmap</code> 插件，其配置文件如下：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cat /etc/cni/net.d/87-podman-bridge.conflist</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"cniVersion\"</span>: <span class=\"string\">\"0.4.0\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"name\"</span>: <span class=\"string\">\"podman\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"plugins\"</span>: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"type\"</span>: <span class=\"string\">\"bridge\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"bridge\"</span>: <span class=\"string\">\"cni-podman0\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"isGateway\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">      <span class=\"string\">\"ipMasq\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">      <span class=\"string\">\"hairpinMode\"</span>: <span class=\"literal\">true</span>,</span><br><span class=\"line\">      <span class=\"string\">\"ipam\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">\"type\"</span>: <span class=\"string\">\"host-local\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"routes\"</span>: [&#123; <span class=\"string\">\"dst\"</span>: <span class=\"string\">\"0.0.0.0/0\"</span> &#125;],</span><br><span class=\"line\">        <span class=\"string\">\"ranges\"</span>: [</span><br><span class=\"line\">          [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">              <span class=\"string\">\"subnet\"</span>: <span class=\"string\">\"10.88.0.0/16\"</span>,</span><br><span class=\"line\">              <span class=\"string\">\"gateway\"</span>: <span class=\"string\">\"10.88.0.1\"</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">          ]</span><br><span class=\"line\">        ]</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"type\"</span>: <span class=\"string\">\"portmap\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"capabilities\"</span>: &#123;</span><br><span class=\"line\">        <span class=\"string\">\"portMappings\"</span>: <span class=\"literal\">true</span></span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"type\"</span>: <span class=\"string\">\"firewall\"</span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"type\"</span>: <span class=\"string\">\"tuning\"</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\"><span class=\"comment\"># 该配置文件位于 Podman 源码 cni/87-podman-bridge.conflist</span></span><br><span class=\"line\"><span class=\"comment\"># Podman 可调用 bridge、portmap 等 CNI 插件</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ sudo podman inspect &lt;container_name&gt; | jq .[0].HostConfig.NetworkMode</span><br><span class=\"line\">  <span class=\"string\">\"bridge\"</span></span><br><span class=\"line\"><span class=\"comment\"># root 用户创建的容器网络模式</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>root 用户创建具有端口映射的容器时，iptables filter 表与 nat 表规则将相应增加：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># ----- filter 表中创建新容器后的新增规则 -----</span></span><br><span class=\"line\">*filter</span><br><span class=\"line\">-A FORWARD -m comment --comment <span class=\"string\">\"CNI firewall plugin rules\"</span> -j CNI-FORWARD</span><br><span class=\"line\">-A CNI-FORWARD -m comment --comment <span class=\"string\">\"CNI firewall plugin admin overrides\"</span> -j CNI-ADMIN</span><br><span class=\"line\">-A CNI-FORWARD -d 10.88.0.3/32 -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT</span><br><span class=\"line\"><span class=\"comment\"># 新增规则：允许 3 层转发目标地址为 10.88.0.3 的流量（进入容器的流量），conntrack 模块进行连接状态追踪。</span></span><br><span class=\"line\"><span class=\"comment\"># 当容器通过 MASQUERADE 对外访问，回包再次进入容器宿主机时不再通过 DNAT 转发，而通过 conntrack </span></span><br><span class=\"line\"><span class=\"comment\"># 记录的连接状态直接转发至该规则并通过 cni-podman0 网桥进入容器。</span></span><br><span class=\"line\">-A CNI-FORWARD -s 10.88.0.3/32 -j ACCEPT</span><br><span class=\"line\"><span class=\"comment\"># 新增规则：允许 3 层转发源地址为 10.88.0.3 的流量（出容器的流量）。</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ----- nat 表中创建新容器后的新增规则 -----</span></span><br><span class=\"line\">*nat</span><br><span class=\"line\">-A PREROUTING -m addrtype --dst-type LOCAL -j CNI-HOSTPORT-DNAT</span><br><span class=\"line\">-A POSTROUTING -m comment --comment <span class=\"string\">\"CNI portfwd requiring masquerade\"</span> -j CNI-HOSTPORT-MASQ</span><br><span class=\"line\">-A POSTROUTING -s 10.88.0.3/32 -m comment --comment <span class=\"string\">\"name: \\\"podman\\\" id: \\\"2d2b3521457cb1d9b7ae6657304d05789a854e7a48916276a40da543df9aa217\\\"\"</span> -j CNI-b6c5fb6c593e895d843cb5bd</span><br><span class=\"line\"><span class=\"comment\"># 新增规则：来自于 10.88.0.3 容器的流量转发至 CNI-b6c5fb6c593e895d843cb5bd 链</span></span><br><span class=\"line\">-A OUTPUT -m addrtype --dst-type LOCAL -j CNI-HOSTPORT-DNAT</span><br><span class=\"line\"><span class=\"comment\"># 启用 CNI 后即创建的规则，该规则接收来自本地应用的流量并转发至 CNI-HOSTPORT-DNAT 链</span></span><br><span class=\"line\">-A CNI-HOSTPORT-SETMARK -m comment --comment <span class=\"string\">\"CNI portfwd masquerade mark\"</span> -j MARK --<span class=\"built_in\">set</span>-xmark 0x2000/0x2000</span><br><span class=\"line\">-A CNI-HOSTPORT-MASQ -m mark --mark 0x2000/0x2000 -j MASQUERADE</span><br><span class=\"line\"><span class=\"comment\">### 以下 6 条在创建新容器时同时创建 </span></span><br><span class=\"line\">-A CNI-HOSTPORT-DNAT -p tcp -m comment --comment <span class=\"string\">\"dnat name: \\\"podman\\\" id: \\\"2d2b3521457cb1d9b7ae6657304d05789a854e7a48916276a40da543df9aa217\\\"\"</span> -m multiport --dports 8843 -j CNI-DN-b6c5fb6c593e895d843cb</span><br><span class=\"line\"><span class=\"comment\"># 自定义 DNAT 链，发送至本地 8843 端口的流量转发至 CNI-DN-b6c5fb6c593e895d843cb 链。</span></span><br><span class=\"line\">-A CNI-b6c5fb6c593e895d843cb5bd -d 10.88.0.0/16 -m comment --comment <span class=\"string\">\"name: \\\"podman\\\" id: \\\"2d2b3521457cb1d9b7ae6657304d05789a854e7a48916276a40da543df9aa217\\\"\"</span> -j ACCEPT</span><br><span class=\"line\"><span class=\"comment\"># 允许转发目标网段为 10.88.0.0/16 的流量（进入容器的流量），该网段为容器所在的网络。</span></span><br><span class=\"line\">-A CNI-b6c5fb6c593e895d843cb5bd ! -d 224.0.0.0/4 -m comment --comment <span class=\"string\">\"name: \\\"podman\\\" id: \\\"2d2b3521457cb1d9b7ae6657304d05789a854e7a48916276a40da543df9aa217\\\"\"</span> -j MASQUERADE</span><br><span class=\"line\"><span class=\"comment\"># MASQUERADE 出容器流量</span></span><br><span class=\"line\">-A CNI-DN-b6c5fb6c593e895d843cb -s 10.88.0.0/16 -p tcp -m tcp --dport 8843 -j CNI-HOSTPORT-SETMARK</span><br><span class=\"line\">-A CNI-DN-b6c5fb6c593e895d843cb -s 127.0.0.1/32 -p tcp -m tcp --dport 8843 -j CNI-HOSTPORT-SETMARK</span><br><span class=\"line\">-A CNI-DN-b6c5fb6c593e895d843cb -p tcp -m tcp --dport 8843 -j DNAT --to-destination 10.88.0.3:443</span><br><span class=\"line\"><span class=\"comment\"># 自定义 DNAT 链实现容器宿主机至容器的端口映射</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>🚀 示例：外部访问容器内 Web 服务时，涉及的宿主机 iptables：<br><img src=\"external-access-container-web-service-iptables.jpg\" alt=\"external-access-container-web-service-iptables.jpg\">从外部访问容器内 Web 服务时，流量将通过 PREROUTING 链及自定义链（<code>CNI-HOSTPORT-DNAT</code>、<code>CNI-DN-xxxx</code>、<code>DNAT</code>），经由 FORWARD 链及自定义链（<code>CNI-FORWARD</code>）的三层转发与 <code>cni-podman0</code> 网桥的二层转发进入容器，容器对外响应的流量将经过 cni-podman0 网桥转发，并经过 CNI-FORWARD 链与 POSTROUTING 链及自定义链（<code>CNI-HOSTPORT-MASQ</code>）出容器宿主机。  </p>\n</li>\n<li><p>🚀 示例：直接从容器内访问外部时，返回容器的回包将直接使用 conntrack 模块追踪的连接状态，流量通过 <code>CNI-FORWARD</code> 链的三层转发与 cni-podman0 的二层转发至容器中，即，回包进入容器宿主机不再通过<code>CNI-HOSTPORT-DNAT</code>链。<br>如下所示，相关的 DNAT 链无流量通过（蓝框），CNI-FORWARD 链均有流量通过（蓝框）。<br><img src=\"container-access-external-iptables.jpg\" alt=\"container-access-external-iptables.jpg\"></p>\n<blockquote>\n<p>📌 <strong>Kubernetes 相关问题提示：</strong></p>\n<ol>\n<li>容器或 pod 通过 cni 网桥桥接的方式在 Kubernetes 或 OpenShift3 中需在计算节点（worker node）上配置 <code>net.bridge.bridge-nf-call-iptables</code> 与 <code>net.bridge.bridge-nf-call-iptables6</code> 内核参数，使 cni 二层网桥可调用 iptables 的 conntrack 模块，以解决前后端 pod 在同一节点上时，由于 pod 直连 cni 二层网桥，而二层网桥只实现二层转发，无法追踪前后端的连接状态，造成后端 pod 向前端 pod 回包时无法处于同一连接链路的问题，可 <a href=\"https://imroc.cc/k8s/faq/why-enable-bridge-nf-call-iptables/\" target=\"_blank\" rel=\"noopener\">点击此处</a> 获得更多帮助。</li>\n<li>使用以上内核参数时，需加载 <code>br_netfilter</code> 内核模块方能生效。</li>\n</ol>\n</blockquote>\n</li>\n<li><p>使用 <code>iperf3</code> 工具的容器测试不同 rootfull 容器之间的网络性能，如下所示：<br><img src=\"rootfull-container-to-container-bandwidth.jpg\" alt=\"rootfull-container-to-container-bandwidth.jpg\"></p>\n</li>\n</ul>\n</li>\n<li><p>普通用户运行 rootless 容器网络分析：  </p>\n<ul>\n<li><code>slirp4netns</code> 程序支持 user rootless network namespace，而非通过 <code>iptables</code> 与 CNI 实现。  </li>\n<li><p>👉 普通用户使用端口映射运行 rootless 容器时，默认情况下只能使用宿主机 1024 以上的端口实现映射，但可使用 <code>net.ipv4.ip_unprivileged_port_start</code> 内核参数实现低于 1024 的端口开始映射，如下所示：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">### 方式 1：###</span></span><br><span class=\"line\">$ sysctl -w net.ipv4.ip_unprivileged_port_start=80</span><br><span class=\"line\"><span class=\"comment\"># 临时配置：允许普通用户从 80 端口开始的端口映射运行 rootless 容器</span></span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\">### 方式 2：###</span></span><br><span class=\"line\">$ <span class=\"built_in\">echo</span> <span class=\"string\">\"net.ipv4.ip_unprivileged_port_start=80\"</span> &gt;&gt; /etc/sysctl.d/rootless.conf</span><br><span class=\"line\"><span class=\"comment\"># 永久配置：将该内核参数写入内核参数配置文件，使其开机永久生效。</span></span><br><span class=\"line\">$ sysctl -p</span><br><span class=\"line\"><span class=\"comment\"># 使配置的内核参数生效</span></span><br><span class=\"line\"></span><br><span class=\"line\"> - 普通用户创建的容器网络模式为 `slirp4netns`（slirp4netns 软件包实现）。    </span><br><span class=\"line\">    ```bash</span><br><span class=\"line\">    $ podman inspect &lt;container_name&gt; | jq .[0].HostConfig.NetworkMode</span><br><span class=\"line\">      <span class=\"string\">\"slirp4netns\"</span></span><br><span class=\"line\">    <span class=\"comment\"># 普通用户创建的 rootless 容器网络模式</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>每个普通用户运行 rootless 容器都将生成 slirp4netns 进程用于隔离该用户的 <code>network namespace</code>，以下分别使用 godev 与 hualf 用户运行 rootless 容器：<br><img src=\"godev-rootless-container.jpg\" alt=\"godev-rootless-container.jpg\"><img src=\"hualf-rootless-container.jpg\" alt=\"hualf-rootless-container.jpg\"> </p>\n</li>\n<li>slirp4netns 实现的网络模式与带宽比较：<br><img src=\"rootless-slirp4netns-networking.jpg\" alt=\"rootless-slirp4netns-networking.jpg\"> </li>\n<li>使用 <code>iperf3</code> 工具的容器测试不同 rootless 容器之间的网络性能，如下所示：<br><img src=\"rootless-container-to-container-bandwidth.jpg\" alt=\"rootless-container-to-container-bandwidth.jpg\">对比 rootfull 容器之间的网络性能来看，slirp4netns 实现的 rootless 容器在不同的网络命名空间内的通信性能损耗较大，而 rootfull 容器之间的网络性能相比前者在此次测试中高出近 5 倍。 </li>\n<li>关于 slirp4netns 更加详细的内容，请参考 <a href=\"https://github.com/rootless-containers/slirp4netns\" target=\"_blank\" rel=\"noopener\">Github 项目</a>。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Podman-的-macvlan-网络实现：\"><a href=\"#Podman-的-macvlan-网络实现：\" class=\"headerlink\" title=\"Podman 的 macvlan 网络实现：\"></a>Podman 的 macvlan 网络实现：</h3><ul>\n<li><code>macvlan</code> 作为 CNI 在 Kubernetes 与 OpenShift v4 中作为 <code>Multus CNI</code> 支持的额外插件类型使用愈加广泛，集群中除了常规使用的 Flannel、Calico 等作为 <code>slow path</code> 的插件外，要求高性能的业务流量可使用 macvlan 直连 pod 宿主机物理网口实现 <code>fast path</code>。</li>\n<li>为后续熟悉以上场景的实现，因此在 Podman <code>rootfull</code> 容器中使用 macvlan 网络模式。</li>\n<li>关于 macvlan 的基础知识可参考 <a href=\"https://mp.weixin.qq.com/s?__biz=MzU1MzY4NzQ1OA==&amp;mid=2247484064&amp;idx=1&amp;sn=ffd745069b6c4aeac0589de00467b2f2&amp;chksm=fbee426dcc99cb7bdf26f5e6a21bbeaebba7ccd384a02f850d4461ea92331ed140edf98ffaec&amp;mpshare=1&amp;scene=1&amp;srcid=03049MKwF55OVgEZ4OCH39wd&amp;sharer_sharetime=1583337046541&amp;sharer_shareid=8eaca72194dae7b3d51d5c708436eee4#rd\" target=\"_blank\" rel=\"noopener\">Linux 虚拟网卡技术：Macvlan</a> 与 <a href=\"https://cizixs.com/2017/02/14/network-virtualization-macvlan/\" target=\"_blank\" rel=\"noopener\">linux 网络虚拟化：macvlan</a></li>\n<li><p>macvlan 特性由 <code>Linux kernel</code> 支持，笔者的实验环境满足 macvlan 的要求，请使用如下命令确定：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo lsmod | grep macvlan</span><br><span class=\"line\"><span class=\"comment\"># 若无任何返回，说明还未加载 macvlan 内核模块。</span></span><br><span class=\"line\">$ sudo modprobe macvlan</span><br><span class=\"line\"><span class=\"comment\"># 加载 macvlan 内核模块，若执行报错，说明 kernel 不支持该特性。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>podman 与 macvlan 类型网络的集成，如下所示：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo podman network create -d macvlan -o parent=ens33 &lt;network_name&gt;</span><br><span class=\"line\">  /etc/cni/net.d/&lt;network_name&gt;.conflist</span><br><span class=\"line\"><span class=\"comment\"># 创建 macvlan 类型网络  </span></span><br><span class=\"line\">$ sudo podman network ls</span><br><span class=\"line\">$ sudo /opt/cni/bin/dhcp daemon</span><br><span class=\"line\"><span class=\"comment\"># 在另一个窗口中启动 dhcp 守护进程供 macvlan 插件调用，为容器网口分配 IP 地址。</span></span><br><span class=\"line\">$ sudo podman run -it --rm \\</span><br><span class=\"line\">  --name &lt;container_name&gt; --network=&lt;network_name&gt; \\</span><br><span class=\"line\">  &lt;container_image&gt;:&lt;tag&gt; /bin/sh</span><br><span class=\"line\"><span class=\"comment\"># 创建支持 macvlan 类型网络的 rootfull 容器</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>从与 rootfull 容器在同一广播域的其他节点上 ping 该容器，可正常通信：<br><img src=\"podman-macvlan-network.png\" alt=\"podman-macvlan-network.png\"></p>\n<blockquote>\n<p>🤔 以上示例的容器中运行 Web 服务（可暴露 443 端口），使用 macvlan 网络模式可打通与同一广播域中外部节点的通信，但无法访问其中的服务，可采取何种方法解决该问题？  </p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"Podman-rootless-容器用户映射实现方式：\"><a href=\"#Podman-rootless-容器用户映射实现方式：\" class=\"headerlink\" title=\"Podman rootless 容器用户映射实现方式：\"></a>Podman rootless 容器用户映射实现方式：</h3><ul>\n<li>Podman rootless 容器的实现核心在于解决 network namespace（NetNS） 与 user namespace（UserNS） 的问题，前文已介绍 NetNS 的实现方式，后文将介绍 UserNS 的实现方式。</li>\n<li><p>若要使用 rootless 容器，需确认 OS 是否开启 user namespace 功能：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo sysctl -a | grep user\\.max_user_namespaces</span><br><span class=\"line\">  user.max_user_namespaces = 47494</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>系统上每创建一个用户就会在 <code>/etc/subuid</code> 与 <code>/etc/subgid</code> 中生成对应用户在其用户命名空间中的映射规则，以 /etc/subuid 为例，参数以冒号分隔，每个参数含义如下所示：  </p>\n<ul>\n<li>第一个参数（uid）：用户名称  </li>\n<li>第二个参数（loweruid）：用户命名空间中起始的映射 uid</li>\n</ul>\n</li>\n<li>第三个参数（count）：用户命名空间内部与外部可映射 uid 数量（可理解为所有容器普通用户的 uid 数量和）<br><img src=\"rootless-user-namespace-mapping.jpg\" alt=\"rootless-user-namespace-mapping.jpg\"></li>\n<li>以上两个文件允许运行进程的 uid 映射范围，在 <code>/proc/&lt;pid&gt;/uid_map</code> 中定义。</li>\n<li>可过滤容器 <code>conmon</code> 进程的 pid 确认每个容器中的 uid 映射情况，参见以下示例。</li>\n<li>关于以上两个文件的具体说明可参考 <code>newuidmap</code> 与 <code>newgidmap</code> 命令的 man 手册。</li>\n<li><p>可参考 Podman 官方推荐的命令创建 uid 的映射，如下所示：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo usermod --add-subuids 10000-75535 $(whoami)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ----- 示例 -----</span></span><br><span class=\"line\">$ sudo cat /etc/subuid</span><br><span class=\"line\">  appuser:10000:500</span><br><span class=\"line\">$ sudo cat /etc/subgid</span><br><span class=\"line\">  appuser:500:50</span><br><span class=\"line\"><span class=\"comment\"># 该用户创建的 user namespace 中可以使用从 10000 开始的 500 个 UID 和从 500 开始的 50 个 GID 的映射。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>🚀 示例：<br>普通用户 hualf 在 /etc/subuid 中映射为 hualf:165536:65536，说明在该用户的用户命名空间中可嵌套一个或多个用户命名空间（或容器），每个容器中的 root 用户 uid 0 都映射为 hualf 用户的 uid 1001（运行容器进程的用户），而容器中普通用户的 uid 映射至宿主机的 subuid 范围中，对于此例 subuid 范围为 165536~231071，容器中的 uid 1 用户映射为宿主机 uid 165536，因此容器中 admin 用户 uid 1000 映射为宿主机 uid 166535（165536+999）。<br>通过容器宿主机上每个普通用户的用户命名空间的 subuid 映射范围，可分配众多 uid 在 rootless 容器中运行应用进程。<br><img src=\"user-namespace-subuid-mapping-1-edited.png\" alt=\"user-namespace-subuid-mapping-1-edited.png\"><img src=\"user-namespace-subuid-mapping-2-edited.png\" alt=\"user-namespace-subuid-mapping-2-edited.png\"></p>\n</li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://projectatomic.io/blog/2018/02/reintroduction-podman/\" target=\"_blank\" rel=\"noopener\">Reintroduction of Podman</a></li>\n<li><a href=\"https://fedoramagazine.org/podman-pods-fedora-containers/\" target=\"_blank\" rel=\"noopener\">Using pods with Podman on Fedora</a></li>\n<li><a href=\"https://www.redhat.com/sysadmin/container-networking-podman\" target=\"_blank\" rel=\"noopener\">Configuring container networking with Podman</a></li>\n<li><a href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/building_running_and_managing_containers/index\" target=\"_blank\" rel=\"noopener\">RedHat docs - Building, running, and managing Linux containers on Red Hat Enterprise Linux 8</a></li>\n<li><a href=\"https://developer.aliyun.com/article/700923\" target=\"_blank\" rel=\"noopener\">容器安全拾遗 - Rootless Container初探</a></li>\n<li><a href=\"https://www.kernel.org/doc/html/latest/admin-guide/sysctl/user.html\" target=\"_blank\" rel=\"noopener\">Documentation for /proc/sys/user/</a></li>\n<li><a href=\"https://docs.docker.com/compose/\" target=\"_blank\" rel=\"noopener\">docker docs - Overview of Docker Compose</a></li>\n<li><a href=\"https://www.cni.dev/plugins/current/meta/firewall/\" target=\"_blank\" rel=\"noopener\">CNI docs - firewall plugin</a></li>\n<li><a href=\"https://www.cni.dev/plugins/current/meta/firewall/\" target=\"_blank\" rel=\"noopener\">CNI docs - Port-mapping plugin</a></li>\n<li><a href=\"https://fossies.org/linux/podman/docs/tutorials/basic_networking.md\" target=\"_blank\" rel=\"noopener\">https://fossies.org/linux/podman/docs/tutorials/basic_networking.md</a></li>\n</ul>\n"},{"title":"Red Hat Quay v3 registry 原理与实现","subtitle":"Red Hat Quay v3 registry Architecture and Implement","header-img":"redhat-quay-bg.jpg","date":"2022-12-05T09:05:39.000Z","_content":"\n### 文档目录：\n- 常用私有容器镜像仓库\n- Red Hat 支持的容器镜像仓库\n- Red Hat 容器镜像安全\n- Red Hat Quay v3 私有容器镜像仓库部署\n- 参考链接\n\n### 常用私有容器镜像仓库：\n- Harbor v1/v2：由 `VMware` 主导开发，并从 `CNCF` 云原生计算基金会孵化成功。\n- **`Red Hat Quay v3`**：由 `Red Hat` 开源的私有容器镜像仓库，类似于 `CoreOS` 的 Quay。\n- registry v2：`Docker` 公司发布的 v2 版本容器镜像仓库镜像，可直接运行提供服务。\n- docker-distribution：由 `docker-distribution` RPM 软件包提供，`systemd` 方式运行。\n\n### Red Hat 支持的容器镜像仓库：\n- **Red Hat Container Registry**：`registry.access.redhat.com`  \n  - 该仓库为公共镜像仓库，用于托管 Red Hat 产品的镜像，无需身份验证。  \n  - 但请注意，虽然此容器镜像仓库是公共的，但 Red Hat 的大多数容器镜像规定要求用户拥有激活的 Red Hat 产品订阅，并且他们遵守产品的终端用户协议（EUA）。  \n  - 只有基于 Red Hat Enterprise Linux Universal Base Images (`UBI`) 的镜像可从该镜像仓库中自由地重新发布。\n- **Red Hat terms-based registry**：`registry.redhat.io`  \n  - 该仓库为私有镜像仓库，用于托管 Red Hat 产品的镜像，并且需要身份验证。  \n  - 从该仓库拉取镜像时，需提供 Red Hat Customer Portal 凭证（credential）进行身份验证。  \n  - 对于共享环境，如 OpenShift 或 CI/CD 管道，可创建 `service account` 或身份验证令牌（token），以避免暴露个人凭据。\n- **Red Hat partner registry**：`registry.connect.redhat.com`  \n  - 该仓库为私有镜像仓库，用于托管来自认证合作伙伴的第三方产品的镜像。  \n  - 它还需提供 Red Hat Customer Portal 凭证进行身份验证。  \n  - 它们可能受制于合伙伙伴的认购或许可。\n- **Quay.io**：  \n  - Red Hat 还管理 `Quay.io` 容器镜像仓库，任何人都可以注册一个免费帐户，并发布自己的容器镜像。  \n  - Red Hat 对任何托管在 Quay.io 上的容器镜像都没有提供保证。  \n  - 大多数用户使用 Quay.io 作为一个公共镜像仓库，但是组织（organization）也可以购买允许使用 Quay.io 作为私有镜像仓库。\n> 👉 关于 Red Hat 容器镜像仓库的说明可参考 [Red Hat Container Registry Authentication](https://access.redhat.com/RegistryAuthentication)\n\n### Red Hat 容器镜像安全：\n- [Red Hat Container Catalog](https://catalog.redhat.com/software/containers/search)（RHCC）可提供构建 S2I 构建镜像的基础容器镜像，也可直接提供 S2I 构建镜像，Red Hat Container Catalog 通过 `https://registry.redhat.io` 作为容器镜像拉取与推送的 portal。\n- 该容器镜像仓库中的镜像通过 `Container Health Index` 进行安全性评估，可根据不同的评估结果选取开发者所需要的镜像，一般选择安全等级为 `A` 或 `B` 的镜像，以下以 `Go Toolset` 镜像为例确定其安全等级：![go-toolset-catalog.jpg](go-toolset-catalog.jpg)\n- 关于 [Red Hat 容器镜像安全等级说明](https://access.redhat.com/articles/2803031)，如下所示：![catalog-health-index.jpg](catalog-health-index.jpg)\n  - Red Hat 安全评级说明文档可参考 [Understanding Red Hat security ratings](https://access.redhat.com/security/updates/classification)\n- 容器镜像的安全评分与分级可参考 [Security Scoring and Grading for Container Images](https://access.redhat.com/blogs/product-security/posts/container-security-scoring)\n\n### Red Hat Quay v3 私有容器镜像仓库部署：\n- Red Hat Quay 容器镜像仓库的高级特性：  \n  - 镜像安全扫描（image security scanning）  \n  - 基于角色的访问（role-based access）  \n  - 组织与团队管理（organization and team management）  \n  - 镜像自动化构建（image build automation）  \n  - 审计（auditing）  \n  - 异地复制（geo-replication）  \n  - 高可用（high availability）\n- 该文档使用 `basic` 方式容器部署，非 **`HA`** 方式。\n- Red Hat Quay v3 私有容器镜像仓库组件：  \n  - `Database`：MySQL 或 PostgreSQL 数据库，主要存储镜像的元数据信息，而非镜像存储。  \n  - `Redis`：键值型存储，存储实时构建日志与 Quay 的向导。  \n  - `Quay`：容器镜像仓库，主要运行 quay 容器服务，该服务由多个组件组成。  \n  - **`Clair`**：静态容器镜像扫描工具，可识别安全隐患与修复问题（fixes）。\n- 部署的容器镜像与版本：  \n  - MySQL：[registry.access.redhat.com/rhscl/mysql-57-rhel7:latest](http://registry.access.redhat.com/rhscl/mysql-57-rhel7:latest)  \n  - Redis：[registry.assess.redhat.com/rhscl/redis-32-rhel7:latest](http://registry.assess.redhat.com/rhscl/redis-32-rhel7:latest)  \n  - Quay：quay.io/redhat/quay:v3.3.0\n> **注意**：拉取该容器镜像前必须先使用相应账号登录 Quay，如下脚本所示。\n- 使用 `docker` 运行各个单容器方式的部署脚本请 [参考此处](https://github.com/Alberthua-Perl/summary-scripts/blob/master/shell-examples/deploy-quay-registry.sh)。\n- 🚀 推荐：  \n  使用 `podman` 运行单 `pod` 集成以上所有容器方式的部署脚本请 [参考此处](https://github.com/Alberthua-Perl/scripts-confs/blob/master/shell-examples/quay-pod-manage.sh)（未集成 Clair）。  \n  该方式中 quay-aio pod 将所有容器限制在同一 `network namespace` 中，Quay 的配置、部署与访问涉及众多端口，使用单容器运行于宿主机上将生成多条 iptables `filter` 与 `nat` 表规则，而集成在单 pod 中更加便于管理。\n- 以第二种方式为例，首先执行 `quay-pod-manage config` 命令，再进行以下配置。\n- 部署前首次配置 Quay 时，需通过 Web 页面将 Quay 与 MySQL 对接，指定仓库 FQDN 及对接的 Redis 数据库地址，若使用 pod 方式部署，其地址即为 pod 所在 `network namespace` 的 ip 地址，并最终下载 quay 的 `.tar.gz` 配置文件。\n- 运行以上命令可能出现的报错（现已解决）：  \n  - 报错 1：由于 `/mnt/quay/config/ssl.key` 权限问题导致无法启动 quay-master 容器，更改其权限为 `0644` 即可。![ssl-key-permission-run-quay-error.jpg](ssl-key-permission-run-quay-error.jpg)\n  - 报错 2：由于 `/mnt/quay/storage/` 所有者问题导致无法从客户端推送容器镜像至镜像仓库中，更改目录的所有者为 `1001` 即可，该用户为 quay-master 容器中主进程的运行用户，必须对宿主机映射的目录具有写权限。![podman-push-quay-permission-denied-1001-1.jpg](podman-push-quay-permission-denied-1001-1.jpg)![podman-push-quay-permission-denied-1001-2.jpg](podman-push-quay-permission-denied-1001-2.jpg)\n- `Web UI` 中的配置过程如下所示：  \n  - 配置并生成 Quay 配置文件：    \n    - 登录 Quay 并完成认证：![first-login-config-quay.png](first-login-config-quay.png)    \n    - 生成 Quay 配置文件：![config-quay-1.png](config-quay-1.png)![config-quay-2.png](config-quay-2.png)![config-quay-3.png](config-quay-3.png)![config-quay-4.png](config-quay-4.png)![config-quay-5.png](config-quay-5.png)![config-quay-6.png](config-quay-6.png)![config-quay-7.png](config-quay-7.png)![config-quay-8.png](config-quay-8.png)\n- 下载 quay 的配置压缩文件后，可执行 `quay-pod-manage deploy` 命令完成 Quay 的部署。\n- 若部署失败可执行 `quay-pod-manage destroy` 命令销毁 pod。\n- 若运行 Quay 的 quay-master 容器状态异常，可执行 `quay-pod-manage recover` 命令恢复故障的容器。\n- 登录与验证 Quay 私有容器镜像仓库：  \n  用户名：`admin` 密码：`1qazZSE$`![normal-login-quay.png](normal-login-quay.png)\n- Podman 客户端登录 Quay：  \n  使用基于 `Docker registry API` 的 `OCI distribution API` 登录并访问 Quay 容器镜像仓库，Red Hat 推荐使用基于 RHEL 的容器工具，即 `Podman`、`Buildah` 与 `Skopeo` 来访问该 API。  \n  ```bash\n  $ sudo mkdir /etc/docker/certs.d/<quay_registry_fqdn>/\n  # 创建 Podman 客户端 Quay CA 证书存储目录\n  $ sudo scp root@<quay_registry_fqdn>:/mnt/quay/config/ssl.cert \\\n    /etc/docker/certs.d/<quay_registry_fqdn>/ssl.crt\n  # 同步 Quay CA 证书至 Podman 客户端\n  \n  # su - contsvc\n  $ vim ~/.config/containers/registries.conf\n    unqualified-search-registries = ['<quay_registry_fqdn>']\n    # 该地址形如 registry.lab.example.com\n    [[registry]]\n    location = \"<quay_registry_fqdn>\"\n    insecure = true\n    blocked = false\n  # 配置普通用户的 Quay 私有容器镜像仓库地址\n  \n  $ podman login <quay_registry_fqdn> \\\n    --username admin --password 1qazZSE$ \\\n    --log-level=debug\n  # 成功登录 Quay 私有容器镜像仓库，并开启 debug 模式。\n  ```\n- Docker 客户端登录 Quay（可选）：![docker-client-login-quay-registry.jpg](docker-client-login-quay-registry.jpg)\n\n### 参考链接：\n- [Quay 基础版安装和部署](https://www.cnblogs.com/ericnie/p/12233269.html)\n- [Deploy Project Quay for proof-of-concept (non-production) purposes](https://docs.projectquay.io/deploy_quay.html)\n- [docker.github.io/registry/deploying.md](https://github.com/docker/docker.github.io/blob/master/registry/deploying.md#get-a-certificate)\n- [docker.github.io/registry/insecure.md](https://github.com/docker/docker.github.io/blob/master/registry/insecure.md)","source":"_posts/redhat-quay-v3-registry.md","raw":"---\ntitle: Red Hat Quay v3 registry 原理与实现\nsubtitle: Red Hat Quay v3 registry Architecture and Implement\nheader-img: redhat-quay-bg.jpg\ndate: 2022-12-05 17:05:39\ntags:\n  - 容器\n  - 云原生\n---\n\n### 文档目录：\n- 常用私有容器镜像仓库\n- Red Hat 支持的容器镜像仓库\n- Red Hat 容器镜像安全\n- Red Hat Quay v3 私有容器镜像仓库部署\n- 参考链接\n\n### 常用私有容器镜像仓库：\n- Harbor v1/v2：由 `VMware` 主导开发，并从 `CNCF` 云原生计算基金会孵化成功。\n- **`Red Hat Quay v3`**：由 `Red Hat` 开源的私有容器镜像仓库，类似于 `CoreOS` 的 Quay。\n- registry v2：`Docker` 公司发布的 v2 版本容器镜像仓库镜像，可直接运行提供服务。\n- docker-distribution：由 `docker-distribution` RPM 软件包提供，`systemd` 方式运行。\n\n### Red Hat 支持的容器镜像仓库：\n- **Red Hat Container Registry**：`registry.access.redhat.com`  \n  - 该仓库为公共镜像仓库，用于托管 Red Hat 产品的镜像，无需身份验证。  \n  - 但请注意，虽然此容器镜像仓库是公共的，但 Red Hat 的大多数容器镜像规定要求用户拥有激活的 Red Hat 产品订阅，并且他们遵守产品的终端用户协议（EUA）。  \n  - 只有基于 Red Hat Enterprise Linux Universal Base Images (`UBI`) 的镜像可从该镜像仓库中自由地重新发布。\n- **Red Hat terms-based registry**：`registry.redhat.io`  \n  - 该仓库为私有镜像仓库，用于托管 Red Hat 产品的镜像，并且需要身份验证。  \n  - 从该仓库拉取镜像时，需提供 Red Hat Customer Portal 凭证（credential）进行身份验证。  \n  - 对于共享环境，如 OpenShift 或 CI/CD 管道，可创建 `service account` 或身份验证令牌（token），以避免暴露个人凭据。\n- **Red Hat partner registry**：`registry.connect.redhat.com`  \n  - 该仓库为私有镜像仓库，用于托管来自认证合作伙伴的第三方产品的镜像。  \n  - 它还需提供 Red Hat Customer Portal 凭证进行身份验证。  \n  - 它们可能受制于合伙伙伴的认购或许可。\n- **Quay.io**：  \n  - Red Hat 还管理 `Quay.io` 容器镜像仓库，任何人都可以注册一个免费帐户，并发布自己的容器镜像。  \n  - Red Hat 对任何托管在 Quay.io 上的容器镜像都没有提供保证。  \n  - 大多数用户使用 Quay.io 作为一个公共镜像仓库，但是组织（organization）也可以购买允许使用 Quay.io 作为私有镜像仓库。\n> 👉 关于 Red Hat 容器镜像仓库的说明可参考 [Red Hat Container Registry Authentication](https://access.redhat.com/RegistryAuthentication)\n\n### Red Hat 容器镜像安全：\n- [Red Hat Container Catalog](https://catalog.redhat.com/software/containers/search)（RHCC）可提供构建 S2I 构建镜像的基础容器镜像，也可直接提供 S2I 构建镜像，Red Hat Container Catalog 通过 `https://registry.redhat.io` 作为容器镜像拉取与推送的 portal。\n- 该容器镜像仓库中的镜像通过 `Container Health Index` 进行安全性评估，可根据不同的评估结果选取开发者所需要的镜像，一般选择安全等级为 `A` 或 `B` 的镜像，以下以 `Go Toolset` 镜像为例确定其安全等级：![go-toolset-catalog.jpg](go-toolset-catalog.jpg)\n- 关于 [Red Hat 容器镜像安全等级说明](https://access.redhat.com/articles/2803031)，如下所示：![catalog-health-index.jpg](catalog-health-index.jpg)\n  - Red Hat 安全评级说明文档可参考 [Understanding Red Hat security ratings](https://access.redhat.com/security/updates/classification)\n- 容器镜像的安全评分与分级可参考 [Security Scoring and Grading for Container Images](https://access.redhat.com/blogs/product-security/posts/container-security-scoring)\n\n### Red Hat Quay v3 私有容器镜像仓库部署：\n- Red Hat Quay 容器镜像仓库的高级特性：  \n  - 镜像安全扫描（image security scanning）  \n  - 基于角色的访问（role-based access）  \n  - 组织与团队管理（organization and team management）  \n  - 镜像自动化构建（image build automation）  \n  - 审计（auditing）  \n  - 异地复制（geo-replication）  \n  - 高可用（high availability）\n- 该文档使用 `basic` 方式容器部署，非 **`HA`** 方式。\n- Red Hat Quay v3 私有容器镜像仓库组件：  \n  - `Database`：MySQL 或 PostgreSQL 数据库，主要存储镜像的元数据信息，而非镜像存储。  \n  - `Redis`：键值型存储，存储实时构建日志与 Quay 的向导。  \n  - `Quay`：容器镜像仓库，主要运行 quay 容器服务，该服务由多个组件组成。  \n  - **`Clair`**：静态容器镜像扫描工具，可识别安全隐患与修复问题（fixes）。\n- 部署的容器镜像与版本：  \n  - MySQL：[registry.access.redhat.com/rhscl/mysql-57-rhel7:latest](http://registry.access.redhat.com/rhscl/mysql-57-rhel7:latest)  \n  - Redis：[registry.assess.redhat.com/rhscl/redis-32-rhel7:latest](http://registry.assess.redhat.com/rhscl/redis-32-rhel7:latest)  \n  - Quay：quay.io/redhat/quay:v3.3.0\n> **注意**：拉取该容器镜像前必须先使用相应账号登录 Quay，如下脚本所示。\n- 使用 `docker` 运行各个单容器方式的部署脚本请 [参考此处](https://github.com/Alberthua-Perl/summary-scripts/blob/master/shell-examples/deploy-quay-registry.sh)。\n- 🚀 推荐：  \n  使用 `podman` 运行单 `pod` 集成以上所有容器方式的部署脚本请 [参考此处](https://github.com/Alberthua-Perl/scripts-confs/blob/master/shell-examples/quay-pod-manage.sh)（未集成 Clair）。  \n  该方式中 quay-aio pod 将所有容器限制在同一 `network namespace` 中，Quay 的配置、部署与访问涉及众多端口，使用单容器运行于宿主机上将生成多条 iptables `filter` 与 `nat` 表规则，而集成在单 pod 中更加便于管理。\n- 以第二种方式为例，首先执行 `quay-pod-manage config` 命令，再进行以下配置。\n- 部署前首次配置 Quay 时，需通过 Web 页面将 Quay 与 MySQL 对接，指定仓库 FQDN 及对接的 Redis 数据库地址，若使用 pod 方式部署，其地址即为 pod 所在 `network namespace` 的 ip 地址，并最终下载 quay 的 `.tar.gz` 配置文件。\n- 运行以上命令可能出现的报错（现已解决）：  \n  - 报错 1：由于 `/mnt/quay/config/ssl.key` 权限问题导致无法启动 quay-master 容器，更改其权限为 `0644` 即可。![ssl-key-permission-run-quay-error.jpg](ssl-key-permission-run-quay-error.jpg)\n  - 报错 2：由于 `/mnt/quay/storage/` 所有者问题导致无法从客户端推送容器镜像至镜像仓库中，更改目录的所有者为 `1001` 即可，该用户为 quay-master 容器中主进程的运行用户，必须对宿主机映射的目录具有写权限。![podman-push-quay-permission-denied-1001-1.jpg](podman-push-quay-permission-denied-1001-1.jpg)![podman-push-quay-permission-denied-1001-2.jpg](podman-push-quay-permission-denied-1001-2.jpg)\n- `Web UI` 中的配置过程如下所示：  \n  - 配置并生成 Quay 配置文件：    \n    - 登录 Quay 并完成认证：![first-login-config-quay.png](first-login-config-quay.png)    \n    - 生成 Quay 配置文件：![config-quay-1.png](config-quay-1.png)![config-quay-2.png](config-quay-2.png)![config-quay-3.png](config-quay-3.png)![config-quay-4.png](config-quay-4.png)![config-quay-5.png](config-quay-5.png)![config-quay-6.png](config-quay-6.png)![config-quay-7.png](config-quay-7.png)![config-quay-8.png](config-quay-8.png)\n- 下载 quay 的配置压缩文件后，可执行 `quay-pod-manage deploy` 命令完成 Quay 的部署。\n- 若部署失败可执行 `quay-pod-manage destroy` 命令销毁 pod。\n- 若运行 Quay 的 quay-master 容器状态异常，可执行 `quay-pod-manage recover` 命令恢复故障的容器。\n- 登录与验证 Quay 私有容器镜像仓库：  \n  用户名：`admin` 密码：`1qazZSE$`![normal-login-quay.png](normal-login-quay.png)\n- Podman 客户端登录 Quay：  \n  使用基于 `Docker registry API` 的 `OCI distribution API` 登录并访问 Quay 容器镜像仓库，Red Hat 推荐使用基于 RHEL 的容器工具，即 `Podman`、`Buildah` 与 `Skopeo` 来访问该 API。  \n  ```bash\n  $ sudo mkdir /etc/docker/certs.d/<quay_registry_fqdn>/\n  # 创建 Podman 客户端 Quay CA 证书存储目录\n  $ sudo scp root@<quay_registry_fqdn>:/mnt/quay/config/ssl.cert \\\n    /etc/docker/certs.d/<quay_registry_fqdn>/ssl.crt\n  # 同步 Quay CA 证书至 Podman 客户端\n  \n  # su - contsvc\n  $ vim ~/.config/containers/registries.conf\n    unqualified-search-registries = ['<quay_registry_fqdn>']\n    # 该地址形如 registry.lab.example.com\n    [[registry]]\n    location = \"<quay_registry_fqdn>\"\n    insecure = true\n    blocked = false\n  # 配置普通用户的 Quay 私有容器镜像仓库地址\n  \n  $ podman login <quay_registry_fqdn> \\\n    --username admin --password 1qazZSE$ \\\n    --log-level=debug\n  # 成功登录 Quay 私有容器镜像仓库，并开启 debug 模式。\n  ```\n- Docker 客户端登录 Quay（可选）：![docker-client-login-quay-registry.jpg](docker-client-login-quay-registry.jpg)\n\n### 参考链接：\n- [Quay 基础版安装和部署](https://www.cnblogs.com/ericnie/p/12233269.html)\n- [Deploy Project Quay for proof-of-concept (non-production) purposes](https://docs.projectquay.io/deploy_quay.html)\n- [docker.github.io/registry/deploying.md](https://github.com/docker/docker.github.io/blob/master/registry/deploying.md#get-a-certificate)\n- [docker.github.io/registry/insecure.md](https://github.com/docker/docker.github.io/blob/master/registry/insecure.md)","slug":"redhat-quay-v3-registry","published":1,"updated":"2022-12-05T09:31:43.745Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldfonoly000i16vdoy45as4e","content":"<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>常用私有容器镜像仓库</li>\n<li>Red Hat 支持的容器镜像仓库</li>\n<li>Red Hat 容器镜像安全</li>\n<li>Red Hat Quay v3 私有容器镜像仓库部署</li>\n<li>参考链接</li>\n</ul>\n<h3 id=\"常用私有容器镜像仓库：\"><a href=\"#常用私有容器镜像仓库：\" class=\"headerlink\" title=\"常用私有容器镜像仓库：\"></a>常用私有容器镜像仓库：</h3><ul>\n<li>Harbor v1/v2：由 <code>VMware</code> 主导开发，并从 <code>CNCF</code> 云原生计算基金会孵化成功。</li>\n<li><strong><code>Red Hat Quay v3</code></strong>：由 <code>Red Hat</code> 开源的私有容器镜像仓库，类似于 <code>CoreOS</code> 的 Quay。</li>\n<li>registry v2：<code>Docker</code> 公司发布的 v2 版本容器镜像仓库镜像，可直接运行提供服务。</li>\n<li>docker-distribution：由 <code>docker-distribution</code> RPM 软件包提供，<code>systemd</code> 方式运行。</li>\n</ul>\n<h3 id=\"Red-Hat-支持的容器镜像仓库：\"><a href=\"#Red-Hat-支持的容器镜像仓库：\" class=\"headerlink\" title=\"Red Hat 支持的容器镜像仓库：\"></a>Red Hat 支持的容器镜像仓库：</h3><ul>\n<li><strong>Red Hat Container Registry</strong>：<code>registry.access.redhat.com</code>  <ul>\n<li>该仓库为公共镜像仓库，用于托管 Red Hat 产品的镜像，无需身份验证。  </li>\n<li>但请注意，虽然此容器镜像仓库是公共的，但 Red Hat 的大多数容器镜像规定要求用户拥有激活的 Red Hat 产品订阅，并且他们遵守产品的终端用户协议（EUA）。  </li>\n<li>只有基于 Red Hat Enterprise Linux Universal Base Images (<code>UBI</code>) 的镜像可从该镜像仓库中自由地重新发布。</li>\n</ul>\n</li>\n<li><strong>Red Hat terms-based registry</strong>：<code>registry.redhat.io</code>  <ul>\n<li>该仓库为私有镜像仓库，用于托管 Red Hat 产品的镜像，并且需要身份验证。  </li>\n<li>从该仓库拉取镜像时，需提供 Red Hat Customer Portal 凭证（credential）进行身份验证。  </li>\n<li>对于共享环境，如 OpenShift 或 CI/CD 管道，可创建 <code>service account</code> 或身份验证令牌（token），以避免暴露个人凭据。</li>\n</ul>\n</li>\n<li><strong>Red Hat partner registry</strong>：<code>registry.connect.redhat.com</code>  <ul>\n<li>该仓库为私有镜像仓库，用于托管来自认证合作伙伴的第三方产品的镜像。  </li>\n<li>它还需提供 Red Hat Customer Portal 凭证进行身份验证。  </li>\n<li>它们可能受制于合伙伙伴的认购或许可。</li>\n</ul>\n</li>\n<li><strong>Quay.io</strong>：  <ul>\n<li>Red Hat 还管理 <code>Quay.io</code> 容器镜像仓库，任何人都可以注册一个免费帐户，并发布自己的容器镜像。  </li>\n<li>Red Hat 对任何托管在 Quay.io 上的容器镜像都没有提供保证。  </li>\n<li>大多数用户使用 Quay.io 作为一个公共镜像仓库，但是组织（organization）也可以购买允许使用 Quay.io 作为私有镜像仓库。<blockquote>\n<p>👉 关于 Red Hat 容器镜像仓库的说明可参考 <a href=\"https://access.redhat.com/RegistryAuthentication\" target=\"_blank\" rel=\"noopener\">Red Hat Container Registry Authentication</a></p>\n</blockquote>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Red-Hat-容器镜像安全：\"><a href=\"#Red-Hat-容器镜像安全：\" class=\"headerlink\" title=\"Red Hat 容器镜像安全：\"></a>Red Hat 容器镜像安全：</h3><ul>\n<li><a href=\"https://catalog.redhat.com/software/containers/search\" target=\"_blank\" rel=\"noopener\">Red Hat Container Catalog</a>（RHCC）可提供构建 S2I 构建镜像的基础容器镜像，也可直接提供 S2I 构建镜像，Red Hat Container Catalog 通过 <code>https://registry.redhat.io</code> 作为容器镜像拉取与推送的 portal。</li>\n<li>该容器镜像仓库中的镜像通过 <code>Container Health Index</code> 进行安全性评估，可根据不同的评估结果选取开发者所需要的镜像，一般选择安全等级为 <code>A</code> 或 <code>B</code> 的镜像，以下以 <code>Go Toolset</code> 镜像为例确定其安全等级：<img src=\"go-toolset-catalog.jpg\" alt=\"go-toolset-catalog.jpg\"></li>\n<li>关于 <a href=\"https://access.redhat.com/articles/2803031\" target=\"_blank\" rel=\"noopener\">Red Hat 容器镜像安全等级说明</a>，如下所示：<img src=\"catalog-health-index.jpg\" alt=\"catalog-health-index.jpg\"><ul>\n<li>Red Hat 安全评级说明文档可参考 <a href=\"https://access.redhat.com/security/updates/classification\" target=\"_blank\" rel=\"noopener\">Understanding Red Hat security ratings</a></li>\n</ul>\n</li>\n<li>容器镜像的安全评分与分级可参考 <a href=\"https://access.redhat.com/blogs/product-security/posts/container-security-scoring\" target=\"_blank\" rel=\"noopener\">Security Scoring and Grading for Container Images</a></li>\n</ul>\n<h3 id=\"Red-Hat-Quay-v3-私有容器镜像仓库部署：\"><a href=\"#Red-Hat-Quay-v3-私有容器镜像仓库部署：\" class=\"headerlink\" title=\"Red Hat Quay v3 私有容器镜像仓库部署：\"></a>Red Hat Quay v3 私有容器镜像仓库部署：</h3><ul>\n<li>Red Hat Quay 容器镜像仓库的高级特性：  <ul>\n<li>镜像安全扫描（image security scanning）  </li>\n<li>基于角色的访问（role-based access）  </li>\n<li>组织与团队管理（organization and team management）  </li>\n<li>镜像自动化构建（image build automation）  </li>\n<li>审计（auditing）  </li>\n<li>异地复制（geo-replication）  </li>\n<li>高可用（high availability）</li>\n</ul>\n</li>\n<li>该文档使用 <code>basic</code> 方式容器部署，非 <strong><code>HA</code></strong> 方式。</li>\n<li>Red Hat Quay v3 私有容器镜像仓库组件：  <ul>\n<li><code>Database</code>：MySQL 或 PostgreSQL 数据库，主要存储镜像的元数据信息，而非镜像存储。  </li>\n<li><code>Redis</code>：键值型存储，存储实时构建日志与 Quay 的向导。  </li>\n<li><code>Quay</code>：容器镜像仓库，主要运行 quay 容器服务，该服务由多个组件组成。  </li>\n<li><strong><code>Clair</code></strong>：静态容器镜像扫描工具，可识别安全隐患与修复问题（fixes）。</li>\n</ul>\n</li>\n<li>部署的容器镜像与版本：  <ul>\n<li>MySQL：<a href=\"http://registry.access.redhat.com/rhscl/mysql-57-rhel7:latest\" target=\"_blank\" rel=\"noopener\">registry.access.redhat.com/rhscl/mysql-57-rhel7:latest</a>  </li>\n<li>Redis：<a href=\"http://registry.assess.redhat.com/rhscl/redis-32-rhel7:latest\" target=\"_blank\" rel=\"noopener\">registry.assess.redhat.com/rhscl/redis-32-rhel7:latest</a>  </li>\n<li>Quay：quay.io/redhat/quay:v3.3.0<blockquote>\n<p><strong>注意</strong>：拉取该容器镜像前必须先使用相应账号登录 Quay，如下脚本所示。</p>\n</blockquote>\n</li>\n</ul>\n</li>\n<li>使用 <code>docker</code> 运行各个单容器方式的部署脚本请 <a href=\"https://github.com/Alberthua-Perl/summary-scripts/blob/master/shell-examples/deploy-quay-registry.sh\" target=\"_blank\" rel=\"noopener\">参考此处</a>。</li>\n<li>🚀 推荐：<br>使用 <code>podman</code> 运行单 <code>pod</code> 集成以上所有容器方式的部署脚本请 <a href=\"https://github.com/Alberthua-Perl/scripts-confs/blob/master/shell-examples/quay-pod-manage.sh\" target=\"_blank\" rel=\"noopener\">参考此处</a>（未集成 Clair）。<br>该方式中 quay-aio pod 将所有容器限制在同一 <code>network namespace</code> 中，Quay 的配置、部署与访问涉及众多端口，使用单容器运行于宿主机上将生成多条 iptables <code>filter</code> 与 <code>nat</code> 表规则，而集成在单 pod 中更加便于管理。</li>\n<li>以第二种方式为例，首先执行 <code>quay-pod-manage config</code> 命令，再进行以下配置。</li>\n<li>部署前首次配置 Quay 时，需通过 Web 页面将 Quay 与 MySQL 对接，指定仓库 FQDN 及对接的 Redis 数据库地址，若使用 pod 方式部署，其地址即为 pod 所在 <code>network namespace</code> 的 ip 地址，并最终下载 quay 的 <code>.tar.gz</code> 配置文件。</li>\n<li>运行以上命令可能出现的报错（现已解决）：  <ul>\n<li>报错 1：由于 <code>/mnt/quay/config/ssl.key</code> 权限问题导致无法启动 quay-master 容器，更改其权限为 <code>0644</code> 即可。<img src=\"ssl-key-permission-run-quay-error.jpg\" alt=\"ssl-key-permission-run-quay-error.jpg\"></li>\n<li>报错 2：由于 <code>/mnt/quay/storage/</code> 所有者问题导致无法从客户端推送容器镜像至镜像仓库中，更改目录的所有者为 <code>1001</code> 即可，该用户为 quay-master 容器中主进程的运行用户，必须对宿主机映射的目录具有写权限。<img src=\"podman-push-quay-permission-denied-1001-1.jpg\" alt=\"podman-push-quay-permission-denied-1001-1.jpg\"><img src=\"podman-push-quay-permission-denied-1001-2.jpg\" alt=\"podman-push-quay-permission-denied-1001-2.jpg\"></li>\n</ul>\n</li>\n<li><code>Web UI</code> 中的配置过程如下所示：  <ul>\n<li>配置并生成 Quay 配置文件：    <ul>\n<li>登录 Quay 并完成认证：<img src=\"first-login-config-quay.png\" alt=\"first-login-config-quay.png\">    </li>\n<li>生成 Quay 配置文件：<img src=\"config-quay-1.png\" alt=\"config-quay-1.png\"><img src=\"config-quay-2.png\" alt=\"config-quay-2.png\"><img src=\"config-quay-3.png\" alt=\"config-quay-3.png\"><img src=\"config-quay-4.png\" alt=\"config-quay-4.png\"><img src=\"config-quay-5.png\" alt=\"config-quay-5.png\"><img src=\"config-quay-6.png\" alt=\"config-quay-6.png\"><img src=\"config-quay-7.png\" alt=\"config-quay-7.png\"><img src=\"config-quay-8.png\" alt=\"config-quay-8.png\"></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>下载 quay 的配置压缩文件后，可执行 <code>quay-pod-manage deploy</code> 命令完成 Quay 的部署。</li>\n<li>若部署失败可执行 <code>quay-pod-manage destroy</code> 命令销毁 pod。</li>\n<li>若运行 Quay 的 quay-master 容器状态异常，可执行 <code>quay-pod-manage recover</code> 命令恢复故障的容器。</li>\n<li>登录与验证 Quay 私有容器镜像仓库：<br>用户名：<code>admin</code> 密码：<code>1qazZSE$</code><img src=\"normal-login-quay.png\" alt=\"normal-login-quay.png\"></li>\n<li><p>Podman 客户端登录 Quay：<br>使用基于 <code>Docker registry API</code> 的 <code>OCI distribution API</code> 登录并访问 Quay 容器镜像仓库，Red Hat 推荐使用基于 RHEL 的容器工具，即 <code>Podman</code>、<code>Buildah</code> 与 <code>Skopeo</code> 来访问该 API。  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo mkdir /etc/docker/certs.d/&lt;quay_registry_fqdn&gt;/</span><br><span class=\"line\"><span class=\"comment\"># 创建 Podman 客户端 Quay CA 证书存储目录</span></span><br><span class=\"line\">$ sudo scp root@&lt;quay_registry_fqdn&gt;:/mnt/quay/config/ssl.cert \\</span><br><span class=\"line\">  /etc/docker/certs.d/&lt;quay_registry_fqdn&gt;/ssl.crt</span><br><span class=\"line\"><span class=\"comment\"># 同步 Quay CA 证书至 Podman 客户端</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># su - contsvc</span></span><br><span class=\"line\">$ vim ~/.config/containers/registries.conf</span><br><span class=\"line\">  unqualified-search-registries = [<span class=\"string\">'&lt;quay_registry_fqdn&gt;'</span>]</span><br><span class=\"line\">  <span class=\"comment\"># 该地址形如 registry.lab.example.com</span></span><br><span class=\"line\">  [[registry]]</span><br><span class=\"line\">  location = <span class=\"string\">\"&lt;quay_registry_fqdn&gt;\"</span></span><br><span class=\"line\">  insecure = <span class=\"literal\">true</span></span><br><span class=\"line\">  blocked = <span class=\"literal\">false</span></span><br><span class=\"line\"><span class=\"comment\"># 配置普通用户的 Quay 私有容器镜像仓库地址</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ podman login &lt;quay_registry_fqdn&gt; \\</span><br><span class=\"line\">  --username admin --password 1qazZSE$ \\</span><br><span class=\"line\">  --<span class=\"built_in\">log</span>-level=debug</span><br><span class=\"line\"><span class=\"comment\"># 成功登录 Quay 私有容器镜像仓库，并开启 debug 模式。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Docker 客户端登录 Quay（可选）：<img src=\"docker-client-login-quay-registry.jpg\" alt=\"docker-client-login-quay-registry.jpg\"></p>\n</li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://www.cnblogs.com/ericnie/p/12233269.html\" target=\"_blank\" rel=\"noopener\">Quay 基础版安装和部署</a></li>\n<li><a href=\"https://docs.projectquay.io/deploy_quay.html\" target=\"_blank\" rel=\"noopener\">Deploy Project Quay for proof-of-concept (non-production) purposes</a></li>\n<li><a href=\"https://github.com/docker/docker.github.io/blob/master/registry/deploying.md#get-a-certificate\" target=\"_blank\" rel=\"noopener\">docker.github.io/registry/deploying.md</a></li>\n<li><a href=\"https://github.com/docker/docker.github.io/blob/master/registry/insecure.md\" target=\"_blank\" rel=\"noopener\">docker.github.io/registry/insecure.md</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>常用私有容器镜像仓库</li>\n<li>Red Hat 支持的容器镜像仓库</li>\n<li>Red Hat 容器镜像安全</li>\n<li>Red Hat Quay v3 私有容器镜像仓库部署</li>\n<li>参考链接</li>\n</ul>\n<h3 id=\"常用私有容器镜像仓库：\"><a href=\"#常用私有容器镜像仓库：\" class=\"headerlink\" title=\"常用私有容器镜像仓库：\"></a>常用私有容器镜像仓库：</h3><ul>\n<li>Harbor v1/v2：由 <code>VMware</code> 主导开发，并从 <code>CNCF</code> 云原生计算基金会孵化成功。</li>\n<li><strong><code>Red Hat Quay v3</code></strong>：由 <code>Red Hat</code> 开源的私有容器镜像仓库，类似于 <code>CoreOS</code> 的 Quay。</li>\n<li>registry v2：<code>Docker</code> 公司发布的 v2 版本容器镜像仓库镜像，可直接运行提供服务。</li>\n<li>docker-distribution：由 <code>docker-distribution</code> RPM 软件包提供，<code>systemd</code> 方式运行。</li>\n</ul>\n<h3 id=\"Red-Hat-支持的容器镜像仓库：\"><a href=\"#Red-Hat-支持的容器镜像仓库：\" class=\"headerlink\" title=\"Red Hat 支持的容器镜像仓库：\"></a>Red Hat 支持的容器镜像仓库：</h3><ul>\n<li><strong>Red Hat Container Registry</strong>：<code>registry.access.redhat.com</code>  <ul>\n<li>该仓库为公共镜像仓库，用于托管 Red Hat 产品的镜像，无需身份验证。  </li>\n<li>但请注意，虽然此容器镜像仓库是公共的，但 Red Hat 的大多数容器镜像规定要求用户拥有激活的 Red Hat 产品订阅，并且他们遵守产品的终端用户协议（EUA）。  </li>\n<li>只有基于 Red Hat Enterprise Linux Universal Base Images (<code>UBI</code>) 的镜像可从该镜像仓库中自由地重新发布。</li>\n</ul>\n</li>\n<li><strong>Red Hat terms-based registry</strong>：<code>registry.redhat.io</code>  <ul>\n<li>该仓库为私有镜像仓库，用于托管 Red Hat 产品的镜像，并且需要身份验证。  </li>\n<li>从该仓库拉取镜像时，需提供 Red Hat Customer Portal 凭证（credential）进行身份验证。  </li>\n<li>对于共享环境，如 OpenShift 或 CI/CD 管道，可创建 <code>service account</code> 或身份验证令牌（token），以避免暴露个人凭据。</li>\n</ul>\n</li>\n<li><strong>Red Hat partner registry</strong>：<code>registry.connect.redhat.com</code>  <ul>\n<li>该仓库为私有镜像仓库，用于托管来自认证合作伙伴的第三方产品的镜像。  </li>\n<li>它还需提供 Red Hat Customer Portal 凭证进行身份验证。  </li>\n<li>它们可能受制于合伙伙伴的认购或许可。</li>\n</ul>\n</li>\n<li><strong>Quay.io</strong>：  <ul>\n<li>Red Hat 还管理 <code>Quay.io</code> 容器镜像仓库，任何人都可以注册一个免费帐户，并发布自己的容器镜像。  </li>\n<li>Red Hat 对任何托管在 Quay.io 上的容器镜像都没有提供保证。  </li>\n<li>大多数用户使用 Quay.io 作为一个公共镜像仓库，但是组织（organization）也可以购买允许使用 Quay.io 作为私有镜像仓库。<blockquote>\n<p>👉 关于 Red Hat 容器镜像仓库的说明可参考 <a href=\"https://access.redhat.com/RegistryAuthentication\" target=\"_blank\" rel=\"noopener\">Red Hat Container Registry Authentication</a></p>\n</blockquote>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Red-Hat-容器镜像安全：\"><a href=\"#Red-Hat-容器镜像安全：\" class=\"headerlink\" title=\"Red Hat 容器镜像安全：\"></a>Red Hat 容器镜像安全：</h3><ul>\n<li><a href=\"https://catalog.redhat.com/software/containers/search\" target=\"_blank\" rel=\"noopener\">Red Hat Container Catalog</a>（RHCC）可提供构建 S2I 构建镜像的基础容器镜像，也可直接提供 S2I 构建镜像，Red Hat Container Catalog 通过 <code>https://registry.redhat.io</code> 作为容器镜像拉取与推送的 portal。</li>\n<li>该容器镜像仓库中的镜像通过 <code>Container Health Index</code> 进行安全性评估，可根据不同的评估结果选取开发者所需要的镜像，一般选择安全等级为 <code>A</code> 或 <code>B</code> 的镜像，以下以 <code>Go Toolset</code> 镜像为例确定其安全等级：<img src=\"go-toolset-catalog.jpg\" alt=\"go-toolset-catalog.jpg\"></li>\n<li>关于 <a href=\"https://access.redhat.com/articles/2803031\" target=\"_blank\" rel=\"noopener\">Red Hat 容器镜像安全等级说明</a>，如下所示：<img src=\"catalog-health-index.jpg\" alt=\"catalog-health-index.jpg\"><ul>\n<li>Red Hat 安全评级说明文档可参考 <a href=\"https://access.redhat.com/security/updates/classification\" target=\"_blank\" rel=\"noopener\">Understanding Red Hat security ratings</a></li>\n</ul>\n</li>\n<li>容器镜像的安全评分与分级可参考 <a href=\"https://access.redhat.com/blogs/product-security/posts/container-security-scoring\" target=\"_blank\" rel=\"noopener\">Security Scoring and Grading for Container Images</a></li>\n</ul>\n<h3 id=\"Red-Hat-Quay-v3-私有容器镜像仓库部署：\"><a href=\"#Red-Hat-Quay-v3-私有容器镜像仓库部署：\" class=\"headerlink\" title=\"Red Hat Quay v3 私有容器镜像仓库部署：\"></a>Red Hat Quay v3 私有容器镜像仓库部署：</h3><ul>\n<li>Red Hat Quay 容器镜像仓库的高级特性：  <ul>\n<li>镜像安全扫描（image security scanning）  </li>\n<li>基于角色的访问（role-based access）  </li>\n<li>组织与团队管理（organization and team management）  </li>\n<li>镜像自动化构建（image build automation）  </li>\n<li>审计（auditing）  </li>\n<li>异地复制（geo-replication）  </li>\n<li>高可用（high availability）</li>\n</ul>\n</li>\n<li>该文档使用 <code>basic</code> 方式容器部署，非 <strong><code>HA</code></strong> 方式。</li>\n<li>Red Hat Quay v3 私有容器镜像仓库组件：  <ul>\n<li><code>Database</code>：MySQL 或 PostgreSQL 数据库，主要存储镜像的元数据信息，而非镜像存储。  </li>\n<li><code>Redis</code>：键值型存储，存储实时构建日志与 Quay 的向导。  </li>\n<li><code>Quay</code>：容器镜像仓库，主要运行 quay 容器服务，该服务由多个组件组成。  </li>\n<li><strong><code>Clair</code></strong>：静态容器镜像扫描工具，可识别安全隐患与修复问题（fixes）。</li>\n</ul>\n</li>\n<li>部署的容器镜像与版本：  <ul>\n<li>MySQL：<a href=\"http://registry.access.redhat.com/rhscl/mysql-57-rhel7:latest\" target=\"_blank\" rel=\"noopener\">registry.access.redhat.com/rhscl/mysql-57-rhel7:latest</a>  </li>\n<li>Redis：<a href=\"http://registry.assess.redhat.com/rhscl/redis-32-rhel7:latest\" target=\"_blank\" rel=\"noopener\">registry.assess.redhat.com/rhscl/redis-32-rhel7:latest</a>  </li>\n<li>Quay：quay.io/redhat/quay:v3.3.0<blockquote>\n<p><strong>注意</strong>：拉取该容器镜像前必须先使用相应账号登录 Quay，如下脚本所示。</p>\n</blockquote>\n</li>\n</ul>\n</li>\n<li>使用 <code>docker</code> 运行各个单容器方式的部署脚本请 <a href=\"https://github.com/Alberthua-Perl/summary-scripts/blob/master/shell-examples/deploy-quay-registry.sh\" target=\"_blank\" rel=\"noopener\">参考此处</a>。</li>\n<li>🚀 推荐：<br>使用 <code>podman</code> 运行单 <code>pod</code> 集成以上所有容器方式的部署脚本请 <a href=\"https://github.com/Alberthua-Perl/scripts-confs/blob/master/shell-examples/quay-pod-manage.sh\" target=\"_blank\" rel=\"noopener\">参考此处</a>（未集成 Clair）。<br>该方式中 quay-aio pod 将所有容器限制在同一 <code>network namespace</code> 中，Quay 的配置、部署与访问涉及众多端口，使用单容器运行于宿主机上将生成多条 iptables <code>filter</code> 与 <code>nat</code> 表规则，而集成在单 pod 中更加便于管理。</li>\n<li>以第二种方式为例，首先执行 <code>quay-pod-manage config</code> 命令，再进行以下配置。</li>\n<li>部署前首次配置 Quay 时，需通过 Web 页面将 Quay 与 MySQL 对接，指定仓库 FQDN 及对接的 Redis 数据库地址，若使用 pod 方式部署，其地址即为 pod 所在 <code>network namespace</code> 的 ip 地址，并最终下载 quay 的 <code>.tar.gz</code> 配置文件。</li>\n<li>运行以上命令可能出现的报错（现已解决）：  <ul>\n<li>报错 1：由于 <code>/mnt/quay/config/ssl.key</code> 权限问题导致无法启动 quay-master 容器，更改其权限为 <code>0644</code> 即可。<img src=\"ssl-key-permission-run-quay-error.jpg\" alt=\"ssl-key-permission-run-quay-error.jpg\"></li>\n<li>报错 2：由于 <code>/mnt/quay/storage/</code> 所有者问题导致无法从客户端推送容器镜像至镜像仓库中，更改目录的所有者为 <code>1001</code> 即可，该用户为 quay-master 容器中主进程的运行用户，必须对宿主机映射的目录具有写权限。<img src=\"podman-push-quay-permission-denied-1001-1.jpg\" alt=\"podman-push-quay-permission-denied-1001-1.jpg\"><img src=\"podman-push-quay-permission-denied-1001-2.jpg\" alt=\"podman-push-quay-permission-denied-1001-2.jpg\"></li>\n</ul>\n</li>\n<li><code>Web UI</code> 中的配置过程如下所示：  <ul>\n<li>配置并生成 Quay 配置文件：    <ul>\n<li>登录 Quay 并完成认证：<img src=\"first-login-config-quay.png\" alt=\"first-login-config-quay.png\">    </li>\n<li>生成 Quay 配置文件：<img src=\"config-quay-1.png\" alt=\"config-quay-1.png\"><img src=\"config-quay-2.png\" alt=\"config-quay-2.png\"><img src=\"config-quay-3.png\" alt=\"config-quay-3.png\"><img src=\"config-quay-4.png\" alt=\"config-quay-4.png\"><img src=\"config-quay-5.png\" alt=\"config-quay-5.png\"><img src=\"config-quay-6.png\" alt=\"config-quay-6.png\"><img src=\"config-quay-7.png\" alt=\"config-quay-7.png\"><img src=\"config-quay-8.png\" alt=\"config-quay-8.png\"></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>下载 quay 的配置压缩文件后，可执行 <code>quay-pod-manage deploy</code> 命令完成 Quay 的部署。</li>\n<li>若部署失败可执行 <code>quay-pod-manage destroy</code> 命令销毁 pod。</li>\n<li>若运行 Quay 的 quay-master 容器状态异常，可执行 <code>quay-pod-manage recover</code> 命令恢复故障的容器。</li>\n<li>登录与验证 Quay 私有容器镜像仓库：<br>用户名：<code>admin</code> 密码：<code>1qazZSE$</code><img src=\"normal-login-quay.png\" alt=\"normal-login-quay.png\"></li>\n<li><p>Podman 客户端登录 Quay：<br>使用基于 <code>Docker registry API</code> 的 <code>OCI distribution API</code> 登录并访问 Quay 容器镜像仓库，Red Hat 推荐使用基于 RHEL 的容器工具，即 <code>Podman</code>、<code>Buildah</code> 与 <code>Skopeo</code> 来访问该 API。  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo mkdir /etc/docker/certs.d/&lt;quay_registry_fqdn&gt;/</span><br><span class=\"line\"><span class=\"comment\"># 创建 Podman 客户端 Quay CA 证书存储目录</span></span><br><span class=\"line\">$ sudo scp root@&lt;quay_registry_fqdn&gt;:/mnt/quay/config/ssl.cert \\</span><br><span class=\"line\">  /etc/docker/certs.d/&lt;quay_registry_fqdn&gt;/ssl.crt</span><br><span class=\"line\"><span class=\"comment\"># 同步 Quay CA 证书至 Podman 客户端</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># su - contsvc</span></span><br><span class=\"line\">$ vim ~/.config/containers/registries.conf</span><br><span class=\"line\">  unqualified-search-registries = [<span class=\"string\">'&lt;quay_registry_fqdn&gt;'</span>]</span><br><span class=\"line\">  <span class=\"comment\"># 该地址形如 registry.lab.example.com</span></span><br><span class=\"line\">  [[registry]]</span><br><span class=\"line\">  location = <span class=\"string\">\"&lt;quay_registry_fqdn&gt;\"</span></span><br><span class=\"line\">  insecure = <span class=\"literal\">true</span></span><br><span class=\"line\">  blocked = <span class=\"literal\">false</span></span><br><span class=\"line\"><span class=\"comment\"># 配置普通用户的 Quay 私有容器镜像仓库地址</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ podman login &lt;quay_registry_fqdn&gt; \\</span><br><span class=\"line\">  --username admin --password 1qazZSE$ \\</span><br><span class=\"line\">  --<span class=\"built_in\">log</span>-level=debug</span><br><span class=\"line\"><span class=\"comment\"># 成功登录 Quay 私有容器镜像仓库，并开启 debug 模式。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Docker 客户端登录 Quay（可选）：<img src=\"docker-client-login-quay-registry.jpg\" alt=\"docker-client-login-quay-registry.jpg\"></p>\n</li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://www.cnblogs.com/ericnie/p/12233269.html\" target=\"_blank\" rel=\"noopener\">Quay 基础版安装和部署</a></li>\n<li><a href=\"https://docs.projectquay.io/deploy_quay.html\" target=\"_blank\" rel=\"noopener\">Deploy Project Quay for proof-of-concept (non-production) purposes</a></li>\n<li><a href=\"https://github.com/docker/docker.github.io/blob/master/registry/deploying.md#get-a-certificate\" target=\"_blank\" rel=\"noopener\">docker.github.io/registry/deploying.md</a></li>\n<li><a href=\"https://github.com/docker/docker.github.io/blob/master/registry/insecure.md\" target=\"_blank\" rel=\"noopener\">docker.github.io/registry/insecure.md</a></li>\n</ul>\n"},{"title":"Kubernetes 中部署 Rocket.Chat 与 MongoDB 实时交流平台","subtitle":"Deploy Rocket.Chat and MongoDB on Kubernetes","header-img":"mongodb-bg-2.png","date":"2022-12-19T06:07:28.000Z","_content":"\n### 部署环境说明：\n- Kubernetes 版本：`v1.22.1`\n- Rocket.Chat 容器镜像版本：`docker.io/rocketchat/rocket.chat:3.18.7`\n- MongoDB 容器镜像版本：`docker.io/library/mongo:4.0`\n- Kubernetes NFS-Client Privisioner 容器镜像版本：\n  `quay.io/external_storage/nfs-client-provisioner:latest`\n- 👉 若拉取失败，以上镜像均可从 https://quay.io/user/alberthua 中拉取下载。\n- 🔗 点击 [链接](https://github.com/Alberthua-Perl/go-kubernetes-learn-path/tree/hotfixes/rocketchat-mongo-statefulset-app)，以获得部署用的相关文件。\n\n### 部署方式及步骤：\n- 💥 该应用后端的 MongoDB 集群使用 `NFS` 作为动态 PV 的提供者，需提前配置 NFS 服务器节点用于提供 PV（见下文）。\n- 然而，Kubernetes 中未集成 NFS 类型的内部调配者（`internal privisioner`），因此需使用 `nfs-client-provisioner` 将外部 NFS 调配至集群以支持 PV 动态分配。\n- PV 动态分配还需使用 `StorageClass` 资源将 `privisioner` 对接入 Kubernetes 集群。\n- 🚀 StorageClass 调用链：\n  Pod **>** PVC **>** StorageClass **>** provisioner (PV 动态分配) **>** NFS Server\n- MongoDB 集群使用 `StatefulSet` 部署，而该资源需使用 `StorageClass` 实现卷声明模板（`volumeClaimTemplates`）。\n- nfs-client-provisioner 在集群中的部署可参考该 [链接](https://github.com/Alberthua-Perl/go-kubernetes-learn-path/tree/hotfixes/nfs-provisioned-storageclass)，也可参考如下步骤实现： \n  - 登录 `NFS` 服务器节点创建 NFS 共享目录：\n    ```bash\n    $ yum install -y nfs-utils\n    $ systemctl enable --now nfs-server.service\n    $ mkdir -p /data/k8s\n    $ chmod -R 0777 /data/k8s\n    $ echo \"/data/k8s  192.168.110.0/24(rw,sync,no_root_squash)\" > /etc/exports.d/kubecluster.exports\n    # 共享目录与存储网段需根据实际情况而定\n    # 注意：\n    #   共享目录的名称必须与 nfs-client-provisioner Deployment 中的 path 字段\n    #   完全相同！\n    $ exportfs -a\n    $ showmount -e localhost\n      Export list for localhost:\n      /data/k8s 192.168.110.0/24\n    $ mkdir /data/k8s/rocketchat-mongodb-app\n    # 以上目录名称中的 rocketchat-mongodb-app 为命名空间的名称\n    $ chmod 0777 /data/k8s/rocketchat-mongodb-app\n    ```\n  - 📢 报错示例 1：    \n    确认集群各节点已安装 `nfs-utils` 软件包，若未安装在部署 `nfs-client-provisioner` pod 时将返回如下报错，pod 状态持续显示为 `ContainerCreating`：    \n    ```bash\n    $ kubectl describe pod nfs-client-provisioner-8b9f4fbcc-rrw8r -n rocketchat-mongodb-app\n    ...\n    Events:\n      Type     Reason       Age                From               Message\n      ----     ------       ----               ----               -------\n      Normal   Scheduled    77s                default-scheduler  Successfully assigned rocketchat-mongodb-app/nfs-client-provisioner-8b9f4fbcc-rrw8r to kube-node2.lab.example.com\n      Warning  FailedMount  12s (x8 over 76s)  kubelet            MountVolume.SetUp failed for volume \"nfs-client-root\" : mount failed: exit status 32\n    Mounting command: mount\n    Mounting arguments: -t nfs 192.168.110.162:/data/k8s/rocketchat-mongodb-app /var/lib/kubelet/pods/393e67de-39ed-4d17-aeca-9f2ebe360199/volumes/kubernetes.io~nfs/nfs-client-root\n    Output: mount: wrong fs type, bad option, bad superblock on 192.168.110.162:/data/k8s/rocketchat-mongodb-app,\n           missing codepage or helper program, or other error\n           (for several filesystems (e.g. nfs, cifs) you might\n           need a /sbin/mount.<type> helper program)\n    \n           In some cases useful info is found in syslog - try\n           dmesg | tail or so.\n    ```\n  - 📢 报错示例 2：    \n    使用 nfs-client-provisioner pod 实现动态 PV 分配时，必须提前在 NFS Server 上创建与调整以命名空间名称为 `basename` 的共享目录（如上所示），否则将返回如下报错，显示无法找到目录：\n    ```bash\n    ...\n    Events:\n      Type     Reason       Age                 From               Message\n      ----     ------       ----                ----               -------\n      Normal   Scheduled    18m                 default-scheduler  Successfully assigned rocketchat-mongodb-app/nfs-client-provisioner-8b9f4fbcc-j9z24 to kube-node2.lab.example.com\n      Warning  FailedMount  14m (x2 over 16m)   kubelet            Unable to attach or mount volumes: unmounted volumes=[nfs-client-root], unattached volumes=[kube-api-access-rhqq9 nfs-client-root]: timed out waiting for the condition\n      Warning  FailedMount  47s (x6 over 12m)   kubelet            Unable to attach or mount volumes: unmounted volumes=[nfs-client-root], unattached volumes=[nfs-client-root kube-api-access-rhqq9]: timed out waiting for the condition\n      Warning  FailedMount  20s (x17 over 18m)  kubelet            MountVolume.SetUp failed for volume \"nfs-client-root\" : mount failed: exit status 32\n    Mounting command: mount\n    Mounting arguments: -t nfs 192.168.110.162:/data/k8s/rocketchat-mongodb-app /var/lib/kubelet/pods/7cad43c0-0e08-4e07-b0e8-5bba0a535c4d/volumes/kubernetes.io~nfs/nfs-client-root\n    Output: mount.nfs: mounting 192.168.110.162:/data/k8s/rocketchat-mongodb-app failed, reason given by server: No such file or directory\n    ```\n  > 💥 nfs-client-provisioner pod 与应用 pod 部署于同一命名空间中。\n\n- 因此，该应用的部署方式如下所示：  \n  ```bash\n  $ kubectl create namespace rocketchat-mongodb-app\n  $ kubectl apply -f \\\n    00-nfs-provisioned-rbac.yml \\\n    01-nfs-provisioned-deployment.yml \\\n    02-nfs-provisioned-class.yml \\\n    -n rocketchat-mongodb-app\n  $ kubectl apply -f 03-mongodb-internal-headless-svc.yml -n rocketchat-mongodb-app\n  $ kubectl apply -f 04-mongodb-statefulset.yml -n rocketchat-mongodb-app\n  # 该资源创建完成后并未实现 MongoDB 的 ReplicaSet 模式集群，需登录至其中的一个节点实现集群的初始化及 mongo 节点的添加。\n  ```\n\n  ```bash\n  $ kubectl exec -it rocketmongo-0 -n rocketchat-mongodb-app -- mongo\n    # 进入 mongo 节点进行集群的初始化与配置\n    ...\n    > rs.initiate()  # 初始化集群\n    {\n        \"info2\" : \"no configuration specified. Using a default configuration for the set\",\n        \"me\" : \"rocketmongo-0:27017\",\n        \"ok\" : 1\n    }\n    rs0:SECONDARY> var config = rs.conf()\n    rs0:PRIMARY> config.members[0].host=\"rocketmongo-0.mongodb-internal:27017\"\n    rocketmongo-0.mongodb-internal:27017  \n    # 通过 headless service 指向 mongo 节点，将该节点配置为 primary 节点。\n    rs0:PRIMARY> rs.reconfig(config)  # 刷新集群配置\n    {\n        \"ok\" : 1,\n        \"operationTime\" : Timestamp(1671036342, 1),\n        \"$clusterTime\" : {\n            \"clusterTime\" : Timestamp(1671036342, 1),\n            \"signature\" : {\n                \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n                \"keyId\" : NumberLong(0)\n            }\n        }\n    }\n    rs0:PRIMARY> rs.add(\"rocketmongo-1.mongodb-internal:27017\")\n    rs0:PRIMARY> rs.add(\"rocketmongo-2.mongodb-internal:27017\")  # 添加额外的 mongo 节点\n    rs0:PRIMARY> rs.status()    # 查看集群的状态\n    rs0:PRIMARY> rs.isMaster()  # 确认当前 mongo 节点是否为 primary 节点 \n    rs0:PRIMARY> exit           # 退出 MongoDB Shell\n    ...\n  ```\n\n  ```bash\n  $ kubectl apply -f 05-rockerchat-deployment.yml -n rocketchat-mongodb-app\n  # 部署前端 Rocket.Chat 应用\n  ```\n  🤘 如下所示，刷新 Rocket.Chat pod 日志可确认其与 MongoDB 集群成功连接：![rocketchat-mongo-connect-successfully.png](rocketchat-mongo-connect-successfully.png)\n\n### 确认应用资源与登录认证：\n- 该应用所涉及的资源对象如下所示：![rocketchat-mongo-app-resources.png](rocketchat-mongo-app-resources.png)  \n  ```bash\n  $ kubectl get pv\n    NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                               STORAGECLASS          REASON   AGE\n    pvc-1bc91589-312c-4878-af37-5e31a7dacc33   3Gi        RWO            Delete           Bound    rocketchat-mongodb-app/mongo-volume-rocketmongo-0   managed-nfs-storage            21h\n    pvc-aebc940f-f3f2-4389-8d8b-62695dd931b6   3Gi        RWO            Delete           Bound    rocketchat-mongodb-app/mongo-volume-rocketmongo-1   managed-nfs-storage            21h\n    pvc-cd42e48c-ab33-481c-a9dd-eae73c876516   3Gi        RWO            Delete           Bound    rocketchat-mongodb-app/mongo-volume-rocketmongo-2   managed-nfs-storage            21h\n  $ kubectl get pvc -n rocketchat-mongodb-app\n    NAME                         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS          AGE\n    mongo-volume-rocketmongo-0   Bound    pvc-1bc91589-312c-4878-af37-5e31a7dacc33   3Gi        RWO            managed-nfs-storage   21h\n    mongo-volume-rocketmongo-1   Bound    pvc-aebc940f-f3f2-4389-8d8b-62695dd931b6   3Gi        RWO            managed-nfs-storage   21h\n    mongo-volume-rocketmongo-2   Bound    pvc-cd42e48c-ab33-481c-a9dd-eae73c876516   3Gi        RWO            managed-nfs-storage   21h\n  # 查看 PV 动态分配的资源\n  ```\n  👉 NFS 服务器上 PV 的命名格式：`${namespace}-${pvcName}-${pvName}`\n  👉 PV 回收时候的命名格式：`archieved-${namespace}-${pvcName}-${pvName}`\n- 可通过 Rocket.Chat pod 日志中的 URL 链接登录应用并注册账户使用。![rocketchat-login.png](rocketchat-login.png)\n\n### 参考链接：\n- [利用 NFS 动态提供 Kubernetes 后端存储卷](https://www.kancloud.cn/huyipow/dr/766694)\n- [Running MongoDB on Kubernetes with StatefulSets](https://kubernetes.io/blog/2017/01/running-mongodb-on-kubernetes-with-statefulsets/)\n- [Running Rocket.Chat and MongoDB on Kubernetes with StatefulSets](https://dev.to/jmarhee/running-rocketchat-and-mongodb-on-kubernetes-with-statefulsets-431o)\n- [Deploy Rocket chat server using Kubernetes](https://ajorloo.medium.com/deploy-rocket-chat-server-using-kubernetes-2d6c4228853)","source":"_posts/rocketchat-mongodb-on-k8s.md","raw":"---\ntitle: Kubernetes 中部署 Rocket.Chat 与 MongoDB 实时交流平台\nsubtitle: Deploy Rocket.Chat and MongoDB on Kubernetes\nheader-img: mongodb-bg-2.png\ndate: 2022-12-19 14:07:28\ntags:\n  - Kubernetes\n  - 数据库\n---\n\n### 部署环境说明：\n- Kubernetes 版本：`v1.22.1`\n- Rocket.Chat 容器镜像版本：`docker.io/rocketchat/rocket.chat:3.18.7`\n- MongoDB 容器镜像版本：`docker.io/library/mongo:4.0`\n- Kubernetes NFS-Client Privisioner 容器镜像版本：\n  `quay.io/external_storage/nfs-client-provisioner:latest`\n- 👉 若拉取失败，以上镜像均可从 https://quay.io/user/alberthua 中拉取下载。\n- 🔗 点击 [链接](https://github.com/Alberthua-Perl/go-kubernetes-learn-path/tree/hotfixes/rocketchat-mongo-statefulset-app)，以获得部署用的相关文件。\n\n### 部署方式及步骤：\n- 💥 该应用后端的 MongoDB 集群使用 `NFS` 作为动态 PV 的提供者，需提前配置 NFS 服务器节点用于提供 PV（见下文）。\n- 然而，Kubernetes 中未集成 NFS 类型的内部调配者（`internal privisioner`），因此需使用 `nfs-client-provisioner` 将外部 NFS 调配至集群以支持 PV 动态分配。\n- PV 动态分配还需使用 `StorageClass` 资源将 `privisioner` 对接入 Kubernetes 集群。\n- 🚀 StorageClass 调用链：\n  Pod **>** PVC **>** StorageClass **>** provisioner (PV 动态分配) **>** NFS Server\n- MongoDB 集群使用 `StatefulSet` 部署，而该资源需使用 `StorageClass` 实现卷声明模板（`volumeClaimTemplates`）。\n- nfs-client-provisioner 在集群中的部署可参考该 [链接](https://github.com/Alberthua-Perl/go-kubernetes-learn-path/tree/hotfixes/nfs-provisioned-storageclass)，也可参考如下步骤实现： \n  - 登录 `NFS` 服务器节点创建 NFS 共享目录：\n    ```bash\n    $ yum install -y nfs-utils\n    $ systemctl enable --now nfs-server.service\n    $ mkdir -p /data/k8s\n    $ chmod -R 0777 /data/k8s\n    $ echo \"/data/k8s  192.168.110.0/24(rw,sync,no_root_squash)\" > /etc/exports.d/kubecluster.exports\n    # 共享目录与存储网段需根据实际情况而定\n    # 注意：\n    #   共享目录的名称必须与 nfs-client-provisioner Deployment 中的 path 字段\n    #   完全相同！\n    $ exportfs -a\n    $ showmount -e localhost\n      Export list for localhost:\n      /data/k8s 192.168.110.0/24\n    $ mkdir /data/k8s/rocketchat-mongodb-app\n    # 以上目录名称中的 rocketchat-mongodb-app 为命名空间的名称\n    $ chmod 0777 /data/k8s/rocketchat-mongodb-app\n    ```\n  - 📢 报错示例 1：    \n    确认集群各节点已安装 `nfs-utils` 软件包，若未安装在部署 `nfs-client-provisioner` pod 时将返回如下报错，pod 状态持续显示为 `ContainerCreating`：    \n    ```bash\n    $ kubectl describe pod nfs-client-provisioner-8b9f4fbcc-rrw8r -n rocketchat-mongodb-app\n    ...\n    Events:\n      Type     Reason       Age                From               Message\n      ----     ------       ----               ----               -------\n      Normal   Scheduled    77s                default-scheduler  Successfully assigned rocketchat-mongodb-app/nfs-client-provisioner-8b9f4fbcc-rrw8r to kube-node2.lab.example.com\n      Warning  FailedMount  12s (x8 over 76s)  kubelet            MountVolume.SetUp failed for volume \"nfs-client-root\" : mount failed: exit status 32\n    Mounting command: mount\n    Mounting arguments: -t nfs 192.168.110.162:/data/k8s/rocketchat-mongodb-app /var/lib/kubelet/pods/393e67de-39ed-4d17-aeca-9f2ebe360199/volumes/kubernetes.io~nfs/nfs-client-root\n    Output: mount: wrong fs type, bad option, bad superblock on 192.168.110.162:/data/k8s/rocketchat-mongodb-app,\n           missing codepage or helper program, or other error\n           (for several filesystems (e.g. nfs, cifs) you might\n           need a /sbin/mount.<type> helper program)\n    \n           In some cases useful info is found in syslog - try\n           dmesg | tail or so.\n    ```\n  - 📢 报错示例 2：    \n    使用 nfs-client-provisioner pod 实现动态 PV 分配时，必须提前在 NFS Server 上创建与调整以命名空间名称为 `basename` 的共享目录（如上所示），否则将返回如下报错，显示无法找到目录：\n    ```bash\n    ...\n    Events:\n      Type     Reason       Age                 From               Message\n      ----     ------       ----                ----               -------\n      Normal   Scheduled    18m                 default-scheduler  Successfully assigned rocketchat-mongodb-app/nfs-client-provisioner-8b9f4fbcc-j9z24 to kube-node2.lab.example.com\n      Warning  FailedMount  14m (x2 over 16m)   kubelet            Unable to attach or mount volumes: unmounted volumes=[nfs-client-root], unattached volumes=[kube-api-access-rhqq9 nfs-client-root]: timed out waiting for the condition\n      Warning  FailedMount  47s (x6 over 12m)   kubelet            Unable to attach or mount volumes: unmounted volumes=[nfs-client-root], unattached volumes=[nfs-client-root kube-api-access-rhqq9]: timed out waiting for the condition\n      Warning  FailedMount  20s (x17 over 18m)  kubelet            MountVolume.SetUp failed for volume \"nfs-client-root\" : mount failed: exit status 32\n    Mounting command: mount\n    Mounting arguments: -t nfs 192.168.110.162:/data/k8s/rocketchat-mongodb-app /var/lib/kubelet/pods/7cad43c0-0e08-4e07-b0e8-5bba0a535c4d/volumes/kubernetes.io~nfs/nfs-client-root\n    Output: mount.nfs: mounting 192.168.110.162:/data/k8s/rocketchat-mongodb-app failed, reason given by server: No such file or directory\n    ```\n  > 💥 nfs-client-provisioner pod 与应用 pod 部署于同一命名空间中。\n\n- 因此，该应用的部署方式如下所示：  \n  ```bash\n  $ kubectl create namespace rocketchat-mongodb-app\n  $ kubectl apply -f \\\n    00-nfs-provisioned-rbac.yml \\\n    01-nfs-provisioned-deployment.yml \\\n    02-nfs-provisioned-class.yml \\\n    -n rocketchat-mongodb-app\n  $ kubectl apply -f 03-mongodb-internal-headless-svc.yml -n rocketchat-mongodb-app\n  $ kubectl apply -f 04-mongodb-statefulset.yml -n rocketchat-mongodb-app\n  # 该资源创建完成后并未实现 MongoDB 的 ReplicaSet 模式集群，需登录至其中的一个节点实现集群的初始化及 mongo 节点的添加。\n  ```\n\n  ```bash\n  $ kubectl exec -it rocketmongo-0 -n rocketchat-mongodb-app -- mongo\n    # 进入 mongo 节点进行集群的初始化与配置\n    ...\n    > rs.initiate()  # 初始化集群\n    {\n        \"info2\" : \"no configuration specified. Using a default configuration for the set\",\n        \"me\" : \"rocketmongo-0:27017\",\n        \"ok\" : 1\n    }\n    rs0:SECONDARY> var config = rs.conf()\n    rs0:PRIMARY> config.members[0].host=\"rocketmongo-0.mongodb-internal:27017\"\n    rocketmongo-0.mongodb-internal:27017  \n    # 通过 headless service 指向 mongo 节点，将该节点配置为 primary 节点。\n    rs0:PRIMARY> rs.reconfig(config)  # 刷新集群配置\n    {\n        \"ok\" : 1,\n        \"operationTime\" : Timestamp(1671036342, 1),\n        \"$clusterTime\" : {\n            \"clusterTime\" : Timestamp(1671036342, 1),\n            \"signature\" : {\n                \"hash\" : BinData(0,\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"),\n                \"keyId\" : NumberLong(0)\n            }\n        }\n    }\n    rs0:PRIMARY> rs.add(\"rocketmongo-1.mongodb-internal:27017\")\n    rs0:PRIMARY> rs.add(\"rocketmongo-2.mongodb-internal:27017\")  # 添加额外的 mongo 节点\n    rs0:PRIMARY> rs.status()    # 查看集群的状态\n    rs0:PRIMARY> rs.isMaster()  # 确认当前 mongo 节点是否为 primary 节点 \n    rs0:PRIMARY> exit           # 退出 MongoDB Shell\n    ...\n  ```\n\n  ```bash\n  $ kubectl apply -f 05-rockerchat-deployment.yml -n rocketchat-mongodb-app\n  # 部署前端 Rocket.Chat 应用\n  ```\n  🤘 如下所示，刷新 Rocket.Chat pod 日志可确认其与 MongoDB 集群成功连接：![rocketchat-mongo-connect-successfully.png](rocketchat-mongo-connect-successfully.png)\n\n### 确认应用资源与登录认证：\n- 该应用所涉及的资源对象如下所示：![rocketchat-mongo-app-resources.png](rocketchat-mongo-app-resources.png)  \n  ```bash\n  $ kubectl get pv\n    NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                               STORAGECLASS          REASON   AGE\n    pvc-1bc91589-312c-4878-af37-5e31a7dacc33   3Gi        RWO            Delete           Bound    rocketchat-mongodb-app/mongo-volume-rocketmongo-0   managed-nfs-storage            21h\n    pvc-aebc940f-f3f2-4389-8d8b-62695dd931b6   3Gi        RWO            Delete           Bound    rocketchat-mongodb-app/mongo-volume-rocketmongo-1   managed-nfs-storage            21h\n    pvc-cd42e48c-ab33-481c-a9dd-eae73c876516   3Gi        RWO            Delete           Bound    rocketchat-mongodb-app/mongo-volume-rocketmongo-2   managed-nfs-storage            21h\n  $ kubectl get pvc -n rocketchat-mongodb-app\n    NAME                         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS          AGE\n    mongo-volume-rocketmongo-0   Bound    pvc-1bc91589-312c-4878-af37-5e31a7dacc33   3Gi        RWO            managed-nfs-storage   21h\n    mongo-volume-rocketmongo-1   Bound    pvc-aebc940f-f3f2-4389-8d8b-62695dd931b6   3Gi        RWO            managed-nfs-storage   21h\n    mongo-volume-rocketmongo-2   Bound    pvc-cd42e48c-ab33-481c-a9dd-eae73c876516   3Gi        RWO            managed-nfs-storage   21h\n  # 查看 PV 动态分配的资源\n  ```\n  👉 NFS 服务器上 PV 的命名格式：`${namespace}-${pvcName}-${pvName}`\n  👉 PV 回收时候的命名格式：`archieved-${namespace}-${pvcName}-${pvName}`\n- 可通过 Rocket.Chat pod 日志中的 URL 链接登录应用并注册账户使用。![rocketchat-login.png](rocketchat-login.png)\n\n### 参考链接：\n- [利用 NFS 动态提供 Kubernetes 后端存储卷](https://www.kancloud.cn/huyipow/dr/766694)\n- [Running MongoDB on Kubernetes with StatefulSets](https://kubernetes.io/blog/2017/01/running-mongodb-on-kubernetes-with-statefulsets/)\n- [Running Rocket.Chat and MongoDB on Kubernetes with StatefulSets](https://dev.to/jmarhee/running-rocketchat-and-mongodb-on-kubernetes-with-statefulsets-431o)\n- [Deploy Rocket chat server using Kubernetes](https://ajorloo.medium.com/deploy-rocket-chat-server-using-kubernetes-2d6c4228853)","slug":"rocketchat-mongodb-on-k8s","published":1,"updated":"2022-12-23T08:10:16.791Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldfonoma000l16vdkg1vquml","content":"<h3 id=\"部署环境说明：\"><a href=\"#部署环境说明：\" class=\"headerlink\" title=\"部署环境说明：\"></a>部署环境说明：</h3><ul>\n<li>Kubernetes 版本：<code>v1.22.1</code></li>\n<li>Rocket.Chat 容器镜像版本：<code>docker.io/rocketchat/rocket.chat:3.18.7</code></li>\n<li>MongoDB 容器镜像版本：<code>docker.io/library/mongo:4.0</code></li>\n<li>Kubernetes NFS-Client Privisioner 容器镜像版本：<br><code>quay.io/external_storage/nfs-client-provisioner:latest</code></li>\n<li>👉 若拉取失败，以上镜像均可从 <a href=\"https://quay.io/user/alberthua\" target=\"_blank\" rel=\"noopener\">https://quay.io/user/alberthua</a> 中拉取下载。</li>\n<li>🔗 点击 <a href=\"https://github.com/Alberthua-Perl/go-kubernetes-learn-path/tree/hotfixes/rocketchat-mongo-statefulset-app\" target=\"_blank\" rel=\"noopener\">链接</a>，以获得部署用的相关文件。</li>\n</ul>\n<h3 id=\"部署方式及步骤：\"><a href=\"#部署方式及步骤：\" class=\"headerlink\" title=\"部署方式及步骤：\"></a>部署方式及步骤：</h3><ul>\n<li>💥 该应用后端的 MongoDB 集群使用 <code>NFS</code> 作为动态 PV 的提供者，需提前配置 NFS 服务器节点用于提供 PV（见下文）。</li>\n<li>然而，Kubernetes 中未集成 NFS 类型的内部调配者（<code>internal privisioner</code>），因此需使用 <code>nfs-client-provisioner</code> 将外部 NFS 调配至集群以支持 PV 动态分配。</li>\n<li>PV 动态分配还需使用 <code>StorageClass</code> 资源将 <code>privisioner</code> 对接入 Kubernetes 集群。</li>\n<li>🚀 StorageClass 调用链：<br>Pod <strong>&gt;</strong> PVC <strong>&gt;</strong> StorageClass <strong>&gt;</strong> provisioner (PV 动态分配) <strong>&gt;</strong> NFS Server</li>\n<li>MongoDB 集群使用 <code>StatefulSet</code> 部署，而该资源需使用 <code>StorageClass</code> 实现卷声明模板（<code>volumeClaimTemplates</code>）。</li>\n<li><p>nfs-client-provisioner 在集群中的部署可参考该 <a href=\"https://github.com/Alberthua-Perl/go-kubernetes-learn-path/tree/hotfixes/nfs-provisioned-storageclass\" target=\"_blank\" rel=\"noopener\">链接</a>，也可参考如下步骤实现： </p>\n<ul>\n<li><p>登录 <code>NFS</code> 服务器节点创建 NFS 共享目录：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum install -y nfs-utils</span><br><span class=\"line\">$ systemctl <span class=\"built_in\">enable</span> --now nfs-server.service</span><br><span class=\"line\">$ mkdir -p /data/k8s</span><br><span class=\"line\">$ chmod -R 0777 /data/k8s</span><br><span class=\"line\">$ <span class=\"built_in\">echo</span> <span class=\"string\">\"/data/k8s  192.168.110.0/24(rw,sync,no_root_squash)\"</span> &gt; /etc/exports.d/kubecluster.exports</span><br><span class=\"line\"><span class=\"comment\"># 共享目录与存储网段需根据实际情况而定</span></span><br><span class=\"line\"><span class=\"comment\"># 注意：</span></span><br><span class=\"line\"><span class=\"comment\">#   共享目录的名称必须与 nfs-client-provisioner Deployment 中的 path 字段</span></span><br><span class=\"line\"><span class=\"comment\">#   完全相同！</span></span><br><span class=\"line\">$ exportfs -a</span><br><span class=\"line\">$ showmount -e localhost</span><br><span class=\"line\">  Export list <span class=\"keyword\">for</span> localhost:</span><br><span class=\"line\">  /data/k8s 192.168.110.0/24</span><br><span class=\"line\">$ mkdir /data/k8s/rocketchat-mongodb-app</span><br><span class=\"line\"><span class=\"comment\"># 以上目录名称中的 rocketchat-mongodb-app 为命名空间的名称</span></span><br><span class=\"line\">$ chmod 0777 /data/k8s/rocketchat-mongodb-app</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>📢 报错示例 1：<br>确认集群各节点已安装 <code>nfs-utils</code> 软件包，若未安装在部署 <code>nfs-client-provisioner</code> pod 时将返回如下报错，pod 状态持续显示为 <code>ContainerCreating</code>：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe pod nfs-client-provisioner-8b9f4fbcc-rrw8r -n rocketchat-mongodb-app</span><br><span class=\"line\">...</span><br><span class=\"line\">Events:</span><br><span class=\"line\">  Type     Reason       Age                From               Message</span><br><span class=\"line\">  ----     ------       ----               ----               -------</span><br><span class=\"line\">  Normal   Scheduled    77s                default-scheduler  Successfully assigned rocketchat-mongodb-app/nfs-client-provisioner-8b9f4fbcc-rrw8r to kube-node2.lab.example.com</span><br><span class=\"line\">  Warning  FailedMount  12s (x8 over 76s)  kubelet            MountVolume.SetUp failed <span class=\"keyword\">for</span> volume <span class=\"string\">\"nfs-client-root\"</span> : mount failed: <span class=\"built_in\">exit</span> status 32</span><br><span class=\"line\">Mounting <span class=\"built_in\">command</span>: mount</span><br><span class=\"line\">Mounting arguments: -t nfs 192.168.110.162:/data/k8s/rocketchat-mongodb-app /var/lib/kubelet/pods/393e67de-39ed-4d17-aeca-9f2ebe360199/volumes/kubernetes.io~nfs/nfs-client-root</span><br><span class=\"line\">Output: mount: wrong fs <span class=\"built_in\">type</span>, bad option, bad superblock on 192.168.110.162:/data/k8s/rocketchat-mongodb-app,</span><br><span class=\"line\">       missing codepage or helper program, or other error</span><br><span class=\"line\">       (<span class=\"keyword\">for</span> several filesystems (e.g. nfs, cifs) you might</span><br><span class=\"line\">       need a /sbin/mount.&lt;<span class=\"built_in\">type</span>&gt; helper program)</span><br><span class=\"line\"></span><br><span class=\"line\">       In some cases useful info is found <span class=\"keyword\">in</span> syslog - try</span><br><span class=\"line\">       dmesg | tail or so.</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>📢 报错示例 2：<br>使用 nfs-client-provisioner pod 实现动态 PV 分配时，必须提前在 NFS Server 上创建与调整以命名空间名称为 <code>basename</code> 的共享目录（如上所示），否则将返回如下报错，显示无法找到目录：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">Events:</span><br><span class=\"line\">  Type     Reason       Age                 From               Message</span><br><span class=\"line\">  ----     ------       ----                ----               -------</span><br><span class=\"line\">  Normal   Scheduled    18m                 default-scheduler  Successfully assigned rocketchat-mongodb-app/nfs-client-provisioner-8b9f4fbcc-j9z24 to kube-node2.lab.example.com</span><br><span class=\"line\">  Warning  FailedMount  14m (x2 over 16m)   kubelet            Unable to attach or mount volumes: unmounted volumes=[nfs-client-root], unattached volumes=[kube-api-access-rhqq9 nfs-client-root]: timed out waiting <span class=\"keyword\">for</span> the condition</span><br><span class=\"line\">  Warning  FailedMount  47s (x6 over 12m)   kubelet            Unable to attach or mount volumes: unmounted volumes=[nfs-client-root], unattached volumes=[nfs-client-root kube-api-access-rhqq9]: timed out waiting <span class=\"keyword\">for</span> the condition</span><br><span class=\"line\">  Warning  FailedMount  20s (x17 over 18m)  kubelet            MountVolume.SetUp failed <span class=\"keyword\">for</span> volume <span class=\"string\">\"nfs-client-root\"</span> : mount failed: <span class=\"built_in\">exit</span> status 32</span><br><span class=\"line\">Mounting <span class=\"built_in\">command</span>: mount</span><br><span class=\"line\">Mounting arguments: -t nfs 192.168.110.162:/data/k8s/rocketchat-mongodb-app /var/lib/kubelet/pods/7cad43c0-0e08-4e07-b0e8-5bba0a535c4d/volumes/kubernetes.io~nfs/nfs-client-root</span><br><span class=\"line\">Output: mount.nfs: mounting 192.168.110.162:/data/k8s/rocketchat-mongodb-app failed, reason given by server: No such file or directory</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<blockquote>\n<p>💥 nfs-client-provisioner pod 与应用 pod 部署于同一命名空间中。</p>\n</blockquote>\n</li>\n<li><p>因此，该应用的部署方式如下所示：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl create namespace rocketchat-mongodb-app</span><br><span class=\"line\">$ kubectl apply -f \\</span><br><span class=\"line\">  00-nfs-provisioned-rbac.yml \\</span><br><span class=\"line\">  01-nfs-provisioned-deployment.yml \\</span><br><span class=\"line\">  02-nfs-provisioned-class.yml \\</span><br><span class=\"line\">  -n rocketchat-mongodb-app</span><br><span class=\"line\">$ kubectl apply -f 03-mongodb-internal-headless-svc.yml -n rocketchat-mongodb-app</span><br><span class=\"line\">$ kubectl apply -f 04-mongodb-statefulset.yml -n rocketchat-mongodb-app</span><br><span class=\"line\"><span class=\"comment\"># 该资源创建完成后并未实现 MongoDB 的 ReplicaSet 模式集群，需登录至其中的一个节点实现集群的初始化及 mongo 节点的添加。</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl <span class=\"built_in\">exec</span> -it rocketmongo-0 -n rocketchat-mongodb-app -- mongo</span><br><span class=\"line\">  <span class=\"comment\"># 进入 mongo 节点进行集群的初始化与配置</span></span><br><span class=\"line\">  ...</span><br><span class=\"line\">  &gt; rs.initiate()  <span class=\"comment\"># 初始化集群</span></span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">      <span class=\"string\">\"info2\"</span> : <span class=\"string\">\"no configuration specified. Using a default configuration for the set\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"me\"</span> : <span class=\"string\">\"rocketmongo-0:27017\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"ok\"</span> : 1</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  rs0:SECONDARY&gt; var config = rs.conf()</span><br><span class=\"line\">  rs0:PRIMARY&gt; config.members[0].host=<span class=\"string\">\"rocketmongo-0.mongodb-internal:27017\"</span></span><br><span class=\"line\">  rocketmongo-0.mongodb-internal:27017  </span><br><span class=\"line\">  <span class=\"comment\"># 通过 headless service 指向 mongo 节点，将该节点配置为 primary 节点。</span></span><br><span class=\"line\">  rs0:PRIMARY&gt; rs.reconfig(config)  <span class=\"comment\"># 刷新集群配置</span></span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">      <span class=\"string\">\"ok\"</span> : 1,</span><br><span class=\"line\">      <span class=\"string\">\"operationTime\"</span> : Timestamp(1671036342, 1),</span><br><span class=\"line\">      <span class=\"string\">\"<span class=\"variable\">$clusterTime</span>\"</span> : &#123;</span><br><span class=\"line\">          <span class=\"string\">\"clusterTime\"</span> : Timestamp(1671036342, 1),</span><br><span class=\"line\">          <span class=\"string\">\"signature\"</span> : &#123;</span><br><span class=\"line\">              <span class=\"string\">\"hash\"</span> : BinData(0,<span class=\"string\">\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"</span>),</span><br><span class=\"line\">              <span class=\"string\">\"keyId\"</span> : NumberLong(0)</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  rs0:PRIMARY&gt; rs.add(<span class=\"string\">\"rocketmongo-1.mongodb-internal:27017\"</span>)</span><br><span class=\"line\">  rs0:PRIMARY&gt; rs.add(<span class=\"string\">\"rocketmongo-2.mongodb-internal:27017\"</span>)  <span class=\"comment\"># 添加额外的 mongo 节点</span></span><br><span class=\"line\">  rs0:PRIMARY&gt; rs.status()    <span class=\"comment\"># 查看集群的状态</span></span><br><span class=\"line\">  rs0:PRIMARY&gt; rs.isMaster()  <span class=\"comment\"># 确认当前 mongo 节点是否为 primary 节点 </span></span><br><span class=\"line\">  rs0:PRIMARY&gt; <span class=\"built_in\">exit</span>           <span class=\"comment\"># 退出 MongoDB Shell</span></span><br><span class=\"line\">  ...</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl apply -f 05-rockerchat-deployment.yml -n rocketchat-mongodb-app</span><br><span class=\"line\"><span class=\"comment\"># 部署前端 Rocket.Chat 应用</span></span><br></pre></td></tr></table></figure>\n<p>🤘 如下所示，刷新 Rocket.Chat pod 日志可确认其与 MongoDB 集群成功连接：<img src=\"rocketchat-mongo-connect-successfully.png\" alt=\"rocketchat-mongo-connect-successfully.png\"></p>\n</li>\n</ul>\n<h3 id=\"确认应用资源与登录认证：\"><a href=\"#确认应用资源与登录认证：\" class=\"headerlink\" title=\"确认应用资源与登录认证：\"></a>确认应用资源与登录认证：</h3><ul>\n<li><p>该应用所涉及的资源对象如下所示：<img src=\"rocketchat-mongo-app-resources.png\" alt=\"rocketchat-mongo-app-resources.png\">  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get pv</span><br><span class=\"line\">  NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                               STORAGECLASS          REASON   AGE</span><br><span class=\"line\">  pvc-1bc91589-312c-4878-af37-5e31a7dacc33   3Gi        RWO            Delete           Bound    rocketchat-mongodb-app/mongo-volume-rocketmongo-0   managed-nfs-storage            21h</span><br><span class=\"line\">  pvc-aebc940f-f3f2-4389-8d8b-62695dd931b6   3Gi        RWO            Delete           Bound    rocketchat-mongodb-app/mongo-volume-rocketmongo-1   managed-nfs-storage            21h</span><br><span class=\"line\">  pvc-cd42e48c-ab33-481c-a9dd-eae73c876516   3Gi        RWO            Delete           Bound    rocketchat-mongodb-app/mongo-volume-rocketmongo-2   managed-nfs-storage            21h</span><br><span class=\"line\">$ kubectl get pvc -n rocketchat-mongodb-app</span><br><span class=\"line\">  NAME                         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS          AGE</span><br><span class=\"line\">  mongo-volume-rocketmongo-0   Bound    pvc-1bc91589-312c-4878-af37-5e31a7dacc33   3Gi        RWO            managed-nfs-storage   21h</span><br><span class=\"line\">  mongo-volume-rocketmongo-1   Bound    pvc-aebc940f-f3f2-4389-8d8b-62695dd931b6   3Gi        RWO            managed-nfs-storage   21h</span><br><span class=\"line\">  mongo-volume-rocketmongo-2   Bound    pvc-cd42e48c-ab33-481c-a9dd-eae73c876516   3Gi        RWO            managed-nfs-storage   21h</span><br><span class=\"line\"><span class=\"comment\"># 查看 PV 动态分配的资源</span></span><br></pre></td></tr></table></figure>\n<p>👉 NFS 服务器上 PV 的命名格式：<code>${namespace}-${pvcName}-${pvName}</code><br>👉 PV 回收时候的命名格式：<code>archieved-${namespace}-${pvcName}-${pvName}</code></p>\n</li>\n<li>可通过 Rocket.Chat pod 日志中的 URL 链接登录应用并注册账户使用。<img src=\"rocketchat-login.png\" alt=\"rocketchat-login.png\"></li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://www.kancloud.cn/huyipow/dr/766694\" target=\"_blank\" rel=\"noopener\">利用 NFS 动态提供 Kubernetes 后端存储卷</a></li>\n<li><a href=\"https://kubernetes.io/blog/2017/01/running-mongodb-on-kubernetes-with-statefulsets/\" target=\"_blank\" rel=\"noopener\">Running MongoDB on Kubernetes with StatefulSets</a></li>\n<li><a href=\"https://dev.to/jmarhee/running-rocketchat-and-mongodb-on-kubernetes-with-statefulsets-431o\" target=\"_blank\" rel=\"noopener\">Running Rocket.Chat and MongoDB on Kubernetes with StatefulSets</a></li>\n<li><a href=\"https://ajorloo.medium.com/deploy-rocket-chat-server-using-kubernetes-2d6c4228853\" target=\"_blank\" rel=\"noopener\">Deploy Rocket chat server using Kubernetes</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"部署环境说明：\"><a href=\"#部署环境说明：\" class=\"headerlink\" title=\"部署环境说明：\"></a>部署环境说明：</h3><ul>\n<li>Kubernetes 版本：<code>v1.22.1</code></li>\n<li>Rocket.Chat 容器镜像版本：<code>docker.io/rocketchat/rocket.chat:3.18.7</code></li>\n<li>MongoDB 容器镜像版本：<code>docker.io/library/mongo:4.0</code></li>\n<li>Kubernetes NFS-Client Privisioner 容器镜像版本：<br><code>quay.io/external_storage/nfs-client-provisioner:latest</code></li>\n<li>👉 若拉取失败，以上镜像均可从 <a href=\"https://quay.io/user/alberthua\" target=\"_blank\" rel=\"noopener\">https://quay.io/user/alberthua</a> 中拉取下载。</li>\n<li>🔗 点击 <a href=\"https://github.com/Alberthua-Perl/go-kubernetes-learn-path/tree/hotfixes/rocketchat-mongo-statefulset-app\" target=\"_blank\" rel=\"noopener\">链接</a>，以获得部署用的相关文件。</li>\n</ul>\n<h3 id=\"部署方式及步骤：\"><a href=\"#部署方式及步骤：\" class=\"headerlink\" title=\"部署方式及步骤：\"></a>部署方式及步骤：</h3><ul>\n<li>💥 该应用后端的 MongoDB 集群使用 <code>NFS</code> 作为动态 PV 的提供者，需提前配置 NFS 服务器节点用于提供 PV（见下文）。</li>\n<li>然而，Kubernetes 中未集成 NFS 类型的内部调配者（<code>internal privisioner</code>），因此需使用 <code>nfs-client-provisioner</code> 将外部 NFS 调配至集群以支持 PV 动态分配。</li>\n<li>PV 动态分配还需使用 <code>StorageClass</code> 资源将 <code>privisioner</code> 对接入 Kubernetes 集群。</li>\n<li>🚀 StorageClass 调用链：<br>Pod <strong>&gt;</strong> PVC <strong>&gt;</strong> StorageClass <strong>&gt;</strong> provisioner (PV 动态分配) <strong>&gt;</strong> NFS Server</li>\n<li>MongoDB 集群使用 <code>StatefulSet</code> 部署，而该资源需使用 <code>StorageClass</code> 实现卷声明模板（<code>volumeClaimTemplates</code>）。</li>\n<li><p>nfs-client-provisioner 在集群中的部署可参考该 <a href=\"https://github.com/Alberthua-Perl/go-kubernetes-learn-path/tree/hotfixes/nfs-provisioned-storageclass\" target=\"_blank\" rel=\"noopener\">链接</a>，也可参考如下步骤实现： </p>\n<ul>\n<li><p>登录 <code>NFS</code> 服务器节点创建 NFS 共享目录：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum install -y nfs-utils</span><br><span class=\"line\">$ systemctl <span class=\"built_in\">enable</span> --now nfs-server.service</span><br><span class=\"line\">$ mkdir -p /data/k8s</span><br><span class=\"line\">$ chmod -R 0777 /data/k8s</span><br><span class=\"line\">$ <span class=\"built_in\">echo</span> <span class=\"string\">\"/data/k8s  192.168.110.0/24(rw,sync,no_root_squash)\"</span> &gt; /etc/exports.d/kubecluster.exports</span><br><span class=\"line\"><span class=\"comment\"># 共享目录与存储网段需根据实际情况而定</span></span><br><span class=\"line\"><span class=\"comment\"># 注意：</span></span><br><span class=\"line\"><span class=\"comment\">#   共享目录的名称必须与 nfs-client-provisioner Deployment 中的 path 字段</span></span><br><span class=\"line\"><span class=\"comment\">#   完全相同！</span></span><br><span class=\"line\">$ exportfs -a</span><br><span class=\"line\">$ showmount -e localhost</span><br><span class=\"line\">  Export list <span class=\"keyword\">for</span> localhost:</span><br><span class=\"line\">  /data/k8s 192.168.110.0/24</span><br><span class=\"line\">$ mkdir /data/k8s/rocketchat-mongodb-app</span><br><span class=\"line\"><span class=\"comment\"># 以上目录名称中的 rocketchat-mongodb-app 为命名空间的名称</span></span><br><span class=\"line\">$ chmod 0777 /data/k8s/rocketchat-mongodb-app</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>📢 报错示例 1：<br>确认集群各节点已安装 <code>nfs-utils</code> 软件包，若未安装在部署 <code>nfs-client-provisioner</code> pod 时将返回如下报错，pod 状态持续显示为 <code>ContainerCreating</code>：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl describe pod nfs-client-provisioner-8b9f4fbcc-rrw8r -n rocketchat-mongodb-app</span><br><span class=\"line\">...</span><br><span class=\"line\">Events:</span><br><span class=\"line\">  Type     Reason       Age                From               Message</span><br><span class=\"line\">  ----     ------       ----               ----               -------</span><br><span class=\"line\">  Normal   Scheduled    77s                default-scheduler  Successfully assigned rocketchat-mongodb-app/nfs-client-provisioner-8b9f4fbcc-rrw8r to kube-node2.lab.example.com</span><br><span class=\"line\">  Warning  FailedMount  12s (x8 over 76s)  kubelet            MountVolume.SetUp failed <span class=\"keyword\">for</span> volume <span class=\"string\">\"nfs-client-root\"</span> : mount failed: <span class=\"built_in\">exit</span> status 32</span><br><span class=\"line\">Mounting <span class=\"built_in\">command</span>: mount</span><br><span class=\"line\">Mounting arguments: -t nfs 192.168.110.162:/data/k8s/rocketchat-mongodb-app /var/lib/kubelet/pods/393e67de-39ed-4d17-aeca-9f2ebe360199/volumes/kubernetes.io~nfs/nfs-client-root</span><br><span class=\"line\">Output: mount: wrong fs <span class=\"built_in\">type</span>, bad option, bad superblock on 192.168.110.162:/data/k8s/rocketchat-mongodb-app,</span><br><span class=\"line\">       missing codepage or helper program, or other error</span><br><span class=\"line\">       (<span class=\"keyword\">for</span> several filesystems (e.g. nfs, cifs) you might</span><br><span class=\"line\">       need a /sbin/mount.&lt;<span class=\"built_in\">type</span>&gt; helper program)</span><br><span class=\"line\"></span><br><span class=\"line\">       In some cases useful info is found <span class=\"keyword\">in</span> syslog - try</span><br><span class=\"line\">       dmesg | tail or so.</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>📢 报错示例 2：<br>使用 nfs-client-provisioner pod 实现动态 PV 分配时，必须提前在 NFS Server 上创建与调整以命名空间名称为 <code>basename</code> 的共享目录（如上所示），否则将返回如下报错，显示无法找到目录：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">Events:</span><br><span class=\"line\">  Type     Reason       Age                 From               Message</span><br><span class=\"line\">  ----     ------       ----                ----               -------</span><br><span class=\"line\">  Normal   Scheduled    18m                 default-scheduler  Successfully assigned rocketchat-mongodb-app/nfs-client-provisioner-8b9f4fbcc-j9z24 to kube-node2.lab.example.com</span><br><span class=\"line\">  Warning  FailedMount  14m (x2 over 16m)   kubelet            Unable to attach or mount volumes: unmounted volumes=[nfs-client-root], unattached volumes=[kube-api-access-rhqq9 nfs-client-root]: timed out waiting <span class=\"keyword\">for</span> the condition</span><br><span class=\"line\">  Warning  FailedMount  47s (x6 over 12m)   kubelet            Unable to attach or mount volumes: unmounted volumes=[nfs-client-root], unattached volumes=[nfs-client-root kube-api-access-rhqq9]: timed out waiting <span class=\"keyword\">for</span> the condition</span><br><span class=\"line\">  Warning  FailedMount  20s (x17 over 18m)  kubelet            MountVolume.SetUp failed <span class=\"keyword\">for</span> volume <span class=\"string\">\"nfs-client-root\"</span> : mount failed: <span class=\"built_in\">exit</span> status 32</span><br><span class=\"line\">Mounting <span class=\"built_in\">command</span>: mount</span><br><span class=\"line\">Mounting arguments: -t nfs 192.168.110.162:/data/k8s/rocketchat-mongodb-app /var/lib/kubelet/pods/7cad43c0-0e08-4e07-b0e8-5bba0a535c4d/volumes/kubernetes.io~nfs/nfs-client-root</span><br><span class=\"line\">Output: mount.nfs: mounting 192.168.110.162:/data/k8s/rocketchat-mongodb-app failed, reason given by server: No such file or directory</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<blockquote>\n<p>💥 nfs-client-provisioner pod 与应用 pod 部署于同一命名空间中。</p>\n</blockquote>\n</li>\n<li><p>因此，该应用的部署方式如下所示：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl create namespace rocketchat-mongodb-app</span><br><span class=\"line\">$ kubectl apply -f \\</span><br><span class=\"line\">  00-nfs-provisioned-rbac.yml \\</span><br><span class=\"line\">  01-nfs-provisioned-deployment.yml \\</span><br><span class=\"line\">  02-nfs-provisioned-class.yml \\</span><br><span class=\"line\">  -n rocketchat-mongodb-app</span><br><span class=\"line\">$ kubectl apply -f 03-mongodb-internal-headless-svc.yml -n rocketchat-mongodb-app</span><br><span class=\"line\">$ kubectl apply -f 04-mongodb-statefulset.yml -n rocketchat-mongodb-app</span><br><span class=\"line\"><span class=\"comment\"># 该资源创建完成后并未实现 MongoDB 的 ReplicaSet 模式集群，需登录至其中的一个节点实现集群的初始化及 mongo 节点的添加。</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl <span class=\"built_in\">exec</span> -it rocketmongo-0 -n rocketchat-mongodb-app -- mongo</span><br><span class=\"line\">  <span class=\"comment\"># 进入 mongo 节点进行集群的初始化与配置</span></span><br><span class=\"line\">  ...</span><br><span class=\"line\">  &gt; rs.initiate()  <span class=\"comment\"># 初始化集群</span></span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">      <span class=\"string\">\"info2\"</span> : <span class=\"string\">\"no configuration specified. Using a default configuration for the set\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"me\"</span> : <span class=\"string\">\"rocketmongo-0:27017\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"ok\"</span> : 1</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  rs0:SECONDARY&gt; var config = rs.conf()</span><br><span class=\"line\">  rs0:PRIMARY&gt; config.members[0].host=<span class=\"string\">\"rocketmongo-0.mongodb-internal:27017\"</span></span><br><span class=\"line\">  rocketmongo-0.mongodb-internal:27017  </span><br><span class=\"line\">  <span class=\"comment\"># 通过 headless service 指向 mongo 节点，将该节点配置为 primary 节点。</span></span><br><span class=\"line\">  rs0:PRIMARY&gt; rs.reconfig(config)  <span class=\"comment\"># 刷新集群配置</span></span><br><span class=\"line\">  &#123;</span><br><span class=\"line\">      <span class=\"string\">\"ok\"</span> : 1,</span><br><span class=\"line\">      <span class=\"string\">\"operationTime\"</span> : Timestamp(1671036342, 1),</span><br><span class=\"line\">      <span class=\"string\">\"<span class=\"variable\">$clusterTime</span>\"</span> : &#123;</span><br><span class=\"line\">          <span class=\"string\">\"clusterTime\"</span> : Timestamp(1671036342, 1),</span><br><span class=\"line\">          <span class=\"string\">\"signature\"</span> : &#123;</span><br><span class=\"line\">              <span class=\"string\">\"hash\"</span> : BinData(0,<span class=\"string\">\"AAAAAAAAAAAAAAAAAAAAAAAAAAA=\"</span>),</span><br><span class=\"line\">              <span class=\"string\">\"keyId\"</span> : NumberLong(0)</span><br><span class=\"line\">          &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  rs0:PRIMARY&gt; rs.add(<span class=\"string\">\"rocketmongo-1.mongodb-internal:27017\"</span>)</span><br><span class=\"line\">  rs0:PRIMARY&gt; rs.add(<span class=\"string\">\"rocketmongo-2.mongodb-internal:27017\"</span>)  <span class=\"comment\"># 添加额外的 mongo 节点</span></span><br><span class=\"line\">  rs0:PRIMARY&gt; rs.status()    <span class=\"comment\"># 查看集群的状态</span></span><br><span class=\"line\">  rs0:PRIMARY&gt; rs.isMaster()  <span class=\"comment\"># 确认当前 mongo 节点是否为 primary 节点 </span></span><br><span class=\"line\">  rs0:PRIMARY&gt; <span class=\"built_in\">exit</span>           <span class=\"comment\"># 退出 MongoDB Shell</span></span><br><span class=\"line\">  ...</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl apply -f 05-rockerchat-deployment.yml -n rocketchat-mongodb-app</span><br><span class=\"line\"><span class=\"comment\"># 部署前端 Rocket.Chat 应用</span></span><br></pre></td></tr></table></figure>\n<p>🤘 如下所示，刷新 Rocket.Chat pod 日志可确认其与 MongoDB 集群成功连接：<img src=\"rocketchat-mongo-connect-successfully.png\" alt=\"rocketchat-mongo-connect-successfully.png\"></p>\n</li>\n</ul>\n<h3 id=\"确认应用资源与登录认证：\"><a href=\"#确认应用资源与登录认证：\" class=\"headerlink\" title=\"确认应用资源与登录认证：\"></a>确认应用资源与登录认证：</h3><ul>\n<li><p>该应用所涉及的资源对象如下所示：<img src=\"rocketchat-mongo-app-resources.png\" alt=\"rocketchat-mongo-app-resources.png\">  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get pv</span><br><span class=\"line\">  NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                               STORAGECLASS          REASON   AGE</span><br><span class=\"line\">  pvc-1bc91589-312c-4878-af37-5e31a7dacc33   3Gi        RWO            Delete           Bound    rocketchat-mongodb-app/mongo-volume-rocketmongo-0   managed-nfs-storage            21h</span><br><span class=\"line\">  pvc-aebc940f-f3f2-4389-8d8b-62695dd931b6   3Gi        RWO            Delete           Bound    rocketchat-mongodb-app/mongo-volume-rocketmongo-1   managed-nfs-storage            21h</span><br><span class=\"line\">  pvc-cd42e48c-ab33-481c-a9dd-eae73c876516   3Gi        RWO            Delete           Bound    rocketchat-mongodb-app/mongo-volume-rocketmongo-2   managed-nfs-storage            21h</span><br><span class=\"line\">$ kubectl get pvc -n rocketchat-mongodb-app</span><br><span class=\"line\">  NAME                         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS          AGE</span><br><span class=\"line\">  mongo-volume-rocketmongo-0   Bound    pvc-1bc91589-312c-4878-af37-5e31a7dacc33   3Gi        RWO            managed-nfs-storage   21h</span><br><span class=\"line\">  mongo-volume-rocketmongo-1   Bound    pvc-aebc940f-f3f2-4389-8d8b-62695dd931b6   3Gi        RWO            managed-nfs-storage   21h</span><br><span class=\"line\">  mongo-volume-rocketmongo-2   Bound    pvc-cd42e48c-ab33-481c-a9dd-eae73c876516   3Gi        RWO            managed-nfs-storage   21h</span><br><span class=\"line\"><span class=\"comment\"># 查看 PV 动态分配的资源</span></span><br></pre></td></tr></table></figure>\n<p>👉 NFS 服务器上 PV 的命名格式：<code>${namespace}-${pvcName}-${pvName}</code><br>👉 PV 回收时候的命名格式：<code>archieved-${namespace}-${pvcName}-${pvName}</code></p>\n</li>\n<li>可通过 Rocket.Chat pod 日志中的 URL 链接登录应用并注册账户使用。<img src=\"rocketchat-login.png\" alt=\"rocketchat-login.png\"></li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://www.kancloud.cn/huyipow/dr/766694\" target=\"_blank\" rel=\"noopener\">利用 NFS 动态提供 Kubernetes 后端存储卷</a></li>\n<li><a href=\"https://kubernetes.io/blog/2017/01/running-mongodb-on-kubernetes-with-statefulsets/\" target=\"_blank\" rel=\"noopener\">Running MongoDB on Kubernetes with StatefulSets</a></li>\n<li><a href=\"https://dev.to/jmarhee/running-rocketchat-and-mongodb-on-kubernetes-with-statefulsets-431o\" target=\"_blank\" rel=\"noopener\">Running Rocket.Chat and MongoDB on Kubernetes with StatefulSets</a></li>\n<li><a href=\"https://ajorloo.medium.com/deploy-rocket-chat-server-using-kubernetes-2d6c4228853\" target=\"_blank\" rel=\"noopener\">Deploy Rocket chat server using Kubernetes</a></li>\n</ul>\n"},{"title":"Skopeo 镜像工具与容器镜像格式的原理与使用","subtitle":"Skopeo Basic Usage and Container Image Format","header-img":"skopeo-bg.jpg","date":"2022-12-06T03:56:03.000Z","_content":"\n### 文档说明：\n- OS 版本：Ubuntu 20.04.3 LTS (Focal Fossa)\n- skopeo 版本：1.3.0-1\n\n### 文档目录：\n- Skopeo 工具概要\n- 使用 Skopeo 认证容器镜像仓库\n- Skopeo 支持的容器镜像存储方式\n- 使用 Skopeo 操作容器镜像\n- 容器镜像格式比较\n- 参考链接\n\n### Skopeo 工具概要：\n- 常用的容器镜像操作工具可使用 docker、podman 命令，但 docker 命令行工具需要使用守护进程与 root 用户权限，在一些场景下使用该工具同步容器镜像的效率是较低的，而 podman 命令虽然不使用守护进程，但是其同步镜像效率依然不高。\n- skopeo 与 buildah 命令可专门用于容器镜像的操作，其中 skopeo 命令更加纯粹地用于容器镜像的搬运与容器镜像格式的转换，效率较其他工具更高，但是不具有容器镜像构建的能力。\n- Podman 更加侧重于容器的生命周期管理，同时具备部分容器镜像管理与构建功能，而 Buildah 支持分别使用命令行从头构建容器镜像与 `Dockerfile` 或 `Containerfile` 的构建方式，同时兼容 Docker 与 OCI 镜像格式。\n> 👉 关于 Podman 更加详细的信息可参考之前写的 [Podman 容器原理与使用（1）](https://alberthua-perl.github.io/2022/12/05/podman-arch-usage/)与 [Podman 容器原理与使用（2）](https://alberthua-perl.github.io/2022/12/05/podman-usage-practice/)。\n- Skopeo 安装方法可参考 [该 GitHub 链接](https://github.com/containers/skopeo/blob/main/install.md)，此处不再赘述。\n- skopeo 命令的帮助信息：  \n  ```bash\n  $ skopeo --help\n  Various operations with container images and container image registries\n  \n  Usage:\n    skopeo [command]\n  \n  Available Commands:\n    copy                                          Copy an IMAGE-NAME from one location to another\n    delete                                        Delete image IMAGE-NAME\n    help                                          Help about any command\n    inspect                                       Inspect image IMAGE-NAME\n    list-tags                                     List tags in the transport/repository specified by the REPOSITORY-NAME\n    login                                         Login to a container registry\n    logout                                        Logout of a container registry\n    manifest-digest                               Compute a manifest digest of a file\n    standalone-sign                               Create a signature using local files\n    standalone-verify                             Verify a signature using local files\n    sync                                          Synchronize one or more images from one location to another\n  \n  Flags:\n        --command-timeout duration   timeout for the command execution\n        --debug                      enable debug output\n    -h, --help                       help for skopeo\n        --insecure-policy            run the tool without any policy check\n        --override-arch ARCH         use ARCH instead of the architecture of the machine for choosing images\n        --override-os OS             use OS instead of the running OS for choosing images\n        --override-variant VARIANT   use VARIANT instead of the running architecture variant for choosing images\n        --policy string              Path to a trust policy file\n        --registries.d DIR           use registry configuration files in DIR (e.g. for container signature storage)\n        --tmpdir string              directory used to store temporary files\n    -v, --version                    Version for Skopeo\n  \n  Use \"skopeo [command] --help\" for more information about a command.\n  ```\n\n### 使用 Skopeo 认证容器镜像仓库：\n- Red Hat 支持 `skopeo` 命令来管理容器镜像仓库中的镜像。\n- Skopeo 可分别用于操作公共（public）与私有（private）容器镜像，对于私有容器镜像需要对容器镜像仓库进行认证。\n- Skopeo 与 Buildah 可使用 Podman 保存的认证 `token`（位于 `/run/user/<UID>/containers/auth.json`），但是无法执行交互式的登录密码输入，因此，若在 skopeo 命令行中指定明文登录密码可在 history 命令历史记录中查看到，存在一定的安全风险，可使用如下以变量形式传递密码的方法优化：![skopeo-inspect-creds.jpg](skopeo-inspect-creds.jpg)\n> 若未使用 Podman 作为容器运行时，而依然使用 Docker 容器运行时的话，其认证 token 依然可被 Skopeo 使用与认证，该认证 token 位于 `$HOME/.docker/config.json`。\n- Skopeo 的众多子命令支持容器镜像仓库的认证，可分别通过用户名与密码及认证的 token 文件实现认证，如下所示：  \n  ```bash\n  ### 示例 ###\n  $ skopeo copy --src-creds <username>:<password> \\\n    docker://registry.redhat.io/rhscl/postgresql-96-rhel7:latest \\\n    oci:postgresql-96-rhel7-latest\n  \n  $ skopeo copy --src-authfile /run/user/<UID>/containers/auth.json \\\n    docker://registry.redhat.io/rhscl/postgresql-96-rhel7:latest \\\n    oci:postgresql-96-rhel7-latest\n  ```\n\n### Skopeo 支持的容器镜像存储方式：\n- Skopeo 使用 `URI` 来表示容器镜像的位置，使用 URI 模式（schema）来表示容器镜像格式和registry APIs。\n- 常见的 URI 模式：  \n  - `oci`：    \n    - 表示存储在本地的 OCI 格式目录中的容器镜像    \n    - 该镜像兼容开放容器镜像层规范（`Open Container Image Layout Specification`）  \n  - `oci-archive`：    \n    - 表示 OCI 镜像格式封装的容器镜像的 tar 归档    \n    - 该镜像兼容开放容器镜像层规范  \n  - `containers-storage`：    \n    - 表示存储于本地容器运行时缓存中的容器镜像    \n    - 后端容器引擎兼容 Podman、CRI-O 与 Buildah  \n  - `docker-daemon`：    \n    - 表示存储于本地 Docker 容器运行时缓存中的容器镜像  \n  - `docker-archive`：    \n    - 表示 Docker 镜像格式封装的容器镜像的 tar 归档  \n  - `dir`：    \n    - 本地存储容器镜像的目录，其中以单个文件的方式包含镜像的 `manifest`、镜像层 tar 归档与各镜像层签名（`digest`）。  \n  - `docker://`：    \n    - 表示存储于容器镜像仓库中的远程容器镜像\n    - 可通过 `Docker Registry HTTP API V2` 操作仓库中的容器镜像\n- 同一容器镜像可以根据不同的场景使用以上不同的方式保存。\n> 👉 关于 Skopeo 更为详细的信息可参考 `man skopeo` 手册。\n\n### 使用 Skopeo 操作容器镜像：\n- Skopeo 不使用容器运行时，并且普通用户可直接使用，比 Podman 使用 tag、pull 与 push 等子命令时更加的高效。\n- 🐳 若使用 docker 或 podman 命令将容器镜像仓库中的镜像保存于本地存储，需分别使用 docker pull|save 与 podman pull|save 命令将本地镜像缓存中的镜像保存于 tar 归档，无法从容器镜像仓库直接保存于文件或目录中，下文中提及的 `skopeo copy` 或 `sync` 子命令可实现该功能，无需存在本地镜像缓存。\n- 🚀 Skopeo 操纵镜像层的方式：  \n  - 出于效率问题，Skopeo 不读取与发送已存在于目标仓库的镜像层，它首先读取源镜像的 manifest，再确定哪些层已存在于目标仓库，然后仅仅拷贝缺失的镜像层。  \n  - 若拷贝来自构建于同一父镜像的镜像，Skopeo 不拷贝多个来自于父镜像的相同镜像层。  \n  - Skopeo 可在容器镜像仓库之间拷贝镜像而不在本地容器存储中保存镜像层缓存，若源仓库与目标仓库需要认证，则需要使用 `--src-creds` 与 `--dest-creds` 选项指定认证用户与明文密码，并且 Skopeo 支持在目标仓库实现镜像 `tag`。\n    ```bash\n    $ skopeo copy \\\n      --src-creds=<username>:<password> \\\n      --dest-creds=<username>:<password> \\\n      docker://<uri_for_src_registry>/<user_or_org>/<repository>:[tag] \\\n      docker://<uri_for_dest_registry>/<user_or_org>/<repository>:[tag]\n    # 分别指定源仓库与目标仓库的认证用户与明文密码，并在仓库间拷贝容器镜像。\n    ```\n    ![skopeo-copy-dest-creds.jpg](skopeo-copy-dest-creds.jpg)\n- `skopeo delete`：删除容器镜像的镜像 tag  \n  - 该命令可删除容器镜像仓库中指定镜像的 tag    \n    若删除公共镜像可直接执行无需用户认证，而删除私有容器镜像需使用 `--creds` 选项或 `--authfile` 选项进行认证后删除，如下所示：\n    ```bash\n    $ skopeo delete --creds <username>:<password> \\\n      docker://<uri_for_registry>/<user_or_org>/<repository>:[tag]\n    ```\n  - 💥 指定镜像 `tag` 时将删除特定 tag，即使将最后一个 tag 删除后也不删除整个镜像仓库，若需要删除整个镜像仓库需登录指定仓库。此处为 Quay.io 为例，在 `Web 控制台` 上删除，如下所示：![skopeo-delete-1.jpg](skopeo-delete-1.jpg)![skopeo-delete-2.jpg](skopeo-delete-2.jpg) \n  - 💥 该命令也可删除本地容器运行时缓存中的镜像 tag，但需注意，若具有多个不同 tag 的容器镜像（实际为同一容器镜像），只具有同一个 image ID（该值来自于镜像的 manifest 中 `.config.digest`），那么在执行删除时即使指定了镜像的 tag，也会将其他具有相同 image ID 的镜像一并删除，该行为与容器镜像仓库中相区别！\n- `skopeo copy`：dir 模式示例\n  > 💥 Skopeo 可将容器镜像仓库中镜像拷贝至本地镜像目录（该目录无需提前创建），该目录中的镜像封装格式保留原始容器镜像仓库中的镜像格式。\n\n  ```bash\n  $ skopeo copy \\\n    docker://<uri_for_registry>/<user_or_org>/<repository>:[tag] \\\n    dir:<dir_of_container_image>\n  ```\n  ![skopeo-copy-docker-format-image-dir.jpg](skopeo-copy-docker-format-image-dir.jpg)除了使用 docker load 或 podman load 直接将容器镜像的 tar 归档导入本地镜像缓存中，也可使用已经保存至本地的目录以 dir 或 oci 模式存在的容器镜像，如下所示：![podman-load-dir-from-skopeo-copy.jpg](podman-load-dir-from-skopeo-copy.jpg)\n  \n  也可以使用 Skopeo 将本地镜像目录拷贝至容器镜像仓库，用以替代 docker push 或 podman push 的功能：\n  ```bash\n  $ skopeo copy \\\n    dir:<dir_of_container_image> \\\n    docker://<uri_for_registry>/<user_or_org>/<repository>:[tag]\n  ```\n  ![skopeo-copy-dir-2.jpg](skopeo-copy-dir-2.jpg)\n- `skopeo copy`：oci 模式示例\n  Skopeo 可将容器镜像仓库中镜像拷贝至本地 `OCI` 格式目录中以存储镜像：\n  ```bash\n  $ skopeo copy \\\n    docker://<uri_for_registry>/<user_or_org>/<repository>:[tag] \\\n    oci:<dir_of_container_image>\n  ```\n  ![skopeo-copy-oci-1.jpg](skopeo-copy-oci-1.jpg)其中拷贝至本地的 OCI 格式目录结构如下所示，包含了容器镜像的各层（layer）。\n  ![skopeo-copy-oci-2.jpg](skopeo-copy-oci-2.jpg)也可使用本地 OCI 格式目录将镜像拷贝至容器镜像仓库中。\n- `skopeo copy`：oci-archive 模式示例  \n  ```bash\n  $ skopeo copy \\\n    docker://<uri_for_registry>/<user_or_org>/<repository>:[tag] \\\n    oci-archive:<oci_contaier_image_name>.tar\n  # 将容器镜像仓库中镜像封装为 tar 归档的 OCI 镜像格式的镜像\n  ```\n- `skopeo copy`：containers-storage 模式示例  \n  \n  > 💥 该模式只能在以 Podman 或 CRI-O 为容器运行时的情况下使用，若使用 Docker 容器运行时将报错！\n\n  ![skopeo-copy-docker-daemon.jpg](skopeo-copy-docker-daemon.jpg)  \n  ```bash\n  $ skopeo copy \\\n    docker://<uri_for_registry>/<user_or_org>/<repository>:[tag] \\\n    containers-storage:<uri_for_registry>/<user_or_org>/<repository>:[tag]\n  # 将容器镜像仓库中的镜像存储于本地镜像缓存\n  ```\n- `skopeo copy`：docker-archive 模式示例  \n  ```bash\n  $ skopeo copy \\\n    docker://<uri_for_registry>/<user_or_org>/<repository>:[tag] \\\n    docker-archive:<docker_contaier_image_name>.tar\n  # 将容器镜像仓库中镜像封装为 tar 归档的 Docker 镜像格式的镜像\n  ```\n- `skopeo copy`：docker-daemon 模式示例\n\n  > 💥 该模式在使用 Docker 容器运行时的情况下使用。\n\n  ```bash\n  $ skopeo copy \\\n    docker://<uri_for_registry>/<user_or_org>/<repository>:[tag] \\\n    docker-daemon:<uri_for_registry>/<user_or_org>/<repository>:[tag]\n  # 将容器镜像仓库中的镜像存储于本地镜像缓存\n  ```\n- 🚀 Skopeo 对容器镜像格式的转换：  \n  - 使用 skopeo copy 命令将容器镜像仓库中镜像拷贝至本地目录或本地 tar 归档存储时，可分别以 Docker 镜像格式或 OCI 镜像格式保存。  \n  - 因此，skopeo copy 命令可同时完成容器镜像的下载与镜像格式的转换。  \n  - 如下所示：![skopeo-copy-transform-image-format.jpg](skopeo-copy-transform-image-format.jpg)\n- `skopeo sync`：  \n  - sync 子命令将容器镜像从 src 源同步至 dest 目的地，功能与 copy 子命令类似。  \n  - skopeo sync 命令可指定的 src 与 dest 类型如下所示：![skopeo-sync-help.jpg](skopeo-sync-help.jpg)\n  - 👉 示例 1：    \n    将远程容器镜像仓库中的镜像同步至本地目录，本地存储容器镜像的目录无需创建。![skopeo-sync-demo.jpg](skopeo-sync-demo.jpg)\n  - 👉 示例 2：    \n    skopeo 命令分别使用两个容器镜像仓库的 token 认证文件将容器镜像同步至另一个仓库中，并且目标仓库只需指定仓库 `URI` 即可，将自动生成对应的镜像名称与标签。![skopeo-sync-between-registry.jpg](skopeo-sync-between-registry.jpg)\n  - 也可使用 skopeo sync 命令将本地 dir 模式存储的容器镜像同步至远程容器镜像仓库中。\n- `skopeo inspect` 与 `skopeo manifest-digest`：\n  - 该命令用于查看详细的容器镜像层信息（image manifest）或容器镜像的配置信息（image config）。  \n  - 🐳 image manifest 包含各镜像层的 `mediaType`、`size`、`digest`，而 image config 包含镜像的其他详细信息。  \n  - 👉 示例 1：Docker 镜像格式的容器镜像目录    \n    如上所述，使用 `dir` 模式存储的容器镜像位于 nexus3-3.37.3 目录中，可直接使用 `jq` 命令查看该镜像的 image manifest 与 image config：    \n    ```bash\n    ### 示例（以下内容为部分输出） ###\n    $ jq '.' nexus3-3.37.3/manifest.json\n    {\n      \"schemaVersion\": 2,\n      \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n      \"config\": {\n        \"mediaType\": \"application/vnd.docker.container.image.v1+json\",\n        \"size\": 10193,\n        \"digest\": \"sha256:1e1d45f195b19d03ec1833561dca6f5c63f9453413247c323c24f2fbcc34bcdd\"\n      },\n      \"layers\": [\n        {\n          \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n          \"size\": 81522888,\n          \"digest\": \"sha256:8dfe9326f733b815c486432e93e0a97f03e90e7cc35def9511cd1efa7f917f56\"\n        },\n        ...\n      ]\n    }\n    # 根据 dir 目录中的 manifest 查看容器镜像及各镜像层信息\n    \n    $ jq '.' nexus3-3.37.3/1e1d45f195b19d03ec1833561dca6f5c63f9453413247c323c24f2fbcc34bcdd\n    {\n      \"architecture\": \"amd64\",\n      \"config\": {\n        \"Hostname\": \"bb4a731bd39e\",\n        \"Domainname\": \"\",\n        \"User\": \"nexus\",\n        ...\n        \"ExposedPorts\": {\n          \"8081/tcp\": {}\n        },\n        \"Tty\": false,\n        \"OpenStdin\": false,\n        \"StdinOnce\": false,\n        \"Env\": [\n          \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n          \"container=oci\",\n          \"SONATYPE_DIR=/opt/sonatype\",\n          \"NEXUS_HOME=/opt/sonatype/nexus\",\n          \"NEXUS_DATA=/nexus-data\",\n          \"NEXUS_CONTEXT=\",\n          \"SONATYPE_WORK=/opt/sonatype/sonatype-work\",\n          \"DOCKER_TYPE=3x-docker\",\n          \"INSTALL4J_ADD_VM_PARAMS=-Xms2703m -Xmx2703m -XX:MaxDirectMemorySize=2703m -Djava.util.prefs.userRoot=/nexus-data/javaprefs\"\n        ],\n        \"Cmd\": [\n          \"sh\",\n          \"-c\",\n          \"${SONATYPE_DIR}/start-nexus-repository-manager.sh\"\n        ],\n        \"Image\": \"sha256:bb968737b5d0d7420e5af7c5524cddc16bd2b43a47f8277e00b1461342d40ba5\",\n        \"Volumes\": {\n          \"/nexus-data\": {}\n        },\n      ...\n      },\n      \"created\": \"2022-03-02T23:52:49.682473465Z\",\n      \"docker_version\": \"20.10.9\",\n      \"history\": [\n        {\n          \"created\": \"2022-02-25T17:39:29.754401796Z\",\n          \"comment\": \"Imported from -\"\n        },\n        ...\n        {\n          \"created\": \"2022-03-02T23:52:49.682473465Z\",\n          \"created_by\": \"/bin/sh -c #(nop)  CMD [\\\"sh\\\" \\\"-c\\\" \\\"${SONATYPE_DIR}/start-nexus-repository-manager.sh\\\"]\",\n          \"empty_layer\": true\n        }\n      ],\n      \"os\": \"linux\",\n      \"rootfs\": {\n        \"type\": \"layers\",\n        \"diff_ids\": [\n          \"sha256:7699752e6ed63eef234d2736d4e37159a433e18e06cd617e254299f324f41797\",\n          \"sha256:c8013a2772b6673d9b750b6407d4ac4f525a47bb2a5b5bf09ba9bf8e10aea3fc\",\n          \"sha256:5a745ebef99f4893aac7c56a26e54f9c6cdc08b02748e0580b1a31d70be0a280\",\n          \"sha256:8d12fc82bf58bf5f7958577a148cc05899f0c19e4654376f5e01d3af46eb0c15\",\n          \"sha256:d17e45a4f748d13d0501b9e1bca5be387e13efa8ce98147a85c904a348764f3b\"\n        ]\n      }\n    }\n    # 根据容器镜像目录中的 config 文件查看具体的 image config \n    ```\n    ```bash\n    $ skopeo inspect dir:nexus3-3.37.3\n    # 查看 nexus3 容器镜像的概要信息\n    \n    $ skopeo inspect --raw dir:nexus3-3.37.3\n    # 查看 nexus3 容器镜像的 manifest 信息，返回的内容与镜像的 manifest.json 一致。\n    \n    $ skopeo inspect --config dir:nexus3-3.37.3\n    # 查看 nexus3 容器镜像的 config 信息，返回的内容与直接查看镜像的配置信息一致。\n    \n    $ skopeo manifest-digest nexus3-3.37.3/manifest.json\n    # 查看 nexus3 容器镜像的 manifest.json 文件的 digest 值\n    ```\n    关于容器镜像目录中 `image manifest` 与其 `digest` 的关系，如下所示：![skopeo-docker-image-format-digest-1.jpg](skopeo-docker-image-format-digest-1.jpg)![skopeo-docker-image-format-digest-2.jpg](skopeo-docker-image-format-digest-2.jpg)\n  - 👉 示例 2：OCI 镜像格式的容器镜像目录    \n    关于容器镜像目录中 `image manifest` 与其 `digest` 的关系，如下所示：![skopeo-oci-image-format-digest.jpg](skopeo-oci-image-format-digest.jpg)\n\n### 🐳 容器镜像格式比较：\n- 对于不同的容器镜像格式，其目录的组织结构存在差异，但彼此间又有联系。\n- 目前采用的容器镜像格式：  \n  - `Docker image format`：Docker 镜像格式  \n  - `OCI image format`：OCI 镜像格式\n- OCI image format 继承于 Docker image format，因此，可运行 OCI image format 镜像的容器运行时也可运行 Docker image format 的镜像。\n- `OCI`（Open Container Initiative，开放容器标准）发展概述：\n  - 为了推进容器化技术的工业标准化，2015 年 6 月在 `DockerCon` 上 Linux 基金会与 Google、华为、惠普、IBM、Docker、Red Hat、VMware 等公司共同宣布成立开放容器项目（OCP），后更名为开放容器标准（OCI）。  \n  - 它的主要目标是建立容器格式和运行时的工业开放通用标准。  \n  - 为了支持 OCI 容器运行时标准的推进，Docker 公司起草了镜像格式和运行时规范的草案，并将 Docker 项目的相关实现捐献给了社区，OCI 作为容器运行时的基础实现，现在项目名为 `runc`。\n- 🤘 发展至今，OCI 制定的主要标准：  \n  - `runtime-spec`：定义容器运行时规范  \n  - `image-spec`：定义容器镜像格式规范  \n  - `distribution-spec`：定义容器镜像的分发规范\n- OCI image format 目录说明：  \n  - 如下所示，以 `debian` 镜像为例：    \n    ```bash\n    $ tree debian-bullseye-20211115-oci\n    debian-bullseye-20211115-oci\n    ├── blobs\n    │   └── sha256\n    │       ├── 468a9be7b68d9b0baf252c3496a6db0a406ba558946d3cfee8f0d2a3be1ec42b\n    │       ├── 5f2f9939c1839f4fee492777a220cfe1e80cd25008df90af6c2b3b2c30e239c6\n    │       └── 61ccfad6b52ee974d14b8e3c998d862e7dedd59fa8e0023e6620b213ea6da1ad\n    ├── index.json\n    └── oci-layout\n    ```\n  - oci-layout：OCI image 的镜像布局规范，此处使用 `OCI 1.0.0` 版本。\n    ```bash\n    $ jq '.' debian-bullseye-20211115-oci/oci-layout\n    {\n      \"imageLayoutVersion\": \"1.0.0\"\n    }\n    ```\n  - index.json：    \n    - `index.json` 文件中的 `manifests` 字段类似于 Docker image 中的 `manifest.json` 作为 OCI image 的顶级配置, 也是镜像的一个入口配置。  \n    - 该文件实际指向 `blobs/sha256/468a9be7b68d9b0baf252c3496a6db0a406ba558946d3cfee8f0d2a3be1ec42b` ，即真正的 OCI image manifest 文件。\n      ```bash\n      $ jq '.' debian-bullseye-20211115-oci/index.json\n      {\n        \"schemaVersion\": 2,\n        \"manifests\": [\n          {\n            \"mediaType\": \"application/vnd.oci.image.manifest.v1+json\",\n            \"digest\": \"sha256:468a9be7b68d9b0baf252c3496a6db0a406ba558946d3cfee8f0d2a3be1ec42b\",\n            \"size\": 349\n          }\n        ]\n      }\n      ```\n    - 从该文件的 `mediaType` 可以看出容器镜像格式已发生的变化：\n      ```bash\n      $ jq '.mediaType' debian-bullseye-20211115-docker/manifest.json\n      \"application/vnd.docker.distribution.manifest.v2+json\"\n      # Docker image format 封装\n      \n      $ jq '.manifests[0].mediaType' debian-bullseye-20211115-oci/index.json\n      \"application/vnd.oci.image.manifest.v1+json\"\n      # OCI image format 封装 \n      ```\n      ```bash\n      $ jq '.' debian-bullseye-20211115-oci/blobs/sha256/468a9be7b68d9b0baf252c3496a6db0a406ba558946d3cfee8f0d2a3be1ec42b\n      {\n        \"schemaVersion\": 2,\n        \"config\": {\n          \"mediaType\": \"application/vnd.oci.image.config.v1+json\",\n          \"digest\": \"sha256:61ccfad6b52ee974d14b8e3c998d862e7dedd59fa8e0023e6620b213ea6da1ad\",\n          \"size\": 579\n        },\n        \"layers\": [\n          {\n            \"mediaType\": \"application/vnd.oci.image.layer.v1.tar+gzip\",\n            \"digest\": \"sha256:5f2f9939c1839f4fee492777a220cfe1e80cd25008df90af6c2b3b2c30e239c6\",\n            \"size\": 56889206\n          }\n        ]\n      }\n      ```\n      以上文件为 OCI image manifest 文件，其中包含 image config 的信息与各镜像层 Layers 的信息，每层 layer 使用 `tar+gzip` 的方式进行压缩。\n- Docker image format 与 OCI image format 的联系与区别：  \n  - 最主要的区别：目录结构不完全相同，配置信息尤其是 `mediaType` 的规范不同。  \n  - 联系：OCI image 的规范是由 Docker image 的规范修改而来，所以类似它们的 blob 的组织形式大致相同，配置文件中很多的参数也相似。  \n  - 另外，可以使用 skopeo 工具很方便地将 Docker image 转换为 OCI image。\n\n### 参考链接：\n- [GitHub Doc - Skopeo](https://github.com/containers/skopeo)\n- [镜像搬运工具 Skopeo 使用](https://mp.weixin.qq.com/s/J2b-PQD5GkN5KEmGB2WAeA)\n- [OCI 与容器镜像构建](https://mp.weixin.qq.com/s/8wAv87DkJjE6fVEEmoQ60Q)\n- [GitHub Doc - opencontainers/image-spec](https://github.com/opencontainers/image-spec)\n- [GitHub Doc - OCI Image Media Types](https://github.com/opencontainers/image-spec/blob/main/media-types.md)\n- [GitHub Doc - Open Container Initiative Runtime Specification](https://github.com/opencontainers/runtime-spec/blob/main/spec.md)","source":"_posts/skopeo-basic-usage.md","raw":"---\ntitle: Skopeo 镜像工具与容器镜像格式的原理与使用\nsubtitle: Skopeo Basic Usage and Container Image Format\nheader-img: skopeo-bg.jpg\ndate: 2022-12-06 11:56:03\ntags:\n  - 容器\n  - 云原生\n---\n\n### 文档说明：\n- OS 版本：Ubuntu 20.04.3 LTS (Focal Fossa)\n- skopeo 版本：1.3.0-1\n\n### 文档目录：\n- Skopeo 工具概要\n- 使用 Skopeo 认证容器镜像仓库\n- Skopeo 支持的容器镜像存储方式\n- 使用 Skopeo 操作容器镜像\n- 容器镜像格式比较\n- 参考链接\n\n### Skopeo 工具概要：\n- 常用的容器镜像操作工具可使用 docker、podman 命令，但 docker 命令行工具需要使用守护进程与 root 用户权限，在一些场景下使用该工具同步容器镜像的效率是较低的，而 podman 命令虽然不使用守护进程，但是其同步镜像效率依然不高。\n- skopeo 与 buildah 命令可专门用于容器镜像的操作，其中 skopeo 命令更加纯粹地用于容器镜像的搬运与容器镜像格式的转换，效率较其他工具更高，但是不具有容器镜像构建的能力。\n- Podman 更加侧重于容器的生命周期管理，同时具备部分容器镜像管理与构建功能，而 Buildah 支持分别使用命令行从头构建容器镜像与 `Dockerfile` 或 `Containerfile` 的构建方式，同时兼容 Docker 与 OCI 镜像格式。\n> 👉 关于 Podman 更加详细的信息可参考之前写的 [Podman 容器原理与使用（1）](https://alberthua-perl.github.io/2022/12/05/podman-arch-usage/)与 [Podman 容器原理与使用（2）](https://alberthua-perl.github.io/2022/12/05/podman-usage-practice/)。\n- Skopeo 安装方法可参考 [该 GitHub 链接](https://github.com/containers/skopeo/blob/main/install.md)，此处不再赘述。\n- skopeo 命令的帮助信息：  \n  ```bash\n  $ skopeo --help\n  Various operations with container images and container image registries\n  \n  Usage:\n    skopeo [command]\n  \n  Available Commands:\n    copy                                          Copy an IMAGE-NAME from one location to another\n    delete                                        Delete image IMAGE-NAME\n    help                                          Help about any command\n    inspect                                       Inspect image IMAGE-NAME\n    list-tags                                     List tags in the transport/repository specified by the REPOSITORY-NAME\n    login                                         Login to a container registry\n    logout                                        Logout of a container registry\n    manifest-digest                               Compute a manifest digest of a file\n    standalone-sign                               Create a signature using local files\n    standalone-verify                             Verify a signature using local files\n    sync                                          Synchronize one or more images from one location to another\n  \n  Flags:\n        --command-timeout duration   timeout for the command execution\n        --debug                      enable debug output\n    -h, --help                       help for skopeo\n        --insecure-policy            run the tool without any policy check\n        --override-arch ARCH         use ARCH instead of the architecture of the machine for choosing images\n        --override-os OS             use OS instead of the running OS for choosing images\n        --override-variant VARIANT   use VARIANT instead of the running architecture variant for choosing images\n        --policy string              Path to a trust policy file\n        --registries.d DIR           use registry configuration files in DIR (e.g. for container signature storage)\n        --tmpdir string              directory used to store temporary files\n    -v, --version                    Version for Skopeo\n  \n  Use \"skopeo [command] --help\" for more information about a command.\n  ```\n\n### 使用 Skopeo 认证容器镜像仓库：\n- Red Hat 支持 `skopeo` 命令来管理容器镜像仓库中的镜像。\n- Skopeo 可分别用于操作公共（public）与私有（private）容器镜像，对于私有容器镜像需要对容器镜像仓库进行认证。\n- Skopeo 与 Buildah 可使用 Podman 保存的认证 `token`（位于 `/run/user/<UID>/containers/auth.json`），但是无法执行交互式的登录密码输入，因此，若在 skopeo 命令行中指定明文登录密码可在 history 命令历史记录中查看到，存在一定的安全风险，可使用如下以变量形式传递密码的方法优化：![skopeo-inspect-creds.jpg](skopeo-inspect-creds.jpg)\n> 若未使用 Podman 作为容器运行时，而依然使用 Docker 容器运行时的话，其认证 token 依然可被 Skopeo 使用与认证，该认证 token 位于 `$HOME/.docker/config.json`。\n- Skopeo 的众多子命令支持容器镜像仓库的认证，可分别通过用户名与密码及认证的 token 文件实现认证，如下所示：  \n  ```bash\n  ### 示例 ###\n  $ skopeo copy --src-creds <username>:<password> \\\n    docker://registry.redhat.io/rhscl/postgresql-96-rhel7:latest \\\n    oci:postgresql-96-rhel7-latest\n  \n  $ skopeo copy --src-authfile /run/user/<UID>/containers/auth.json \\\n    docker://registry.redhat.io/rhscl/postgresql-96-rhel7:latest \\\n    oci:postgresql-96-rhel7-latest\n  ```\n\n### Skopeo 支持的容器镜像存储方式：\n- Skopeo 使用 `URI` 来表示容器镜像的位置，使用 URI 模式（schema）来表示容器镜像格式和registry APIs。\n- 常见的 URI 模式：  \n  - `oci`：    \n    - 表示存储在本地的 OCI 格式目录中的容器镜像    \n    - 该镜像兼容开放容器镜像层规范（`Open Container Image Layout Specification`）  \n  - `oci-archive`：    \n    - 表示 OCI 镜像格式封装的容器镜像的 tar 归档    \n    - 该镜像兼容开放容器镜像层规范  \n  - `containers-storage`：    \n    - 表示存储于本地容器运行时缓存中的容器镜像    \n    - 后端容器引擎兼容 Podman、CRI-O 与 Buildah  \n  - `docker-daemon`：    \n    - 表示存储于本地 Docker 容器运行时缓存中的容器镜像  \n  - `docker-archive`：    \n    - 表示 Docker 镜像格式封装的容器镜像的 tar 归档  \n  - `dir`：    \n    - 本地存储容器镜像的目录，其中以单个文件的方式包含镜像的 `manifest`、镜像层 tar 归档与各镜像层签名（`digest`）。  \n  - `docker://`：    \n    - 表示存储于容器镜像仓库中的远程容器镜像\n    - 可通过 `Docker Registry HTTP API V2` 操作仓库中的容器镜像\n- 同一容器镜像可以根据不同的场景使用以上不同的方式保存。\n> 👉 关于 Skopeo 更为详细的信息可参考 `man skopeo` 手册。\n\n### 使用 Skopeo 操作容器镜像：\n- Skopeo 不使用容器运行时，并且普通用户可直接使用，比 Podman 使用 tag、pull 与 push 等子命令时更加的高效。\n- 🐳 若使用 docker 或 podman 命令将容器镜像仓库中的镜像保存于本地存储，需分别使用 docker pull|save 与 podman pull|save 命令将本地镜像缓存中的镜像保存于 tar 归档，无法从容器镜像仓库直接保存于文件或目录中，下文中提及的 `skopeo copy` 或 `sync` 子命令可实现该功能，无需存在本地镜像缓存。\n- 🚀 Skopeo 操纵镜像层的方式：  \n  - 出于效率问题，Skopeo 不读取与发送已存在于目标仓库的镜像层，它首先读取源镜像的 manifest，再确定哪些层已存在于目标仓库，然后仅仅拷贝缺失的镜像层。  \n  - 若拷贝来自构建于同一父镜像的镜像，Skopeo 不拷贝多个来自于父镜像的相同镜像层。  \n  - Skopeo 可在容器镜像仓库之间拷贝镜像而不在本地容器存储中保存镜像层缓存，若源仓库与目标仓库需要认证，则需要使用 `--src-creds` 与 `--dest-creds` 选项指定认证用户与明文密码，并且 Skopeo 支持在目标仓库实现镜像 `tag`。\n    ```bash\n    $ skopeo copy \\\n      --src-creds=<username>:<password> \\\n      --dest-creds=<username>:<password> \\\n      docker://<uri_for_src_registry>/<user_or_org>/<repository>:[tag] \\\n      docker://<uri_for_dest_registry>/<user_or_org>/<repository>:[tag]\n    # 分别指定源仓库与目标仓库的认证用户与明文密码，并在仓库间拷贝容器镜像。\n    ```\n    ![skopeo-copy-dest-creds.jpg](skopeo-copy-dest-creds.jpg)\n- `skopeo delete`：删除容器镜像的镜像 tag  \n  - 该命令可删除容器镜像仓库中指定镜像的 tag    \n    若删除公共镜像可直接执行无需用户认证，而删除私有容器镜像需使用 `--creds` 选项或 `--authfile` 选项进行认证后删除，如下所示：\n    ```bash\n    $ skopeo delete --creds <username>:<password> \\\n      docker://<uri_for_registry>/<user_or_org>/<repository>:[tag]\n    ```\n  - 💥 指定镜像 `tag` 时将删除特定 tag，即使将最后一个 tag 删除后也不删除整个镜像仓库，若需要删除整个镜像仓库需登录指定仓库。此处为 Quay.io 为例，在 `Web 控制台` 上删除，如下所示：![skopeo-delete-1.jpg](skopeo-delete-1.jpg)![skopeo-delete-2.jpg](skopeo-delete-2.jpg) \n  - 💥 该命令也可删除本地容器运行时缓存中的镜像 tag，但需注意，若具有多个不同 tag 的容器镜像（实际为同一容器镜像），只具有同一个 image ID（该值来自于镜像的 manifest 中 `.config.digest`），那么在执行删除时即使指定了镜像的 tag，也会将其他具有相同 image ID 的镜像一并删除，该行为与容器镜像仓库中相区别！\n- `skopeo copy`：dir 模式示例\n  > 💥 Skopeo 可将容器镜像仓库中镜像拷贝至本地镜像目录（该目录无需提前创建），该目录中的镜像封装格式保留原始容器镜像仓库中的镜像格式。\n\n  ```bash\n  $ skopeo copy \\\n    docker://<uri_for_registry>/<user_or_org>/<repository>:[tag] \\\n    dir:<dir_of_container_image>\n  ```\n  ![skopeo-copy-docker-format-image-dir.jpg](skopeo-copy-docker-format-image-dir.jpg)除了使用 docker load 或 podman load 直接将容器镜像的 tar 归档导入本地镜像缓存中，也可使用已经保存至本地的目录以 dir 或 oci 模式存在的容器镜像，如下所示：![podman-load-dir-from-skopeo-copy.jpg](podman-load-dir-from-skopeo-copy.jpg)\n  \n  也可以使用 Skopeo 将本地镜像目录拷贝至容器镜像仓库，用以替代 docker push 或 podman push 的功能：\n  ```bash\n  $ skopeo copy \\\n    dir:<dir_of_container_image> \\\n    docker://<uri_for_registry>/<user_or_org>/<repository>:[tag]\n  ```\n  ![skopeo-copy-dir-2.jpg](skopeo-copy-dir-2.jpg)\n- `skopeo copy`：oci 模式示例\n  Skopeo 可将容器镜像仓库中镜像拷贝至本地 `OCI` 格式目录中以存储镜像：\n  ```bash\n  $ skopeo copy \\\n    docker://<uri_for_registry>/<user_or_org>/<repository>:[tag] \\\n    oci:<dir_of_container_image>\n  ```\n  ![skopeo-copy-oci-1.jpg](skopeo-copy-oci-1.jpg)其中拷贝至本地的 OCI 格式目录结构如下所示，包含了容器镜像的各层（layer）。\n  ![skopeo-copy-oci-2.jpg](skopeo-copy-oci-2.jpg)也可使用本地 OCI 格式目录将镜像拷贝至容器镜像仓库中。\n- `skopeo copy`：oci-archive 模式示例  \n  ```bash\n  $ skopeo copy \\\n    docker://<uri_for_registry>/<user_or_org>/<repository>:[tag] \\\n    oci-archive:<oci_contaier_image_name>.tar\n  # 将容器镜像仓库中镜像封装为 tar 归档的 OCI 镜像格式的镜像\n  ```\n- `skopeo copy`：containers-storage 模式示例  \n  \n  > 💥 该模式只能在以 Podman 或 CRI-O 为容器运行时的情况下使用，若使用 Docker 容器运行时将报错！\n\n  ![skopeo-copy-docker-daemon.jpg](skopeo-copy-docker-daemon.jpg)  \n  ```bash\n  $ skopeo copy \\\n    docker://<uri_for_registry>/<user_or_org>/<repository>:[tag] \\\n    containers-storage:<uri_for_registry>/<user_or_org>/<repository>:[tag]\n  # 将容器镜像仓库中的镜像存储于本地镜像缓存\n  ```\n- `skopeo copy`：docker-archive 模式示例  \n  ```bash\n  $ skopeo copy \\\n    docker://<uri_for_registry>/<user_or_org>/<repository>:[tag] \\\n    docker-archive:<docker_contaier_image_name>.tar\n  # 将容器镜像仓库中镜像封装为 tar 归档的 Docker 镜像格式的镜像\n  ```\n- `skopeo copy`：docker-daemon 模式示例\n\n  > 💥 该模式在使用 Docker 容器运行时的情况下使用。\n\n  ```bash\n  $ skopeo copy \\\n    docker://<uri_for_registry>/<user_or_org>/<repository>:[tag] \\\n    docker-daemon:<uri_for_registry>/<user_or_org>/<repository>:[tag]\n  # 将容器镜像仓库中的镜像存储于本地镜像缓存\n  ```\n- 🚀 Skopeo 对容器镜像格式的转换：  \n  - 使用 skopeo copy 命令将容器镜像仓库中镜像拷贝至本地目录或本地 tar 归档存储时，可分别以 Docker 镜像格式或 OCI 镜像格式保存。  \n  - 因此，skopeo copy 命令可同时完成容器镜像的下载与镜像格式的转换。  \n  - 如下所示：![skopeo-copy-transform-image-format.jpg](skopeo-copy-transform-image-format.jpg)\n- `skopeo sync`：  \n  - sync 子命令将容器镜像从 src 源同步至 dest 目的地，功能与 copy 子命令类似。  \n  - skopeo sync 命令可指定的 src 与 dest 类型如下所示：![skopeo-sync-help.jpg](skopeo-sync-help.jpg)\n  - 👉 示例 1：    \n    将远程容器镜像仓库中的镜像同步至本地目录，本地存储容器镜像的目录无需创建。![skopeo-sync-demo.jpg](skopeo-sync-demo.jpg)\n  - 👉 示例 2：    \n    skopeo 命令分别使用两个容器镜像仓库的 token 认证文件将容器镜像同步至另一个仓库中，并且目标仓库只需指定仓库 `URI` 即可，将自动生成对应的镜像名称与标签。![skopeo-sync-between-registry.jpg](skopeo-sync-between-registry.jpg)\n  - 也可使用 skopeo sync 命令将本地 dir 模式存储的容器镜像同步至远程容器镜像仓库中。\n- `skopeo inspect` 与 `skopeo manifest-digest`：\n  - 该命令用于查看详细的容器镜像层信息（image manifest）或容器镜像的配置信息（image config）。  \n  - 🐳 image manifest 包含各镜像层的 `mediaType`、`size`、`digest`，而 image config 包含镜像的其他详细信息。  \n  - 👉 示例 1：Docker 镜像格式的容器镜像目录    \n    如上所述，使用 `dir` 模式存储的容器镜像位于 nexus3-3.37.3 目录中，可直接使用 `jq` 命令查看该镜像的 image manifest 与 image config：    \n    ```bash\n    ### 示例（以下内容为部分输出） ###\n    $ jq '.' nexus3-3.37.3/manifest.json\n    {\n      \"schemaVersion\": 2,\n      \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n      \"config\": {\n        \"mediaType\": \"application/vnd.docker.container.image.v1+json\",\n        \"size\": 10193,\n        \"digest\": \"sha256:1e1d45f195b19d03ec1833561dca6f5c63f9453413247c323c24f2fbcc34bcdd\"\n      },\n      \"layers\": [\n        {\n          \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n          \"size\": 81522888,\n          \"digest\": \"sha256:8dfe9326f733b815c486432e93e0a97f03e90e7cc35def9511cd1efa7f917f56\"\n        },\n        ...\n      ]\n    }\n    # 根据 dir 目录中的 manifest 查看容器镜像及各镜像层信息\n    \n    $ jq '.' nexus3-3.37.3/1e1d45f195b19d03ec1833561dca6f5c63f9453413247c323c24f2fbcc34bcdd\n    {\n      \"architecture\": \"amd64\",\n      \"config\": {\n        \"Hostname\": \"bb4a731bd39e\",\n        \"Domainname\": \"\",\n        \"User\": \"nexus\",\n        ...\n        \"ExposedPorts\": {\n          \"8081/tcp\": {}\n        },\n        \"Tty\": false,\n        \"OpenStdin\": false,\n        \"StdinOnce\": false,\n        \"Env\": [\n          \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n          \"container=oci\",\n          \"SONATYPE_DIR=/opt/sonatype\",\n          \"NEXUS_HOME=/opt/sonatype/nexus\",\n          \"NEXUS_DATA=/nexus-data\",\n          \"NEXUS_CONTEXT=\",\n          \"SONATYPE_WORK=/opt/sonatype/sonatype-work\",\n          \"DOCKER_TYPE=3x-docker\",\n          \"INSTALL4J_ADD_VM_PARAMS=-Xms2703m -Xmx2703m -XX:MaxDirectMemorySize=2703m -Djava.util.prefs.userRoot=/nexus-data/javaprefs\"\n        ],\n        \"Cmd\": [\n          \"sh\",\n          \"-c\",\n          \"${SONATYPE_DIR}/start-nexus-repository-manager.sh\"\n        ],\n        \"Image\": \"sha256:bb968737b5d0d7420e5af7c5524cddc16bd2b43a47f8277e00b1461342d40ba5\",\n        \"Volumes\": {\n          \"/nexus-data\": {}\n        },\n      ...\n      },\n      \"created\": \"2022-03-02T23:52:49.682473465Z\",\n      \"docker_version\": \"20.10.9\",\n      \"history\": [\n        {\n          \"created\": \"2022-02-25T17:39:29.754401796Z\",\n          \"comment\": \"Imported from -\"\n        },\n        ...\n        {\n          \"created\": \"2022-03-02T23:52:49.682473465Z\",\n          \"created_by\": \"/bin/sh -c #(nop)  CMD [\\\"sh\\\" \\\"-c\\\" \\\"${SONATYPE_DIR}/start-nexus-repository-manager.sh\\\"]\",\n          \"empty_layer\": true\n        }\n      ],\n      \"os\": \"linux\",\n      \"rootfs\": {\n        \"type\": \"layers\",\n        \"diff_ids\": [\n          \"sha256:7699752e6ed63eef234d2736d4e37159a433e18e06cd617e254299f324f41797\",\n          \"sha256:c8013a2772b6673d9b750b6407d4ac4f525a47bb2a5b5bf09ba9bf8e10aea3fc\",\n          \"sha256:5a745ebef99f4893aac7c56a26e54f9c6cdc08b02748e0580b1a31d70be0a280\",\n          \"sha256:8d12fc82bf58bf5f7958577a148cc05899f0c19e4654376f5e01d3af46eb0c15\",\n          \"sha256:d17e45a4f748d13d0501b9e1bca5be387e13efa8ce98147a85c904a348764f3b\"\n        ]\n      }\n    }\n    # 根据容器镜像目录中的 config 文件查看具体的 image config \n    ```\n    ```bash\n    $ skopeo inspect dir:nexus3-3.37.3\n    # 查看 nexus3 容器镜像的概要信息\n    \n    $ skopeo inspect --raw dir:nexus3-3.37.3\n    # 查看 nexus3 容器镜像的 manifest 信息，返回的内容与镜像的 manifest.json 一致。\n    \n    $ skopeo inspect --config dir:nexus3-3.37.3\n    # 查看 nexus3 容器镜像的 config 信息，返回的内容与直接查看镜像的配置信息一致。\n    \n    $ skopeo manifest-digest nexus3-3.37.3/manifest.json\n    # 查看 nexus3 容器镜像的 manifest.json 文件的 digest 值\n    ```\n    关于容器镜像目录中 `image manifest` 与其 `digest` 的关系，如下所示：![skopeo-docker-image-format-digest-1.jpg](skopeo-docker-image-format-digest-1.jpg)![skopeo-docker-image-format-digest-2.jpg](skopeo-docker-image-format-digest-2.jpg)\n  - 👉 示例 2：OCI 镜像格式的容器镜像目录    \n    关于容器镜像目录中 `image manifest` 与其 `digest` 的关系，如下所示：![skopeo-oci-image-format-digest.jpg](skopeo-oci-image-format-digest.jpg)\n\n### 🐳 容器镜像格式比较：\n- 对于不同的容器镜像格式，其目录的组织结构存在差异，但彼此间又有联系。\n- 目前采用的容器镜像格式：  \n  - `Docker image format`：Docker 镜像格式  \n  - `OCI image format`：OCI 镜像格式\n- OCI image format 继承于 Docker image format，因此，可运行 OCI image format 镜像的容器运行时也可运行 Docker image format 的镜像。\n- `OCI`（Open Container Initiative，开放容器标准）发展概述：\n  - 为了推进容器化技术的工业标准化，2015 年 6 月在 `DockerCon` 上 Linux 基金会与 Google、华为、惠普、IBM、Docker、Red Hat、VMware 等公司共同宣布成立开放容器项目（OCP），后更名为开放容器标准（OCI）。  \n  - 它的主要目标是建立容器格式和运行时的工业开放通用标准。  \n  - 为了支持 OCI 容器运行时标准的推进，Docker 公司起草了镜像格式和运行时规范的草案，并将 Docker 项目的相关实现捐献给了社区，OCI 作为容器运行时的基础实现，现在项目名为 `runc`。\n- 🤘 发展至今，OCI 制定的主要标准：  \n  - `runtime-spec`：定义容器运行时规范  \n  - `image-spec`：定义容器镜像格式规范  \n  - `distribution-spec`：定义容器镜像的分发规范\n- OCI image format 目录说明：  \n  - 如下所示，以 `debian` 镜像为例：    \n    ```bash\n    $ tree debian-bullseye-20211115-oci\n    debian-bullseye-20211115-oci\n    ├── blobs\n    │   └── sha256\n    │       ├── 468a9be7b68d9b0baf252c3496a6db0a406ba558946d3cfee8f0d2a3be1ec42b\n    │       ├── 5f2f9939c1839f4fee492777a220cfe1e80cd25008df90af6c2b3b2c30e239c6\n    │       └── 61ccfad6b52ee974d14b8e3c998d862e7dedd59fa8e0023e6620b213ea6da1ad\n    ├── index.json\n    └── oci-layout\n    ```\n  - oci-layout：OCI image 的镜像布局规范，此处使用 `OCI 1.0.0` 版本。\n    ```bash\n    $ jq '.' debian-bullseye-20211115-oci/oci-layout\n    {\n      \"imageLayoutVersion\": \"1.0.0\"\n    }\n    ```\n  - index.json：    \n    - `index.json` 文件中的 `manifests` 字段类似于 Docker image 中的 `manifest.json` 作为 OCI image 的顶级配置, 也是镜像的一个入口配置。  \n    - 该文件实际指向 `blobs/sha256/468a9be7b68d9b0baf252c3496a6db0a406ba558946d3cfee8f0d2a3be1ec42b` ，即真正的 OCI image manifest 文件。\n      ```bash\n      $ jq '.' debian-bullseye-20211115-oci/index.json\n      {\n        \"schemaVersion\": 2,\n        \"manifests\": [\n          {\n            \"mediaType\": \"application/vnd.oci.image.manifest.v1+json\",\n            \"digest\": \"sha256:468a9be7b68d9b0baf252c3496a6db0a406ba558946d3cfee8f0d2a3be1ec42b\",\n            \"size\": 349\n          }\n        ]\n      }\n      ```\n    - 从该文件的 `mediaType` 可以看出容器镜像格式已发生的变化：\n      ```bash\n      $ jq '.mediaType' debian-bullseye-20211115-docker/manifest.json\n      \"application/vnd.docker.distribution.manifest.v2+json\"\n      # Docker image format 封装\n      \n      $ jq '.manifests[0].mediaType' debian-bullseye-20211115-oci/index.json\n      \"application/vnd.oci.image.manifest.v1+json\"\n      # OCI image format 封装 \n      ```\n      ```bash\n      $ jq '.' debian-bullseye-20211115-oci/blobs/sha256/468a9be7b68d9b0baf252c3496a6db0a406ba558946d3cfee8f0d2a3be1ec42b\n      {\n        \"schemaVersion\": 2,\n        \"config\": {\n          \"mediaType\": \"application/vnd.oci.image.config.v1+json\",\n          \"digest\": \"sha256:61ccfad6b52ee974d14b8e3c998d862e7dedd59fa8e0023e6620b213ea6da1ad\",\n          \"size\": 579\n        },\n        \"layers\": [\n          {\n            \"mediaType\": \"application/vnd.oci.image.layer.v1.tar+gzip\",\n            \"digest\": \"sha256:5f2f9939c1839f4fee492777a220cfe1e80cd25008df90af6c2b3b2c30e239c6\",\n            \"size\": 56889206\n          }\n        ]\n      }\n      ```\n      以上文件为 OCI image manifest 文件，其中包含 image config 的信息与各镜像层 Layers 的信息，每层 layer 使用 `tar+gzip` 的方式进行压缩。\n- Docker image format 与 OCI image format 的联系与区别：  \n  - 最主要的区别：目录结构不完全相同，配置信息尤其是 `mediaType` 的规范不同。  \n  - 联系：OCI image 的规范是由 Docker image 的规范修改而来，所以类似它们的 blob 的组织形式大致相同，配置文件中很多的参数也相似。  \n  - 另外，可以使用 skopeo 工具很方便地将 Docker image 转换为 OCI image。\n\n### 参考链接：\n- [GitHub Doc - Skopeo](https://github.com/containers/skopeo)\n- [镜像搬运工具 Skopeo 使用](https://mp.weixin.qq.com/s/J2b-PQD5GkN5KEmGB2WAeA)\n- [OCI 与容器镜像构建](https://mp.weixin.qq.com/s/8wAv87DkJjE6fVEEmoQ60Q)\n- [GitHub Doc - opencontainers/image-spec](https://github.com/opencontainers/image-spec)\n- [GitHub Doc - OCI Image Media Types](https://github.com/opencontainers/image-spec/blob/main/media-types.md)\n- [GitHub Doc - Open Container Initiative Runtime Specification](https://github.com/opencontainers/runtime-spec/blob/main/spec.md)","slug":"skopeo-basic-usage","published":1,"updated":"2022-12-06T05:33:17.881Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldfonoso001p16vdx2hmxdxp","content":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li>OS 版本：Ubuntu 20.04.3 LTS (Focal Fossa)</li>\n<li>skopeo 版本：1.3.0-1</li>\n</ul>\n<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>Skopeo 工具概要</li>\n<li>使用 Skopeo 认证容器镜像仓库</li>\n<li>Skopeo 支持的容器镜像存储方式</li>\n<li>使用 Skopeo 操作容器镜像</li>\n<li>容器镜像格式比较</li>\n<li>参考链接</li>\n</ul>\n<h3 id=\"Skopeo-工具概要：\"><a href=\"#Skopeo-工具概要：\" class=\"headerlink\" title=\"Skopeo 工具概要：\"></a>Skopeo 工具概要：</h3><ul>\n<li>常用的容器镜像操作工具可使用 docker、podman 命令，但 docker 命令行工具需要使用守护进程与 root 用户权限，在一些场景下使用该工具同步容器镜像的效率是较低的，而 podman 命令虽然不使用守护进程，但是其同步镜像效率依然不高。</li>\n<li>skopeo 与 buildah 命令可专门用于容器镜像的操作，其中 skopeo 命令更加纯粹地用于容器镜像的搬运与容器镜像格式的转换，效率较其他工具更高，但是不具有容器镜像构建的能力。</li>\n<li>Podman 更加侧重于容器的生命周期管理，同时具备部分容器镜像管理与构建功能，而 Buildah 支持分别使用命令行从头构建容器镜像与 <code>Dockerfile</code> 或 <code>Containerfile</code> 的构建方式，同时兼容 Docker 与 OCI 镜像格式。<blockquote>\n<p>👉 关于 Podman 更加详细的信息可参考之前写的 <a href=\"https://alberthua-perl.github.io/2022/12/05/podman-arch-usage/\">Podman 容器原理与使用（1）</a>与 <a href=\"https://alberthua-perl.github.io/2022/12/05/podman-usage-practice/\">Podman 容器原理与使用（2）</a>。</p>\n</blockquote>\n</li>\n<li>Skopeo 安装方法可参考 <a href=\"https://github.com/containers/skopeo/blob/main/install.md\" target=\"_blank\" rel=\"noopener\">该 GitHub 链接</a>，此处不再赘述。</li>\n<li>skopeo 命令的帮助信息：  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo --<span class=\"built_in\">help</span></span><br><span class=\"line\">Various operations with container images and container image registries</span><br><span class=\"line\"></span><br><span class=\"line\">Usage:</span><br><span class=\"line\">  skopeo [<span class=\"built_in\">command</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">Available Commands:</span><br><span class=\"line\">  copy                                          Copy an IMAGE-NAME from one location to another</span><br><span class=\"line\">  delete                                        Delete image IMAGE-NAME</span><br><span class=\"line\">  <span class=\"built_in\">help</span>                                          Help about any <span class=\"built_in\">command</span></span><br><span class=\"line\">  inspect                                       Inspect image IMAGE-NAME</span><br><span class=\"line\">  list-tags                                     List tags <span class=\"keyword\">in</span> the transport/repository specified by the REPOSITORY-NAME</span><br><span class=\"line\">  login                                         Login to a container registry</span><br><span class=\"line\">  <span class=\"built_in\">logout</span>                                        Logout of a container registry</span><br><span class=\"line\">  manifest-digest                               Compute a manifest digest of a file</span><br><span class=\"line\">  standalone-sign                               Create a signature using <span class=\"built_in\">local</span> files</span><br><span class=\"line\">  standalone-verify                             Verify a signature using <span class=\"built_in\">local</span> files</span><br><span class=\"line\">  sync                                          Synchronize one or more images from one location to another</span><br><span class=\"line\"></span><br><span class=\"line\">Flags:</span><br><span class=\"line\">      --<span class=\"built_in\">command</span>-timeout duration   timeout <span class=\"keyword\">for</span> the <span class=\"built_in\">command</span> execution</span><br><span class=\"line\">      --debug                      <span class=\"built_in\">enable</span> debug output</span><br><span class=\"line\">  -h, --<span class=\"built_in\">help</span>                       <span class=\"built_in\">help</span> <span class=\"keyword\">for</span> skopeo</span><br><span class=\"line\">      --insecure-policy            run the tool without any policy check</span><br><span class=\"line\">      --override-arch ARCH         use ARCH instead of the architecture of the machine <span class=\"keyword\">for</span> choosing images</span><br><span class=\"line\">      --override-os OS             use OS instead of the running OS <span class=\"keyword\">for</span> choosing images</span><br><span class=\"line\">      --override-variant VARIANT   use VARIANT instead of the running architecture variant <span class=\"keyword\">for</span> choosing images</span><br><span class=\"line\">      --policy string              Path to a trust policy file</span><br><span class=\"line\">      --registries.d DIR           use registry configuration files <span class=\"keyword\">in</span> DIR (e.g. <span class=\"keyword\">for</span> container signature storage)</span><br><span class=\"line\">      --tmpdir string              directory used to store temporary files</span><br><span class=\"line\">  -v, --version                    Version <span class=\"keyword\">for</span> Skopeo</span><br><span class=\"line\"></span><br><span class=\"line\">Use <span class=\"string\">\"skopeo [command] --help\"</span> <span class=\"keyword\">for</span> more information about a <span class=\"built_in\">command</span>.</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"使用-Skopeo-认证容器镜像仓库：\"><a href=\"#使用-Skopeo-认证容器镜像仓库：\" class=\"headerlink\" title=\"使用 Skopeo 认证容器镜像仓库：\"></a>使用 Skopeo 认证容器镜像仓库：</h3><ul>\n<li>Red Hat 支持 <code>skopeo</code> 命令来管理容器镜像仓库中的镜像。</li>\n<li>Skopeo 可分别用于操作公共（public）与私有（private）容器镜像，对于私有容器镜像需要对容器镜像仓库进行认证。</li>\n<li>Skopeo 与 Buildah 可使用 Podman 保存的认证 <code>token</code>（位于 <code>/run/user/&lt;UID&gt;/containers/auth.json</code>），但是无法执行交互式的登录密码输入，因此，若在 skopeo 命令行中指定明文登录密码可在 history 命令历史记录中查看到，存在一定的安全风险，可使用如下以变量形式传递密码的方法优化：<img src=\"skopeo-inspect-creds.jpg\" alt=\"skopeo-inspect-creds.jpg\"><blockquote>\n<p>若未使用 Podman 作为容器运行时，而依然使用 Docker 容器运行时的话，其认证 token 依然可被 Skopeo 使用与认证，该认证 token 位于 <code>$HOME/.docker/config.json</code>。</p>\n</blockquote>\n</li>\n<li>Skopeo 的众多子命令支持容器镜像仓库的认证，可分别通过用户名与密码及认证的 token 文件实现认证，如下所示：  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">### 示例 ###</span></span><br><span class=\"line\">$ skopeo copy --src-creds &lt;username&gt;:&lt;password&gt; \\</span><br><span class=\"line\">  docker://registry.redhat.io/rhscl/postgresql-96-rhel7:latest \\</span><br><span class=\"line\">  oci:postgresql-96-rhel7-latest</span><br><span class=\"line\"></span><br><span class=\"line\">$ skopeo copy --src-authfile /run/user/&lt;UID&gt;/containers/auth.json \\</span><br><span class=\"line\">  docker://registry.redhat.io/rhscl/postgresql-96-rhel7:latest \\</span><br><span class=\"line\">  oci:postgresql-96-rhel7-latest</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"Skopeo-支持的容器镜像存储方式：\"><a href=\"#Skopeo-支持的容器镜像存储方式：\" class=\"headerlink\" title=\"Skopeo 支持的容器镜像存储方式：\"></a>Skopeo 支持的容器镜像存储方式：</h3><ul>\n<li>Skopeo 使用 <code>URI</code> 来表示容器镜像的位置，使用 URI 模式（schema）来表示容器镜像格式和registry APIs。</li>\n<li>常见的 URI 模式：  <ul>\n<li><code>oci</code>：    <ul>\n<li>表示存储在本地的 OCI 格式目录中的容器镜像    </li>\n<li>该镜像兼容开放容器镜像层规范（<code>Open Container Image Layout Specification</code>）  </li>\n</ul>\n</li>\n<li><code>oci-archive</code>：    <ul>\n<li>表示 OCI 镜像格式封装的容器镜像的 tar 归档    </li>\n<li>该镜像兼容开放容器镜像层规范  </li>\n</ul>\n</li>\n<li><code>containers-storage</code>：    <ul>\n<li>表示存储于本地容器运行时缓存中的容器镜像    </li>\n<li>后端容器引擎兼容 Podman、CRI-O 与 Buildah  </li>\n</ul>\n</li>\n<li><code>docker-daemon</code>：    <ul>\n<li>表示存储于本地 Docker 容器运行时缓存中的容器镜像  </li>\n</ul>\n</li>\n<li><code>docker-archive</code>：    <ul>\n<li>表示 Docker 镜像格式封装的容器镜像的 tar 归档  </li>\n</ul>\n</li>\n<li><code>dir</code>：    <ul>\n<li>本地存储容器镜像的目录，其中以单个文件的方式包含镜像的 <code>manifest</code>、镜像层 tar 归档与各镜像层签名（<code>digest</code>）。  </li>\n</ul>\n</li>\n<li><code>docker://</code>：    <ul>\n<li>表示存储于容器镜像仓库中的远程容器镜像</li>\n<li>可通过 <code>Docker Registry HTTP API V2</code> 操作仓库中的容器镜像</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>同一容器镜像可以根据不同的场景使用以上不同的方式保存。<blockquote>\n<p>👉 关于 Skopeo 更为详细的信息可参考 <code>man skopeo</code> 手册。</p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"使用-Skopeo-操作容器镜像：\"><a href=\"#使用-Skopeo-操作容器镜像：\" class=\"headerlink\" title=\"使用 Skopeo 操作容器镜像：\"></a>使用 Skopeo 操作容器镜像：</h3><ul>\n<li>Skopeo 不使用容器运行时，并且普通用户可直接使用，比 Podman 使用 tag、pull 与 push 等子命令时更加的高效。</li>\n<li>🐳 若使用 docker 或 podman 命令将容器镜像仓库中的镜像保存于本地存储，需分别使用 docker pull|save 与 podman pull|save 命令将本地镜像缓存中的镜像保存于 tar 归档，无法从容器镜像仓库直接保存于文件或目录中，下文中提及的 <code>skopeo copy</code> 或 <code>sync</code> 子命令可实现该功能，无需存在本地镜像缓存。</li>\n<li><p>🚀 Skopeo 操纵镜像层的方式：  </p>\n<ul>\n<li>出于效率问题，Skopeo 不读取与发送已存在于目标仓库的镜像层，它首先读取源镜像的 manifest，再确定哪些层已存在于目标仓库，然后仅仅拷贝缺失的镜像层。  </li>\n<li>若拷贝来自构建于同一父镜像的镜像，Skopeo 不拷贝多个来自于父镜像的相同镜像层。  </li>\n<li><p>Skopeo 可在容器镜像仓库之间拷贝镜像而不在本地容器存储中保存镜像层缓存，若源仓库与目标仓库需要认证，则需要使用 <code>--src-creds</code> 与 <code>--dest-creds</code> 选项指定认证用户与明文密码，并且 Skopeo 支持在目标仓库实现镜像 <code>tag</code>。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo copy \\</span><br><span class=\"line\">  --src-creds=&lt;username&gt;:&lt;password&gt; \\</span><br><span class=\"line\">  --dest-creds=&lt;username&gt;:&lt;password&gt; \\</span><br><span class=\"line\">  docker://&lt;uri_for_src_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag] \\</span><br><span class=\"line\">  docker://&lt;uri_for_dest_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag]</span><br><span class=\"line\"><span class=\"comment\"># 分别指定源仓库与目标仓库的认证用户与明文密码，并在仓库间拷贝容器镜像。</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"skopeo-copy-dest-creds.jpg\" alt=\"skopeo-copy-dest-creds.jpg\"></p>\n</li>\n</ul>\n</li>\n<li><p><code>skopeo delete</code>：删除容器镜像的镜像 tag  </p>\n<ul>\n<li><p>该命令可删除容器镜像仓库中指定镜像的 tag<br>若删除公共镜像可直接执行无需用户认证，而删除私有容器镜像需使用 <code>--creds</code> 选项或 <code>--authfile</code> 选项进行认证后删除，如下所示：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo delete --creds &lt;username&gt;:&lt;password&gt; \\</span><br><span class=\"line\">  docker://&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag]</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>💥 指定镜像 <code>tag</code> 时将删除特定 tag，即使将最后一个 tag 删除后也不删除整个镜像仓库，若需要删除整个镜像仓库需登录指定仓库。此处为 Quay.io 为例，在 <code>Web 控制台</code> 上删除，如下所示：<img src=\"skopeo-delete-1.jpg\" alt=\"skopeo-delete-1.jpg\"><img src=\"skopeo-delete-2.jpg\" alt=\"skopeo-delete-2.jpg\"> </p>\n</li>\n<li>💥 该命令也可删除本地容器运行时缓存中的镜像 tag，但需注意，若具有多个不同 tag 的容器镜像（实际为同一容器镜像），只具有同一个 image ID（该值来自于镜像的 manifest 中 <code>.config.digest</code>），那么在执行删除时即使指定了镜像的 tag，也会将其他具有相同 image ID 的镜像一并删除，该行为与容器镜像仓库中相区别！</li>\n</ul>\n</li>\n<li><p><code>skopeo copy</code>：dir 模式示例</p>\n<blockquote>\n<p>💥 Skopeo 可将容器镜像仓库中镜像拷贝至本地镜像目录（该目录无需提前创建），该目录中的镜像封装格式保留原始容器镜像仓库中的镜像格式。</p>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo copy \\</span><br><span class=\"line\">  docker://&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag] \\</span><br><span class=\"line\">  dir:&lt;dir_of_container_image&gt;</span><br></pre></td></tr></table></figure>\n<p><img src=\"skopeo-copy-docker-format-image-dir.jpg\" alt=\"skopeo-copy-docker-format-image-dir.jpg\">除了使用 docker load 或 podman load 直接将容器镜像的 tar 归档导入本地镜像缓存中，也可使用已经保存至本地的目录以 dir 或 oci 模式存在的容器镜像，如下所示：<img src=\"podman-load-dir-from-skopeo-copy.jpg\" alt=\"podman-load-dir-from-skopeo-copy.jpg\"></p>\n<p>也可以使用 Skopeo 将本地镜像目录拷贝至容器镜像仓库，用以替代 docker push 或 podman push 的功能：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo copy \\</span><br><span class=\"line\">  dir:&lt;dir_of_container_image&gt; \\</span><br><span class=\"line\">  docker://&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag]</span><br></pre></td></tr></table></figure>\n<p><img src=\"skopeo-copy-dir-2.jpg\" alt=\"skopeo-copy-dir-2.jpg\"></p>\n</li>\n<li><p><code>skopeo copy</code>：oci 模式示例<br>Skopeo 可将容器镜像仓库中镜像拷贝至本地 <code>OCI</code> 格式目录中以存储镜像：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo copy \\</span><br><span class=\"line\">  docker://&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag] \\</span><br><span class=\"line\">  oci:&lt;dir_of_container_image&gt;</span><br></pre></td></tr></table></figure>\n<p><img src=\"skopeo-copy-oci-1.jpg\" alt=\"skopeo-copy-oci-1.jpg\">其中拷贝至本地的 OCI 格式目录结构如下所示，包含了容器镜像的各层（layer）。<br><img src=\"skopeo-copy-oci-2.jpg\" alt=\"skopeo-copy-oci-2.jpg\">也可使用本地 OCI 格式目录将镜像拷贝至容器镜像仓库中。</p>\n</li>\n<li><p><code>skopeo copy</code>：oci-archive 模式示例  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo copy \\</span><br><span class=\"line\">  docker://&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag] \\</span><br><span class=\"line\">  oci-archive:&lt;oci_contaier_image_name&gt;.tar</span><br><span class=\"line\"><span class=\"comment\"># 将容器镜像仓库中镜像封装为 tar 归档的 OCI 镜像格式的镜像</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>skopeo copy</code>：containers-storage 模式示例  </p>\n<blockquote>\n<p>💥 该模式只能在以 Podman 或 CRI-O 为容器运行时的情况下使用，若使用 Docker 容器运行时将报错！</p>\n</blockquote>\n<p><img src=\"skopeo-copy-docker-daemon.jpg\" alt=\"skopeo-copy-docker-daemon.jpg\">  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo copy \\</span><br><span class=\"line\">  docker://&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag] \\</span><br><span class=\"line\">  containers-storage:&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag]</span><br><span class=\"line\"><span class=\"comment\"># 将容器镜像仓库中的镜像存储于本地镜像缓存</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>skopeo copy</code>：docker-archive 模式示例  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo copy \\</span><br><span class=\"line\">  docker://&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag] \\</span><br><span class=\"line\">  docker-archive:&lt;docker_contaier_image_name&gt;.tar</span><br><span class=\"line\"><span class=\"comment\"># 将容器镜像仓库中镜像封装为 tar 归档的 Docker 镜像格式的镜像</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>skopeo copy</code>：docker-daemon 模式示例</p>\n<blockquote>\n<p>💥 该模式在使用 Docker 容器运行时的情况下使用。</p>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo copy \\</span><br><span class=\"line\">  docker://&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag] \\</span><br><span class=\"line\">  docker-daemon:&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag]</span><br><span class=\"line\"><span class=\"comment\"># 将容器镜像仓库中的镜像存储于本地镜像缓存</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>🚀 Skopeo 对容器镜像格式的转换：  </p>\n<ul>\n<li>使用 skopeo copy 命令将容器镜像仓库中镜像拷贝至本地目录或本地 tar 归档存储时，可分别以 Docker 镜像格式或 OCI 镜像格式保存。  </li>\n<li>因此，skopeo copy 命令可同时完成容器镜像的下载与镜像格式的转换。  </li>\n<li>如下所示：<img src=\"skopeo-copy-transform-image-format.jpg\" alt=\"skopeo-copy-transform-image-format.jpg\"></li>\n</ul>\n</li>\n<li><code>skopeo sync</code>：  <ul>\n<li>sync 子命令将容器镜像从 src 源同步至 dest 目的地，功能与 copy 子命令类似。  </li>\n<li>skopeo sync 命令可指定的 src 与 dest 类型如下所示：<img src=\"skopeo-sync-help.jpg\" alt=\"skopeo-sync-help.jpg\"></li>\n<li>👉 示例 1：<br>将远程容器镜像仓库中的镜像同步至本地目录，本地存储容器镜像的目录无需创建。<img src=\"skopeo-sync-demo.jpg\" alt=\"skopeo-sync-demo.jpg\"></li>\n<li>👉 示例 2：<br>skopeo 命令分别使用两个容器镜像仓库的 token 认证文件将容器镜像同步至另一个仓库中，并且目标仓库只需指定仓库 <code>URI</code> 即可，将自动生成对应的镜像名称与标签。<img src=\"skopeo-sync-between-registry.jpg\" alt=\"skopeo-sync-between-registry.jpg\"></li>\n<li>也可使用 skopeo sync 命令将本地 dir 模式存储的容器镜像同步至远程容器镜像仓库中。</li>\n</ul>\n</li>\n<li><p><code>skopeo inspect</code> 与 <code>skopeo manifest-digest</code>：</p>\n<ul>\n<li>该命令用于查看详细的容器镜像层信息（image manifest）或容器镜像的配置信息（image config）。  </li>\n<li>🐳 image manifest 包含各镜像层的 <code>mediaType</code>、<code>size</code>、<code>digest</code>，而 image config 包含镜像的其他详细信息。  </li>\n<li><p>👉 示例 1：Docker 镜像格式的容器镜像目录<br>如上所述，使用 <code>dir</code> 模式存储的容器镜像位于 nexus3-3.37.3 目录中，可直接使用 <code>jq</code> 命令查看该镜像的 image manifest 与 image config：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">### 示例（以下内容为部分输出） ###</span></span><br><span class=\"line\">$ jq <span class=\"string\">'.'</span> nexus3-3.37.3/manifest.json</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"schemaVersion\"</span>: 2,</span><br><span class=\"line\">  <span class=\"string\">\"mediaType\"</span>: <span class=\"string\">\"application/vnd.docker.distribution.manifest.v2+json\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"config\"</span>: &#123;</span><br><span class=\"line\">    <span class=\"string\">\"mediaType\"</span>: <span class=\"string\">\"application/vnd.docker.container.image.v1+json\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"size\"</span>: 10193,</span><br><span class=\"line\">    <span class=\"string\">\"digest\"</span>: <span class=\"string\">\"sha256:1e1d45f195b19d03ec1833561dca6f5c63f9453413247c323c24f2fbcc34bcdd\"</span></span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  <span class=\"string\">\"layers\"</span>: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"mediaType\"</span>: <span class=\"string\">\"application/vnd.docker.image.rootfs.diff.tar.gzip\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"size\"</span>: 81522888,</span><br><span class=\"line\">      <span class=\"string\">\"digest\"</span>: <span class=\"string\">\"sha256:8dfe9326f733b815c486432e93e0a97f03e90e7cc35def9511cd1efa7f917f56\"</span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    ...</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\"># 根据 dir 目录中的 manifest 查看容器镜像及各镜像层信息</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ jq <span class=\"string\">'.'</span> nexus3-3.37.3/1e1d45f195b19d03ec1833561dca6f5c63f9453413247c323c24f2fbcc34bcdd</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"architecture\"</span>: <span class=\"string\">\"amd64\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"config\"</span>: &#123;</span><br><span class=\"line\">    <span class=\"string\">\"Hostname\"</span>: <span class=\"string\">\"bb4a731bd39e\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"Domainname\"</span>: <span class=\"string\">\"\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"User\"</span>: <span class=\"string\">\"nexus\"</span>,</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"string\">\"ExposedPorts\"</span>: &#123;</span><br><span class=\"line\">      <span class=\"string\">\"8081/tcp\"</span>: &#123;&#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">\"Tty\"</span>: <span class=\"literal\">false</span>,</span><br><span class=\"line\">    <span class=\"string\">\"OpenStdin\"</span>: <span class=\"literal\">false</span>,</span><br><span class=\"line\">    <span class=\"string\">\"StdinOnce\"</span>: <span class=\"literal\">false</span>,</span><br><span class=\"line\">    <span class=\"string\">\"Env\"</span>: [</span><br><span class=\"line\">      <span class=\"string\">\"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"container=oci\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"SONATYPE_DIR=/opt/sonatype\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"NEXUS_HOME=/opt/sonatype/nexus\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"NEXUS_DATA=/nexus-data\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"NEXUS_CONTEXT=\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"SONATYPE_WORK=/opt/sonatype/sonatype-work\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"DOCKER_TYPE=3x-docker\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"INSTALL4J_ADD_VM_PARAMS=-Xms2703m -Xmx2703m -XX:MaxDirectMemorySize=2703m -Djava.util.prefs.userRoot=/nexus-data/javaprefs\"</span></span><br><span class=\"line\">    ],</span><br><span class=\"line\">    <span class=\"string\">\"Cmd\"</span>: [</span><br><span class=\"line\">      <span class=\"string\">\"sh\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"-c\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"<span class=\"variable\">$&#123;SONATYPE_DIR&#125;</span>/start-nexus-repository-manager.sh\"</span></span><br><span class=\"line\">    ],</span><br><span class=\"line\">    <span class=\"string\">\"Image\"</span>: <span class=\"string\">\"sha256:bb968737b5d0d7420e5af7c5524cddc16bd2b43a47f8277e00b1461342d40ba5\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"Volumes\"</span>: &#123;</span><br><span class=\"line\">      <span class=\"string\">\"/nexus-data\"</span>: &#123;&#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  <span class=\"string\">\"created\"</span>: <span class=\"string\">\"2022-03-02T23:52:49.682473465Z\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"docker_version\"</span>: <span class=\"string\">\"20.10.9\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"history\"</span>: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"created\"</span>: <span class=\"string\">\"2022-02-25T17:39:29.754401796Z\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"comment\"</span>: <span class=\"string\">\"Imported from -\"</span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"created\"</span>: <span class=\"string\">\"2022-03-02T23:52:49.682473465Z\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"created_by\"</span>: <span class=\"string\">\"/bin/sh -c #(nop)  CMD [\\\"sh\\\" \\\"-c\\\" \\\"<span class=\"variable\">$&#123;SONATYPE_DIR&#125;</span>/start-nexus-repository-manager.sh\\\"]\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"empty_layer\"</span>: <span class=\"literal\">true</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ],</span><br><span class=\"line\">  <span class=\"string\">\"os\"</span>: <span class=\"string\">\"linux\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"rootfs\"</span>: &#123;</span><br><span class=\"line\">    <span class=\"string\">\"type\"</span>: <span class=\"string\">\"layers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"diff_ids\"</span>: [</span><br><span class=\"line\">      <span class=\"string\">\"sha256:7699752e6ed63eef234d2736d4e37159a433e18e06cd617e254299f324f41797\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"sha256:c8013a2772b6673d9b750b6407d4ac4f525a47bb2a5b5bf09ba9bf8e10aea3fc\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"sha256:5a745ebef99f4893aac7c56a26e54f9c6cdc08b02748e0580b1a31d70be0a280\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"sha256:8d12fc82bf58bf5f7958577a148cc05899f0c19e4654376f5e01d3af46eb0c15\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"sha256:d17e45a4f748d13d0501b9e1bca5be387e13efa8ce98147a85c904a348764f3b\"</span></span><br><span class=\"line\">    ]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\"># 根据容器镜像目录中的 config 文件查看具体的 image config</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo inspect dir:nexus3-3.37.3</span><br><span class=\"line\"><span class=\"comment\"># 查看 nexus3 容器镜像的概要信息</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ skopeo inspect --raw dir:nexus3-3.37.3</span><br><span class=\"line\"><span class=\"comment\"># 查看 nexus3 容器镜像的 manifest 信息，返回的内容与镜像的 manifest.json 一致。</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ skopeo inspect --config dir:nexus3-3.37.3</span><br><span class=\"line\"><span class=\"comment\"># 查看 nexus3 容器镜像的 config 信息，返回的内容与直接查看镜像的配置信息一致。</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ skopeo manifest-digest nexus3-3.37.3/manifest.json</span><br><span class=\"line\"><span class=\"comment\"># 查看 nexus3 容器镜像的 manifest.json 文件的 digest 值</span></span><br></pre></td></tr></table></figure>\n<p>关于容器镜像目录中 <code>image manifest</code> 与其 <code>digest</code> 的关系，如下所示：<img src=\"skopeo-docker-image-format-digest-1.jpg\" alt=\"skopeo-docker-image-format-digest-1.jpg\"><img src=\"skopeo-docker-image-format-digest-2.jpg\" alt=\"skopeo-docker-image-format-digest-2.jpg\"></p>\n</li>\n<li>👉 示例 2：OCI 镜像格式的容器镜像目录<br>关于容器镜像目录中 <code>image manifest</code> 与其 <code>digest</code> 的关系，如下所示：<img src=\"skopeo-oci-image-format-digest.jpg\" alt=\"skopeo-oci-image-format-digest.jpg\"></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"🐳-容器镜像格式比较：\"><a href=\"#🐳-容器镜像格式比较：\" class=\"headerlink\" title=\"🐳 容器镜像格式比较：\"></a>🐳 容器镜像格式比较：</h3><ul>\n<li>对于不同的容器镜像格式，其目录的组织结构存在差异，但彼此间又有联系。</li>\n<li>目前采用的容器镜像格式：  <ul>\n<li><code>Docker image format</code>：Docker 镜像格式  </li>\n<li><code>OCI image format</code>：OCI 镜像格式</li>\n</ul>\n</li>\n<li>OCI image format 继承于 Docker image format，因此，可运行 OCI image format 镜像的容器运行时也可运行 Docker image format 的镜像。</li>\n<li><code>OCI</code>（Open Container Initiative，开放容器标准）发展概述：<ul>\n<li>为了推进容器化技术的工业标准化，2015 年 6 月在 <code>DockerCon</code> 上 Linux 基金会与 Google、华为、惠普、IBM、Docker、Red Hat、VMware 等公司共同宣布成立开放容器项目（OCP），后更名为开放容器标准（OCI）。  </li>\n<li>它的主要目标是建立容器格式和运行时的工业开放通用标准。  </li>\n<li>为了支持 OCI 容器运行时标准的推进，Docker 公司起草了镜像格式和运行时规范的草案，并将 Docker 项目的相关实现捐献给了社区，OCI 作为容器运行时的基础实现，现在项目名为 <code>runc</code>。</li>\n</ul>\n</li>\n<li>🤘 发展至今，OCI 制定的主要标准：  <ul>\n<li><code>runtime-spec</code>：定义容器运行时规范  </li>\n<li><code>image-spec</code>：定义容器镜像格式规范  </li>\n<li><code>distribution-spec</code>：定义容器镜像的分发规范</li>\n</ul>\n</li>\n<li><p>OCI image format 目录说明：  </p>\n<ul>\n<li><p>如下所示，以 <code>debian</code> 镜像为例：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ tree debian-bullseye-20211115-oci</span><br><span class=\"line\">debian-bullseye-20211115-oci</span><br><span class=\"line\">├── blobs</span><br><span class=\"line\">│   └── sha256</span><br><span class=\"line\">│       ├── 468a9be7b68d9b0baf252c3496a6db0a406ba558946d3cfee8f0d2a3be1ec42b</span><br><span class=\"line\">│       ├── 5f2f9939c1839f4fee492777a220cfe1e80cd25008df90af6c2b3b2c30e239c6</span><br><span class=\"line\">│       └── 61ccfad6b52ee974d14b8e3c998d862e7dedd59fa8e0023e6620b213ea6da1ad</span><br><span class=\"line\">├── index.json</span><br><span class=\"line\">└── oci-layout</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>oci-layout：OCI image 的镜像布局规范，此处使用 <code>OCI 1.0.0</code> 版本。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ jq <span class=\"string\">'.'</span> debian-bullseye-20211115-oci/oci-layout</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"imageLayoutVersion\"</span>: <span class=\"string\">\"1.0.0\"</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>index.json：    </p>\n<ul>\n<li><code>index.json</code> 文件中的 <code>manifests</code> 字段类似于 Docker image 中的 <code>manifest.json</code> 作为 OCI image 的顶级配置, 也是镜像的一个入口配置。  </li>\n<li><p>该文件实际指向 <code>blobs/sha256/468a9be7b68d9b0baf252c3496a6db0a406ba558946d3cfee8f0d2a3be1ec42b</code> ，即真正的 OCI image manifest 文件。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ jq <span class=\"string\">'.'</span> debian-bullseye-20211115-oci/index.json</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"schemaVersion\"</span>: 2,</span><br><span class=\"line\">  <span class=\"string\">\"manifests\"</span>: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"mediaType\"</span>: <span class=\"string\">\"application/vnd.oci.image.manifest.v1+json\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"digest\"</span>: <span class=\"string\">\"sha256:468a9be7b68d9b0baf252c3496a6db0a406ba558946d3cfee8f0d2a3be1ec42b\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"size\"</span>: 349</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>从该文件的 <code>mediaType</code> 可以看出容器镜像格式已发生的变化：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ jq <span class=\"string\">'.mediaType'</span> debian-bullseye-20211115-docker/manifest.json</span><br><span class=\"line\"><span class=\"string\">\"application/vnd.docker.distribution.manifest.v2+json\"</span></span><br><span class=\"line\"><span class=\"comment\"># Docker image format 封装</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ jq <span class=\"string\">'.manifests[0].mediaType'</span> debian-bullseye-20211115-oci/index.json</span><br><span class=\"line\"><span class=\"string\">\"application/vnd.oci.image.manifest.v1+json\"</span></span><br><span class=\"line\"><span class=\"comment\"># OCI image format 封装</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ jq <span class=\"string\">'.'</span> debian-bullseye-20211115-oci/blobs/sha256/468a9be7b68d9b0baf252c3496a6db0a406ba558946d3cfee8f0d2a3be1ec42b</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"schemaVersion\"</span>: 2,</span><br><span class=\"line\">  <span class=\"string\">\"config\"</span>: &#123;</span><br><span class=\"line\">    <span class=\"string\">\"mediaType\"</span>: <span class=\"string\">\"application/vnd.oci.image.config.v1+json\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"digest\"</span>: <span class=\"string\">\"sha256:61ccfad6b52ee974d14b8e3c998d862e7dedd59fa8e0023e6620b213ea6da1ad\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"size\"</span>: 579</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  <span class=\"string\">\"layers\"</span>: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"mediaType\"</span>: <span class=\"string\">\"application/vnd.oci.image.layer.v1.tar+gzip\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"digest\"</span>: <span class=\"string\">\"sha256:5f2f9939c1839f4fee492777a220cfe1e80cd25008df90af6c2b3b2c30e239c6\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"size\"</span>: 56889206</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>以上文件为 OCI image manifest 文件，其中包含 image config 的信息与各镜像层 Layers 的信息，每层 layer 使用 <code>tar+gzip</code> 的方式进行压缩。</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Docker image format 与 OCI image format 的联系与区别：  <ul>\n<li>最主要的区别：目录结构不完全相同，配置信息尤其是 <code>mediaType</code> 的规范不同。  </li>\n<li>联系：OCI image 的规范是由 Docker image 的规范修改而来，所以类似它们的 blob 的组织形式大致相同，配置文件中很多的参数也相似。  </li>\n<li>另外，可以使用 skopeo 工具很方便地将 Docker image 转换为 OCI image。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://github.com/containers/skopeo\" target=\"_blank\" rel=\"noopener\">GitHub Doc - Skopeo</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/J2b-PQD5GkN5KEmGB2WAeA\" target=\"_blank\" rel=\"noopener\">镜像搬运工具 Skopeo 使用</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/8wAv87DkJjE6fVEEmoQ60Q\" target=\"_blank\" rel=\"noopener\">OCI 与容器镜像构建</a></li>\n<li><a href=\"https://github.com/opencontainers/image-spec\" target=\"_blank\" rel=\"noopener\">GitHub Doc - opencontainers/image-spec</a></li>\n<li><a href=\"https://github.com/opencontainers/image-spec/blob/main/media-types.md\" target=\"_blank\" rel=\"noopener\">GitHub Doc - OCI Image Media Types</a></li>\n<li><a href=\"https://github.com/opencontainers/runtime-spec/blob/main/spec.md\" target=\"_blank\" rel=\"noopener\">GitHub Doc - Open Container Initiative Runtime Specification</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li>OS 版本：Ubuntu 20.04.3 LTS (Focal Fossa)</li>\n<li>skopeo 版本：1.3.0-1</li>\n</ul>\n<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>Skopeo 工具概要</li>\n<li>使用 Skopeo 认证容器镜像仓库</li>\n<li>Skopeo 支持的容器镜像存储方式</li>\n<li>使用 Skopeo 操作容器镜像</li>\n<li>容器镜像格式比较</li>\n<li>参考链接</li>\n</ul>\n<h3 id=\"Skopeo-工具概要：\"><a href=\"#Skopeo-工具概要：\" class=\"headerlink\" title=\"Skopeo 工具概要：\"></a>Skopeo 工具概要：</h3><ul>\n<li>常用的容器镜像操作工具可使用 docker、podman 命令，但 docker 命令行工具需要使用守护进程与 root 用户权限，在一些场景下使用该工具同步容器镜像的效率是较低的，而 podman 命令虽然不使用守护进程，但是其同步镜像效率依然不高。</li>\n<li>skopeo 与 buildah 命令可专门用于容器镜像的操作，其中 skopeo 命令更加纯粹地用于容器镜像的搬运与容器镜像格式的转换，效率较其他工具更高，但是不具有容器镜像构建的能力。</li>\n<li>Podman 更加侧重于容器的生命周期管理，同时具备部分容器镜像管理与构建功能，而 Buildah 支持分别使用命令行从头构建容器镜像与 <code>Dockerfile</code> 或 <code>Containerfile</code> 的构建方式，同时兼容 Docker 与 OCI 镜像格式。<blockquote>\n<p>👉 关于 Podman 更加详细的信息可参考之前写的 <a href=\"https://alberthua-perl.github.io/2022/12/05/podman-arch-usage/\">Podman 容器原理与使用（1）</a>与 <a href=\"https://alberthua-perl.github.io/2022/12/05/podman-usage-practice/\">Podman 容器原理与使用（2）</a>。</p>\n</blockquote>\n</li>\n<li>Skopeo 安装方法可参考 <a href=\"https://github.com/containers/skopeo/blob/main/install.md\" target=\"_blank\" rel=\"noopener\">该 GitHub 链接</a>，此处不再赘述。</li>\n<li>skopeo 命令的帮助信息：  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo --<span class=\"built_in\">help</span></span><br><span class=\"line\">Various operations with container images and container image registries</span><br><span class=\"line\"></span><br><span class=\"line\">Usage:</span><br><span class=\"line\">  skopeo [<span class=\"built_in\">command</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">Available Commands:</span><br><span class=\"line\">  copy                                          Copy an IMAGE-NAME from one location to another</span><br><span class=\"line\">  delete                                        Delete image IMAGE-NAME</span><br><span class=\"line\">  <span class=\"built_in\">help</span>                                          Help about any <span class=\"built_in\">command</span></span><br><span class=\"line\">  inspect                                       Inspect image IMAGE-NAME</span><br><span class=\"line\">  list-tags                                     List tags <span class=\"keyword\">in</span> the transport/repository specified by the REPOSITORY-NAME</span><br><span class=\"line\">  login                                         Login to a container registry</span><br><span class=\"line\">  <span class=\"built_in\">logout</span>                                        Logout of a container registry</span><br><span class=\"line\">  manifest-digest                               Compute a manifest digest of a file</span><br><span class=\"line\">  standalone-sign                               Create a signature using <span class=\"built_in\">local</span> files</span><br><span class=\"line\">  standalone-verify                             Verify a signature using <span class=\"built_in\">local</span> files</span><br><span class=\"line\">  sync                                          Synchronize one or more images from one location to another</span><br><span class=\"line\"></span><br><span class=\"line\">Flags:</span><br><span class=\"line\">      --<span class=\"built_in\">command</span>-timeout duration   timeout <span class=\"keyword\">for</span> the <span class=\"built_in\">command</span> execution</span><br><span class=\"line\">      --debug                      <span class=\"built_in\">enable</span> debug output</span><br><span class=\"line\">  -h, --<span class=\"built_in\">help</span>                       <span class=\"built_in\">help</span> <span class=\"keyword\">for</span> skopeo</span><br><span class=\"line\">      --insecure-policy            run the tool without any policy check</span><br><span class=\"line\">      --override-arch ARCH         use ARCH instead of the architecture of the machine <span class=\"keyword\">for</span> choosing images</span><br><span class=\"line\">      --override-os OS             use OS instead of the running OS <span class=\"keyword\">for</span> choosing images</span><br><span class=\"line\">      --override-variant VARIANT   use VARIANT instead of the running architecture variant <span class=\"keyword\">for</span> choosing images</span><br><span class=\"line\">      --policy string              Path to a trust policy file</span><br><span class=\"line\">      --registries.d DIR           use registry configuration files <span class=\"keyword\">in</span> DIR (e.g. <span class=\"keyword\">for</span> container signature storage)</span><br><span class=\"line\">      --tmpdir string              directory used to store temporary files</span><br><span class=\"line\">  -v, --version                    Version <span class=\"keyword\">for</span> Skopeo</span><br><span class=\"line\"></span><br><span class=\"line\">Use <span class=\"string\">\"skopeo [command] --help\"</span> <span class=\"keyword\">for</span> more information about a <span class=\"built_in\">command</span>.</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"使用-Skopeo-认证容器镜像仓库：\"><a href=\"#使用-Skopeo-认证容器镜像仓库：\" class=\"headerlink\" title=\"使用 Skopeo 认证容器镜像仓库：\"></a>使用 Skopeo 认证容器镜像仓库：</h3><ul>\n<li>Red Hat 支持 <code>skopeo</code> 命令来管理容器镜像仓库中的镜像。</li>\n<li>Skopeo 可分别用于操作公共（public）与私有（private）容器镜像，对于私有容器镜像需要对容器镜像仓库进行认证。</li>\n<li>Skopeo 与 Buildah 可使用 Podman 保存的认证 <code>token</code>（位于 <code>/run/user/&lt;UID&gt;/containers/auth.json</code>），但是无法执行交互式的登录密码输入，因此，若在 skopeo 命令行中指定明文登录密码可在 history 命令历史记录中查看到，存在一定的安全风险，可使用如下以变量形式传递密码的方法优化：<img src=\"skopeo-inspect-creds.jpg\" alt=\"skopeo-inspect-creds.jpg\"><blockquote>\n<p>若未使用 Podman 作为容器运行时，而依然使用 Docker 容器运行时的话，其认证 token 依然可被 Skopeo 使用与认证，该认证 token 位于 <code>$HOME/.docker/config.json</code>。</p>\n</blockquote>\n</li>\n<li>Skopeo 的众多子命令支持容器镜像仓库的认证，可分别通过用户名与密码及认证的 token 文件实现认证，如下所示：  <figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">### 示例 ###</span></span><br><span class=\"line\">$ skopeo copy --src-creds &lt;username&gt;:&lt;password&gt; \\</span><br><span class=\"line\">  docker://registry.redhat.io/rhscl/postgresql-96-rhel7:latest \\</span><br><span class=\"line\">  oci:postgresql-96-rhel7-latest</span><br><span class=\"line\"></span><br><span class=\"line\">$ skopeo copy --src-authfile /run/user/&lt;UID&gt;/containers/auth.json \\</span><br><span class=\"line\">  docker://registry.redhat.io/rhscl/postgresql-96-rhel7:latest \\</span><br><span class=\"line\">  oci:postgresql-96-rhel7-latest</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"Skopeo-支持的容器镜像存储方式：\"><a href=\"#Skopeo-支持的容器镜像存储方式：\" class=\"headerlink\" title=\"Skopeo 支持的容器镜像存储方式：\"></a>Skopeo 支持的容器镜像存储方式：</h3><ul>\n<li>Skopeo 使用 <code>URI</code> 来表示容器镜像的位置，使用 URI 模式（schema）来表示容器镜像格式和registry APIs。</li>\n<li>常见的 URI 模式：  <ul>\n<li><code>oci</code>：    <ul>\n<li>表示存储在本地的 OCI 格式目录中的容器镜像    </li>\n<li>该镜像兼容开放容器镜像层规范（<code>Open Container Image Layout Specification</code>）  </li>\n</ul>\n</li>\n<li><code>oci-archive</code>：    <ul>\n<li>表示 OCI 镜像格式封装的容器镜像的 tar 归档    </li>\n<li>该镜像兼容开放容器镜像层规范  </li>\n</ul>\n</li>\n<li><code>containers-storage</code>：    <ul>\n<li>表示存储于本地容器运行时缓存中的容器镜像    </li>\n<li>后端容器引擎兼容 Podman、CRI-O 与 Buildah  </li>\n</ul>\n</li>\n<li><code>docker-daemon</code>：    <ul>\n<li>表示存储于本地 Docker 容器运行时缓存中的容器镜像  </li>\n</ul>\n</li>\n<li><code>docker-archive</code>：    <ul>\n<li>表示 Docker 镜像格式封装的容器镜像的 tar 归档  </li>\n</ul>\n</li>\n<li><code>dir</code>：    <ul>\n<li>本地存储容器镜像的目录，其中以单个文件的方式包含镜像的 <code>manifest</code>、镜像层 tar 归档与各镜像层签名（<code>digest</code>）。  </li>\n</ul>\n</li>\n<li><code>docker://</code>：    <ul>\n<li>表示存储于容器镜像仓库中的远程容器镜像</li>\n<li>可通过 <code>Docker Registry HTTP API V2</code> 操作仓库中的容器镜像</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>同一容器镜像可以根据不同的场景使用以上不同的方式保存。<blockquote>\n<p>👉 关于 Skopeo 更为详细的信息可参考 <code>man skopeo</code> 手册。</p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"使用-Skopeo-操作容器镜像：\"><a href=\"#使用-Skopeo-操作容器镜像：\" class=\"headerlink\" title=\"使用 Skopeo 操作容器镜像：\"></a>使用 Skopeo 操作容器镜像：</h3><ul>\n<li>Skopeo 不使用容器运行时，并且普通用户可直接使用，比 Podman 使用 tag、pull 与 push 等子命令时更加的高效。</li>\n<li>🐳 若使用 docker 或 podman 命令将容器镜像仓库中的镜像保存于本地存储，需分别使用 docker pull|save 与 podman pull|save 命令将本地镜像缓存中的镜像保存于 tar 归档，无法从容器镜像仓库直接保存于文件或目录中，下文中提及的 <code>skopeo copy</code> 或 <code>sync</code> 子命令可实现该功能，无需存在本地镜像缓存。</li>\n<li><p>🚀 Skopeo 操纵镜像层的方式：  </p>\n<ul>\n<li>出于效率问题，Skopeo 不读取与发送已存在于目标仓库的镜像层，它首先读取源镜像的 manifest，再确定哪些层已存在于目标仓库，然后仅仅拷贝缺失的镜像层。  </li>\n<li>若拷贝来自构建于同一父镜像的镜像，Skopeo 不拷贝多个来自于父镜像的相同镜像层。  </li>\n<li><p>Skopeo 可在容器镜像仓库之间拷贝镜像而不在本地容器存储中保存镜像层缓存，若源仓库与目标仓库需要认证，则需要使用 <code>--src-creds</code> 与 <code>--dest-creds</code> 选项指定认证用户与明文密码，并且 Skopeo 支持在目标仓库实现镜像 <code>tag</code>。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo copy \\</span><br><span class=\"line\">  --src-creds=&lt;username&gt;:&lt;password&gt; \\</span><br><span class=\"line\">  --dest-creds=&lt;username&gt;:&lt;password&gt; \\</span><br><span class=\"line\">  docker://&lt;uri_for_src_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag] \\</span><br><span class=\"line\">  docker://&lt;uri_for_dest_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag]</span><br><span class=\"line\"><span class=\"comment\"># 分别指定源仓库与目标仓库的认证用户与明文密码，并在仓库间拷贝容器镜像。</span></span><br></pre></td></tr></table></figure>\n<p><img src=\"skopeo-copy-dest-creds.jpg\" alt=\"skopeo-copy-dest-creds.jpg\"></p>\n</li>\n</ul>\n</li>\n<li><p><code>skopeo delete</code>：删除容器镜像的镜像 tag  </p>\n<ul>\n<li><p>该命令可删除容器镜像仓库中指定镜像的 tag<br>若删除公共镜像可直接执行无需用户认证，而删除私有容器镜像需使用 <code>--creds</code> 选项或 <code>--authfile</code> 选项进行认证后删除，如下所示：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo delete --creds &lt;username&gt;:&lt;password&gt; \\</span><br><span class=\"line\">  docker://&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag]</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>💥 指定镜像 <code>tag</code> 时将删除特定 tag，即使将最后一个 tag 删除后也不删除整个镜像仓库，若需要删除整个镜像仓库需登录指定仓库。此处为 Quay.io 为例，在 <code>Web 控制台</code> 上删除，如下所示：<img src=\"skopeo-delete-1.jpg\" alt=\"skopeo-delete-1.jpg\"><img src=\"skopeo-delete-2.jpg\" alt=\"skopeo-delete-2.jpg\"> </p>\n</li>\n<li>💥 该命令也可删除本地容器运行时缓存中的镜像 tag，但需注意，若具有多个不同 tag 的容器镜像（实际为同一容器镜像），只具有同一个 image ID（该值来自于镜像的 manifest 中 <code>.config.digest</code>），那么在执行删除时即使指定了镜像的 tag，也会将其他具有相同 image ID 的镜像一并删除，该行为与容器镜像仓库中相区别！</li>\n</ul>\n</li>\n<li><p><code>skopeo copy</code>：dir 模式示例</p>\n<blockquote>\n<p>💥 Skopeo 可将容器镜像仓库中镜像拷贝至本地镜像目录（该目录无需提前创建），该目录中的镜像封装格式保留原始容器镜像仓库中的镜像格式。</p>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo copy \\</span><br><span class=\"line\">  docker://&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag] \\</span><br><span class=\"line\">  dir:&lt;dir_of_container_image&gt;</span><br></pre></td></tr></table></figure>\n<p><img src=\"skopeo-copy-docker-format-image-dir.jpg\" alt=\"skopeo-copy-docker-format-image-dir.jpg\">除了使用 docker load 或 podman load 直接将容器镜像的 tar 归档导入本地镜像缓存中，也可使用已经保存至本地的目录以 dir 或 oci 模式存在的容器镜像，如下所示：<img src=\"podman-load-dir-from-skopeo-copy.jpg\" alt=\"podman-load-dir-from-skopeo-copy.jpg\"></p>\n<p>也可以使用 Skopeo 将本地镜像目录拷贝至容器镜像仓库，用以替代 docker push 或 podman push 的功能：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo copy \\</span><br><span class=\"line\">  dir:&lt;dir_of_container_image&gt; \\</span><br><span class=\"line\">  docker://&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag]</span><br></pre></td></tr></table></figure>\n<p><img src=\"skopeo-copy-dir-2.jpg\" alt=\"skopeo-copy-dir-2.jpg\"></p>\n</li>\n<li><p><code>skopeo copy</code>：oci 模式示例<br>Skopeo 可将容器镜像仓库中镜像拷贝至本地 <code>OCI</code> 格式目录中以存储镜像：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo copy \\</span><br><span class=\"line\">  docker://&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag] \\</span><br><span class=\"line\">  oci:&lt;dir_of_container_image&gt;</span><br></pre></td></tr></table></figure>\n<p><img src=\"skopeo-copy-oci-1.jpg\" alt=\"skopeo-copy-oci-1.jpg\">其中拷贝至本地的 OCI 格式目录结构如下所示，包含了容器镜像的各层（layer）。<br><img src=\"skopeo-copy-oci-2.jpg\" alt=\"skopeo-copy-oci-2.jpg\">也可使用本地 OCI 格式目录将镜像拷贝至容器镜像仓库中。</p>\n</li>\n<li><p><code>skopeo copy</code>：oci-archive 模式示例  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo copy \\</span><br><span class=\"line\">  docker://&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag] \\</span><br><span class=\"line\">  oci-archive:&lt;oci_contaier_image_name&gt;.tar</span><br><span class=\"line\"><span class=\"comment\"># 将容器镜像仓库中镜像封装为 tar 归档的 OCI 镜像格式的镜像</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>skopeo copy</code>：containers-storage 模式示例  </p>\n<blockquote>\n<p>💥 该模式只能在以 Podman 或 CRI-O 为容器运行时的情况下使用，若使用 Docker 容器运行时将报错！</p>\n</blockquote>\n<p><img src=\"skopeo-copy-docker-daemon.jpg\" alt=\"skopeo-copy-docker-daemon.jpg\">  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo copy \\</span><br><span class=\"line\">  docker://&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag] \\</span><br><span class=\"line\">  containers-storage:&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag]</span><br><span class=\"line\"><span class=\"comment\"># 将容器镜像仓库中的镜像存储于本地镜像缓存</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>skopeo copy</code>：docker-archive 模式示例  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo copy \\</span><br><span class=\"line\">  docker://&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag] \\</span><br><span class=\"line\">  docker-archive:&lt;docker_contaier_image_name&gt;.tar</span><br><span class=\"line\"><span class=\"comment\"># 将容器镜像仓库中镜像封装为 tar 归档的 Docker 镜像格式的镜像</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p><code>skopeo copy</code>：docker-daemon 模式示例</p>\n<blockquote>\n<p>💥 该模式在使用 Docker 容器运行时的情况下使用。</p>\n</blockquote>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo copy \\</span><br><span class=\"line\">  docker://&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag] \\</span><br><span class=\"line\">  docker-daemon:&lt;uri_for_registry&gt;/&lt;user_or_org&gt;/&lt;repository&gt;:[tag]</span><br><span class=\"line\"><span class=\"comment\"># 将容器镜像仓库中的镜像存储于本地镜像缓存</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>🚀 Skopeo 对容器镜像格式的转换：  </p>\n<ul>\n<li>使用 skopeo copy 命令将容器镜像仓库中镜像拷贝至本地目录或本地 tar 归档存储时，可分别以 Docker 镜像格式或 OCI 镜像格式保存。  </li>\n<li>因此，skopeo copy 命令可同时完成容器镜像的下载与镜像格式的转换。  </li>\n<li>如下所示：<img src=\"skopeo-copy-transform-image-format.jpg\" alt=\"skopeo-copy-transform-image-format.jpg\"></li>\n</ul>\n</li>\n<li><code>skopeo sync</code>：  <ul>\n<li>sync 子命令将容器镜像从 src 源同步至 dest 目的地，功能与 copy 子命令类似。  </li>\n<li>skopeo sync 命令可指定的 src 与 dest 类型如下所示：<img src=\"skopeo-sync-help.jpg\" alt=\"skopeo-sync-help.jpg\"></li>\n<li>👉 示例 1：<br>将远程容器镜像仓库中的镜像同步至本地目录，本地存储容器镜像的目录无需创建。<img src=\"skopeo-sync-demo.jpg\" alt=\"skopeo-sync-demo.jpg\"></li>\n<li>👉 示例 2：<br>skopeo 命令分别使用两个容器镜像仓库的 token 认证文件将容器镜像同步至另一个仓库中，并且目标仓库只需指定仓库 <code>URI</code> 即可，将自动生成对应的镜像名称与标签。<img src=\"skopeo-sync-between-registry.jpg\" alt=\"skopeo-sync-between-registry.jpg\"></li>\n<li>也可使用 skopeo sync 命令将本地 dir 模式存储的容器镜像同步至远程容器镜像仓库中。</li>\n</ul>\n</li>\n<li><p><code>skopeo inspect</code> 与 <code>skopeo manifest-digest</code>：</p>\n<ul>\n<li>该命令用于查看详细的容器镜像层信息（image manifest）或容器镜像的配置信息（image config）。  </li>\n<li>🐳 image manifest 包含各镜像层的 <code>mediaType</code>、<code>size</code>、<code>digest</code>，而 image config 包含镜像的其他详细信息。  </li>\n<li><p>👉 示例 1：Docker 镜像格式的容器镜像目录<br>如上所述，使用 <code>dir</code> 模式存储的容器镜像位于 nexus3-3.37.3 目录中，可直接使用 <code>jq</code> 命令查看该镜像的 image manifest 与 image config：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">### 示例（以下内容为部分输出） ###</span></span><br><span class=\"line\">$ jq <span class=\"string\">'.'</span> nexus3-3.37.3/manifest.json</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"schemaVersion\"</span>: 2,</span><br><span class=\"line\">  <span class=\"string\">\"mediaType\"</span>: <span class=\"string\">\"application/vnd.docker.distribution.manifest.v2+json\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"config\"</span>: &#123;</span><br><span class=\"line\">    <span class=\"string\">\"mediaType\"</span>: <span class=\"string\">\"application/vnd.docker.container.image.v1+json\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"size\"</span>: 10193,</span><br><span class=\"line\">    <span class=\"string\">\"digest\"</span>: <span class=\"string\">\"sha256:1e1d45f195b19d03ec1833561dca6f5c63f9453413247c323c24f2fbcc34bcdd\"</span></span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  <span class=\"string\">\"layers\"</span>: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"mediaType\"</span>: <span class=\"string\">\"application/vnd.docker.image.rootfs.diff.tar.gzip\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"size\"</span>: 81522888,</span><br><span class=\"line\">      <span class=\"string\">\"digest\"</span>: <span class=\"string\">\"sha256:8dfe9326f733b815c486432e93e0a97f03e90e7cc35def9511cd1efa7f917f56\"</span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    ...</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\"># 根据 dir 目录中的 manifest 查看容器镜像及各镜像层信息</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ jq <span class=\"string\">'.'</span> nexus3-3.37.3/1e1d45f195b19d03ec1833561dca6f5c63f9453413247c323c24f2fbcc34bcdd</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"architecture\"</span>: <span class=\"string\">\"amd64\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"config\"</span>: &#123;</span><br><span class=\"line\">    <span class=\"string\">\"Hostname\"</span>: <span class=\"string\">\"bb4a731bd39e\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"Domainname\"</span>: <span class=\"string\">\"\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"User\"</span>: <span class=\"string\">\"nexus\"</span>,</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    <span class=\"string\">\"ExposedPorts\"</span>: &#123;</span><br><span class=\"line\">      <span class=\"string\">\"8081/tcp\"</span>: &#123;&#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    <span class=\"string\">\"Tty\"</span>: <span class=\"literal\">false</span>,</span><br><span class=\"line\">    <span class=\"string\">\"OpenStdin\"</span>: <span class=\"literal\">false</span>,</span><br><span class=\"line\">    <span class=\"string\">\"StdinOnce\"</span>: <span class=\"literal\">false</span>,</span><br><span class=\"line\">    <span class=\"string\">\"Env\"</span>: [</span><br><span class=\"line\">      <span class=\"string\">\"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"container=oci\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"SONATYPE_DIR=/opt/sonatype\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"NEXUS_HOME=/opt/sonatype/nexus\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"NEXUS_DATA=/nexus-data\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"NEXUS_CONTEXT=\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"SONATYPE_WORK=/opt/sonatype/sonatype-work\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"DOCKER_TYPE=3x-docker\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"INSTALL4J_ADD_VM_PARAMS=-Xms2703m -Xmx2703m -XX:MaxDirectMemorySize=2703m -Djava.util.prefs.userRoot=/nexus-data/javaprefs\"</span></span><br><span class=\"line\">    ],</span><br><span class=\"line\">    <span class=\"string\">\"Cmd\"</span>: [</span><br><span class=\"line\">      <span class=\"string\">\"sh\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"-c\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"<span class=\"variable\">$&#123;SONATYPE_DIR&#125;</span>/start-nexus-repository-manager.sh\"</span></span><br><span class=\"line\">    ],</span><br><span class=\"line\">    <span class=\"string\">\"Image\"</span>: <span class=\"string\">\"sha256:bb968737b5d0d7420e5af7c5524cddc16bd2b43a47f8277e00b1461342d40ba5\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"Volumes\"</span>: &#123;</span><br><span class=\"line\">      <span class=\"string\">\"/nexus-data\"</span>: &#123;&#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  <span class=\"string\">\"created\"</span>: <span class=\"string\">\"2022-03-02T23:52:49.682473465Z\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"docker_version\"</span>: <span class=\"string\">\"20.10.9\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"history\"</span>: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"created\"</span>: <span class=\"string\">\"2022-02-25T17:39:29.754401796Z\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"comment\"</span>: <span class=\"string\">\"Imported from -\"</span></span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"created\"</span>: <span class=\"string\">\"2022-03-02T23:52:49.682473465Z\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"created_by\"</span>: <span class=\"string\">\"/bin/sh -c #(nop)  CMD [\\\"sh\\\" \\\"-c\\\" \\\"<span class=\"variable\">$&#123;SONATYPE_DIR&#125;</span>/start-nexus-repository-manager.sh\\\"]\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"empty_layer\"</span>: <span class=\"literal\">true</span></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ],</span><br><span class=\"line\">  <span class=\"string\">\"os\"</span>: <span class=\"string\">\"linux\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"rootfs\"</span>: &#123;</span><br><span class=\"line\">    <span class=\"string\">\"type\"</span>: <span class=\"string\">\"layers\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"diff_ids\"</span>: [</span><br><span class=\"line\">      <span class=\"string\">\"sha256:7699752e6ed63eef234d2736d4e37159a433e18e06cd617e254299f324f41797\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"sha256:c8013a2772b6673d9b750b6407d4ac4f525a47bb2a5b5bf09ba9bf8e10aea3fc\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"sha256:5a745ebef99f4893aac7c56a26e54f9c6cdc08b02748e0580b1a31d70be0a280\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"sha256:8d12fc82bf58bf5f7958577a148cc05899f0c19e4654376f5e01d3af46eb0c15\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"sha256:d17e45a4f748d13d0501b9e1bca5be387e13efa8ce98147a85c904a348764f3b\"</span></span><br><span class=\"line\">    ]</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\"># 根据容器镜像目录中的 config 文件查看具体的 image config</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ skopeo inspect dir:nexus3-3.37.3</span><br><span class=\"line\"><span class=\"comment\"># 查看 nexus3 容器镜像的概要信息</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ skopeo inspect --raw dir:nexus3-3.37.3</span><br><span class=\"line\"><span class=\"comment\"># 查看 nexus3 容器镜像的 manifest 信息，返回的内容与镜像的 manifest.json 一致。</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ skopeo inspect --config dir:nexus3-3.37.3</span><br><span class=\"line\"><span class=\"comment\"># 查看 nexus3 容器镜像的 config 信息，返回的内容与直接查看镜像的配置信息一致。</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ skopeo manifest-digest nexus3-3.37.3/manifest.json</span><br><span class=\"line\"><span class=\"comment\"># 查看 nexus3 容器镜像的 manifest.json 文件的 digest 值</span></span><br></pre></td></tr></table></figure>\n<p>关于容器镜像目录中 <code>image manifest</code> 与其 <code>digest</code> 的关系，如下所示：<img src=\"skopeo-docker-image-format-digest-1.jpg\" alt=\"skopeo-docker-image-format-digest-1.jpg\"><img src=\"skopeo-docker-image-format-digest-2.jpg\" alt=\"skopeo-docker-image-format-digest-2.jpg\"></p>\n</li>\n<li>👉 示例 2：OCI 镜像格式的容器镜像目录<br>关于容器镜像目录中 <code>image manifest</code> 与其 <code>digest</code> 的关系，如下所示：<img src=\"skopeo-oci-image-format-digest.jpg\" alt=\"skopeo-oci-image-format-digest.jpg\"></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"🐳-容器镜像格式比较：\"><a href=\"#🐳-容器镜像格式比较：\" class=\"headerlink\" title=\"🐳 容器镜像格式比较：\"></a>🐳 容器镜像格式比较：</h3><ul>\n<li>对于不同的容器镜像格式，其目录的组织结构存在差异，但彼此间又有联系。</li>\n<li>目前采用的容器镜像格式：  <ul>\n<li><code>Docker image format</code>：Docker 镜像格式  </li>\n<li><code>OCI image format</code>：OCI 镜像格式</li>\n</ul>\n</li>\n<li>OCI image format 继承于 Docker image format，因此，可运行 OCI image format 镜像的容器运行时也可运行 Docker image format 的镜像。</li>\n<li><code>OCI</code>（Open Container Initiative，开放容器标准）发展概述：<ul>\n<li>为了推进容器化技术的工业标准化，2015 年 6 月在 <code>DockerCon</code> 上 Linux 基金会与 Google、华为、惠普、IBM、Docker、Red Hat、VMware 等公司共同宣布成立开放容器项目（OCP），后更名为开放容器标准（OCI）。  </li>\n<li>它的主要目标是建立容器格式和运行时的工业开放通用标准。  </li>\n<li>为了支持 OCI 容器运行时标准的推进，Docker 公司起草了镜像格式和运行时规范的草案，并将 Docker 项目的相关实现捐献给了社区，OCI 作为容器运行时的基础实现，现在项目名为 <code>runc</code>。</li>\n</ul>\n</li>\n<li>🤘 发展至今，OCI 制定的主要标准：  <ul>\n<li><code>runtime-spec</code>：定义容器运行时规范  </li>\n<li><code>image-spec</code>：定义容器镜像格式规范  </li>\n<li><code>distribution-spec</code>：定义容器镜像的分发规范</li>\n</ul>\n</li>\n<li><p>OCI image format 目录说明：  </p>\n<ul>\n<li><p>如下所示，以 <code>debian</code> 镜像为例：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ tree debian-bullseye-20211115-oci</span><br><span class=\"line\">debian-bullseye-20211115-oci</span><br><span class=\"line\">├── blobs</span><br><span class=\"line\">│   └── sha256</span><br><span class=\"line\">│       ├── 468a9be7b68d9b0baf252c3496a6db0a406ba558946d3cfee8f0d2a3be1ec42b</span><br><span class=\"line\">│       ├── 5f2f9939c1839f4fee492777a220cfe1e80cd25008df90af6c2b3b2c30e239c6</span><br><span class=\"line\">│       └── 61ccfad6b52ee974d14b8e3c998d862e7dedd59fa8e0023e6620b213ea6da1ad</span><br><span class=\"line\">├── index.json</span><br><span class=\"line\">└── oci-layout</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>oci-layout：OCI image 的镜像布局规范，此处使用 <code>OCI 1.0.0</code> 版本。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ jq <span class=\"string\">'.'</span> debian-bullseye-20211115-oci/oci-layout</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"imageLayoutVersion\"</span>: <span class=\"string\">\"1.0.0\"</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>index.json：    </p>\n<ul>\n<li><code>index.json</code> 文件中的 <code>manifests</code> 字段类似于 Docker image 中的 <code>manifest.json</code> 作为 OCI image 的顶级配置, 也是镜像的一个入口配置。  </li>\n<li><p>该文件实际指向 <code>blobs/sha256/468a9be7b68d9b0baf252c3496a6db0a406ba558946d3cfee8f0d2a3be1ec42b</code> ，即真正的 OCI image manifest 文件。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ jq <span class=\"string\">'.'</span> debian-bullseye-20211115-oci/index.json</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"schemaVersion\"</span>: 2,</span><br><span class=\"line\">  <span class=\"string\">\"manifests\"</span>: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"mediaType\"</span>: <span class=\"string\">\"application/vnd.oci.image.manifest.v1+json\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"digest\"</span>: <span class=\"string\">\"sha256:468a9be7b68d9b0baf252c3496a6db0a406ba558946d3cfee8f0d2a3be1ec42b\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"size\"</span>: 349</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>从该文件的 <code>mediaType</code> 可以看出容器镜像格式已发生的变化：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ jq <span class=\"string\">'.mediaType'</span> debian-bullseye-20211115-docker/manifest.json</span><br><span class=\"line\"><span class=\"string\">\"application/vnd.docker.distribution.manifest.v2+json\"</span></span><br><span class=\"line\"><span class=\"comment\"># Docker image format 封装</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ jq <span class=\"string\">'.manifests[0].mediaType'</span> debian-bullseye-20211115-oci/index.json</span><br><span class=\"line\"><span class=\"string\">\"application/vnd.oci.image.manifest.v1+json\"</span></span><br><span class=\"line\"><span class=\"comment\"># OCI image format 封装</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ jq <span class=\"string\">'.'</span> debian-bullseye-20211115-oci/blobs/sha256/468a9be7b68d9b0baf252c3496a6db0a406ba558946d3cfee8f0d2a3be1ec42b</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"schemaVersion\"</span>: 2,</span><br><span class=\"line\">  <span class=\"string\">\"config\"</span>: &#123;</span><br><span class=\"line\">    <span class=\"string\">\"mediaType\"</span>: <span class=\"string\">\"application/vnd.oci.image.config.v1+json\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"digest\"</span>: <span class=\"string\">\"sha256:61ccfad6b52ee974d14b8e3c998d862e7dedd59fa8e0023e6620b213ea6da1ad\"</span>,</span><br><span class=\"line\">    <span class=\"string\">\"size\"</span>: 579</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  <span class=\"string\">\"layers\"</span>: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      <span class=\"string\">\"mediaType\"</span>: <span class=\"string\">\"application/vnd.oci.image.layer.v1.tar+gzip\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"digest\"</span>: <span class=\"string\">\"sha256:5f2f9939c1839f4fee492777a220cfe1e80cd25008df90af6c2b3b2c30e239c6\"</span>,</span><br><span class=\"line\">      <span class=\"string\">\"size\"</span>: 56889206</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>以上文件为 OCI image manifest 文件，其中包含 image config 的信息与各镜像层 Layers 的信息，每层 layer 使用 <code>tar+gzip</code> 的方式进行压缩。</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Docker image format 与 OCI image format 的联系与区别：  <ul>\n<li>最主要的区别：目录结构不完全相同，配置信息尤其是 <code>mediaType</code> 的规范不同。  </li>\n<li>联系：OCI image 的规范是由 Docker image 的规范修改而来，所以类似它们的 blob 的组织形式大致相同，配置文件中很多的参数也相似。  </li>\n<li>另外，可以使用 skopeo 工具很方便地将 Docker image 转换为 OCI image。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"参考链接：\"><a href=\"#参考链接：\" class=\"headerlink\" title=\"参考链接：\"></a>参考链接：</h3><ul>\n<li><a href=\"https://github.com/containers/skopeo\" target=\"_blank\" rel=\"noopener\">GitHub Doc - Skopeo</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/J2b-PQD5GkN5KEmGB2WAeA\" target=\"_blank\" rel=\"noopener\">镜像搬运工具 Skopeo 使用</a></li>\n<li><a href=\"https://mp.weixin.qq.com/s/8wAv87DkJjE6fVEEmoQ60Q\" target=\"_blank\" rel=\"noopener\">OCI 与容器镜像构建</a></li>\n<li><a href=\"https://github.com/opencontainers/image-spec\" target=\"_blank\" rel=\"noopener\">GitHub Doc - opencontainers/image-spec</a></li>\n<li><a href=\"https://github.com/opencontainers/image-spec/blob/main/media-types.md\" target=\"_blank\" rel=\"noopener\">GitHub Doc - OCI Image Media Types</a></li>\n<li><a href=\"https://github.com/opencontainers/runtime-spec/blob/main/spec.md\" target=\"_blank\" rel=\"noopener\">GitHub Doc - Open Container Initiative Runtime Specification</a></li>\n</ul>\n"},{"title":"Podman 容器原理与使用（2）","subtitle":"Podman Architecture and Usage (2)","header-img":"podman-bg.webp","date":"2022-12-05T07:12:51.000Z","_content":"\n### 文档说明：\n- [上一篇](https://alberthua-perl.github.io/2022/12/05/podman-arch-usage/) 已说明 Podman 原理与实现，该文档将继续说明 Podman 容器的使用与实践。\n\n### 文档目录：\n- podman 单容器使用及通信方式示例\n- 使用 podman-compose 实现 Gogs 轻量级代码仓库\n- podman pod 多容器编排使用示例\n- 使用 podman kube play 实现 WordPress 的一键部署\n- Podman 使用报错示例\n- Podman 有待测试功能\n\n### podman 单容器使用及通信方式示例：\n- 示例 1：  \n  👉 使用 podman 命令登录 `Quay` 公共容器镜像仓库并推送镜像：![podman-push-quay.jpg](podman-push-quay.jpg)👉 搜索并拉取 Red Hat 容器镜像仓库中的镜像列表：![podman-pull-image.jpg](podman-pull-image.jpg)\n- 示例 2：  \n  🤘 部署并使用云原生轻量级对象存储 `MinIO Server`：  \n  ![minio-server-cloud-native-object-storage-demo-1.jpg](minio-server-cloud-native-object-storage-demo-1.jpg)![minio-server-cloud-native-object-storage-demo-2.jpg](minio-server-cloud-native-object-storage-demo-2.jpg)以上示例将 podman 与 systemd 集成实现普通用户的 rootless 容器开机自启动。![minio-server-cloud-native-object-storage-demo-3.jpg](minio-server-cloud-native-object-storage-demo-3.jpg)关于 MinIO Server 分布式对象存储的详细内容，请 [参考官网](https://min.io/)。\n- 示例 3：  \n  🤘 请参考该文档 [部署 loganalyzer 管理集中式日志](https://alberthua-perl.github.io/2022/12/05/loganalyzer-rsyslog-mysql/) 以理解多个 rootfull 容器间的通信方式（通过 `cni-podman0` 网桥与 `iptables` 互相通信）。\n\n### 使用 podman-compose 实现 Gogs 轻量级代码仓库：\n- 使用 `podman-compose` 通过 `link` 链接至指定的容器建立通信。\n- 如下所示，部署 Gogs 轻量级代码仓库：`Gogs + PostgreSQL`  \n  - 关于 podman-compose 的安装可参考 [GitHub 项目](https://github.com/containers/podman-compose)\n  \n  > 🤔 可考虑使用 podman-compose 部署轻量级 `Gitea + Drone` CI 持续集成平台\n  \n  - 关于 Gogs 项目的详细内容可参考 [Gogs GitHub 项目](https://github.com/gogs/gogs)  \n  - Gogs 代码版本控制仓库使用 Golang 语言开发，可与后端 MySQL、PostgreSQL、SQLite3、TiDB 等集成。  \n  - 此处使用容器化部署 Gogs，并与 PostgreSQL 集成。  \n  - 部署用主机上必须先安装 podman 与 podman-compose，并拉取相应容器镜像加速部署过程，如下所示：![podman-image-list.jps.JPG](podman-image-list.jps.JPG)\n    \n    > 📌**注意：**\n    > \n    > podman-compose 使用创建 `pod` 将多个容器组建成 pod 的方式进行容器编排，因此必须具有 `pause` 容器镜像提供 pod 的共享网络命名空间与挂载命名空间。\n  \n  - 使用普通用户部署，过程如下所示：  \n    ```bash\n    $ mkdir -p gogs-app/gogs-data/{gogs,gogs-logs,postgresql}\n    # 创建用于存储 gogs 与 postgresql 数据映射的目录\n    $ sudo chown -R 100999:100999 gogs-app/gogs-data/{gogs,gogs-logs}\n    # 更改映射目录的属组，否则容器启动权限报错。\n    $ getenforce\n      Enforcing\n    # 确认系统处于 enforcing SELinux 状态，需设置目录映射时的标签。\n    # 也可禁用 SELinux，若禁用 SELinux，以下两步可不执行并且去除 podman-compose 定义文件中的 \"Z\"。\n    $ sudo semanage port -a -t http_port_t -p tcp 10800\n    $ sudo semanage port -a -t ssh_port_t -p tcp 10022\n    # 添加自定义端口至 SELinux 数据库中，否则由于权限问题无法访问并安装 Gogs。\n    $ vim gogs-app/gogs-postgres-podman-compose.yaml\n    ```\n  - 如下所示 `gogs-postgres-podman-compose.yaml` 文件可参考 [此处](https://github.com/Alberthua-Perl/dockerfile-s2i-demo/blob/master/gogs-postgres-compose/gogs-postgres-podman-compose.yaml)：\n    ```yaml\n    version: \"3\"\n    services:\n      postgresql:\n        image: docker.io/library/postgres:14.1-bullseye\n        container_name: \"gogs-postgresql\"\n        volumes:\n          - \"./gogs-data/postgresql:/var/lib/postgresql:Z\"\n        environment:\n          - \"POSTGRES_USER=gogs\"\n          - \"POSTGRES_PASSWORD=redhat\"\n          - \"POSTGRES_DB=gogs\"\n        ports:\n          - \"5432:5432\"\n    \n      gogs:\n        image: docker.io/gogs/gogs:0.12\n        container_name: \"gogs\"\n        volumes:\n          - \"./gogs-data/gogs:/data:Z\"\n          - \"./gogs-data/gogs-logs:/app/gogs/log:Z\"\n        ports:\n          - \"10022:22\"\n          - \"10800:3000\"\n        links:\n          - postgresql\n    ```\n  - 编辑完成 yaml 文件后，使用如下命令启动应用：  \n    ```bash\n    $ podman-compose -f gogs-app/gogs-postgres-podman-compose.yaml --project gogs-app up\n    # 启动 Gogs 与 PostgreSQL 容器，并指定项目名称。\n    # 若不指定项目名称，项目默认为 yaml 文件所在的目录名称。\n    # 首次启动容器时，所有的启动与运行日志将打印至终端屏幕上，该终端不可关闭，直至关闭所有服务容器后将自动退出。\n    $ podman-compose -f gogs-app/gogs-postgres-podman-compose.yaml --project gogs-app ps\n      using podman version: podman version 3.2.3\n      podman ps -a --filter label=io.podman.compose.project=gogs-app\n      CONTAINER ID  IMAGE                                     COMMAND               CREATED      STATUS          PORTS                                                                   NAMES\n      2bed211ffe60  docker.io/library/postgres:14.1-bullseye  postgres              6 hours ago  Up 3 hours ago  0.0.0.0:10022->22/tcp, 0.0.0.0:10800->3000/tcp, 0.0.0.0:5432->5432/tcp  gogs-postgresql\n      2c7d0de4b0a0  docker.io/gogs/gogs:0.12                  /bin/s6-svscan /a...  6 hours ago  Up 3 hours ago  0.0.0.0:10022->22/tcp, 0.0.0.0:10800->3000/tcp, 0.0.0.0:5432->5432/tcp  gogs\n      0\n    # 查看 podman-compose 管理的容器服务\n    $ podman ps\n      CONTAINER ID  IMAGE                                     COMMAND               CREATED      STATUS          PORTS                                                                   NAMES\n      b6df150a3a49  k8s.gcr.io/pause:3.5                                            6 hours ago  Up 6 hours ago  0.0.0.0:10022->22/tcp, 0.0.0.0:10800->3000/tcp, 0.0.0.0:5432->5432/tcp  c3a10da46f18-infra\n      2bed211ffe60  docker.io/library/postgres:14.1-bullseye  postgres              6 hours ago  Up 3 hours ago  0.0.0.0:10022->22/tcp, 0.0.0.0:10800->3000/tcp, 0.0.0.0:5432->5432/tcp  gogs-postgresql\n      2c7d0de4b0a0  docker.io/gogs/gogs:0.12                  /bin/s6-svscan /a...  6 hours ago  Up 3 hours ago  0.0.0.0:10022->22/tcp, 0.0.0.0:10800->3000/tcp, 0.0.0.0:5432->5432/tcp  gogs\n    # 查看正在运行的容器，包含 infra 容器。\n    ```\n  - 所有容器正常运行后，使用 `http://<容器宿主机 IP 地址>:10800` 访问 Gogs 安装界面，需填入的值参考如下：![gogs-settings.jpg](gogs-settings.jpg)    \n    - Run User 值：默认 `git`。\n    - Domain 值：若要从其他主机连接至 Gogs 仓库，Domian 必须配置为容器宿主机的 IP 地址或主机名。\n    - SSH Port 值：podman-compose 定义文件中对外暴露的 SSH 端口号。\n    - HTTP Port 值：默认 `3000` 端口。  \n  - Web 页面中最后需设置 Gogs 管理员账号以完成安装。  \n  - 安装完成后，使用管理员账号登录或重新注册新账号登录与使用。  \n  - 如下所示，使用 `devops` 用户创建新代码库并完成 commit 提交：![gogs-git-repository.jpg](gogs-git-repository.jpg)  \n  - 如需关闭 Gogs 代码仓库，请使用以下方法停止 gogs 与 postgresql 容器服务即可：    \n    ```bash\n    $ podman-compose -f gogs-app/gogs-postgres-podman-compose.yaml --project gogs-app stop gogs postgresql\n      using podman version: podman version 3.2.3\n      podman stop -t 10 gogs\n      gogs\n      0\n      podman stop -t 10 gogs-postgresql\n      gogs-postgresql\n      0\n    $ podman ps\n      CONTAINER ID  IMAGE                 COMMAND     CREATED       STATUS             PORTS                                                                   NAMES\n      b6df150a3a49  k8s.gcr.io/pause:3.5              30 hours ago  Up 39 minutes ago  0.0.0.0:10022->22/tcp, 0.0.0.0:10800->3000/tcp, 0.0.0.0:5432->5432/tcp  c3a10da46f18-infra  \n    ```\n\n    > 💥**注意：**\n    > \n    > 切不可直接使用 podman-compose 命令的 `down` 子命令，该子命令将所有相关的容器与 pod 全部删除，pod 删除后无法将其中的各容器映射至宿主机对应的目录中，即使原始数据依然保留于目录中。\n\n  - 重新启动 Gogs 代码仓库的方式，如下所示： \n    ```bash\n    $ podman-compose -f gogs-app/gogs-postgres-podman-compose.yaml --project gogs-app start gogs postgresql\n      using podman version: podman version 3.2.3\n      podman start gogs\n      gogs\n      0\n      podman start gogs-postgresql\n      gogs-postgresql\n      0\n    ```\n\n### podman pod 多容器编排使用示例：\n- `podman-compose` 的使用依赖于 `python` 版本以及依赖包，若在不同平台中使用可能存在无法安装对应版本的 python 及依赖包的情况，因此 podman-compose 并不能很好的解决单机上的多容器编排问题。\n- 值得庆幸的是，podman 自带的 `podman pod` 子命令可原生支持多容器编排，该命令可将多容器运行于同一 pod 中使用相同的 `network namespace` 以更方便的调配容器。\n- 如下命令所示：  \n  👉 从头创建 pod 并附加额外的容器：  \n  ```bash\n  $ podman pod create --name <pod_name> [-p <host_port>:<pod_port>]\n  # 使用 pause 容器镜像从头创建 pod\n  # 若之后需在 pod 中创建使用端口映射的容器，需要在创建 pod 之初指定端口映射关系，无法在创建容器时指定，由于 pod\n  # 提供了其中所有容器的共享网络命名空间。\n  # 注意：若需指定多个端口，可同时使用多个 -p 选项。\n  $ podman run -d --name <container_name> --pod <pod_name> <container_image>:<tag>\n  # 创建容器将其附加到 pod 中\n  $ podman pod [ps|list|ls]\n  # 查看已存在的 pod\n  $ podman pod [stop|rm] <pod_name>\n  # 停止或删除 pod，将一并删除 pod 中的所有容器。\n  ```\n\n  > 📌**注意：**\n  > \n  > 1. `k8s.gcr.io/pause:3.5` 镜像拉取需要科学上网。\n  > 2. 若无法拉取，可先拉取 `registry.aliyuncs.com/google_containers/pause:3.5` 镜像，再更改其 `tag` 即可。\n\n  👉 随创建容器时同时创建 pod：  \n  ```bash\n  $ podman run -d \\\n    --name <container_name> --pod new:<pod_name> \\\n    [-p <host_port>:<pod_port>] \\\n    <container_image>:<tag>\n  # 随创建容器时同时创建 pod\n  $ podman run -d \\\n    --name <container_name> --pod <pod_name> \\\n    <container_image>:<tag>\n  # 在 pod 中创建新的容器\n  ```\n- 示例 1：  \n  如下所示，创建名为 `nginx-docs` 的容器并同时创建名为 `docker-docs` 的 pod，也可创建其他容器添加至 pod 中，pod 中的容器共享 `network namespace`：![podman-run-pod-create.jpg](podman-run-pod-create.jpg)\n- 🤘 示例 2：\n  使用 podman 在单个 pod 中集成多容器的方法，可参考 [之前发布的文档](https://alberthua-perl.github.io/2022/12/05/redhat-quay-v3-registry/)，该文档中将 Quay、MySQL 与 Redis 的单容器集成在单个 pod 中，使用 pod 的 `network namespace` 方便 Quay 镜像仓库的管理。\n\n### 🚀 使用 podman kube play 实现 WordPress 的一键部署：\n- 除上述 podman pod 容器编排的方式以外，podman 也已支持类似于使用 `Kubernetes` 结构化 `yaml` 文件的方式，即可使用 `podman kube play` 创建 `Pod`、`Deployment` 与 `PersistentVolumeClaim` 等。\n- 可将由 `podman pod create` 创建的 pod 通过如下命令生成 pod 的资源定义文件：  \n  ```bash\n  $ podman generate kube <pod_name> > <application_name>.yml\n  # 导出已存在 pod 的资源定义文件\n  ```\n- 该示例中生成的 pod 资源定义文件需稍加改动用于应用的部署，可参考 [该链接](https://github.com/Alberthua-Perl/go-kubernetes-learn-path/blob/hotfixes/mywpblog-pod.yml)：  \n  ```yaml\n  apiVersion: v1\n  kind: Pod\n  metadata:\n    labels:\n      app: mywpblog\n    name: mywpblog\n  spec:\n    automountServiceAccountToken: false\n    containers:\n    - args:\n      - mysqld\n      env:\n      - name: MYSQL_USER\n        value: wp_user\n      - name: MYSQL_ROOT_PASSWORD\n        value: redhat\n      - name: MYSQL_PASSWORD\n        value: wp_pass\n      - name: MYSQL_DATABASE\n        value: wp_blog\n      image: docker.io/library/mysql:5.7.40-debian\n      name: wpdatabase\n      ports:\n      - containerPort: 3306\n        hostPort: 3306\n      resources: {}\n      securityContext:\n        capabilities:\n          drop:\n          - CAP_MKNOD\n          - CAP_NET_RAW\n          - CAP_AUDIT_WRITE\n      volumeMounts:\n      - mountPath: /var/lib/mysql\n        name: tmp-wpdbfiles-host-0\n    - args:\n      - apache2-foreground\n      env:\n      - name: WORDPRESS_DB_NAME\n        value: wp_blog\n      - name: WORDPRESS_DB_HOST\n        value: \"0.0.0.0\"\n        # WORDPRESS_DB_HOST definied as '0.0.0.0' because two containers \n        # use same network namespace\n        # WORDPRESS_DB_HOST is different from 'podman pod create' and \n        # 'podman kube play'.\n      - name: WORDPRESS_DB_USER\n        value: wp_user\n      - name: WORDPRESS_DB_PASSWORD\n        value: wp_pass\n      image: docker.io/library/wordpress:6.1.1-php7.4-apache\n      name: wpfrontend\n      ports:\n        - containerPort: 80\n          hostPort: 8080\n      resources: {}\n      securityContext:\n        capabilities:\n          drop:\n          - CAP_MKNOD\n          - CAP_NET_RAW\n          - CAP_AUDIT_WRITE\n      volumeMounts:\n      - mountPath: /var/www/html\n        name: tmp-wpfront-host-0\n    enableServiceLinks: false\n    hostname: mywpblog\n    restartPolicy: Never\n    volumes:\n    - hostPath:\n        path: /tmp/wpdbfiles\n        type: Directory\n      name: tmp-wpdbfiles-host-0\n    - hostPath:\n        path: /tmp/wpfront\n        type: Directory\n      name: tmp-wpfront-host-0\n  status: {}\n  ```\n- 使用该 [脚本](https://github.com/Alberthua-Perl/go-kubernetes-learn-path/blob/hotfixes/wpblog-pod-manage) 实现 WordPress 应用的一键部署与管理，WordPress 容器与 MySQL 容器运行于同一 pod 中，运行成功后打开浏览器即可访问安装 WordPress 应用，如下所示：\n  ```bash\n  $ ./wpblog-pod-manage --kube-deploy\n  ---> Start deploy blog pod...\n  ---> Use podman kube play to create and run pod...\n  Pod:\n  7e8d6586ed246380fdb9ee00e73361b16938d4f2d5b646041f5036d9b7e4e8ae\n  Containers:\n  5132590944a03adcdfc08ba27945c708ae23b19fdce24fbcda9df6c845b5bc4e\n  cc2e7cb2a3a5423a7f0d93d07590b5826657eeb59d0491c5578dde0a1d10de1e\n  ---> Pod and containers as followings...\n  POD ID        NAME        STATUS      CREATED         INFRA ID      # OF CONTAINERS\n  7e8d6586ed24  mywpblog    Running     34 seconds ago  ca2ea53dfcbb  3\n  \n  CONTAINER ID  IMAGE                                            COMMAND               CREATED         STATUS            PORTS                                         NAMES\n  ca2ea53dfcbb  localhost/podman-pause:4.3.0-1666339791                                35 seconds ago  Up 2 seconds ago  0.0.0.0:3306->3306/tcp, 0.0.0.0:8080->80/tcp  7e8d6586ed24-infra    \n  5132590944a0  docker.io/library/mysql:5.7.40-debian            mysqld                19 seconds ago  Up 2 seconds ago  0.0.0.0:3306->3306/tcp, 0.0.0.0:8080->80/tcp  mywpblog-wpdatabase   \n  cc2e7cb2a3a5  docker.io/library/wordpress:6.1.1-php7.4-apache  apache2-foregroun...  4 seconds ago   Up 2 seconds ago  0.0.0.0:3306->3306/tcp, 0.0.0.0:8080->80/tcp  mywpblog-wpfrontend   \n  # 使用 podman kube play 的方式部署 WordPress 应用\n  ```\n\n### Podman 报错示例：\n- podman 容器镜像仓库的配置方式：  \n  - 全局配置：`/etc/containers/registries.conf`\n  - 局部配置：`$HOME/.config/containers/registroes.conf`\n- 若 podman 安装后在以上配置中未唯一指定的容器镜像仓库，那么在拉取容器镜像时，将交互式提示用户选择容器镜像仓库。\n- Podman 登录容器镜像仓库的方式：  \n  - 使用 `podman login` 子命令登录指定的容器镜像仓库时，Podman 将访问 token 默认存储于 `/run/user/<UID>/containers/auth.json` 文件中，当 logout 仓库时，该 token 将被移除，并且该文件中可存储多个登录的仓库 token。![podman-login-token.jpg](podman-login-token.jpg)    \n    ```bash\n    $ podman logout --all\n    # 登出所有的容器镜像仓库，并从 auth.json 文件中移除所有的 token。\n    ```\n  - Podman 默认情况下需要与容器镜像仓库使用 `TLS` 认证，若容器镜像仓库未配置 TLS、使用自签名的 TLS 证书或未知的 CA 签署的证书，需对 login、pull 或 push 子命令添加 `--tls-verify=false` 选项以完成认证。  \n  - Skopeo 与 Buildah 也可使用 Podman 保存的认证 token，但是无法执行交互式的登录密码输入。\n- 示例 1：  \n  👉 podman v3.2.3 登录 Harbor v1.8.1 身份认证报错：  \n  ```bash\n  $ podman login harbor.domain12.example.com:8880\n    Username: admin\n    Password: redhat\n    Error: authenticating creds for \"harbor.domain12.example.com:8880\": error pinging docker registry \n    harbor.domain12.example.com:8880: Get \"https://harbor.domain12.example.com:8880/v2/\": \n    http: server gave HTTP response to HTTPS client\n  # Podman 未做任何配置登录 Harbor 报错，该 Harbor 容器镜像仓库未配置 TLS 加密传输。\n  # 报错显示 Harbor 响应 HTTP 请求，而 Podman 发送 HTTPS 请求登录。\n  # 因此，将 Podman 配置为发送 HTTP 请求的客户端。\n  ```\n  🤔 解决方式一：  \n  ```bash\n  $ podman login --tls-verify=false harbor.domain12.example.com:8880\n    Username: admin\n    Password: redhat\n    Login Succeeded!\n  # Podman 未进行任何配置，直接使用 --tls-verify=false 选项即可认证登录。\n  ```\n  🤔 解决方式二：  \n  ```bash\n  $ mkdir -p ~/.config/containers/ && cd ~/.config/containers/\n  # 创建普通用户 rootless 容器的目录\n  $ vim ~/.config/containers/registries.conf\n    unqualified-search-registries = ['harbor.domain12.example.com:8880']\n  \n    [[registry]]\n    location = \"harbor.domain12.example.com:8880\"\n    insecure = true\n    # If true, unencrypted HTTP as well as TLS connections with untrusted\n    # certificates are allowed.\n    block = false\n  # 配置未加密传输的 Harbor 容器镜像仓库的主机名与端口\n  \n  $ podman login --log-level=debug harbor.domain12.example.com:8880\n    INFO[0000] podman filtering at log level debug\n    DEBU[0000] Called login.PersistentPreRunE(podman login --log-level=debug harbor.domain12.example.com:8880)\n    DEBU[0000] overlay storage already configured with a mount-program\n    DEBU[0000] Merged system config \"/usr/share/containers/containers.conf\"\n    DEBU[0000] overlay storage already configured with a mount-program\n    DEBU[0000] Using conmon: \"/usr/bin/conmon\"\n    ...\n    DEBU[0000] Using OCI runtime \"/usr/bin/runc\"\n    DEBU[0000] Default CNI network name podman is unchangeable\n    INFO[0000] Setting parallel job count to 13\n    DEBU[0000] Loading registries configuration \"/home/kiosk/.config/containers/registries.conf\"\n    DEBU[0000] Loading registries configuration \"/etc/containers/registries.conf.d/000-shortnames.conf\"\n    DEBU[0000] Loading registries configuration \"/etc/containers/registries.conf.d/001-rhel-shortnames.conf\"\n    DEBU[0000] Loading registries configuration \"/etc/containers/registries.conf.d/002-rhel-shortnames-overrides.conf\"\n    DEBU[0000] No credentials for harbor.domain12.example.com:8880 found\n    Username: admin\n    Password: # 交互式输入登录密码\n    DEBU[0004] Looking for TLS certificates and private keys in /etc/docker/certs.d/harbor.domain12.example.com:8880\n    DEBU[0004] GET https://harbor.domain12.example.com:8880/v2/\n    DEBU[0004] Ping https://harbor.domain12.example.com:8880/v2/ err Get \"https://harbor.domain12.example.com:8880/v2/\": http: \n    server gave HTTP response to HTTPS client (&url.Error{Op:\"Get\", URL:\"https://harbor.domain12.example.com:8880/v2/\", \n    Err:(*errors.errorString)(0xc000590030)})\n    ...\n    DEBU[0004] GET http://harbor.domain12.example.com:8880/service/token?account=admin&service=harbor-registry\n    DEBU[0004] GET http://harbor.domain12.example.com:8880/v2/\n    DEBU[0004] Stored credentials for harbor.domain12.example.com:8880 in credential helper containers-auth.json\n    Login Succeeded!\n    DEBU[0004] Called login.PersistentPostRunE(podman login --log-level=debug harbor.domain12.example.com:8880)\n  # Podman 默认使用 TLS 加密传输\n  # 以上配置文件将使 Podman 以 HTTP 方式认证登录 Harbor。\n  ```\n- 示例 2： \n  👉 podman v3.2.3 推送容器镜像至 Harbor v1.8.1 中显示 \"不完整\"：  \n  ```bash\n  $ podman push harbor.domain12.example.com:8880/library/apache-rhce8.2-alpine:1.0\n    Getting image source signatures\n    Copying blob 551db21ded82 skipped: already exists\n    Copying blob 8213d0880f11 skipped: already exists\n    Copying blob e2eb06d8af82 skipped: already exists\n    ...\n    Copying blob 05e56f8d5aae skipped: already exists\n    Copying blob 631e8a8040bb skipped: already exists\n    Copying blob dedba5c062fc skipped: already exists\n    Copying blob 0e609f35aa06 [--------------------------------------] 0.0b / 0.0b\n    Copying config 34f32c2e7a [======================================] 10.0KiB / 10.0KiB\n    Writing manifest to image destination\n    Storing signatures\n  ```\n  从推送的返回结果显示，具有 2 层容器镜像层似乎未推送成功，但将该镜像从 Harbor 中拉取并重新运行容器后，容器能正常提供服务，因此最后 2 层镜像层实际推送成功。\n- 示例 3：  \n  👉 容器镜像无任何运行或退出状态容器占用，但依然无法删除镜像，可尝试使用 `--force` 选项将其强制删除。![podman-rmi-error-no-container-use.jpg](podman-rmi-error-no-container-use.jpg)\n- 示例 4：\n  👉 由于从 `dockerbub` 上直接拉取的镜像为 `docker image format`，无法使用 `podman commit` 命令提交为新的容器镜像，该命令对于 `-m` 选项不能对 docker image format 镜像生效，默认只支持 `OCI image format`，因此使用 -m 选项对容器执行提交时需强制指定 `-f docker` 才能生效。\n  \n  > 📌**注意：**\n  > \n  > 可使用 `skopeo` 工具转换 docker image format 与 OCI image format。\n  \n  ![podman-commit-warning.jpg](podman-commit-warning.jpg)\n\n- 示例 5：\n  👉 podman 运行 rootfull 或 rootless busybox 容器后，`ping` 外网报错权限问题无法 ping 通外网，但使用其他工具可与外网通信，通过 [该文档](https://www.redhat.com/sysadmin/container-networking-podman) 中可知，ping 命令对 `capability` 敏感，容器可能缺少 `CAP_NET_RAW `capability 无法通过宿主机 ping 通外网。  \n  👉 当然，运行容器时指定 `--privileged` 选项可使容器获得与宿主机 root 用户同样的与宿主机交互的权限能力，但赋予的权限过高，应当压制该权限，更好的选择是对运行容器添加适当的 `Linux capabilities`。![podman-busybox-capability.jpg](podman-busybox-capability.jpg)\n\n### Podman 有待测试功能：\nPodman 日志驱动目前只支持 `k8s-file`、`journald` 与 `none`，暂时不支持容器日志的 `JSON` 格式输出，因此不能与日志收集引擎 `fluentd` 集成，由其实现将日志传输至 ELK 或 EFK 进行集中式的存储与索引。","source":"_posts/podman-usage-practice.md","raw":"---\ntitle: Podman 容器原理与使用（2）\nsubtitle: Podman Architecture and Usage (2)\nheader-img: podman-bg.webp\ndate: 2022-12-05 15:12:51\ntags:\n  - 容器\n  - 云原生\n---\n\n### 文档说明：\n- [上一篇](https://alberthua-perl.github.io/2022/12/05/podman-arch-usage/) 已说明 Podman 原理与实现，该文档将继续说明 Podman 容器的使用与实践。\n\n### 文档目录：\n- podman 单容器使用及通信方式示例\n- 使用 podman-compose 实现 Gogs 轻量级代码仓库\n- podman pod 多容器编排使用示例\n- 使用 podman kube play 实现 WordPress 的一键部署\n- Podman 使用报错示例\n- Podman 有待测试功能\n\n### podman 单容器使用及通信方式示例：\n- 示例 1：  \n  👉 使用 podman 命令登录 `Quay` 公共容器镜像仓库并推送镜像：![podman-push-quay.jpg](podman-push-quay.jpg)👉 搜索并拉取 Red Hat 容器镜像仓库中的镜像列表：![podman-pull-image.jpg](podman-pull-image.jpg)\n- 示例 2：  \n  🤘 部署并使用云原生轻量级对象存储 `MinIO Server`：  \n  ![minio-server-cloud-native-object-storage-demo-1.jpg](minio-server-cloud-native-object-storage-demo-1.jpg)![minio-server-cloud-native-object-storage-demo-2.jpg](minio-server-cloud-native-object-storage-demo-2.jpg)以上示例将 podman 与 systemd 集成实现普通用户的 rootless 容器开机自启动。![minio-server-cloud-native-object-storage-demo-3.jpg](minio-server-cloud-native-object-storage-demo-3.jpg)关于 MinIO Server 分布式对象存储的详细内容，请 [参考官网](https://min.io/)。\n- 示例 3：  \n  🤘 请参考该文档 [部署 loganalyzer 管理集中式日志](https://alberthua-perl.github.io/2022/12/05/loganalyzer-rsyslog-mysql/) 以理解多个 rootfull 容器间的通信方式（通过 `cni-podman0` 网桥与 `iptables` 互相通信）。\n\n### 使用 podman-compose 实现 Gogs 轻量级代码仓库：\n- 使用 `podman-compose` 通过 `link` 链接至指定的容器建立通信。\n- 如下所示，部署 Gogs 轻量级代码仓库：`Gogs + PostgreSQL`  \n  - 关于 podman-compose 的安装可参考 [GitHub 项目](https://github.com/containers/podman-compose)\n  \n  > 🤔 可考虑使用 podman-compose 部署轻量级 `Gitea + Drone` CI 持续集成平台\n  \n  - 关于 Gogs 项目的详细内容可参考 [Gogs GitHub 项目](https://github.com/gogs/gogs)  \n  - Gogs 代码版本控制仓库使用 Golang 语言开发，可与后端 MySQL、PostgreSQL、SQLite3、TiDB 等集成。  \n  - 此处使用容器化部署 Gogs，并与 PostgreSQL 集成。  \n  - 部署用主机上必须先安装 podman 与 podman-compose，并拉取相应容器镜像加速部署过程，如下所示：![podman-image-list.jps.JPG](podman-image-list.jps.JPG)\n    \n    > 📌**注意：**\n    > \n    > podman-compose 使用创建 `pod` 将多个容器组建成 pod 的方式进行容器编排，因此必须具有 `pause` 容器镜像提供 pod 的共享网络命名空间与挂载命名空间。\n  \n  - 使用普通用户部署，过程如下所示：  \n    ```bash\n    $ mkdir -p gogs-app/gogs-data/{gogs,gogs-logs,postgresql}\n    # 创建用于存储 gogs 与 postgresql 数据映射的目录\n    $ sudo chown -R 100999:100999 gogs-app/gogs-data/{gogs,gogs-logs}\n    # 更改映射目录的属组，否则容器启动权限报错。\n    $ getenforce\n      Enforcing\n    # 确认系统处于 enforcing SELinux 状态，需设置目录映射时的标签。\n    # 也可禁用 SELinux，若禁用 SELinux，以下两步可不执行并且去除 podman-compose 定义文件中的 \"Z\"。\n    $ sudo semanage port -a -t http_port_t -p tcp 10800\n    $ sudo semanage port -a -t ssh_port_t -p tcp 10022\n    # 添加自定义端口至 SELinux 数据库中，否则由于权限问题无法访问并安装 Gogs。\n    $ vim gogs-app/gogs-postgres-podman-compose.yaml\n    ```\n  - 如下所示 `gogs-postgres-podman-compose.yaml` 文件可参考 [此处](https://github.com/Alberthua-Perl/dockerfile-s2i-demo/blob/master/gogs-postgres-compose/gogs-postgres-podman-compose.yaml)：\n    ```yaml\n    version: \"3\"\n    services:\n      postgresql:\n        image: docker.io/library/postgres:14.1-bullseye\n        container_name: \"gogs-postgresql\"\n        volumes:\n          - \"./gogs-data/postgresql:/var/lib/postgresql:Z\"\n        environment:\n          - \"POSTGRES_USER=gogs\"\n          - \"POSTGRES_PASSWORD=redhat\"\n          - \"POSTGRES_DB=gogs\"\n        ports:\n          - \"5432:5432\"\n    \n      gogs:\n        image: docker.io/gogs/gogs:0.12\n        container_name: \"gogs\"\n        volumes:\n          - \"./gogs-data/gogs:/data:Z\"\n          - \"./gogs-data/gogs-logs:/app/gogs/log:Z\"\n        ports:\n          - \"10022:22\"\n          - \"10800:3000\"\n        links:\n          - postgresql\n    ```\n  - 编辑完成 yaml 文件后，使用如下命令启动应用：  \n    ```bash\n    $ podman-compose -f gogs-app/gogs-postgres-podman-compose.yaml --project gogs-app up\n    # 启动 Gogs 与 PostgreSQL 容器，并指定项目名称。\n    # 若不指定项目名称，项目默认为 yaml 文件所在的目录名称。\n    # 首次启动容器时，所有的启动与运行日志将打印至终端屏幕上，该终端不可关闭，直至关闭所有服务容器后将自动退出。\n    $ podman-compose -f gogs-app/gogs-postgres-podman-compose.yaml --project gogs-app ps\n      using podman version: podman version 3.2.3\n      podman ps -a --filter label=io.podman.compose.project=gogs-app\n      CONTAINER ID  IMAGE                                     COMMAND               CREATED      STATUS          PORTS                                                                   NAMES\n      2bed211ffe60  docker.io/library/postgres:14.1-bullseye  postgres              6 hours ago  Up 3 hours ago  0.0.0.0:10022->22/tcp, 0.0.0.0:10800->3000/tcp, 0.0.0.0:5432->5432/tcp  gogs-postgresql\n      2c7d0de4b0a0  docker.io/gogs/gogs:0.12                  /bin/s6-svscan /a...  6 hours ago  Up 3 hours ago  0.0.0.0:10022->22/tcp, 0.0.0.0:10800->3000/tcp, 0.0.0.0:5432->5432/tcp  gogs\n      0\n    # 查看 podman-compose 管理的容器服务\n    $ podman ps\n      CONTAINER ID  IMAGE                                     COMMAND               CREATED      STATUS          PORTS                                                                   NAMES\n      b6df150a3a49  k8s.gcr.io/pause:3.5                                            6 hours ago  Up 6 hours ago  0.0.0.0:10022->22/tcp, 0.0.0.0:10800->3000/tcp, 0.0.0.0:5432->5432/tcp  c3a10da46f18-infra\n      2bed211ffe60  docker.io/library/postgres:14.1-bullseye  postgres              6 hours ago  Up 3 hours ago  0.0.0.0:10022->22/tcp, 0.0.0.0:10800->3000/tcp, 0.0.0.0:5432->5432/tcp  gogs-postgresql\n      2c7d0de4b0a0  docker.io/gogs/gogs:0.12                  /bin/s6-svscan /a...  6 hours ago  Up 3 hours ago  0.0.0.0:10022->22/tcp, 0.0.0.0:10800->3000/tcp, 0.0.0.0:5432->5432/tcp  gogs\n    # 查看正在运行的容器，包含 infra 容器。\n    ```\n  - 所有容器正常运行后，使用 `http://<容器宿主机 IP 地址>:10800` 访问 Gogs 安装界面，需填入的值参考如下：![gogs-settings.jpg](gogs-settings.jpg)    \n    - Run User 值：默认 `git`。\n    - Domain 值：若要从其他主机连接至 Gogs 仓库，Domian 必须配置为容器宿主机的 IP 地址或主机名。\n    - SSH Port 值：podman-compose 定义文件中对外暴露的 SSH 端口号。\n    - HTTP Port 值：默认 `3000` 端口。  \n  - Web 页面中最后需设置 Gogs 管理员账号以完成安装。  \n  - 安装完成后，使用管理员账号登录或重新注册新账号登录与使用。  \n  - 如下所示，使用 `devops` 用户创建新代码库并完成 commit 提交：![gogs-git-repository.jpg](gogs-git-repository.jpg)  \n  - 如需关闭 Gogs 代码仓库，请使用以下方法停止 gogs 与 postgresql 容器服务即可：    \n    ```bash\n    $ podman-compose -f gogs-app/gogs-postgres-podman-compose.yaml --project gogs-app stop gogs postgresql\n      using podman version: podman version 3.2.3\n      podman stop -t 10 gogs\n      gogs\n      0\n      podman stop -t 10 gogs-postgresql\n      gogs-postgresql\n      0\n    $ podman ps\n      CONTAINER ID  IMAGE                 COMMAND     CREATED       STATUS             PORTS                                                                   NAMES\n      b6df150a3a49  k8s.gcr.io/pause:3.5              30 hours ago  Up 39 minutes ago  0.0.0.0:10022->22/tcp, 0.0.0.0:10800->3000/tcp, 0.0.0.0:5432->5432/tcp  c3a10da46f18-infra  \n    ```\n\n    > 💥**注意：**\n    > \n    > 切不可直接使用 podman-compose 命令的 `down` 子命令，该子命令将所有相关的容器与 pod 全部删除，pod 删除后无法将其中的各容器映射至宿主机对应的目录中，即使原始数据依然保留于目录中。\n\n  - 重新启动 Gogs 代码仓库的方式，如下所示： \n    ```bash\n    $ podman-compose -f gogs-app/gogs-postgres-podman-compose.yaml --project gogs-app start gogs postgresql\n      using podman version: podman version 3.2.3\n      podman start gogs\n      gogs\n      0\n      podman start gogs-postgresql\n      gogs-postgresql\n      0\n    ```\n\n### podman pod 多容器编排使用示例：\n- `podman-compose` 的使用依赖于 `python` 版本以及依赖包，若在不同平台中使用可能存在无法安装对应版本的 python 及依赖包的情况，因此 podman-compose 并不能很好的解决单机上的多容器编排问题。\n- 值得庆幸的是，podman 自带的 `podman pod` 子命令可原生支持多容器编排，该命令可将多容器运行于同一 pod 中使用相同的 `network namespace` 以更方便的调配容器。\n- 如下命令所示：  \n  👉 从头创建 pod 并附加额外的容器：  \n  ```bash\n  $ podman pod create --name <pod_name> [-p <host_port>:<pod_port>]\n  # 使用 pause 容器镜像从头创建 pod\n  # 若之后需在 pod 中创建使用端口映射的容器，需要在创建 pod 之初指定端口映射关系，无法在创建容器时指定，由于 pod\n  # 提供了其中所有容器的共享网络命名空间。\n  # 注意：若需指定多个端口，可同时使用多个 -p 选项。\n  $ podman run -d --name <container_name> --pod <pod_name> <container_image>:<tag>\n  # 创建容器将其附加到 pod 中\n  $ podman pod [ps|list|ls]\n  # 查看已存在的 pod\n  $ podman pod [stop|rm] <pod_name>\n  # 停止或删除 pod，将一并删除 pod 中的所有容器。\n  ```\n\n  > 📌**注意：**\n  > \n  > 1. `k8s.gcr.io/pause:3.5` 镜像拉取需要科学上网。\n  > 2. 若无法拉取，可先拉取 `registry.aliyuncs.com/google_containers/pause:3.5` 镜像，再更改其 `tag` 即可。\n\n  👉 随创建容器时同时创建 pod：  \n  ```bash\n  $ podman run -d \\\n    --name <container_name> --pod new:<pod_name> \\\n    [-p <host_port>:<pod_port>] \\\n    <container_image>:<tag>\n  # 随创建容器时同时创建 pod\n  $ podman run -d \\\n    --name <container_name> --pod <pod_name> \\\n    <container_image>:<tag>\n  # 在 pod 中创建新的容器\n  ```\n- 示例 1：  \n  如下所示，创建名为 `nginx-docs` 的容器并同时创建名为 `docker-docs` 的 pod，也可创建其他容器添加至 pod 中，pod 中的容器共享 `network namespace`：![podman-run-pod-create.jpg](podman-run-pod-create.jpg)\n- 🤘 示例 2：\n  使用 podman 在单个 pod 中集成多容器的方法，可参考 [之前发布的文档](https://alberthua-perl.github.io/2022/12/05/redhat-quay-v3-registry/)，该文档中将 Quay、MySQL 与 Redis 的单容器集成在单个 pod 中，使用 pod 的 `network namespace` 方便 Quay 镜像仓库的管理。\n\n### 🚀 使用 podman kube play 实现 WordPress 的一键部署：\n- 除上述 podman pod 容器编排的方式以外，podman 也已支持类似于使用 `Kubernetes` 结构化 `yaml` 文件的方式，即可使用 `podman kube play` 创建 `Pod`、`Deployment` 与 `PersistentVolumeClaim` 等。\n- 可将由 `podman pod create` 创建的 pod 通过如下命令生成 pod 的资源定义文件：  \n  ```bash\n  $ podman generate kube <pod_name> > <application_name>.yml\n  # 导出已存在 pod 的资源定义文件\n  ```\n- 该示例中生成的 pod 资源定义文件需稍加改动用于应用的部署，可参考 [该链接](https://github.com/Alberthua-Perl/go-kubernetes-learn-path/blob/hotfixes/mywpblog-pod.yml)：  \n  ```yaml\n  apiVersion: v1\n  kind: Pod\n  metadata:\n    labels:\n      app: mywpblog\n    name: mywpblog\n  spec:\n    automountServiceAccountToken: false\n    containers:\n    - args:\n      - mysqld\n      env:\n      - name: MYSQL_USER\n        value: wp_user\n      - name: MYSQL_ROOT_PASSWORD\n        value: redhat\n      - name: MYSQL_PASSWORD\n        value: wp_pass\n      - name: MYSQL_DATABASE\n        value: wp_blog\n      image: docker.io/library/mysql:5.7.40-debian\n      name: wpdatabase\n      ports:\n      - containerPort: 3306\n        hostPort: 3306\n      resources: {}\n      securityContext:\n        capabilities:\n          drop:\n          - CAP_MKNOD\n          - CAP_NET_RAW\n          - CAP_AUDIT_WRITE\n      volumeMounts:\n      - mountPath: /var/lib/mysql\n        name: tmp-wpdbfiles-host-0\n    - args:\n      - apache2-foreground\n      env:\n      - name: WORDPRESS_DB_NAME\n        value: wp_blog\n      - name: WORDPRESS_DB_HOST\n        value: \"0.0.0.0\"\n        # WORDPRESS_DB_HOST definied as '0.0.0.0' because two containers \n        # use same network namespace\n        # WORDPRESS_DB_HOST is different from 'podman pod create' and \n        # 'podman kube play'.\n      - name: WORDPRESS_DB_USER\n        value: wp_user\n      - name: WORDPRESS_DB_PASSWORD\n        value: wp_pass\n      image: docker.io/library/wordpress:6.1.1-php7.4-apache\n      name: wpfrontend\n      ports:\n        - containerPort: 80\n          hostPort: 8080\n      resources: {}\n      securityContext:\n        capabilities:\n          drop:\n          - CAP_MKNOD\n          - CAP_NET_RAW\n          - CAP_AUDIT_WRITE\n      volumeMounts:\n      - mountPath: /var/www/html\n        name: tmp-wpfront-host-0\n    enableServiceLinks: false\n    hostname: mywpblog\n    restartPolicy: Never\n    volumes:\n    - hostPath:\n        path: /tmp/wpdbfiles\n        type: Directory\n      name: tmp-wpdbfiles-host-0\n    - hostPath:\n        path: /tmp/wpfront\n        type: Directory\n      name: tmp-wpfront-host-0\n  status: {}\n  ```\n- 使用该 [脚本](https://github.com/Alberthua-Perl/go-kubernetes-learn-path/blob/hotfixes/wpblog-pod-manage) 实现 WordPress 应用的一键部署与管理，WordPress 容器与 MySQL 容器运行于同一 pod 中，运行成功后打开浏览器即可访问安装 WordPress 应用，如下所示：\n  ```bash\n  $ ./wpblog-pod-manage --kube-deploy\n  ---> Start deploy blog pod...\n  ---> Use podman kube play to create and run pod...\n  Pod:\n  7e8d6586ed246380fdb9ee00e73361b16938d4f2d5b646041f5036d9b7e4e8ae\n  Containers:\n  5132590944a03adcdfc08ba27945c708ae23b19fdce24fbcda9df6c845b5bc4e\n  cc2e7cb2a3a5423a7f0d93d07590b5826657eeb59d0491c5578dde0a1d10de1e\n  ---> Pod and containers as followings...\n  POD ID        NAME        STATUS      CREATED         INFRA ID      # OF CONTAINERS\n  7e8d6586ed24  mywpblog    Running     34 seconds ago  ca2ea53dfcbb  3\n  \n  CONTAINER ID  IMAGE                                            COMMAND               CREATED         STATUS            PORTS                                         NAMES\n  ca2ea53dfcbb  localhost/podman-pause:4.3.0-1666339791                                35 seconds ago  Up 2 seconds ago  0.0.0.0:3306->3306/tcp, 0.0.0.0:8080->80/tcp  7e8d6586ed24-infra    \n  5132590944a0  docker.io/library/mysql:5.7.40-debian            mysqld                19 seconds ago  Up 2 seconds ago  0.0.0.0:3306->3306/tcp, 0.0.0.0:8080->80/tcp  mywpblog-wpdatabase   \n  cc2e7cb2a3a5  docker.io/library/wordpress:6.1.1-php7.4-apache  apache2-foregroun...  4 seconds ago   Up 2 seconds ago  0.0.0.0:3306->3306/tcp, 0.0.0.0:8080->80/tcp  mywpblog-wpfrontend   \n  # 使用 podman kube play 的方式部署 WordPress 应用\n  ```\n\n### Podman 报错示例：\n- podman 容器镜像仓库的配置方式：  \n  - 全局配置：`/etc/containers/registries.conf`\n  - 局部配置：`$HOME/.config/containers/registroes.conf`\n- 若 podman 安装后在以上配置中未唯一指定的容器镜像仓库，那么在拉取容器镜像时，将交互式提示用户选择容器镜像仓库。\n- Podman 登录容器镜像仓库的方式：  \n  - 使用 `podman login` 子命令登录指定的容器镜像仓库时，Podman 将访问 token 默认存储于 `/run/user/<UID>/containers/auth.json` 文件中，当 logout 仓库时，该 token 将被移除，并且该文件中可存储多个登录的仓库 token。![podman-login-token.jpg](podman-login-token.jpg)    \n    ```bash\n    $ podman logout --all\n    # 登出所有的容器镜像仓库，并从 auth.json 文件中移除所有的 token。\n    ```\n  - Podman 默认情况下需要与容器镜像仓库使用 `TLS` 认证，若容器镜像仓库未配置 TLS、使用自签名的 TLS 证书或未知的 CA 签署的证书，需对 login、pull 或 push 子命令添加 `--tls-verify=false` 选项以完成认证。  \n  - Skopeo 与 Buildah 也可使用 Podman 保存的认证 token，但是无法执行交互式的登录密码输入。\n- 示例 1：  \n  👉 podman v3.2.3 登录 Harbor v1.8.1 身份认证报错：  \n  ```bash\n  $ podman login harbor.domain12.example.com:8880\n    Username: admin\n    Password: redhat\n    Error: authenticating creds for \"harbor.domain12.example.com:8880\": error pinging docker registry \n    harbor.domain12.example.com:8880: Get \"https://harbor.domain12.example.com:8880/v2/\": \n    http: server gave HTTP response to HTTPS client\n  # Podman 未做任何配置登录 Harbor 报错，该 Harbor 容器镜像仓库未配置 TLS 加密传输。\n  # 报错显示 Harbor 响应 HTTP 请求，而 Podman 发送 HTTPS 请求登录。\n  # 因此，将 Podman 配置为发送 HTTP 请求的客户端。\n  ```\n  🤔 解决方式一：  \n  ```bash\n  $ podman login --tls-verify=false harbor.domain12.example.com:8880\n    Username: admin\n    Password: redhat\n    Login Succeeded!\n  # Podman 未进行任何配置，直接使用 --tls-verify=false 选项即可认证登录。\n  ```\n  🤔 解决方式二：  \n  ```bash\n  $ mkdir -p ~/.config/containers/ && cd ~/.config/containers/\n  # 创建普通用户 rootless 容器的目录\n  $ vim ~/.config/containers/registries.conf\n    unqualified-search-registries = ['harbor.domain12.example.com:8880']\n  \n    [[registry]]\n    location = \"harbor.domain12.example.com:8880\"\n    insecure = true\n    # If true, unencrypted HTTP as well as TLS connections with untrusted\n    # certificates are allowed.\n    block = false\n  # 配置未加密传输的 Harbor 容器镜像仓库的主机名与端口\n  \n  $ podman login --log-level=debug harbor.domain12.example.com:8880\n    INFO[0000] podman filtering at log level debug\n    DEBU[0000] Called login.PersistentPreRunE(podman login --log-level=debug harbor.domain12.example.com:8880)\n    DEBU[0000] overlay storage already configured with a mount-program\n    DEBU[0000] Merged system config \"/usr/share/containers/containers.conf\"\n    DEBU[0000] overlay storage already configured with a mount-program\n    DEBU[0000] Using conmon: \"/usr/bin/conmon\"\n    ...\n    DEBU[0000] Using OCI runtime \"/usr/bin/runc\"\n    DEBU[0000] Default CNI network name podman is unchangeable\n    INFO[0000] Setting parallel job count to 13\n    DEBU[0000] Loading registries configuration \"/home/kiosk/.config/containers/registries.conf\"\n    DEBU[0000] Loading registries configuration \"/etc/containers/registries.conf.d/000-shortnames.conf\"\n    DEBU[0000] Loading registries configuration \"/etc/containers/registries.conf.d/001-rhel-shortnames.conf\"\n    DEBU[0000] Loading registries configuration \"/etc/containers/registries.conf.d/002-rhel-shortnames-overrides.conf\"\n    DEBU[0000] No credentials for harbor.domain12.example.com:8880 found\n    Username: admin\n    Password: # 交互式输入登录密码\n    DEBU[0004] Looking for TLS certificates and private keys in /etc/docker/certs.d/harbor.domain12.example.com:8880\n    DEBU[0004] GET https://harbor.domain12.example.com:8880/v2/\n    DEBU[0004] Ping https://harbor.domain12.example.com:8880/v2/ err Get \"https://harbor.domain12.example.com:8880/v2/\": http: \n    server gave HTTP response to HTTPS client (&url.Error{Op:\"Get\", URL:\"https://harbor.domain12.example.com:8880/v2/\", \n    Err:(*errors.errorString)(0xc000590030)})\n    ...\n    DEBU[0004] GET http://harbor.domain12.example.com:8880/service/token?account=admin&service=harbor-registry\n    DEBU[0004] GET http://harbor.domain12.example.com:8880/v2/\n    DEBU[0004] Stored credentials for harbor.domain12.example.com:8880 in credential helper containers-auth.json\n    Login Succeeded!\n    DEBU[0004] Called login.PersistentPostRunE(podman login --log-level=debug harbor.domain12.example.com:8880)\n  # Podman 默认使用 TLS 加密传输\n  # 以上配置文件将使 Podman 以 HTTP 方式认证登录 Harbor。\n  ```\n- 示例 2： \n  👉 podman v3.2.3 推送容器镜像至 Harbor v1.8.1 中显示 \"不完整\"：  \n  ```bash\n  $ podman push harbor.domain12.example.com:8880/library/apache-rhce8.2-alpine:1.0\n    Getting image source signatures\n    Copying blob 551db21ded82 skipped: already exists\n    Copying blob 8213d0880f11 skipped: already exists\n    Copying blob e2eb06d8af82 skipped: already exists\n    ...\n    Copying blob 05e56f8d5aae skipped: already exists\n    Copying blob 631e8a8040bb skipped: already exists\n    Copying blob dedba5c062fc skipped: already exists\n    Copying blob 0e609f35aa06 [--------------------------------------] 0.0b / 0.0b\n    Copying config 34f32c2e7a [======================================] 10.0KiB / 10.0KiB\n    Writing manifest to image destination\n    Storing signatures\n  ```\n  从推送的返回结果显示，具有 2 层容器镜像层似乎未推送成功，但将该镜像从 Harbor 中拉取并重新运行容器后，容器能正常提供服务，因此最后 2 层镜像层实际推送成功。\n- 示例 3：  \n  👉 容器镜像无任何运行或退出状态容器占用，但依然无法删除镜像，可尝试使用 `--force` 选项将其强制删除。![podman-rmi-error-no-container-use.jpg](podman-rmi-error-no-container-use.jpg)\n- 示例 4：\n  👉 由于从 `dockerbub` 上直接拉取的镜像为 `docker image format`，无法使用 `podman commit` 命令提交为新的容器镜像，该命令对于 `-m` 选项不能对 docker image format 镜像生效，默认只支持 `OCI image format`，因此使用 -m 选项对容器执行提交时需强制指定 `-f docker` 才能生效。\n  \n  > 📌**注意：**\n  > \n  > 可使用 `skopeo` 工具转换 docker image format 与 OCI image format。\n  \n  ![podman-commit-warning.jpg](podman-commit-warning.jpg)\n\n- 示例 5：\n  👉 podman 运行 rootfull 或 rootless busybox 容器后，`ping` 外网报错权限问题无法 ping 通外网，但使用其他工具可与外网通信，通过 [该文档](https://www.redhat.com/sysadmin/container-networking-podman) 中可知，ping 命令对 `capability` 敏感，容器可能缺少 `CAP_NET_RAW `capability 无法通过宿主机 ping 通外网。  \n  👉 当然，运行容器时指定 `--privileged` 选项可使容器获得与宿主机 root 用户同样的与宿主机交互的权限能力，但赋予的权限过高，应当压制该权限，更好的选择是对运行容器添加适当的 `Linux capabilities`。![podman-busybox-capability.jpg](podman-busybox-capability.jpg)\n\n### Podman 有待测试功能：\nPodman 日志驱动目前只支持 `k8s-file`、`journald` 与 `none`，暂时不支持容器日志的 `JSON` 格式输出，因此不能与日志收集引擎 `fluentd` 集成，由其实现将日志传输至 ELK 或 EFK 进行集中式的存储与索引。","slug":"podman-usage-practice","published":1,"updated":"2022-12-06T02:56:01.829Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cldfonot1001r16vdfvxbn1bd","content":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li><a href=\"https://alberthua-perl.github.io/2022/12/05/podman-arch-usage/\">上一篇</a> 已说明 Podman 原理与实现，该文档将继续说明 Podman 容器的使用与实践。</li>\n</ul>\n<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>podman 单容器使用及通信方式示例</li>\n<li>使用 podman-compose 实现 Gogs 轻量级代码仓库</li>\n<li>podman pod 多容器编排使用示例</li>\n<li>使用 podman kube play 实现 WordPress 的一键部署</li>\n<li>Podman 使用报错示例</li>\n<li>Podman 有待测试功能</li>\n</ul>\n<h3 id=\"podman-单容器使用及通信方式示例：\"><a href=\"#podman-单容器使用及通信方式示例：\" class=\"headerlink\" title=\"podman 单容器使用及通信方式示例：\"></a>podman 单容器使用及通信方式示例：</h3><ul>\n<li>示例 1：<br>👉 使用 podman 命令登录 <code>Quay</code> 公共容器镜像仓库并推送镜像：<img src=\"podman-push-quay.jpg\" alt=\"podman-push-quay.jpg\">👉 搜索并拉取 Red Hat 容器镜像仓库中的镜像列表：<img src=\"podman-pull-image.jpg\" alt=\"podman-pull-image.jpg\"></li>\n<li>示例 2：<br>🤘 部署并使用云原生轻量级对象存储 <code>MinIO Server</code>：<br><img src=\"minio-server-cloud-native-object-storage-demo-1.jpg\" alt=\"minio-server-cloud-native-object-storage-demo-1.jpg\"><img src=\"minio-server-cloud-native-object-storage-demo-2.jpg\" alt=\"minio-server-cloud-native-object-storage-demo-2.jpg\">以上示例将 podman 与 systemd 集成实现普通用户的 rootless 容器开机自启动。<img src=\"minio-server-cloud-native-object-storage-demo-3.jpg\" alt=\"minio-server-cloud-native-object-storage-demo-3.jpg\">关于 MinIO Server 分布式对象存储的详细内容，请 <a href=\"https://min.io/\" target=\"_blank\" rel=\"noopener\">参考官网</a>。</li>\n<li>示例 3：<br>🤘 请参考该文档 <a href=\"https://alberthua-perl.github.io/2022/12/05/loganalyzer-rsyslog-mysql/\">部署 loganalyzer 管理集中式日志</a> 以理解多个 rootfull 容器间的通信方式（通过 <code>cni-podman0</code> 网桥与 <code>iptables</code> 互相通信）。</li>\n</ul>\n<h3 id=\"使用-podman-compose-实现-Gogs-轻量级代码仓库：\"><a href=\"#使用-podman-compose-实现-Gogs-轻量级代码仓库：\" class=\"headerlink\" title=\"使用 podman-compose 实现 Gogs 轻量级代码仓库：\"></a>使用 podman-compose 实现 Gogs 轻量级代码仓库：</h3><ul>\n<li>使用 <code>podman-compose</code> 通过 <code>link</code> 链接至指定的容器建立通信。</li>\n<li><p>如下所示，部署 Gogs 轻量级代码仓库：<code>Gogs + PostgreSQL</code>  </p>\n<ul>\n<li>关于 podman-compose 的安装可参考 <a href=\"https://github.com/containers/podman-compose\" target=\"_blank\" rel=\"noopener\">GitHub 项目</a></li>\n</ul>\n<blockquote>\n<p>🤔 可考虑使用 podman-compose 部署轻量级 <code>Gitea + Drone</code> CI 持续集成平台</p>\n</blockquote>\n<ul>\n<li>关于 Gogs 项目的详细内容可参考 <a href=\"https://github.com/gogs/gogs\" target=\"_blank\" rel=\"noopener\">Gogs GitHub 项目</a>  </li>\n<li>Gogs 代码版本控制仓库使用 Golang 语言开发，可与后端 MySQL、PostgreSQL、SQLite3、TiDB 等集成。  </li>\n<li>此处使用容器化部署 Gogs，并与 PostgreSQL 集成。  </li>\n<li><p>部署用主机上必须先安装 podman 与 podman-compose，并拉取相应容器镜像加速部署过程，如下所示：<img src=\"podman-image-list.jps.JPG\" alt=\"podman-image-list.jps.JPG\"></p>\n<blockquote>\n<p>📌<strong>注意：</strong></p>\n<p>podman-compose 使用创建 <code>pod</code> 将多个容器组建成 pod 的方式进行容器编排，因此必须具有 <code>pause</code> 容器镜像提供 pod 的共享网络命名空间与挂载命名空间。</p>\n</blockquote>\n</li>\n<li><p>使用普通用户部署，过程如下所示：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mkdir -p gogs-app/gogs-data/&#123;gogs,gogs-logs,postgresql&#125;</span><br><span class=\"line\"><span class=\"comment\"># 创建用于存储 gogs 与 postgresql 数据映射的目录</span></span><br><span class=\"line\">$ sudo chown -R 100999:100999 gogs-app/gogs-data/&#123;gogs,gogs-logs&#125;</span><br><span class=\"line\"><span class=\"comment\"># 更改映射目录的属组，否则容器启动权限报错。</span></span><br><span class=\"line\">$ getenforce</span><br><span class=\"line\">  Enforcing</span><br><span class=\"line\"><span class=\"comment\"># 确认系统处于 enforcing SELinux 状态，需设置目录映射时的标签。</span></span><br><span class=\"line\"><span class=\"comment\"># 也可禁用 SELinux，若禁用 SELinux，以下两步可不执行并且去除 podman-compose 定义文件中的 \"Z\"。</span></span><br><span class=\"line\">$ sudo semanage port -a -t http_port_t -p tcp 10800</span><br><span class=\"line\">$ sudo semanage port -a -t ssh_port_t -p tcp 10022</span><br><span class=\"line\"><span class=\"comment\"># 添加自定义端口至 SELinux 数据库中，否则由于权限问题无法访问并安装 Gogs。</span></span><br><span class=\"line\">$ vim gogs-app/gogs-postgres-podman-compose.yaml</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>如下所示 <code>gogs-postgres-podman-compose.yaml</code> 文件可参考 <a href=\"https://github.com/Alberthua-Perl/dockerfile-s2i-demo/blob/master/gogs-postgres-compose/gogs-postgres-podman-compose.yaml\" target=\"_blank\" rel=\"noopener\">此处</a>：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">version:</span> <span class=\"string\">\"3\"</span></span><br><span class=\"line\"><span class=\"attr\">services:</span></span><br><span class=\"line\">  <span class=\"attr\">postgresql:</span></span><br><span class=\"line\">    <span class=\"attr\">image:</span> <span class=\"string\">docker.io/library/postgres:14.1-bullseye</span></span><br><span class=\"line\">    <span class=\"attr\">container_name:</span> <span class=\"string\">\"gogs-postgresql\"</span></span><br><span class=\"line\">    <span class=\"attr\">volumes:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"./gogs-data/postgresql:/var/lib/postgresql:Z\"</span></span><br><span class=\"line\">    <span class=\"attr\">environment:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"POSTGRES_USER=gogs\"</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"POSTGRES_PASSWORD=redhat\"</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"POSTGRES_DB=gogs\"</span></span><br><span class=\"line\">    <span class=\"attr\">ports:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"5432:5432\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"attr\">gogs:</span></span><br><span class=\"line\">    <span class=\"attr\">image:</span> <span class=\"string\">docker.io/gogs/gogs:0.12</span></span><br><span class=\"line\">    <span class=\"attr\">container_name:</span> <span class=\"string\">\"gogs\"</span></span><br><span class=\"line\">    <span class=\"attr\">volumes:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"./gogs-data/gogs:/data:Z\"</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"./gogs-data/gogs-logs:/app/gogs/log:Z\"</span></span><br><span class=\"line\">    <span class=\"attr\">ports:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"10022:22\"</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"10800:3000\"</span></span><br><span class=\"line\">    <span class=\"attr\">links:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">postgresql</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>编辑完成 yaml 文件后，使用如下命令启动应用：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman-compose -f gogs-app/gogs-postgres-podman-compose.yaml --project gogs-app up</span><br><span class=\"line\"><span class=\"comment\"># 启动 Gogs 与 PostgreSQL 容器，并指定项目名称。</span></span><br><span class=\"line\"><span class=\"comment\"># 若不指定项目名称，项目默认为 yaml 文件所在的目录名称。</span></span><br><span class=\"line\"><span class=\"comment\"># 首次启动容器时，所有的启动与运行日志将打印至终端屏幕上，该终端不可关闭，直至关闭所有服务容器后将自动退出。</span></span><br><span class=\"line\">$ podman-compose -f gogs-app/gogs-postgres-podman-compose.yaml --project gogs-app ps</span><br><span class=\"line\">  using podman version: podman version 3.2.3</span><br><span class=\"line\">  podman ps -a --filter label=io.podman.compose.project=gogs-app</span><br><span class=\"line\">  CONTAINER ID  IMAGE                                     COMMAND               CREATED      STATUS          PORTS                                                                   NAMES</span><br><span class=\"line\">  2bed211ffe60  docker.io/library/postgres:14.1-bullseye  postgres              6 hours ago  Up 3 hours ago  0.0.0.0:10022-&gt;22/tcp, 0.0.0.0:10800-&gt;3000/tcp, 0.0.0.0:5432-&gt;5432/tcp  gogs-postgresql</span><br><span class=\"line\">  2c7d0de4b0a0  docker.io/gogs/gogs:0.12                  /bin/s6-svscan /a...  6 hours ago  Up 3 hours ago  0.0.0.0:10022-&gt;22/tcp, 0.0.0.0:10800-&gt;3000/tcp, 0.0.0.0:5432-&gt;5432/tcp  gogs</span><br><span class=\"line\">  0</span><br><span class=\"line\"><span class=\"comment\"># 查看 podman-compose 管理的容器服务</span></span><br><span class=\"line\">$ podman ps</span><br><span class=\"line\">  CONTAINER ID  IMAGE                                     COMMAND               CREATED      STATUS          PORTS                                                                   NAMES</span><br><span class=\"line\">  b6df150a3a49  k8s.gcr.io/pause:3.5                                            6 hours ago  Up 6 hours ago  0.0.0.0:10022-&gt;22/tcp, 0.0.0.0:10800-&gt;3000/tcp, 0.0.0.0:5432-&gt;5432/tcp  c3a10da46f18-infra</span><br><span class=\"line\">  2bed211ffe60  docker.io/library/postgres:14.1-bullseye  postgres              6 hours ago  Up 3 hours ago  0.0.0.0:10022-&gt;22/tcp, 0.0.0.0:10800-&gt;3000/tcp, 0.0.0.0:5432-&gt;5432/tcp  gogs-postgresql</span><br><span class=\"line\">  2c7d0de4b0a0  docker.io/gogs/gogs:0.12                  /bin/s6-svscan /a...  6 hours ago  Up 3 hours ago  0.0.0.0:10022-&gt;22/tcp, 0.0.0.0:10800-&gt;3000/tcp, 0.0.0.0:5432-&gt;5432/tcp  gogs</span><br><span class=\"line\"><span class=\"comment\"># 查看正在运行的容器，包含 infra 容器。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>所有容器正常运行后，使用 <code>http://&lt;容器宿主机 IP 地址&gt;:10800</code> 访问 Gogs 安装界面，需填入的值参考如下：<img src=\"gogs-settings.jpg\" alt=\"gogs-settings.jpg\">    </p>\n<ul>\n<li>Run User 值：默认 <code>git</code>。</li>\n<li>Domain 值：若要从其他主机连接至 Gogs 仓库，Domian 必须配置为容器宿主机的 IP 地址或主机名。</li>\n<li>SSH Port 值：podman-compose 定义文件中对外暴露的 SSH 端口号。</li>\n<li>HTTP Port 值：默认 <code>3000</code> 端口。  </li>\n</ul>\n</li>\n<li>Web 页面中最后需设置 Gogs 管理员账号以完成安装。  </li>\n<li>安装完成后，使用管理员账号登录或重新注册新账号登录与使用。  </li>\n<li>如下所示，使用 <code>devops</code> 用户创建新代码库并完成 commit 提交：<img src=\"gogs-git-repository.jpg\" alt=\"gogs-git-repository.jpg\">  </li>\n<li><p>如需关闭 Gogs 代码仓库，请使用以下方法停止 gogs 与 postgresql 容器服务即可：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman-compose -f gogs-app/gogs-postgres-podman-compose.yaml --project gogs-app stop gogs postgresql</span><br><span class=\"line\">  using podman version: podman version 3.2.3</span><br><span class=\"line\">  podman stop -t 10 gogs</span><br><span class=\"line\">  gogs</span><br><span class=\"line\">  0</span><br><span class=\"line\">  podman stop -t 10 gogs-postgresql</span><br><span class=\"line\">  gogs-postgresql</span><br><span class=\"line\">  0</span><br><span class=\"line\">$ podman ps</span><br><span class=\"line\">  CONTAINER ID  IMAGE                 COMMAND     CREATED       STATUS             PORTS                                                                   NAMES</span><br><span class=\"line\">  b6df150a3a49  k8s.gcr.io/pause:3.5              30 hours ago  Up 39 minutes ago  0.0.0.0:10022-&gt;22/tcp, 0.0.0.0:10800-&gt;3000/tcp, 0.0.0.0:5432-&gt;5432/tcp  c3a10da46f18-infra</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>💥<strong>注意：</strong></p>\n<p>切不可直接使用 podman-compose 命令的 <code>down</code> 子命令，该子命令将所有相关的容器与 pod 全部删除，pod 删除后无法将其中的各容器映射至宿主机对应的目录中，即使原始数据依然保留于目录中。</p>\n</blockquote>\n</li>\n<li><p>重新启动 Gogs 代码仓库的方式，如下所示： </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman-compose -f gogs-app/gogs-postgres-podman-compose.yaml --project gogs-app start gogs postgresql</span><br><span class=\"line\">  using podman version: podman version 3.2.3</span><br><span class=\"line\">  podman start gogs</span><br><span class=\"line\">  gogs</span><br><span class=\"line\">  0</span><br><span class=\"line\">  podman start gogs-postgresql</span><br><span class=\"line\">  gogs-postgresql</span><br><span class=\"line\">  0</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"podman-pod-多容器编排使用示例：\"><a href=\"#podman-pod-多容器编排使用示例：\" class=\"headerlink\" title=\"podman pod 多容器编排使用示例：\"></a>podman pod 多容器编排使用示例：</h3><ul>\n<li><code>podman-compose</code> 的使用依赖于 <code>python</code> 版本以及依赖包，若在不同平台中使用可能存在无法安装对应版本的 python 及依赖包的情况，因此 podman-compose 并不能很好的解决单机上的多容器编排问题。</li>\n<li>值得庆幸的是，podman 自带的 <code>podman pod</code> 子命令可原生支持多容器编排，该命令可将多容器运行于同一 pod 中使用相同的 <code>network namespace</code> 以更方便的调配容器。</li>\n<li><p>如下命令所示：<br>👉 从头创建 pod 并附加额外的容器：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman pod create --name &lt;pod_name&gt; [-p &lt;host_port&gt;:&lt;pod_port&gt;]</span><br><span class=\"line\"><span class=\"comment\"># 使用 pause 容器镜像从头创建 pod</span></span><br><span class=\"line\"><span class=\"comment\"># 若之后需在 pod 中创建使用端口映射的容器，需要在创建 pod 之初指定端口映射关系，无法在创建容器时指定，由于 pod</span></span><br><span class=\"line\"><span class=\"comment\"># 提供了其中所有容器的共享网络命名空间。</span></span><br><span class=\"line\"><span class=\"comment\"># 注意：若需指定多个端口，可同时使用多个 -p 选项。</span></span><br><span class=\"line\">$ podman run -d --name &lt;container_name&gt; --pod &lt;pod_name&gt; &lt;container_image&gt;:&lt;tag&gt;</span><br><span class=\"line\"><span class=\"comment\"># 创建容器将其附加到 pod 中</span></span><br><span class=\"line\">$ podman pod [ps|list|ls]</span><br><span class=\"line\"><span class=\"comment\"># 查看已存在的 pod</span></span><br><span class=\"line\">$ podman pod [stop|rm] &lt;pod_name&gt;</span><br><span class=\"line\"><span class=\"comment\"># 停止或删除 pod，将一并删除 pod 中的所有容器。</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>📌<strong>注意：</strong></p>\n<ol>\n<li><code>k8s.gcr.io/pause:3.5</code> 镜像拉取需要科学上网。</li>\n<li>若无法拉取，可先拉取 <code>registry.aliyuncs.com/google_containers/pause:3.5</code> 镜像，再更改其 <code>tag</code> 即可。</li>\n</ol>\n</blockquote>\n<p>👉 随创建容器时同时创建 pod：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman run -d \\</span><br><span class=\"line\">  --name &lt;container_name&gt; --pod new:&lt;pod_name&gt; \\</span><br><span class=\"line\">  [-p &lt;host_port&gt;:&lt;pod_port&gt;] \\</span><br><span class=\"line\">  &lt;container_image&gt;:&lt;tag&gt;</span><br><span class=\"line\"><span class=\"comment\"># 随创建容器时同时创建 pod</span></span><br><span class=\"line\">$ podman run -d \\</span><br><span class=\"line\">  --name &lt;container_name&gt; --pod &lt;pod_name&gt; \\</span><br><span class=\"line\">  &lt;container_image&gt;:&lt;tag&gt;</span><br><span class=\"line\"><span class=\"comment\"># 在 pod 中创建新的容器</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>示例 1：<br>如下所示，创建名为 <code>nginx-docs</code> 的容器并同时创建名为 <code>docker-docs</code> 的 pod，也可创建其他容器添加至 pod 中，pod 中的容器共享 <code>network namespace</code>：<img src=\"podman-run-pod-create.jpg\" alt=\"podman-run-pod-create.jpg\"></p>\n</li>\n<li>🤘 示例 2：<br>使用 podman 在单个 pod 中集成多容器的方法，可参考 <a href=\"https://alberthua-perl.github.io/2022/12/05/redhat-quay-v3-registry/\">之前发布的文档</a>，该文档中将 Quay、MySQL 与 Redis 的单容器集成在单个 pod 中，使用 pod 的 <code>network namespace</code> 方便 Quay 镜像仓库的管理。</li>\n</ul>\n<h3 id=\"🚀-使用-podman-kube-play-实现-WordPress-的一键部署：\"><a href=\"#🚀-使用-podman-kube-play-实现-WordPress-的一键部署：\" class=\"headerlink\" title=\"🚀 使用 podman kube play 实现 WordPress 的一键部署：\"></a>🚀 使用 podman kube play 实现 WordPress 的一键部署：</h3><ul>\n<li>除上述 podman pod 容器编排的方式以外，podman 也已支持类似于使用 <code>Kubernetes</code> 结构化 <code>yaml</code> 文件的方式，即可使用 <code>podman kube play</code> 创建 <code>Pod</code>、<code>Deployment</code> 与 <code>PersistentVolumeClaim</code> 等。</li>\n<li><p>可将由 <code>podman pod create</code> 创建的 pod 通过如下命令生成 pod 的资源定义文件：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman generate kube &lt;pod_name&gt; &gt; &lt;application_name&gt;.yml</span><br><span class=\"line\"><span class=\"comment\"># 导出已存在 pod 的资源定义文件</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>该示例中生成的 pod 资源定义文件需稍加改动用于应用的部署，可参考 <a href=\"https://github.com/Alberthua-Perl/go-kubernetes-learn-path/blob/hotfixes/mywpblog-pod.yml\" target=\"_blank\" rel=\"noopener\">该链接</a>：  </p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Pod</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">app:</span> <span class=\"string\">mywpblog</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">mywpblog</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">automountServiceAccountToken:</span> <span class=\"literal\">false</span></span><br><span class=\"line\">  <span class=\"attr\">containers:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"attr\">args:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"string\">mysqld</span></span><br><span class=\"line\">    <span class=\"attr\">env:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">MYSQL_USER</span></span><br><span class=\"line\">      <span class=\"attr\">value:</span> <span class=\"string\">wp_user</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">MYSQL_ROOT_PASSWORD</span></span><br><span class=\"line\">      <span class=\"attr\">value:</span> <span class=\"string\">redhat</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">MYSQL_PASSWORD</span></span><br><span class=\"line\">      <span class=\"attr\">value:</span> <span class=\"string\">wp_pass</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">MYSQL_DATABASE</span></span><br><span class=\"line\">      <span class=\"attr\">value:</span> <span class=\"string\">wp_blog</span></span><br><span class=\"line\">    <span class=\"attr\">image:</span> <span class=\"string\">docker.io/library/mysql:5.7.40-debian</span></span><br><span class=\"line\">    <span class=\"attr\">name:</span> <span class=\"string\">wpdatabase</span></span><br><span class=\"line\">    <span class=\"attr\">ports:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">containerPort:</span> <span class=\"number\">3306</span></span><br><span class=\"line\">      <span class=\"attr\">hostPort:</span> <span class=\"number\">3306</span></span><br><span class=\"line\">    <span class=\"attr\">resources:</span> <span class=\"string\">&#123;&#125;</span></span><br><span class=\"line\">    <span class=\"attr\">securityContext:</span></span><br><span class=\"line\">      <span class=\"attr\">capabilities:</span></span><br><span class=\"line\">        <span class=\"attr\">drop:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">CAP_MKNOD</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">CAP_NET_RAW</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">CAP_AUDIT_WRITE</span></span><br><span class=\"line\">    <span class=\"attr\">volumeMounts:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/lib/mysql</span></span><br><span class=\"line\">      <span class=\"attr\">name:</span> <span class=\"string\">tmp-wpdbfiles-host-0</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"attr\">args:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"string\">apache2-foreground</span></span><br><span class=\"line\">    <span class=\"attr\">env:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">WORDPRESS_DB_NAME</span></span><br><span class=\"line\">      <span class=\"attr\">value:</span> <span class=\"string\">wp_blog</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">WORDPRESS_DB_HOST</span></span><br><span class=\"line\">      <span class=\"attr\">value:</span> <span class=\"string\">\"0.0.0.0\"</span></span><br><span class=\"line\">      <span class=\"comment\"># WORDPRESS_DB_HOST definied as '0.0.0.0' because two containers </span></span><br><span class=\"line\">      <span class=\"comment\"># use same network namespace</span></span><br><span class=\"line\">      <span class=\"comment\"># WORDPRESS_DB_HOST is different from 'podman pod create' and </span></span><br><span class=\"line\">      <span class=\"comment\"># 'podman kube play'.</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">WORDPRESS_DB_USER</span></span><br><span class=\"line\">      <span class=\"attr\">value:</span> <span class=\"string\">wp_user</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">WORDPRESS_DB_PASSWORD</span></span><br><span class=\"line\">      <span class=\"attr\">value:</span> <span class=\"string\">wp_pass</span></span><br><span class=\"line\">    <span class=\"attr\">image:</span> <span class=\"string\">docker.io/library/wordpress:6.1.1-php7.4-apache</span></span><br><span class=\"line\">    <span class=\"attr\">name:</span> <span class=\"string\">wpfrontend</span></span><br><span class=\"line\">    <span class=\"attr\">ports:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"attr\">containerPort:</span> <span class=\"number\">80</span></span><br><span class=\"line\">        <span class=\"attr\">hostPort:</span> <span class=\"number\">8080</span></span><br><span class=\"line\">    <span class=\"attr\">resources:</span> <span class=\"string\">&#123;&#125;</span></span><br><span class=\"line\">    <span class=\"attr\">securityContext:</span></span><br><span class=\"line\">      <span class=\"attr\">capabilities:</span></span><br><span class=\"line\">        <span class=\"attr\">drop:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">CAP_MKNOD</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">CAP_NET_RAW</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">CAP_AUDIT_WRITE</span></span><br><span class=\"line\">    <span class=\"attr\">volumeMounts:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/www/html</span></span><br><span class=\"line\">      <span class=\"attr\">name:</span> <span class=\"string\">tmp-wpfront-host-0</span></span><br><span class=\"line\">  <span class=\"attr\">enableServiceLinks:</span> <span class=\"literal\">false</span></span><br><span class=\"line\">  <span class=\"attr\">hostname:</span> <span class=\"string\">mywpblog</span></span><br><span class=\"line\">  <span class=\"attr\">restartPolicy:</span> <span class=\"string\">Never</span></span><br><span class=\"line\">  <span class=\"attr\">volumes:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">      <span class=\"attr\">path:</span> <span class=\"string\">/tmp/wpdbfiles</span></span><br><span class=\"line\">      <span class=\"attr\">type:</span> <span class=\"string\">Directory</span></span><br><span class=\"line\">    <span class=\"attr\">name:</span> <span class=\"string\">tmp-wpdbfiles-host-0</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">      <span class=\"attr\">path:</span> <span class=\"string\">/tmp/wpfront</span></span><br><span class=\"line\">      <span class=\"attr\">type:</span> <span class=\"string\">Directory</span></span><br><span class=\"line\">    <span class=\"attr\">name:</span> <span class=\"string\">tmp-wpfront-host-0</span></span><br><span class=\"line\"><span class=\"attr\">status:</span> <span class=\"string\">&#123;&#125;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用该 <a href=\"https://github.com/Alberthua-Perl/go-kubernetes-learn-path/blob/hotfixes/wpblog-pod-manage\" target=\"_blank\" rel=\"noopener\">脚本</a> 实现 WordPress 应用的一键部署与管理，WordPress 容器与 MySQL 容器运行于同一 pod 中，运行成功后打开浏览器即可访问安装 WordPress 应用，如下所示：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ./wpblog-pod-manage --kube-deploy</span><br><span class=\"line\">---&gt; Start deploy blog pod...</span><br><span class=\"line\">---&gt; Use podman kube play to create and run pod...</span><br><span class=\"line\">Pod:</span><br><span class=\"line\">7e8d6586ed246380fdb9ee00e73361b16938d4f2d5b646041f5036d9b7e4e8ae</span><br><span class=\"line\">Containers:</span><br><span class=\"line\">5132590944a03adcdfc08ba27945c708ae23b19fdce24fbcda9df6c845b5bc4e</span><br><span class=\"line\">cc2e7cb2a3a5423a7f0d93d07590b5826657eeb59d0491c5578dde0a1d10de1e</span><br><span class=\"line\">---&gt; Pod and containers as followings...</span><br><span class=\"line\">POD ID        NAME        STATUS      CREATED         INFRA ID      <span class=\"comment\"># OF CONTAINERS</span></span><br><span class=\"line\">7e8d6586ed24  mywpblog    Running     34 seconds ago  ca2ea53dfcbb  3</span><br><span class=\"line\"></span><br><span class=\"line\">CONTAINER ID  IMAGE                                            COMMAND               CREATED         STATUS            PORTS                                         NAMES</span><br><span class=\"line\">ca2ea53dfcbb  localhost/podman-pause:4.3.0-1666339791                                35 seconds ago  Up 2 seconds ago  0.0.0.0:3306-&gt;3306/tcp, 0.0.0.0:8080-&gt;80/tcp  7e8d6586ed24-infra    </span><br><span class=\"line\">5132590944a0  docker.io/library/mysql:5.7.40-debian            mysqld                19 seconds ago  Up 2 seconds ago  0.0.0.0:3306-&gt;3306/tcp, 0.0.0.0:8080-&gt;80/tcp  mywpblog-wpdatabase   </span><br><span class=\"line\">cc2e7cb2a3a5  docker.io/library/wordpress:6.1.1-php7.4-apache  apache2-foregroun...  4 seconds ago   Up 2 seconds ago  0.0.0.0:3306-&gt;3306/tcp, 0.0.0.0:8080-&gt;80/tcp  mywpblog-wpfrontend   </span><br><span class=\"line\"><span class=\"comment\"># 使用 podman kube play 的方式部署 WordPress 应用</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"Podman-报错示例：\"><a href=\"#Podman-报错示例：\" class=\"headerlink\" title=\"Podman 报错示例：\"></a>Podman 报错示例：</h3><ul>\n<li>podman 容器镜像仓库的配置方式：  <ul>\n<li>全局配置：<code>/etc/containers/registries.conf</code></li>\n<li>局部配置：<code>$HOME/.config/containers/registroes.conf</code></li>\n</ul>\n</li>\n<li>若 podman 安装后在以上配置中未唯一指定的容器镜像仓库，那么在拉取容器镜像时，将交互式提示用户选择容器镜像仓库。</li>\n<li><p>Podman 登录容器镜像仓库的方式：  </p>\n<ul>\n<li><p>使用 <code>podman login</code> 子命令登录指定的容器镜像仓库时，Podman 将访问 token 默认存储于 <code>/run/user/&lt;UID&gt;/containers/auth.json</code> 文件中，当 logout 仓库时，该 token 将被移除，并且该文件中可存储多个登录的仓库 token。<img src=\"podman-login-token.jpg\" alt=\"podman-login-token.jpg\">    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman <span class=\"built_in\">logout</span> --all</span><br><span class=\"line\"><span class=\"comment\"># 登出所有的容器镜像仓库，并从 auth.json 文件中移除所有的 token。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Podman 默认情况下需要与容器镜像仓库使用 <code>TLS</code> 认证，若容器镜像仓库未配置 TLS、使用自签名的 TLS 证书或未知的 CA 签署的证书，需对 login、pull 或 push 子命令添加 <code>--tls-verify=false</code> 选项以完成认证。  </p>\n</li>\n<li>Skopeo 与 Buildah 也可使用 Podman 保存的认证 token，但是无法执行交互式的登录密码输入。</li>\n</ul>\n</li>\n<li><p>示例 1：<br>👉 podman v3.2.3 登录 Harbor v1.8.1 身份认证报错：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman login harbor.domain12.example.com:8880</span><br><span class=\"line\">  Username: admin</span><br><span class=\"line\">  Password: redhat</span><br><span class=\"line\">  Error: authenticating creds <span class=\"keyword\">for</span> <span class=\"string\">\"harbor.domain12.example.com:8880\"</span>: error pinging docker registry </span><br><span class=\"line\">  harbor.domain12.example.com:8880: Get <span class=\"string\">\"https://harbor.domain12.example.com:8880/v2/\"</span>: </span><br><span class=\"line\">  http: server gave HTTP response to HTTPS client</span><br><span class=\"line\"><span class=\"comment\"># Podman 未做任何配置登录 Harbor 报错，该 Harbor 容器镜像仓库未配置 TLS 加密传输。</span></span><br><span class=\"line\"><span class=\"comment\"># 报错显示 Harbor 响应 HTTP 请求，而 Podman 发送 HTTPS 请求登录。</span></span><br><span class=\"line\"><span class=\"comment\"># 因此，将 Podman 配置为发送 HTTP 请求的客户端。</span></span><br></pre></td></tr></table></figure>\n<p>🤔 解决方式一：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman login --tls-verify=<span class=\"literal\">false</span> harbor.domain12.example.com:8880</span><br><span class=\"line\">  Username: admin</span><br><span class=\"line\">  Password: redhat</span><br><span class=\"line\">  Login Succeeded!</span><br><span class=\"line\"><span class=\"comment\"># Podman 未进行任何配置，直接使用 --tls-verify=false 选项即可认证登录。</span></span><br></pre></td></tr></table></figure>\n<p>🤔 解决方式二：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mkdir -p ~/.config/containers/ &amp;&amp; <span class=\"built_in\">cd</span> ~/.config/containers/</span><br><span class=\"line\"><span class=\"comment\"># 创建普通用户 rootless 容器的目录</span></span><br><span class=\"line\">$ vim ~/.config/containers/registries.conf</span><br><span class=\"line\">  unqualified-search-registries = [<span class=\"string\">'harbor.domain12.example.com:8880'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">  [[registry]]</span><br><span class=\"line\">  location = <span class=\"string\">\"harbor.domain12.example.com:8880\"</span></span><br><span class=\"line\">  insecure = <span class=\"literal\">true</span></span><br><span class=\"line\">  <span class=\"comment\"># If true, unencrypted HTTP as well as TLS connections with untrusted</span></span><br><span class=\"line\">  <span class=\"comment\"># certificates are allowed.</span></span><br><span class=\"line\">  block = <span class=\"literal\">false</span></span><br><span class=\"line\"><span class=\"comment\"># 配置未加密传输的 Harbor 容器镜像仓库的主机名与端口</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ podman login --<span class=\"built_in\">log</span>-level=debug harbor.domain12.example.com:8880</span><br><span class=\"line\">  INFO[0000] podman filtering at <span class=\"built_in\">log</span> level debug</span><br><span class=\"line\">  DEBU[0000] Called login.PersistentPreRunE(podman login --<span class=\"built_in\">log</span>-level=debug harbor.domain12.example.com:8880)</span><br><span class=\"line\">  DEBU[0000] overlay storage already configured with a mount-program</span><br><span class=\"line\">  DEBU[0000] Merged system config <span class=\"string\">\"/usr/share/containers/containers.conf\"</span></span><br><span class=\"line\">  DEBU[0000] overlay storage already configured with a mount-program</span><br><span class=\"line\">  DEBU[0000] Using conmon: <span class=\"string\">\"/usr/bin/conmon\"</span></span><br><span class=\"line\">  ...</span><br><span class=\"line\">  DEBU[0000] Using OCI runtime <span class=\"string\">\"/usr/bin/runc\"</span></span><br><span class=\"line\">  DEBU[0000] Default CNI network name podman is unchangeable</span><br><span class=\"line\">  INFO[0000] Setting parallel job count to 13</span><br><span class=\"line\">  DEBU[0000] Loading registries configuration <span class=\"string\">\"/home/kiosk/.config/containers/registries.conf\"</span></span><br><span class=\"line\">  DEBU[0000] Loading registries configuration <span class=\"string\">\"/etc/containers/registries.conf.d/000-shortnames.conf\"</span></span><br><span class=\"line\">  DEBU[0000] Loading registries configuration <span class=\"string\">\"/etc/containers/registries.conf.d/001-rhel-shortnames.conf\"</span></span><br><span class=\"line\">  DEBU[0000] Loading registries configuration <span class=\"string\">\"/etc/containers/registries.conf.d/002-rhel-shortnames-overrides.conf\"</span></span><br><span class=\"line\">  DEBU[0000] No credentials <span class=\"keyword\">for</span> harbor.domain12.example.com:8880 found</span><br><span class=\"line\">  Username: admin</span><br><span class=\"line\">  Password: <span class=\"comment\"># 交互式输入登录密码</span></span><br><span class=\"line\">  DEBU[0004] Looking <span class=\"keyword\">for</span> TLS certificates and private keys <span class=\"keyword\">in</span> /etc/docker/certs.d/harbor.domain12.example.com:8880</span><br><span class=\"line\">  DEBU[0004] GET https://harbor.domain12.example.com:8880/v2/</span><br><span class=\"line\">  DEBU[0004] Ping https://harbor.domain12.example.com:8880/v2/ err Get <span class=\"string\">\"https://harbor.domain12.example.com:8880/v2/\"</span>: http: </span><br><span class=\"line\">  server gave HTTP response to HTTPS client (&amp;url.Error&#123;Op:<span class=\"string\">\"Get\"</span>, URL:<span class=\"string\">\"https://harbor.domain12.example.com:8880/v2/\"</span>, </span><br><span class=\"line\">  Err:(*errors.errorString)(0xc000590030)&#125;)</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  DEBU[0004] GET http://harbor.domain12.example.com:8880/service/token?account=admin&amp;service=harbor-registry</span><br><span class=\"line\">  DEBU[0004] GET http://harbor.domain12.example.com:8880/v2/</span><br><span class=\"line\">  DEBU[0004] Stored credentials <span class=\"keyword\">for</span> harbor.domain12.example.com:8880 <span class=\"keyword\">in</span> credential helper containers-auth.json</span><br><span class=\"line\">  Login Succeeded!</span><br><span class=\"line\">  DEBU[0004] Called login.PersistentPostRunE(podman login --<span class=\"built_in\">log</span>-level=debug harbor.domain12.example.com:8880)</span><br><span class=\"line\"><span class=\"comment\"># Podman 默认使用 TLS 加密传输</span></span><br><span class=\"line\"><span class=\"comment\"># 以上配置文件将使 Podman 以 HTTP 方式认证登录 Harbor。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>示例 2：<br>👉 podman v3.2.3 推送容器镜像至 Harbor v1.8.1 中显示 “不完整”：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman push harbor.domain12.example.com:8880/library/apache-rhce8.2-alpine:1.0</span><br><span class=\"line\">  Getting image <span class=\"built_in\">source</span> signatures</span><br><span class=\"line\">  Copying blob 551db21ded82 skipped: already exists</span><br><span class=\"line\">  Copying blob 8213d0880f11 skipped: already exists</span><br><span class=\"line\">  Copying blob e2eb06d8af82 skipped: already exists</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  Copying blob 05e56f8d5aae skipped: already exists</span><br><span class=\"line\">  Copying blob 631e8a8040bb skipped: already exists</span><br><span class=\"line\">  Copying blob dedba5c062fc skipped: already exists</span><br><span class=\"line\">  Copying blob 0e609f35aa06 [--------------------------------------] 0.0b / 0.0b</span><br><span class=\"line\">  Copying config 34f32c2e7a [======================================] 10.0KiB / 10.0KiB</span><br><span class=\"line\">  Writing manifest to image destination</span><br><span class=\"line\">  Storing signatures</span><br></pre></td></tr></table></figure>\n<p>从推送的返回结果显示，具有 2 层容器镜像层似乎未推送成功，但将该镜像从 Harbor 中拉取并重新运行容器后，容器能正常提供服务，因此最后 2 层镜像层实际推送成功。</p>\n</li>\n<li>示例 3：<br>👉 容器镜像无任何运行或退出状态容器占用，但依然无法删除镜像，可尝试使用 <code>--force</code> 选项将其强制删除。<img src=\"podman-rmi-error-no-container-use.jpg\" alt=\"podman-rmi-error-no-container-use.jpg\"></li>\n<li><p>示例 4：<br>👉 由于从 <code>dockerbub</code> 上直接拉取的镜像为 <code>docker image format</code>，无法使用 <code>podman commit</code> 命令提交为新的容器镜像，该命令对于 <code>-m</code> 选项不能对 docker image format 镜像生效，默认只支持 <code>OCI image format</code>，因此使用 -m 选项对容器执行提交时需强制指定 <code>-f docker</code> 才能生效。</p>\n<blockquote>\n<p>📌<strong>注意：</strong></p>\n<p>可使用 <code>skopeo</code> 工具转换 docker image format 与 OCI image format。</p>\n</blockquote>\n<p><img src=\"podman-commit-warning.jpg\" alt=\"podman-commit-warning.jpg\"></p>\n</li>\n<li><p>示例 5：<br>👉 podman 运行 rootfull 或 rootless busybox 容器后，<code>ping</code> 外网报错权限问题无法 ping 通外网，但使用其他工具可与外网通信，通过 <a href=\"https://www.redhat.com/sysadmin/container-networking-podman\" target=\"_blank\" rel=\"noopener\">该文档</a> 中可知，ping 命令对 <code>capability</code> 敏感，容器可能缺少 <code>CAP_NET_RAW</code>capability 无法通过宿主机 ping 通外网。<br>👉 当然，运行容器时指定 <code>--privileged</code> 选项可使容器获得与宿主机 root 用户同样的与宿主机交互的权限能力，但赋予的权限过高，应当压制该权限，更好的选择是对运行容器添加适当的 <code>Linux capabilities</code>。<img src=\"podman-busybox-capability.jpg\" alt=\"podman-busybox-capability.jpg\"></p>\n</li>\n</ul>\n<h3 id=\"Podman-有待测试功能：\"><a href=\"#Podman-有待测试功能：\" class=\"headerlink\" title=\"Podman 有待测试功能：\"></a>Podman 有待测试功能：</h3><p>Podman 日志驱动目前只支持 <code>k8s-file</code>、<code>journald</code> 与 <code>none</code>，暂时不支持容器日志的 <code>JSON</code> 格式输出，因此不能与日志收集引擎 <code>fluentd</code> 集成，由其实现将日志传输至 ELK 或 EFK 进行集中式的存储与索引。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"文档说明：\"><a href=\"#文档说明：\" class=\"headerlink\" title=\"文档说明：\"></a>文档说明：</h3><ul>\n<li><a href=\"https://alberthua-perl.github.io/2022/12/05/podman-arch-usage/\">上一篇</a> 已说明 Podman 原理与实现，该文档将继续说明 Podman 容器的使用与实践。</li>\n</ul>\n<h3 id=\"文档目录：\"><a href=\"#文档目录：\" class=\"headerlink\" title=\"文档目录：\"></a>文档目录：</h3><ul>\n<li>podman 单容器使用及通信方式示例</li>\n<li>使用 podman-compose 实现 Gogs 轻量级代码仓库</li>\n<li>podman pod 多容器编排使用示例</li>\n<li>使用 podman kube play 实现 WordPress 的一键部署</li>\n<li>Podman 使用报错示例</li>\n<li>Podman 有待测试功能</li>\n</ul>\n<h3 id=\"podman-单容器使用及通信方式示例：\"><a href=\"#podman-单容器使用及通信方式示例：\" class=\"headerlink\" title=\"podman 单容器使用及通信方式示例：\"></a>podman 单容器使用及通信方式示例：</h3><ul>\n<li>示例 1：<br>👉 使用 podman 命令登录 <code>Quay</code> 公共容器镜像仓库并推送镜像：<img src=\"podman-push-quay.jpg\" alt=\"podman-push-quay.jpg\">👉 搜索并拉取 Red Hat 容器镜像仓库中的镜像列表：<img src=\"podman-pull-image.jpg\" alt=\"podman-pull-image.jpg\"></li>\n<li>示例 2：<br>🤘 部署并使用云原生轻量级对象存储 <code>MinIO Server</code>：<br><img src=\"minio-server-cloud-native-object-storage-demo-1.jpg\" alt=\"minio-server-cloud-native-object-storage-demo-1.jpg\"><img src=\"minio-server-cloud-native-object-storage-demo-2.jpg\" alt=\"minio-server-cloud-native-object-storage-demo-2.jpg\">以上示例将 podman 与 systemd 集成实现普通用户的 rootless 容器开机自启动。<img src=\"minio-server-cloud-native-object-storage-demo-3.jpg\" alt=\"minio-server-cloud-native-object-storage-demo-3.jpg\">关于 MinIO Server 分布式对象存储的详细内容，请 <a href=\"https://min.io/\" target=\"_blank\" rel=\"noopener\">参考官网</a>。</li>\n<li>示例 3：<br>🤘 请参考该文档 <a href=\"https://alberthua-perl.github.io/2022/12/05/loganalyzer-rsyslog-mysql/\">部署 loganalyzer 管理集中式日志</a> 以理解多个 rootfull 容器间的通信方式（通过 <code>cni-podman0</code> 网桥与 <code>iptables</code> 互相通信）。</li>\n</ul>\n<h3 id=\"使用-podman-compose-实现-Gogs-轻量级代码仓库：\"><a href=\"#使用-podman-compose-实现-Gogs-轻量级代码仓库：\" class=\"headerlink\" title=\"使用 podman-compose 实现 Gogs 轻量级代码仓库：\"></a>使用 podman-compose 实现 Gogs 轻量级代码仓库：</h3><ul>\n<li>使用 <code>podman-compose</code> 通过 <code>link</code> 链接至指定的容器建立通信。</li>\n<li><p>如下所示，部署 Gogs 轻量级代码仓库：<code>Gogs + PostgreSQL</code>  </p>\n<ul>\n<li>关于 podman-compose 的安装可参考 <a href=\"https://github.com/containers/podman-compose\" target=\"_blank\" rel=\"noopener\">GitHub 项目</a></li>\n</ul>\n<blockquote>\n<p>🤔 可考虑使用 podman-compose 部署轻量级 <code>Gitea + Drone</code> CI 持续集成平台</p>\n</blockquote>\n<ul>\n<li>关于 Gogs 项目的详细内容可参考 <a href=\"https://github.com/gogs/gogs\" target=\"_blank\" rel=\"noopener\">Gogs GitHub 项目</a>  </li>\n<li>Gogs 代码版本控制仓库使用 Golang 语言开发，可与后端 MySQL、PostgreSQL、SQLite3、TiDB 等集成。  </li>\n<li>此处使用容器化部署 Gogs，并与 PostgreSQL 集成。  </li>\n<li><p>部署用主机上必须先安装 podman 与 podman-compose，并拉取相应容器镜像加速部署过程，如下所示：<img src=\"podman-image-list.jps.JPG\" alt=\"podman-image-list.jps.JPG\"></p>\n<blockquote>\n<p>📌<strong>注意：</strong></p>\n<p>podman-compose 使用创建 <code>pod</code> 将多个容器组建成 pod 的方式进行容器编排，因此必须具有 <code>pause</code> 容器镜像提供 pod 的共享网络命名空间与挂载命名空间。</p>\n</blockquote>\n</li>\n<li><p>使用普通用户部署，过程如下所示：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mkdir -p gogs-app/gogs-data/&#123;gogs,gogs-logs,postgresql&#125;</span><br><span class=\"line\"><span class=\"comment\"># 创建用于存储 gogs 与 postgresql 数据映射的目录</span></span><br><span class=\"line\">$ sudo chown -R 100999:100999 gogs-app/gogs-data/&#123;gogs,gogs-logs&#125;</span><br><span class=\"line\"><span class=\"comment\"># 更改映射目录的属组，否则容器启动权限报错。</span></span><br><span class=\"line\">$ getenforce</span><br><span class=\"line\">  Enforcing</span><br><span class=\"line\"><span class=\"comment\"># 确认系统处于 enforcing SELinux 状态，需设置目录映射时的标签。</span></span><br><span class=\"line\"><span class=\"comment\"># 也可禁用 SELinux，若禁用 SELinux，以下两步可不执行并且去除 podman-compose 定义文件中的 \"Z\"。</span></span><br><span class=\"line\">$ sudo semanage port -a -t http_port_t -p tcp 10800</span><br><span class=\"line\">$ sudo semanage port -a -t ssh_port_t -p tcp 10022</span><br><span class=\"line\"><span class=\"comment\"># 添加自定义端口至 SELinux 数据库中，否则由于权限问题无法访问并安装 Gogs。</span></span><br><span class=\"line\">$ vim gogs-app/gogs-postgres-podman-compose.yaml</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>如下所示 <code>gogs-postgres-podman-compose.yaml</code> 文件可参考 <a href=\"https://github.com/Alberthua-Perl/dockerfile-s2i-demo/blob/master/gogs-postgres-compose/gogs-postgres-podman-compose.yaml\" target=\"_blank\" rel=\"noopener\">此处</a>：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">version:</span> <span class=\"string\">\"3\"</span></span><br><span class=\"line\"><span class=\"attr\">services:</span></span><br><span class=\"line\">  <span class=\"attr\">postgresql:</span></span><br><span class=\"line\">    <span class=\"attr\">image:</span> <span class=\"string\">docker.io/library/postgres:14.1-bullseye</span></span><br><span class=\"line\">    <span class=\"attr\">container_name:</span> <span class=\"string\">\"gogs-postgresql\"</span></span><br><span class=\"line\">    <span class=\"attr\">volumes:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"./gogs-data/postgresql:/var/lib/postgresql:Z\"</span></span><br><span class=\"line\">    <span class=\"attr\">environment:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"POSTGRES_USER=gogs\"</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"POSTGRES_PASSWORD=redhat\"</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"POSTGRES_DB=gogs\"</span></span><br><span class=\"line\">    <span class=\"attr\">ports:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"5432:5432\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"attr\">gogs:</span></span><br><span class=\"line\">    <span class=\"attr\">image:</span> <span class=\"string\">docker.io/gogs/gogs:0.12</span></span><br><span class=\"line\">    <span class=\"attr\">container_name:</span> <span class=\"string\">\"gogs\"</span></span><br><span class=\"line\">    <span class=\"attr\">volumes:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"./gogs-data/gogs:/data:Z\"</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"./gogs-data/gogs-logs:/app/gogs/log:Z\"</span></span><br><span class=\"line\">    <span class=\"attr\">ports:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"10022:22\"</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">\"10800:3000\"</span></span><br><span class=\"line\">    <span class=\"attr\">links:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"string\">postgresql</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>编辑完成 yaml 文件后，使用如下命令启动应用：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman-compose -f gogs-app/gogs-postgres-podman-compose.yaml --project gogs-app up</span><br><span class=\"line\"><span class=\"comment\"># 启动 Gogs 与 PostgreSQL 容器，并指定项目名称。</span></span><br><span class=\"line\"><span class=\"comment\"># 若不指定项目名称，项目默认为 yaml 文件所在的目录名称。</span></span><br><span class=\"line\"><span class=\"comment\"># 首次启动容器时，所有的启动与运行日志将打印至终端屏幕上，该终端不可关闭，直至关闭所有服务容器后将自动退出。</span></span><br><span class=\"line\">$ podman-compose -f gogs-app/gogs-postgres-podman-compose.yaml --project gogs-app ps</span><br><span class=\"line\">  using podman version: podman version 3.2.3</span><br><span class=\"line\">  podman ps -a --filter label=io.podman.compose.project=gogs-app</span><br><span class=\"line\">  CONTAINER ID  IMAGE                                     COMMAND               CREATED      STATUS          PORTS                                                                   NAMES</span><br><span class=\"line\">  2bed211ffe60  docker.io/library/postgres:14.1-bullseye  postgres              6 hours ago  Up 3 hours ago  0.0.0.0:10022-&gt;22/tcp, 0.0.0.0:10800-&gt;3000/tcp, 0.0.0.0:5432-&gt;5432/tcp  gogs-postgresql</span><br><span class=\"line\">  2c7d0de4b0a0  docker.io/gogs/gogs:0.12                  /bin/s6-svscan /a...  6 hours ago  Up 3 hours ago  0.0.0.0:10022-&gt;22/tcp, 0.0.0.0:10800-&gt;3000/tcp, 0.0.0.0:5432-&gt;5432/tcp  gogs</span><br><span class=\"line\">  0</span><br><span class=\"line\"><span class=\"comment\"># 查看 podman-compose 管理的容器服务</span></span><br><span class=\"line\">$ podman ps</span><br><span class=\"line\">  CONTAINER ID  IMAGE                                     COMMAND               CREATED      STATUS          PORTS                                                                   NAMES</span><br><span class=\"line\">  b6df150a3a49  k8s.gcr.io/pause:3.5                                            6 hours ago  Up 6 hours ago  0.0.0.0:10022-&gt;22/tcp, 0.0.0.0:10800-&gt;3000/tcp, 0.0.0.0:5432-&gt;5432/tcp  c3a10da46f18-infra</span><br><span class=\"line\">  2bed211ffe60  docker.io/library/postgres:14.1-bullseye  postgres              6 hours ago  Up 3 hours ago  0.0.0.0:10022-&gt;22/tcp, 0.0.0.0:10800-&gt;3000/tcp, 0.0.0.0:5432-&gt;5432/tcp  gogs-postgresql</span><br><span class=\"line\">  2c7d0de4b0a0  docker.io/gogs/gogs:0.12                  /bin/s6-svscan /a...  6 hours ago  Up 3 hours ago  0.0.0.0:10022-&gt;22/tcp, 0.0.0.0:10800-&gt;3000/tcp, 0.0.0.0:5432-&gt;5432/tcp  gogs</span><br><span class=\"line\"><span class=\"comment\"># 查看正在运行的容器，包含 infra 容器。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>所有容器正常运行后，使用 <code>http://&lt;容器宿主机 IP 地址&gt;:10800</code> 访问 Gogs 安装界面，需填入的值参考如下：<img src=\"gogs-settings.jpg\" alt=\"gogs-settings.jpg\">    </p>\n<ul>\n<li>Run User 值：默认 <code>git</code>。</li>\n<li>Domain 值：若要从其他主机连接至 Gogs 仓库，Domian 必须配置为容器宿主机的 IP 地址或主机名。</li>\n<li>SSH Port 值：podman-compose 定义文件中对外暴露的 SSH 端口号。</li>\n<li>HTTP Port 值：默认 <code>3000</code> 端口。  </li>\n</ul>\n</li>\n<li>Web 页面中最后需设置 Gogs 管理员账号以完成安装。  </li>\n<li>安装完成后，使用管理员账号登录或重新注册新账号登录与使用。  </li>\n<li>如下所示，使用 <code>devops</code> 用户创建新代码库并完成 commit 提交：<img src=\"gogs-git-repository.jpg\" alt=\"gogs-git-repository.jpg\">  </li>\n<li><p>如需关闭 Gogs 代码仓库，请使用以下方法停止 gogs 与 postgresql 容器服务即可：    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman-compose -f gogs-app/gogs-postgres-podman-compose.yaml --project gogs-app stop gogs postgresql</span><br><span class=\"line\">  using podman version: podman version 3.2.3</span><br><span class=\"line\">  podman stop -t 10 gogs</span><br><span class=\"line\">  gogs</span><br><span class=\"line\">  0</span><br><span class=\"line\">  podman stop -t 10 gogs-postgresql</span><br><span class=\"line\">  gogs-postgresql</span><br><span class=\"line\">  0</span><br><span class=\"line\">$ podman ps</span><br><span class=\"line\">  CONTAINER ID  IMAGE                 COMMAND     CREATED       STATUS             PORTS                                                                   NAMES</span><br><span class=\"line\">  b6df150a3a49  k8s.gcr.io/pause:3.5              30 hours ago  Up 39 minutes ago  0.0.0.0:10022-&gt;22/tcp, 0.0.0.0:10800-&gt;3000/tcp, 0.0.0.0:5432-&gt;5432/tcp  c3a10da46f18-infra</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>💥<strong>注意：</strong></p>\n<p>切不可直接使用 podman-compose 命令的 <code>down</code> 子命令，该子命令将所有相关的容器与 pod 全部删除，pod 删除后无法将其中的各容器映射至宿主机对应的目录中，即使原始数据依然保留于目录中。</p>\n</blockquote>\n</li>\n<li><p>重新启动 Gogs 代码仓库的方式，如下所示： </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman-compose -f gogs-app/gogs-postgres-podman-compose.yaml --project gogs-app start gogs postgresql</span><br><span class=\"line\">  using podman version: podman version 3.2.3</span><br><span class=\"line\">  podman start gogs</span><br><span class=\"line\">  gogs</span><br><span class=\"line\">  0</span><br><span class=\"line\">  podman start gogs-postgresql</span><br><span class=\"line\">  gogs-postgresql</span><br><span class=\"line\">  0</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"podman-pod-多容器编排使用示例：\"><a href=\"#podman-pod-多容器编排使用示例：\" class=\"headerlink\" title=\"podman pod 多容器编排使用示例：\"></a>podman pod 多容器编排使用示例：</h3><ul>\n<li><code>podman-compose</code> 的使用依赖于 <code>python</code> 版本以及依赖包，若在不同平台中使用可能存在无法安装对应版本的 python 及依赖包的情况，因此 podman-compose 并不能很好的解决单机上的多容器编排问题。</li>\n<li>值得庆幸的是，podman 自带的 <code>podman pod</code> 子命令可原生支持多容器编排，该命令可将多容器运行于同一 pod 中使用相同的 <code>network namespace</code> 以更方便的调配容器。</li>\n<li><p>如下命令所示：<br>👉 从头创建 pod 并附加额外的容器：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman pod create --name &lt;pod_name&gt; [-p &lt;host_port&gt;:&lt;pod_port&gt;]</span><br><span class=\"line\"><span class=\"comment\"># 使用 pause 容器镜像从头创建 pod</span></span><br><span class=\"line\"><span class=\"comment\"># 若之后需在 pod 中创建使用端口映射的容器，需要在创建 pod 之初指定端口映射关系，无法在创建容器时指定，由于 pod</span></span><br><span class=\"line\"><span class=\"comment\"># 提供了其中所有容器的共享网络命名空间。</span></span><br><span class=\"line\"><span class=\"comment\"># 注意：若需指定多个端口，可同时使用多个 -p 选项。</span></span><br><span class=\"line\">$ podman run -d --name &lt;container_name&gt; --pod &lt;pod_name&gt; &lt;container_image&gt;:&lt;tag&gt;</span><br><span class=\"line\"><span class=\"comment\"># 创建容器将其附加到 pod 中</span></span><br><span class=\"line\">$ podman pod [ps|list|ls]</span><br><span class=\"line\"><span class=\"comment\"># 查看已存在的 pod</span></span><br><span class=\"line\">$ podman pod [stop|rm] &lt;pod_name&gt;</span><br><span class=\"line\"><span class=\"comment\"># 停止或删除 pod，将一并删除 pod 中的所有容器。</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>📌<strong>注意：</strong></p>\n<ol>\n<li><code>k8s.gcr.io/pause:3.5</code> 镜像拉取需要科学上网。</li>\n<li>若无法拉取，可先拉取 <code>registry.aliyuncs.com/google_containers/pause:3.5</code> 镜像，再更改其 <code>tag</code> 即可。</li>\n</ol>\n</blockquote>\n<p>👉 随创建容器时同时创建 pod：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman run -d \\</span><br><span class=\"line\">  --name &lt;container_name&gt; --pod new:&lt;pod_name&gt; \\</span><br><span class=\"line\">  [-p &lt;host_port&gt;:&lt;pod_port&gt;] \\</span><br><span class=\"line\">  &lt;container_image&gt;:&lt;tag&gt;</span><br><span class=\"line\"><span class=\"comment\"># 随创建容器时同时创建 pod</span></span><br><span class=\"line\">$ podman run -d \\</span><br><span class=\"line\">  --name &lt;container_name&gt; --pod &lt;pod_name&gt; \\</span><br><span class=\"line\">  &lt;container_image&gt;:&lt;tag&gt;</span><br><span class=\"line\"><span class=\"comment\"># 在 pod 中创建新的容器</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>示例 1：<br>如下所示，创建名为 <code>nginx-docs</code> 的容器并同时创建名为 <code>docker-docs</code> 的 pod，也可创建其他容器添加至 pod 中，pod 中的容器共享 <code>network namespace</code>：<img src=\"podman-run-pod-create.jpg\" alt=\"podman-run-pod-create.jpg\"></p>\n</li>\n<li>🤘 示例 2：<br>使用 podman 在单个 pod 中集成多容器的方法，可参考 <a href=\"https://alberthua-perl.github.io/2022/12/05/redhat-quay-v3-registry/\">之前发布的文档</a>，该文档中将 Quay、MySQL 与 Redis 的单容器集成在单个 pod 中，使用 pod 的 <code>network namespace</code> 方便 Quay 镜像仓库的管理。</li>\n</ul>\n<h3 id=\"🚀-使用-podman-kube-play-实现-WordPress-的一键部署：\"><a href=\"#🚀-使用-podman-kube-play-实现-WordPress-的一键部署：\" class=\"headerlink\" title=\"🚀 使用 podman kube play 实现 WordPress 的一键部署：\"></a>🚀 使用 podman kube play 实现 WordPress 的一键部署：</h3><ul>\n<li>除上述 podman pod 容器编排的方式以外，podman 也已支持类似于使用 <code>Kubernetes</code> 结构化 <code>yaml</code> 文件的方式，即可使用 <code>podman kube play</code> 创建 <code>Pod</code>、<code>Deployment</code> 与 <code>PersistentVolumeClaim</code> 等。</li>\n<li><p>可将由 <code>podman pod create</code> 创建的 pod 通过如下命令生成 pod 的资源定义文件：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman generate kube &lt;pod_name&gt; &gt; &lt;application_name&gt;.yml</span><br><span class=\"line\"><span class=\"comment\"># 导出已存在 pod 的资源定义文件</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>该示例中生成的 pod 资源定义文件需稍加改动用于应用的部署，可参考 <a href=\"https://github.com/Alberthua-Perl/go-kubernetes-learn-path/blob/hotfixes/mywpblog-pod.yml\" target=\"_blank\" rel=\"noopener\">该链接</a>：  </p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Pod</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\">  <span class=\"attr\">labels:</span></span><br><span class=\"line\">    <span class=\"attr\">app:</span> <span class=\"string\">mywpblog</span></span><br><span class=\"line\">  <span class=\"attr\">name:</span> <span class=\"string\">mywpblog</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\">  <span class=\"attr\">automountServiceAccountToken:</span> <span class=\"literal\">false</span></span><br><span class=\"line\">  <span class=\"attr\">containers:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"attr\">args:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"string\">mysqld</span></span><br><span class=\"line\">    <span class=\"attr\">env:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">MYSQL_USER</span></span><br><span class=\"line\">      <span class=\"attr\">value:</span> <span class=\"string\">wp_user</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">MYSQL_ROOT_PASSWORD</span></span><br><span class=\"line\">      <span class=\"attr\">value:</span> <span class=\"string\">redhat</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">MYSQL_PASSWORD</span></span><br><span class=\"line\">      <span class=\"attr\">value:</span> <span class=\"string\">wp_pass</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">MYSQL_DATABASE</span></span><br><span class=\"line\">      <span class=\"attr\">value:</span> <span class=\"string\">wp_blog</span></span><br><span class=\"line\">    <span class=\"attr\">image:</span> <span class=\"string\">docker.io/library/mysql:5.7.40-debian</span></span><br><span class=\"line\">    <span class=\"attr\">name:</span> <span class=\"string\">wpdatabase</span></span><br><span class=\"line\">    <span class=\"attr\">ports:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">containerPort:</span> <span class=\"number\">3306</span></span><br><span class=\"line\">      <span class=\"attr\">hostPort:</span> <span class=\"number\">3306</span></span><br><span class=\"line\">    <span class=\"attr\">resources:</span> <span class=\"string\">&#123;&#125;</span></span><br><span class=\"line\">    <span class=\"attr\">securityContext:</span></span><br><span class=\"line\">      <span class=\"attr\">capabilities:</span></span><br><span class=\"line\">        <span class=\"attr\">drop:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">CAP_MKNOD</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">CAP_NET_RAW</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">CAP_AUDIT_WRITE</span></span><br><span class=\"line\">    <span class=\"attr\">volumeMounts:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/lib/mysql</span></span><br><span class=\"line\">      <span class=\"attr\">name:</span> <span class=\"string\">tmp-wpdbfiles-host-0</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"attr\">args:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"string\">apache2-foreground</span></span><br><span class=\"line\">    <span class=\"attr\">env:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">WORDPRESS_DB_NAME</span></span><br><span class=\"line\">      <span class=\"attr\">value:</span> <span class=\"string\">wp_blog</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">WORDPRESS_DB_HOST</span></span><br><span class=\"line\">      <span class=\"attr\">value:</span> <span class=\"string\">\"0.0.0.0\"</span></span><br><span class=\"line\">      <span class=\"comment\"># WORDPRESS_DB_HOST definied as '0.0.0.0' because two containers </span></span><br><span class=\"line\">      <span class=\"comment\"># use same network namespace</span></span><br><span class=\"line\">      <span class=\"comment\"># WORDPRESS_DB_HOST is different from 'podman pod create' and </span></span><br><span class=\"line\">      <span class=\"comment\"># 'podman kube play'.</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">WORDPRESS_DB_USER</span></span><br><span class=\"line\">      <span class=\"attr\">value:</span> <span class=\"string\">wp_user</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">name:</span> <span class=\"string\">WORDPRESS_DB_PASSWORD</span></span><br><span class=\"line\">      <span class=\"attr\">value:</span> <span class=\"string\">wp_pass</span></span><br><span class=\"line\">    <span class=\"attr\">image:</span> <span class=\"string\">docker.io/library/wordpress:6.1.1-php7.4-apache</span></span><br><span class=\"line\">    <span class=\"attr\">name:</span> <span class=\"string\">wpfrontend</span></span><br><span class=\"line\">    <span class=\"attr\">ports:</span></span><br><span class=\"line\">      <span class=\"bullet\">-</span> <span class=\"attr\">containerPort:</span> <span class=\"number\">80</span></span><br><span class=\"line\">        <span class=\"attr\">hostPort:</span> <span class=\"number\">8080</span></span><br><span class=\"line\">    <span class=\"attr\">resources:</span> <span class=\"string\">&#123;&#125;</span></span><br><span class=\"line\">    <span class=\"attr\">securityContext:</span></span><br><span class=\"line\">      <span class=\"attr\">capabilities:</span></span><br><span class=\"line\">        <span class=\"attr\">drop:</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">CAP_MKNOD</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">CAP_NET_RAW</span></span><br><span class=\"line\">        <span class=\"bullet\">-</span> <span class=\"string\">CAP_AUDIT_WRITE</span></span><br><span class=\"line\">    <span class=\"attr\">volumeMounts:</span></span><br><span class=\"line\">    <span class=\"bullet\">-</span> <span class=\"attr\">mountPath:</span> <span class=\"string\">/var/www/html</span></span><br><span class=\"line\">      <span class=\"attr\">name:</span> <span class=\"string\">tmp-wpfront-host-0</span></span><br><span class=\"line\">  <span class=\"attr\">enableServiceLinks:</span> <span class=\"literal\">false</span></span><br><span class=\"line\">  <span class=\"attr\">hostname:</span> <span class=\"string\">mywpblog</span></span><br><span class=\"line\">  <span class=\"attr\">restartPolicy:</span> <span class=\"string\">Never</span></span><br><span class=\"line\">  <span class=\"attr\">volumes:</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">      <span class=\"attr\">path:</span> <span class=\"string\">/tmp/wpdbfiles</span></span><br><span class=\"line\">      <span class=\"attr\">type:</span> <span class=\"string\">Directory</span></span><br><span class=\"line\">    <span class=\"attr\">name:</span> <span class=\"string\">tmp-wpdbfiles-host-0</span></span><br><span class=\"line\">  <span class=\"bullet\">-</span> <span class=\"attr\">hostPath:</span></span><br><span class=\"line\">      <span class=\"attr\">path:</span> <span class=\"string\">/tmp/wpfront</span></span><br><span class=\"line\">      <span class=\"attr\">type:</span> <span class=\"string\">Directory</span></span><br><span class=\"line\">    <span class=\"attr\">name:</span> <span class=\"string\">tmp-wpfront-host-0</span></span><br><span class=\"line\"><span class=\"attr\">status:</span> <span class=\"string\">&#123;&#125;</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用该 <a href=\"https://github.com/Alberthua-Perl/go-kubernetes-learn-path/blob/hotfixes/wpblog-pod-manage\" target=\"_blank\" rel=\"noopener\">脚本</a> 实现 WordPress 应用的一键部署与管理，WordPress 容器与 MySQL 容器运行于同一 pod 中，运行成功后打开浏览器即可访问安装 WordPress 应用，如下所示：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ./wpblog-pod-manage --kube-deploy</span><br><span class=\"line\">---&gt; Start deploy blog pod...</span><br><span class=\"line\">---&gt; Use podman kube play to create and run pod...</span><br><span class=\"line\">Pod:</span><br><span class=\"line\">7e8d6586ed246380fdb9ee00e73361b16938d4f2d5b646041f5036d9b7e4e8ae</span><br><span class=\"line\">Containers:</span><br><span class=\"line\">5132590944a03adcdfc08ba27945c708ae23b19fdce24fbcda9df6c845b5bc4e</span><br><span class=\"line\">cc2e7cb2a3a5423a7f0d93d07590b5826657eeb59d0491c5578dde0a1d10de1e</span><br><span class=\"line\">---&gt; Pod and containers as followings...</span><br><span class=\"line\">POD ID        NAME        STATUS      CREATED         INFRA ID      <span class=\"comment\"># OF CONTAINERS</span></span><br><span class=\"line\">7e8d6586ed24  mywpblog    Running     34 seconds ago  ca2ea53dfcbb  3</span><br><span class=\"line\"></span><br><span class=\"line\">CONTAINER ID  IMAGE                                            COMMAND               CREATED         STATUS            PORTS                                         NAMES</span><br><span class=\"line\">ca2ea53dfcbb  localhost/podman-pause:4.3.0-1666339791                                35 seconds ago  Up 2 seconds ago  0.0.0.0:3306-&gt;3306/tcp, 0.0.0.0:8080-&gt;80/tcp  7e8d6586ed24-infra    </span><br><span class=\"line\">5132590944a0  docker.io/library/mysql:5.7.40-debian            mysqld                19 seconds ago  Up 2 seconds ago  0.0.0.0:3306-&gt;3306/tcp, 0.0.0.0:8080-&gt;80/tcp  mywpblog-wpdatabase   </span><br><span class=\"line\">cc2e7cb2a3a5  docker.io/library/wordpress:6.1.1-php7.4-apache  apache2-foregroun...  4 seconds ago   Up 2 seconds ago  0.0.0.0:3306-&gt;3306/tcp, 0.0.0.0:8080-&gt;80/tcp  mywpblog-wpfrontend   </span><br><span class=\"line\"><span class=\"comment\"># 使用 podman kube play 的方式部署 WordPress 应用</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"Podman-报错示例：\"><a href=\"#Podman-报错示例：\" class=\"headerlink\" title=\"Podman 报错示例：\"></a>Podman 报错示例：</h3><ul>\n<li>podman 容器镜像仓库的配置方式：  <ul>\n<li>全局配置：<code>/etc/containers/registries.conf</code></li>\n<li>局部配置：<code>$HOME/.config/containers/registroes.conf</code></li>\n</ul>\n</li>\n<li>若 podman 安装后在以上配置中未唯一指定的容器镜像仓库，那么在拉取容器镜像时，将交互式提示用户选择容器镜像仓库。</li>\n<li><p>Podman 登录容器镜像仓库的方式：  </p>\n<ul>\n<li><p>使用 <code>podman login</code> 子命令登录指定的容器镜像仓库时，Podman 将访问 token 默认存储于 <code>/run/user/&lt;UID&gt;/containers/auth.json</code> 文件中，当 logout 仓库时，该 token 将被移除，并且该文件中可存储多个登录的仓库 token。<img src=\"podman-login-token.jpg\" alt=\"podman-login-token.jpg\">    </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman <span class=\"built_in\">logout</span> --all</span><br><span class=\"line\"><span class=\"comment\"># 登出所有的容器镜像仓库，并从 auth.json 文件中移除所有的 token。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Podman 默认情况下需要与容器镜像仓库使用 <code>TLS</code> 认证，若容器镜像仓库未配置 TLS、使用自签名的 TLS 证书或未知的 CA 签署的证书，需对 login、pull 或 push 子命令添加 <code>--tls-verify=false</code> 选项以完成认证。  </p>\n</li>\n<li>Skopeo 与 Buildah 也可使用 Podman 保存的认证 token，但是无法执行交互式的登录密码输入。</li>\n</ul>\n</li>\n<li><p>示例 1：<br>👉 podman v3.2.3 登录 Harbor v1.8.1 身份认证报错：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman login harbor.domain12.example.com:8880</span><br><span class=\"line\">  Username: admin</span><br><span class=\"line\">  Password: redhat</span><br><span class=\"line\">  Error: authenticating creds <span class=\"keyword\">for</span> <span class=\"string\">\"harbor.domain12.example.com:8880\"</span>: error pinging docker registry </span><br><span class=\"line\">  harbor.domain12.example.com:8880: Get <span class=\"string\">\"https://harbor.domain12.example.com:8880/v2/\"</span>: </span><br><span class=\"line\">  http: server gave HTTP response to HTTPS client</span><br><span class=\"line\"><span class=\"comment\"># Podman 未做任何配置登录 Harbor 报错，该 Harbor 容器镜像仓库未配置 TLS 加密传输。</span></span><br><span class=\"line\"><span class=\"comment\"># 报错显示 Harbor 响应 HTTP 请求，而 Podman 发送 HTTPS 请求登录。</span></span><br><span class=\"line\"><span class=\"comment\"># 因此，将 Podman 配置为发送 HTTP 请求的客户端。</span></span><br></pre></td></tr></table></figure>\n<p>🤔 解决方式一：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman login --tls-verify=<span class=\"literal\">false</span> harbor.domain12.example.com:8880</span><br><span class=\"line\">  Username: admin</span><br><span class=\"line\">  Password: redhat</span><br><span class=\"line\">  Login Succeeded!</span><br><span class=\"line\"><span class=\"comment\"># Podman 未进行任何配置，直接使用 --tls-verify=false 选项即可认证登录。</span></span><br></pre></td></tr></table></figure>\n<p>🤔 解决方式二：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mkdir -p ~/.config/containers/ &amp;&amp; <span class=\"built_in\">cd</span> ~/.config/containers/</span><br><span class=\"line\"><span class=\"comment\"># 创建普通用户 rootless 容器的目录</span></span><br><span class=\"line\">$ vim ~/.config/containers/registries.conf</span><br><span class=\"line\">  unqualified-search-registries = [<span class=\"string\">'harbor.domain12.example.com:8880'</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">  [[registry]]</span><br><span class=\"line\">  location = <span class=\"string\">\"harbor.domain12.example.com:8880\"</span></span><br><span class=\"line\">  insecure = <span class=\"literal\">true</span></span><br><span class=\"line\">  <span class=\"comment\"># If true, unencrypted HTTP as well as TLS connections with untrusted</span></span><br><span class=\"line\">  <span class=\"comment\"># certificates are allowed.</span></span><br><span class=\"line\">  block = <span class=\"literal\">false</span></span><br><span class=\"line\"><span class=\"comment\"># 配置未加密传输的 Harbor 容器镜像仓库的主机名与端口</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ podman login --<span class=\"built_in\">log</span>-level=debug harbor.domain12.example.com:8880</span><br><span class=\"line\">  INFO[0000] podman filtering at <span class=\"built_in\">log</span> level debug</span><br><span class=\"line\">  DEBU[0000] Called login.PersistentPreRunE(podman login --<span class=\"built_in\">log</span>-level=debug harbor.domain12.example.com:8880)</span><br><span class=\"line\">  DEBU[0000] overlay storage already configured with a mount-program</span><br><span class=\"line\">  DEBU[0000] Merged system config <span class=\"string\">\"/usr/share/containers/containers.conf\"</span></span><br><span class=\"line\">  DEBU[0000] overlay storage already configured with a mount-program</span><br><span class=\"line\">  DEBU[0000] Using conmon: <span class=\"string\">\"/usr/bin/conmon\"</span></span><br><span class=\"line\">  ...</span><br><span class=\"line\">  DEBU[0000] Using OCI runtime <span class=\"string\">\"/usr/bin/runc\"</span></span><br><span class=\"line\">  DEBU[0000] Default CNI network name podman is unchangeable</span><br><span class=\"line\">  INFO[0000] Setting parallel job count to 13</span><br><span class=\"line\">  DEBU[0000] Loading registries configuration <span class=\"string\">\"/home/kiosk/.config/containers/registries.conf\"</span></span><br><span class=\"line\">  DEBU[0000] Loading registries configuration <span class=\"string\">\"/etc/containers/registries.conf.d/000-shortnames.conf\"</span></span><br><span class=\"line\">  DEBU[0000] Loading registries configuration <span class=\"string\">\"/etc/containers/registries.conf.d/001-rhel-shortnames.conf\"</span></span><br><span class=\"line\">  DEBU[0000] Loading registries configuration <span class=\"string\">\"/etc/containers/registries.conf.d/002-rhel-shortnames-overrides.conf\"</span></span><br><span class=\"line\">  DEBU[0000] No credentials <span class=\"keyword\">for</span> harbor.domain12.example.com:8880 found</span><br><span class=\"line\">  Username: admin</span><br><span class=\"line\">  Password: <span class=\"comment\"># 交互式输入登录密码</span></span><br><span class=\"line\">  DEBU[0004] Looking <span class=\"keyword\">for</span> TLS certificates and private keys <span class=\"keyword\">in</span> /etc/docker/certs.d/harbor.domain12.example.com:8880</span><br><span class=\"line\">  DEBU[0004] GET https://harbor.domain12.example.com:8880/v2/</span><br><span class=\"line\">  DEBU[0004] Ping https://harbor.domain12.example.com:8880/v2/ err Get <span class=\"string\">\"https://harbor.domain12.example.com:8880/v2/\"</span>: http: </span><br><span class=\"line\">  server gave HTTP response to HTTPS client (&amp;url.Error&#123;Op:<span class=\"string\">\"Get\"</span>, URL:<span class=\"string\">\"https://harbor.domain12.example.com:8880/v2/\"</span>, </span><br><span class=\"line\">  Err:(*errors.errorString)(0xc000590030)&#125;)</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  DEBU[0004] GET http://harbor.domain12.example.com:8880/service/token?account=admin&amp;service=harbor-registry</span><br><span class=\"line\">  DEBU[0004] GET http://harbor.domain12.example.com:8880/v2/</span><br><span class=\"line\">  DEBU[0004] Stored credentials <span class=\"keyword\">for</span> harbor.domain12.example.com:8880 <span class=\"keyword\">in</span> credential helper containers-auth.json</span><br><span class=\"line\">  Login Succeeded!</span><br><span class=\"line\">  DEBU[0004] Called login.PersistentPostRunE(podman login --<span class=\"built_in\">log</span>-level=debug harbor.domain12.example.com:8880)</span><br><span class=\"line\"><span class=\"comment\"># Podman 默认使用 TLS 加密传输</span></span><br><span class=\"line\"><span class=\"comment\"># 以上配置文件将使 Podman 以 HTTP 方式认证登录 Harbor。</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>示例 2：<br>👉 podman v3.2.3 推送容器镜像至 Harbor v1.8.1 中显示 “不完整”：  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ podman push harbor.domain12.example.com:8880/library/apache-rhce8.2-alpine:1.0</span><br><span class=\"line\">  Getting image <span class=\"built_in\">source</span> signatures</span><br><span class=\"line\">  Copying blob 551db21ded82 skipped: already exists</span><br><span class=\"line\">  Copying blob 8213d0880f11 skipped: already exists</span><br><span class=\"line\">  Copying blob e2eb06d8af82 skipped: already exists</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  Copying blob 05e56f8d5aae skipped: already exists</span><br><span class=\"line\">  Copying blob 631e8a8040bb skipped: already exists</span><br><span class=\"line\">  Copying blob dedba5c062fc skipped: already exists</span><br><span class=\"line\">  Copying blob 0e609f35aa06 [--------------------------------------] 0.0b / 0.0b</span><br><span class=\"line\">  Copying config 34f32c2e7a [======================================] 10.0KiB / 10.0KiB</span><br><span class=\"line\">  Writing manifest to image destination</span><br><span class=\"line\">  Storing signatures</span><br></pre></td></tr></table></figure>\n<p>从推送的返回结果显示，具有 2 层容器镜像层似乎未推送成功，但将该镜像从 Harbor 中拉取并重新运行容器后，容器能正常提供服务，因此最后 2 层镜像层实际推送成功。</p>\n</li>\n<li>示例 3：<br>👉 容器镜像无任何运行或退出状态容器占用，但依然无法删除镜像，可尝试使用 <code>--force</code> 选项将其强制删除。<img src=\"podman-rmi-error-no-container-use.jpg\" alt=\"podman-rmi-error-no-container-use.jpg\"></li>\n<li><p>示例 4：<br>👉 由于从 <code>dockerbub</code> 上直接拉取的镜像为 <code>docker image format</code>，无法使用 <code>podman commit</code> 命令提交为新的容器镜像，该命令对于 <code>-m</code> 选项不能对 docker image format 镜像生效，默认只支持 <code>OCI image format</code>，因此使用 -m 选项对容器执行提交时需强制指定 <code>-f docker</code> 才能生效。</p>\n<blockquote>\n<p>📌<strong>注意：</strong></p>\n<p>可使用 <code>skopeo</code> 工具转换 docker image format 与 OCI image format。</p>\n</blockquote>\n<p><img src=\"podman-commit-warning.jpg\" alt=\"podman-commit-warning.jpg\"></p>\n</li>\n<li><p>示例 5：<br>👉 podman 运行 rootfull 或 rootless busybox 容器后，<code>ping</code> 外网报错权限问题无法 ping 通外网，但使用其他工具可与外网通信，通过 <a href=\"https://www.redhat.com/sysadmin/container-networking-podman\" target=\"_blank\" rel=\"noopener\">该文档</a> 中可知，ping 命令对 <code>capability</code> 敏感，容器可能缺少 <code>CAP_NET_RAW</code>capability 无法通过宿主机 ping 通外网。<br>👉 当然，运行容器时指定 <code>--privileged</code> 选项可使容器获得与宿主机 root 用户同样的与宿主机交互的权限能力，但赋予的权限过高，应当压制该权限，更好的选择是对运行容器添加适当的 <code>Linux capabilities</code>。<img src=\"podman-busybox-capability.jpg\" alt=\"podman-busybox-capability.jpg\"></p>\n</li>\n</ul>\n<h3 id=\"Podman-有待测试功能：\"><a href=\"#Podman-有待测试功能：\" class=\"headerlink\" title=\"Podman 有待测试功能：\"></a>Podman 有待测试功能：</h3><p>Podman 日志驱动目前只支持 <code>k8s-file</code>、<code>journald</code> 与 <code>none</code>，暂时不支持容器日志的 <code>JSON</code> 格式输出，因此不能与日志收集引擎 <code>fluentd</code> 集成，由其实现将日志传输至 ELK 或 EFK 进行集中式的存储与索引。</p>\n"}],"PostAsset":[{"_id":"source/_posts/fcos-rhcos-basic-usage/quay-coreos-butane-release.png","slug":"quay-coreos-butane-release.png","post":"cldfonoia000116vdetjs0rfb","modified":1,"renderable":0},{"_id":"source/_posts/https-handshake-authentication/server-ca-signed-certification.png","slug":"server-ca-signed-certification.png","post":"cldfonol2000b16vdp2mvhc7i","modified":1,"renderable":0},{"_id":"source/_posts/kani-deploy-k8s/crictl-ssl-ca-request-quay-error.jpg","slug":"crictl-ssl-ca-request-quay-error.jpg","post":"cldfonola000d16vdd44th76p","modified":1,"renderable":0},{"_id":"source/_posts/kani-deploy-k8s/kubernetes-cluster-status.jpg","slug":"kubernetes-cluster-status.jpg","post":"cldfonola000d16vdd44th76p","modified":1,"renderable":0},{"_id":"source/_posts/kani-deploy-k8s/register-var-used-between-two-plays-error.jpg","slug":"register-var-used-between-two-plays-error.jpg","post":"cldfonola000d16vdd44th76p","modified":1,"renderable":0},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-6.jpg","slug":"loganalyzer-web-6.jpg","post":"cldfonoll000e16vdvqcp5vmt","modified":1,"renderable":0},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-7.jpg","slug":"loganalyzer-web-7.jpg","post":"cldfonoll000e16vdvqcp5vmt","modified":1,"renderable":0},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-5.jpg","slug":"loganalyzer-web-5.jpg","post":"cldfonoll000e16vdvqcp5vmt","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/cockpit-podman-1.jpg","slug":"cockpit-podman-1.jpg","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/cockpit-podman-2.jpg","slug":"cockpit-podman-2.jpg","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/gogs-settings.jpg","slug":"gogs-settings.jpg","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/podman-network-mode.jpg","slug":"podman-network-mode.jpg","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/podman-image-list.jps.JPG","slug":"podman-image-list.jps.JPG","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/rootless-slirp4netns-networking.jpg","slug":"rootless-slirp4netns-networking.jpg","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/redhat-quay-v3-registry/podman-push-quay-permission-denied-1001-2.jpg","slug":"podman-push-quay-permission-denied-1001-2.jpg","post":"cldfonoly000i16vdoy45as4e","modified":1,"renderable":0},{"_id":"source/_posts/skopeo-basic-usage/skopeo-inspect-creds.jpg","slug":"skopeo-inspect-creds.jpg","post":"cldfonoso001p16vdx2hmxdxp","modified":1,"renderable":0},{"_id":"source/_posts/https-handshake-authentication/client-hello-body-1.png","slug":"client-hello-body-1.png","post":"cldfonol2000b16vdp2mvhc7i","modified":1,"renderable":0},{"_id":"source/_posts/https-handshake-authentication/https-bg.png","slug":"https-bg.png","post":"cldfonol2000b16vdp2mvhc7i","modified":1,"renderable":0},{"_id":"source/_posts/https-handshake-authentication/https-mutual-no-client-cert-error-2.png","slug":"https-mutual-no-client-cert-error-2.png","post":"cldfonol2000b16vdp2mvhc7i","modified":1,"renderable":0},{"_id":"source/_posts/https-handshake-authentication/https-single-auth-chrome-error-2.png","slug":"https-single-auth-chrome-error-2.png","post":"cldfonol2000b16vdp2mvhc7i","modified":1,"renderable":0},{"_id":"source/_posts/k8s-cluster-resource-basic/kubernetes-interface-1.jpg","slug":"kubernetes-interface-1.jpg","post":"cldfonoko000816vdmg3j0qwb","modified":1,"renderable":0},{"_id":"source/_posts/https-handshake-authentication/ssl-tls-single-authentication-progress.png","slug":"ssl-tls-single-authentication-progress.png","post":"cldfonol2000b16vdp2mvhc7i","modified":1,"renderable":0},{"_id":"source/_posts/kani-deploy-k8s/kani-ansible-k8s.jpg","slug":"kani-ansible-k8s.jpg","post":"cldfonola000d16vdd44th76p","modified":1,"renderable":0},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-4.jpg","slug":"loganalyzer-web-4.jpg","post":"cldfonoll000e16vdvqcp5vmt","modified":1,"renderable":0},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/quay-push-error-1.jpg","slug":"quay-push-error-1.jpg","post":"cldfonoll000e16vdvqcp5vmt","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/external-access-container-web-service-iptables.jpg","slug":"external-access-container-web-service-iptables.jpg","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/minio-server-cloud-native-object-storage-demo-2.jpg","slug":"minio-server-cloud-native-object-storage-demo-2.jpg","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/hualf-rootless-container.jpg","slug":"hualf-rootless-container.jpg","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/podman-usage-practice/cockpit-podman-2.jpg","slug":"cockpit-podman-2.jpg","post":"cldfonot1001r16vdfvxbn1bd","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/user-namespace-subuid-mapping-1.jpg","slug":"user-namespace-subuid-mapping-1.jpg","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/podman-usage-practice/external-access-container-web-service-iptables.jpg","slug":"external-access-container-web-service-iptables.jpg","post":"cldfonot1001r16vdfvxbn1bd","modified":1,"renderable":0},{"_id":"source/_posts/podman-usage-practice/minio-server-cloud-native-object-storage-demo-2.jpg","slug":"minio-server-cloud-native-object-storage-demo-2.jpg","post":"cldfonot1001r16vdfvxbn1bd","modified":1,"renderable":0},{"_id":"source/_posts/kani-deploy-k8s/kani-ansible-k8s.svg","slug":"kani-ansible-k8s.svg","post":"cldfonola000d16vdd44th76p","modified":1,"renderable":0},{"_id":"source/_posts/skopeo-basic-usage/skopeo-copy-docker-format-image-dir.jpg","slug":"skopeo-copy-docker-format-image-dir.jpg","post":"cldfonoso001p16vdx2hmxdxp","modified":1,"renderable":0},{"_id":"source/_posts/skopeo-basic-usage/skopeo-copy-oci-2.jpg","slug":"skopeo-copy-oci-2.jpg","post":"cldfonoso001p16vdx2hmxdxp","modified":1,"renderable":0},{"_id":"source/_posts/https-handshake-authentication/ssl-four-handshakes-https-single-and-mutual-authentication.png","slug":"ssl-four-handshakes-https-single-and-mutual-authentication.png","post":"cldfonol2000b16vdp2mvhc7i","modified":1,"renderable":0},{"_id":"source/_posts/https-handshake-authentication/wireshark-https-mutual-progress.png","slug":"wireshark-https-mutual-progress.png","post":"cldfonol2000b16vdp2mvhc7i","modified":1,"renderable":0},{"_id":"source/_posts/k8s-cluster-resource-basic/kubernetes-apiserver-manifest.jpg","slug":"kubernetes-apiserver-manifest.jpg","post":"cldfonoko000816vdmg3j0qwb","modified":1,"renderable":0},{"_id":"source/_posts/k8s-cluster-resource-basic/kubernetes-single-master-arch.jpg","slug":"kubernetes-single-master-arch.jpg","post":"cldfonoko000816vdmg3j0qwb","modified":1,"renderable":0},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-8.jpg","slug":"loganalyzer-web-8.jpg","post":"cldfonoll000e16vdvqcp5vmt","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/centos79-kernel-not-support-podman-rootless.jpg","slug":"centos79-kernel-not-support-podman-rootless.jpg","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/podman-usage-practice/rootless-container-to-container-bandwidth.jpg","slug":"rootless-container-to-container-bandwidth.jpg","post":"cldfonot1001r16vdfvxbn1bd","modified":1,"renderable":0},{"_id":"source/_posts/podman-usage-practice/user-namespace-subuid-mapping-1.jpg","slug":"user-namespace-subuid-mapping-1.jpg","post":"cldfonot1001r16vdfvxbn1bd","modified":1,"renderable":0},{"_id":"source/_posts/kani-deploy-k8s/kubeadm-init-master-error-2.jpg","slug":"kubeadm-init-master-error-2.jpg","post":"cldfonola000d16vdd44th76p","modified":1,"renderable":0},{"_id":"source/_posts/kani-deploy-k8s/kubeadm-init-master-error-1.jpg","slug":"kubeadm-init-master-error-1.jpg","post":"cldfonola000d16vdd44th76p","modified":1,"renderable":0},{"_id":"source/_posts/redhat-quay-v3-registry/ssl-key-permission-run-quay-error.jpg","slug":"ssl-key-permission-run-quay-error.jpg","post":"cldfonoly000i16vdoy45as4e","modified":1,"renderable":0},{"_id":"source/_posts/rocketchat-mongodb-on-k8s/mongodb-bg-2.png","slug":"mongodb-bg-2.png","post":"cldfonoma000l16vdkg1vquml","modified":1,"renderable":0},{"_id":"source/_posts/skopeo-basic-usage/skopeo-copy-docker-daemon.jpg","slug":"skopeo-copy-docker-daemon.jpg","post":"cldfonoso001p16vdx2hmxdxp","modified":1,"renderable":0},{"_id":"source/_posts/skopeo-basic-usage/skopeo-copy-oci-1.jpg","slug":"skopeo-copy-oci-1.jpg","post":"cldfonoso001p16vdx2hmxdxp","modified":1,"renderable":0},{"_id":"source/_posts/golang-code-server/code-server-bg.png","post":"cldfonojo000316vdbsql1wkd","slug":"code-server-bg.png","modified":1,"renderable":1},{"_id":"source/_posts/kubeadm-update-k8s-certs/kubeadm-certs-bg.jpg","post":"cldfonokl000716vde5os9l41","slug":"kubeadm-certs-bg.jpg","modified":1,"renderable":1},{"_id":"source/_posts/rocketchat-mongodb-on-k8s/rocketchat-login.png","post":"cldfonoma000l16vdkg1vquml","slug":"rocketchat-login.png","modified":1,"renderable":1},{"_id":"source/_posts/rocketchat-mongodb-on-k8s/rocketchat-mongo-app-resources.png","slug":"rocketchat-mongo-app-resources.png","post":"cldfonoma000l16vdkg1vquml","modified":1,"renderable":0},{"_id":"source/_posts/rocketchat-mongodb-on-k8s/rocketchat-mongo-connect-successfully.png","slug":"rocketchat-mongo-connect-successfully.png","post":"cldfonoma000l16vdkg1vquml","modified":1,"renderable":0},{"_id":"source/_posts/rocketchat-mongodb-on-k8s/rocketchat-with-mismatch-version-mongo-error.png","slug":"rocketchat-with-mismatch-version-mongo-error.png","post":"cldfonoma000l16vdkg1vquml","modified":1,"renderable":0},{"_id":"source/_posts/fcos-rhcos-basic-usage/coreos-installer-customized-install.png","post":"cldfonoia000116vdetjs0rfb","slug":"coreos-installer-customized-install.png","modified":1,"renderable":1},{"_id":"source/_posts/fcos-rhcos-basic-usage/fedora-coreos-bg.jpg","slug":"fedora-coreos-bg.jpg","post":"cldfonoia000116vdetjs0rfb","modified":1,"renderable":0},{"_id":"source/_posts/fcos-rhcos-basic-usage/fedora-coreos-release-version.png","post":"cldfonoia000116vdetjs0rfb","slug":"fedora-coreos-release-version.png","modified":1,"renderable":1},{"_id":"source/_posts/fcos-rhcos-basic-usage/login-fedora-coreos-live.png","post":"cldfonoia000116vdetjs0rfb","slug":"login-fedora-coreos-live.png","modified":1,"renderable":1},{"_id":"source/_posts/fcos-rhcos-basic-usage/use-fedora-coreos-live-to-install.png","post":"cldfonoia000116vdetjs0rfb","slug":"use-fedora-coreos-live-to-install.png","modified":1,"renderable":1},{"_id":"source/_posts/k8s-cluster-resource-basic/k8s-resource-basic.png","post":"cldfonoko000816vdmg3j0qwb","slug":"k8s-resource-basic.png","modified":1,"renderable":1},{"_id":"source/_posts/k8s-cluster-resource-basic/k8s-resource-basic.svg","post":"cldfonoko000816vdmg3j0qwb","slug":"k8s-resource-basic.svg","modified":1,"renderable":1},{"_id":"source/_posts/k8s-cluster-resource-basic/kubectl-get-raw-json.jpg","post":"cldfonoko000816vdmg3j0qwb","slug":"kubectl-get-raw-json.jpg","modified":1,"renderable":1},{"_id":"source/_posts/k8s-cluster-resource-basic/kubernetes-ha-arch-demo.jpg","slug":"kubernetes-ha-arch-demo.jpg","post":"cldfonoko000816vdmg3j0qwb","modified":1,"renderable":0},{"_id":"source/_posts/k8s-cluster-resource-basic/kubernetes-interface-2.jpg","post":"cldfonoko000816vdmg3j0qwb","slug":"kubernetes-interface-2.jpg","modified":1,"renderable":1},{"_id":"source/_posts/k8s-cluster-resource-basic/pod-name.jpg","post":"cldfonoko000816vdmg3j0qwb","slug":"pod-name.jpg","modified":1,"renderable":1},{"_id":"source/_posts/skopeo-basic-usage/skopeo-oci-image-format-digest.jpg","slug":"skopeo-oci-image-format-digest.jpg","post":"cldfonoso001p16vdx2hmxdxp","modified":1,"renderable":0},{"_id":"source/_posts/golang-environment-deploy/golang-develop-bg.png","post":"cldfonokg000616vdxjsn08as","slug":"golang-develop-bg.png","modified":1,"renderable":1},{"_id":"source/_posts/golang-environment-deploy/golang-develop-bg.svg","post":"cldfonokg000616vdxjsn08as","slug":"golang-develop-bg.svg","modified":1,"renderable":1},{"_id":"source/_posts/golang-environment-deploy/sublime-text-golang-1.png","post":"cldfonokg000616vdxjsn08as","slug":"sublime-text-golang-1.png","modified":1,"renderable":1},{"_id":"source/_posts/golang-environment-deploy/sublime-text-golang-2.png","post":"cldfonokg000616vdxjsn08as","slug":"sublime-text-golang-2.png","modified":1,"renderable":1},{"_id":"source/_posts/golang-environment-deploy/sublime-text-golang-3.png","post":"cldfonokg000616vdxjsn08as","slug":"sublime-text-golang-3.png","modified":1,"renderable":1},{"_id":"source/_posts/golang-environment-deploy/sublime-text-golang-4.png","post":"cldfonokg000616vdxjsn08as","slug":"sublime-text-golang-4.png","modified":1,"renderable":1},{"_id":"source/_posts/golang-environment-deploy/sublime-text-golang-5.png","post":"cldfonokg000616vdxjsn08as","slug":"sublime-text-golang-5.png","modified":1,"renderable":1},{"_id":"source/_posts/golang-environment-deploy/sublime-text-golang-6.png","post":"cldfonokg000616vdxjsn08as","slug":"sublime-text-golang-6.png","modified":1,"renderable":1},{"_id":"source/_posts/golang-environment-deploy/sublime-text-golang-7.png","post":"cldfonokg000616vdxjsn08as","slug":"sublime-text-golang-7.png","modified":1,"renderable":1},{"_id":"source/_posts/golang-environment-deploy/sublime-text-golang-8.png","post":"cldfonokg000616vdxjsn08as","slug":"sublime-text-golang-8.png","modified":1,"renderable":1},{"_id":"source/_posts/golang-environment-deploy/vim-error.jpg","post":"cldfonokg000616vdxjsn08as","slug":"vim-error.jpg","modified":1,"renderable":1},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/hello-world-dark-bg.jpg","slug":"hello-world-dark-bg.jpg","post":"cldfonoll000e16vdvqcp5vmt","modified":1,"renderable":0},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-mysql-rsyslogserver.jpg","post":"cldfonoll000e16vdvqcp5vmt","slug":"loganalyzer-mysql-rsyslogserver.jpg","modified":1,"renderable":1},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-1.jpg","post":"cldfonoll000e16vdvqcp5vmt","slug":"loganalyzer-web-1.jpg","modified":1,"renderable":1},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-10.jpg","slug":"loganalyzer-web-10.jpg","post":"cldfonoll000e16vdvqcp5vmt","modified":1,"renderable":0},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-2.jpg","post":"cldfonoll000e16vdvqcp5vmt","slug":"loganalyzer-web-2.jpg","modified":1,"renderable":1},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-3.jpg","slug":"loganalyzer-web-3.jpg","post":"cldfonoll000e16vdvqcp5vmt","modified":1,"renderable":0},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/loganalyzer-web-9.jpg","post":"cldfonoll000e16vdvqcp5vmt","slug":"loganalyzer-web-9.jpg","modified":1,"renderable":1},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/mysql-container-run-error.jpg","slug":"mysql-container-run-error.jpg","post":"cldfonoll000e16vdvqcp5vmt","modified":1,"renderable":0},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/quay-push-error-2.jpg","post":"cldfonoll000e16vdvqcp5vmt","slug":"quay-push-error-2.jpg","modified":1,"renderable":1},{"_id":"source/_posts/loganalyzer-rsyslog-mysql/selinux-php-mysql-connection.jpg","slug":"selinux-php-mysql-connection.jpg","post":"cldfonoll000e16vdvqcp5vmt","modified":1,"renderable":0},{"_id":"source/_posts/redhat-quay-v3-registry/catalog-health-index.jpg","post":"cldfonoly000i16vdoy45as4e","slug":"catalog-health-index.jpg","modified":1,"renderable":1},{"_id":"source/_posts/redhat-quay-v3-registry/config-quay-1.png","post":"cldfonoly000i16vdoy45as4e","slug":"config-quay-1.png","modified":1,"renderable":1},{"_id":"source/_posts/redhat-quay-v3-registry/config-quay-2.png","post":"cldfonoly000i16vdoy45as4e","slug":"config-quay-2.png","modified":1,"renderable":1},{"_id":"source/_posts/redhat-quay-v3-registry/config-quay-3.png","post":"cldfonoly000i16vdoy45as4e","slug":"config-quay-3.png","modified":1,"renderable":1},{"_id":"source/_posts/redhat-quay-v3-registry/config-quay-4.png","post":"cldfonoly000i16vdoy45as4e","slug":"config-quay-4.png","modified":1,"renderable":1},{"_id":"source/_posts/redhat-quay-v3-registry/config-quay-5.png","post":"cldfonoly000i16vdoy45as4e","slug":"config-quay-5.png","modified":1,"renderable":1},{"_id":"source/_posts/redhat-quay-v3-registry/config-quay-6.png","post":"cldfonoly000i16vdoy45as4e","slug":"config-quay-6.png","modified":1,"renderable":1},{"_id":"source/_posts/redhat-quay-v3-registry/config-quay-7.png","post":"cldfonoly000i16vdoy45as4e","slug":"config-quay-7.png","modified":1,"renderable":1},{"_id":"source/_posts/redhat-quay-v3-registry/config-quay-8.png","post":"cldfonoly000i16vdoy45as4e","slug":"config-quay-8.png","modified":1,"renderable":1},{"_id":"source/_posts/redhat-quay-v3-registry/docker-client-login-quay-registry.jpg","post":"cldfonoly000i16vdoy45as4e","slug":"docker-client-login-quay-registry.jpg","modified":1,"renderable":1},{"_id":"source/_posts/redhat-quay-v3-registry/first-login-config-quay.png","post":"cldfonoly000i16vdoy45as4e","slug":"first-login-config-quay.png","modified":1,"renderable":1},{"_id":"source/_posts/redhat-quay-v3-registry/go-toolset-catalog.jpg","post":"cldfonoly000i16vdoy45as4e","slug":"go-toolset-catalog.jpg","modified":1,"renderable":1},{"_id":"source/_posts/redhat-quay-v3-registry/normal-login-quay.png","post":"cldfonoly000i16vdoy45as4e","slug":"normal-login-quay.png","modified":1,"renderable":1},{"_id":"source/_posts/redhat-quay-v3-registry/podman-push-quay-permission-denied-1001-1.jpg","post":"cldfonoly000i16vdoy45as4e","slug":"podman-push-quay-permission-denied-1001-1.jpg","modified":1,"renderable":1},{"_id":"source/_posts/redhat-quay-v3-registry/redhat-quay-bg.jpg","slug":"redhat-quay-bg.jpg","post":"cldfonoly000i16vdoy45as4e","modified":1,"renderable":0},{"_id":"source/_posts/https-handshake-authentication/client-server-tcp-ssl-socket.png","post":"cldfonol2000b16vdp2mvhc7i","slug":"client-server-tcp-ssl-socket.png","modified":1,"renderable":1},{"_id":"source/_posts/podman-arch-usage/rootless-container-to-container-bandwidth.jpg","post":"cldfonols000g16vdrnw9xusi","slug":"rootless-container-to-container-bandwidth.jpg","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/ca-signed-certification-verify.jpg","post":"cldfonol2000b16vdp2mvhc7i","slug":"ca-signed-certification-verify.jpg","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/client-hello-body-2.png","post":"cldfonol2000b16vdp2mvhc7i","slug":"client-hello-body-2.png","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/client-response-to-server-ssl.jpg","post":"cldfonol2000b16vdp2mvhc7i","slug":"client-response-to-server-ssl.jpg","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/firefox-import-pc12-certs-1.png","post":"cldfonol2000b16vdp2mvhc7i","slug":"firefox-import-pc12-certs-1.png","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/firefox-import-pc12-certs-2.png","post":"cldfonol2000b16vdp2mvhc7i","slug":"firefox-import-pc12-certs-2.png","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/firefox-import-pc12-certs-3.png","post":"cldfonol2000b16vdp2mvhc7i","slug":"firefox-import-pc12-certs-3.png","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/firefox-import-pc12-certs-4.png","post":"cldfonol2000b16vdp2mvhc7i","slug":"firefox-import-pc12-certs-4.png","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/firefox-import-pc12-certs-5.png","post":"cldfonol2000b16vdp2mvhc7i","slug":"firefox-import-pc12-certs-5.png","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/https-mutual-no-client-cert-error-1.png","post":"cldfonol2000b16vdp2mvhc7i","slug":"https-mutual-no-client-cert-error-1.png","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/https-single-auth-chrome-error-1.png","post":"cldfonol2000b16vdp2mvhc7i","slug":"https-single-auth-chrome-error-1.png","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/server-hello-done.jpg","post":"cldfonol2000b16vdp2mvhc7i","slug":"server-hello-done.jpg","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/server-key-exchange.png","post":"cldfonol2000b16vdp2mvhc7i","slug":"server-key-exchange.png","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/server-response-to-client-4-phase.png","post":"cldfonol2000b16vdp2mvhc7i","slug":"server-response-to-client-4-phase.png","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/server-response-to-client-ssl.png","post":"cldfonol2000b16vdp2mvhc7i","slug":"server-response-to-client-ssl.png","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/ssl-tls-authentication.png","post":"cldfonol2000b16vdp2mvhc7i","slug":"ssl-tls-authentication.png","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/ssl-tls-handshake-end.png","post":"cldfonol2000b16vdp2mvhc7i","slug":"ssl-tls-handshake-end.png","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/ssl-tls-in-network-stack.png","post":"cldfonol2000b16vdp2mvhc7i","slug":"ssl-tls-in-network-stack.png","modified":1,"renderable":1},{"_id":"source/_posts/https-handshake-authentication/wireshark-https-single-progress.png","slug":"wireshark-https-single-progress.png","post":"cldfonol2000b16vdp2mvhc7i","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/user-namespace-subuid-mapping-2-edited.png","post":"cldfonols000g16vdrnw9xusi","slug":"user-namespace-subuid-mapping-2-edited.png","modified":1,"renderable":1},{"_id":"source/_posts/podman-arch-usage/container-access-external-iptables.jpg","post":"cldfonols000g16vdrnw9xusi","slug":"container-access-external-iptables.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-arch-usage/godev-rootless-container.jpg","slug":"godev-rootless-container.jpg","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/gogs-git-repository.jpg","post":"cldfonols000g16vdrnw9xusi","slug":"gogs-git-repository.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-arch-usage/minio-server-cloud-native-object-storage-demo-1.jpg","post":"cldfonols000g16vdrnw9xusi","slug":"minio-server-cloud-native-object-storage-demo-1.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-arch-usage/minio-server-cloud-native-object-storage-demo-3.jpg","post":"cldfonols000g16vdrnw9xusi","slug":"minio-server-cloud-native-object-storage-demo-3.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-arch-usage/podman-bg.png","slug":"podman-bg.png","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/podman-bg.webp","post":"cldfonols000g16vdrnw9xusi","slug":"podman-bg.webp","modified":1,"renderable":1},{"_id":"source/_posts/podman-arch-usage/podman-busybox-capability.jpg","post":"cldfonols000g16vdrnw9xusi","slug":"podman-busybox-capability.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-arch-usage/podman-commit-warning.jpg","post":"cldfonols000g16vdrnw9xusi","slug":"podman-commit-warning.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-arch-usage/podman-login-token.jpg","post":"cldfonols000g16vdrnw9xusi","slug":"podman-login-token.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-arch-usage/podman-macvlan-network.png","slug":"podman-macvlan-network.png","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/podman-pull-image.jpg","slug":"podman-pull-image.jpg","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/podman-push-quay.jpg","post":"cldfonols000g16vdrnw9xusi","slug":"podman-push-quay.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-arch-usage/podman-rmi-error-no-container-use.jpg","post":"cldfonols000g16vdrnw9xusi","slug":"podman-rmi-error-no-container-use.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-arch-usage/podman-run-pod-create.jpg","post":"cldfonols000g16vdrnw9xusi","slug":"podman-run-pod-create.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-arch-usage/podman-version-compare.png","post":"cldfonols000g16vdrnw9xusi","slug":"podman-version-compare.png","modified":1,"renderable":1},{"_id":"source/_posts/podman-arch-usage/rootfull-container-to-container-bandwidth.jpg","slug":"rootfull-container-to-container-bandwidth.jpg","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/rootless-user-namespace-mapping.jpg","slug":"rootless-user-namespace-mapping.jpg","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/user-namespace-subuid-mapping-1-edited.png","slug":"user-namespace-subuid-mapping-1-edited.png","post":"cldfonols000g16vdrnw9xusi","modified":1,"renderable":0},{"_id":"source/_posts/podman-arch-usage/user-namespace-subuid-mapping-2.jpg","post":"cldfonols000g16vdrnw9xusi","slug":"user-namespace-subuid-mapping-2.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/centos79-kernel-not-support-podman-rootless.jpg","slug":"centos79-kernel-not-support-podman-rootless.jpg","post":"cldfonot1001r16vdfvxbn1bd","modified":1,"renderable":0},{"_id":"source/_posts/podman-usage-practice/user-namespace-subuid-mapping-2-edited.png","slug":"user-namespace-subuid-mapping-2-edited.png","post":"cldfonot1001r16vdfvxbn1bd","modified":1,"renderable":0},{"_id":"source/_posts/skopeo-basic-usage/podman-load-dir-from-skopeo-copy.jpg","post":"cldfonoso001p16vdx2hmxdxp","slug":"podman-load-dir-from-skopeo-copy.jpg","modified":1,"renderable":1},{"_id":"source/_posts/skopeo-basic-usage/skopeo-bg.jpg","post":"cldfonoso001p16vdx2hmxdxp","slug":"skopeo-bg.jpg","modified":1,"renderable":1},{"_id":"source/_posts/skopeo-basic-usage/skopeo-copy-dest-creds.jpg","post":"cldfonoso001p16vdx2hmxdxp","slug":"skopeo-copy-dest-creds.jpg","modified":1,"renderable":1},{"_id":"source/_posts/skopeo-basic-usage/skopeo-copy-dir-2.jpg","post":"cldfonoso001p16vdx2hmxdxp","slug":"skopeo-copy-dir-2.jpg","modified":1,"renderable":1},{"_id":"source/_posts/skopeo-basic-usage/skopeo-copy-transform-image-format.jpg","post":"cldfonoso001p16vdx2hmxdxp","slug":"skopeo-copy-transform-image-format.jpg","modified":1,"renderable":1},{"_id":"source/_posts/skopeo-basic-usage/skopeo-delete-1.jpg","post":"cldfonoso001p16vdx2hmxdxp","slug":"skopeo-delete-1.jpg","modified":1,"renderable":1},{"_id":"source/_posts/skopeo-basic-usage/skopeo-delete-2.jpg","post":"cldfonoso001p16vdx2hmxdxp","slug":"skopeo-delete-2.jpg","modified":1,"renderable":1},{"_id":"source/_posts/skopeo-basic-usage/skopeo-docker-image-format-digest-1.jpg","post":"cldfonoso001p16vdx2hmxdxp","slug":"skopeo-docker-image-format-digest-1.jpg","modified":1,"renderable":1},{"_id":"source/_posts/skopeo-basic-usage/skopeo-docker-image-format-digest-2.jpg","post":"cldfonoso001p16vdx2hmxdxp","slug":"skopeo-docker-image-format-digest-2.jpg","modified":1,"renderable":1},{"_id":"source/_posts/skopeo-basic-usage/skopeo-sync-between-registry.jpg","post":"cldfonoso001p16vdx2hmxdxp","slug":"skopeo-sync-between-registry.jpg","modified":1,"renderable":1},{"_id":"source/_posts/skopeo-basic-usage/skopeo-sync-demo.jpg","post":"cldfonoso001p16vdx2hmxdxp","slug":"skopeo-sync-demo.jpg","modified":1,"renderable":1},{"_id":"source/_posts/skopeo-basic-usage/skopeo-sync-help.jpg","post":"cldfonoso001p16vdx2hmxdxp","slug":"skopeo-sync-help.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/cockpit-podman-1.jpg","post":"cldfonot1001r16vdfvxbn1bd","slug":"cockpit-podman-1.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/container-access-external-iptables.jpg","post":"cldfonot1001r16vdfvxbn1bd","slug":"container-access-external-iptables.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/godev-rootless-container.jpg","slug":"godev-rootless-container.jpg","post":"cldfonot1001r16vdfvxbn1bd","modified":1,"renderable":0},{"_id":"source/_posts/podman-usage-practice/gogs-git-repository.jpg","post":"cldfonot1001r16vdfvxbn1bd","slug":"gogs-git-repository.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/gogs-settings.jpg","post":"cldfonot1001r16vdfvxbn1bd","slug":"gogs-settings.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/hualf-rootless-container.jpg","post":"cldfonot1001r16vdfvxbn1bd","slug":"hualf-rootless-container.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/minio-server-cloud-native-object-storage-demo-1.jpg","post":"cldfonot1001r16vdfvxbn1bd","slug":"minio-server-cloud-native-object-storage-demo-1.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/minio-server-cloud-native-object-storage-demo-3.jpg","post":"cldfonot1001r16vdfvxbn1bd","slug":"minio-server-cloud-native-object-storage-demo-3.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/podman-bg.webp","post":"cldfonot1001r16vdfvxbn1bd","slug":"podman-bg.webp","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/podman-busybox-capability.jpg","post":"cldfonot1001r16vdfvxbn1bd","slug":"podman-busybox-capability.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/podman-commit-warning.jpg","post":"cldfonot1001r16vdfvxbn1bd","slug":"podman-commit-warning.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/podman-image-list.jps.JPG","post":"cldfonot1001r16vdfvxbn1bd","slug":"podman-image-list.jps.JPG","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/podman-login-token.jpg","post":"cldfonot1001r16vdfvxbn1bd","slug":"podman-login-token.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/podman-macvlan-network.png","slug":"podman-macvlan-network.png","post":"cldfonot1001r16vdfvxbn1bd","modified":1,"renderable":0},{"_id":"source/_posts/podman-usage-practice/podman-network-mode.jpg","post":"cldfonot1001r16vdfvxbn1bd","slug":"podman-network-mode.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/podman-pull-image.jpg","slug":"podman-pull-image.jpg","post":"cldfonot1001r16vdfvxbn1bd","modified":1,"renderable":0},{"_id":"source/_posts/podman-usage-practice/podman-push-quay.jpg","post":"cldfonot1001r16vdfvxbn1bd","slug":"podman-push-quay.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/podman-rmi-error-no-container-use.jpg","post":"cldfonot1001r16vdfvxbn1bd","slug":"podman-rmi-error-no-container-use.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/podman-run-pod-create.jpg","post":"cldfonot1001r16vdfvxbn1bd","slug":"podman-run-pod-create.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/rootfull-container-to-container-bandwidth.jpg","slug":"rootfull-container-to-container-bandwidth.jpg","post":"cldfonot1001r16vdfvxbn1bd","modified":1,"renderable":0},{"_id":"source/_posts/podman-usage-practice/rootless-slirp4netns-networking.jpg","post":"cldfonot1001r16vdfvxbn1bd","slug":"rootless-slirp4netns-networking.jpg","modified":1,"renderable":1},{"_id":"source/_posts/podman-usage-practice/rootless-user-namespace-mapping.jpg","slug":"rootless-user-namespace-mapping.jpg","post":"cldfonot1001r16vdfvxbn1bd","modified":1,"renderable":0},{"_id":"source/_posts/podman-usage-practice/user-namespace-subuid-mapping-1-edited.png","slug":"user-namespace-subuid-mapping-1-edited.png","post":"cldfonot1001r16vdfvxbn1bd","modified":1,"renderable":0},{"_id":"source/_posts/podman-usage-practice/user-namespace-subuid-mapping-2.jpg","post":"cldfonot1001r16vdfvxbn1bd","slug":"user-namespace-subuid-mapping-2.jpg","modified":1,"renderable":1},{"_id":"source/_posts/linux-process-uid/linux-ruid-euid-test.png","slug":"linux-ruid-euid-test.png","post":"cldfonoky000a16vd2mlvz048","modified":1,"renderable":0},{"_id":"source/_posts/linux-process-uid/linux-process-uid-table.png","slug":"linux-process-uid-table.png","post":"cldfonoky000a16vd2mlvz048","modified":1,"renderable":0},{"_id":"source/_posts/linux-process-uid/linux-process-uid-mapping.png","slug":"linux-process-uid-mapping.png","post":"cldfonoky000a16vd2mlvz048","modified":1,"renderable":0},{"_id":"source/_posts/linux-process-uid/linux-process_bg.jpg","slug":"linux-process_bg.jpg","post":"cldfonoky000a16vd2mlvz048","modified":1,"renderable":0}],"PostCategory":[],"PostTag":[{"post_id":"cldfonoia000116vdetjs0rfb","tag_id":"cldfonok9000516vdt952szzj","_id":"cldfonolu000h16vdjn9in2do"},{"post_id":"cldfonoia000116vdetjs0rfb","tag_id":"cldfonokq000916vd8vn29wp5","_id":"cldfonom1000j16vdsnbho0fq"},{"post_id":"cldfonoia000116vdetjs0rfb","tag_id":"cldfonol4000c16vdxhope1b2","_id":"cldfonomf000m16vd174flat7"},{"post_id":"cldfonojo000316vdbsql1wkd","tag_id":"cldfonolq000f16vdsugl6dn1","_id":"cldfonomm000n16vdcxerup1z"},{"post_id":"cldfonokg000616vdxjsn08as","tag_id":"cldfonolq000f16vdsugl6dn1","_id":"cldfononj000q16vdw1t9e21f"},{"post_id":"cldfonokg000616vdxjsn08as","tag_id":"cldfonomv000o16vdqlhjv902","_id":"cldfonont000r16vdhx4ji5r0"},{"post_id":"cldfonokl000716vde5os9l41","tag_id":"cldfonond000p16vd10ybfqt3","_id":"cldfonoog000u16vdwp4kgy9v"},{"post_id":"cldfonokl000716vde5os9l41","tag_id":"cldfonomv000o16vdqlhjv902","_id":"cldfonoos000v16vd3w0bt4ov"},{"post_id":"cldfonoko000816vdmg3j0qwb","tag_id":"cldfonond000p16vd10ybfqt3","_id":"cldfonoph000y16vdra41kkf4"},{"post_id":"cldfonoko000816vdmg3j0qwb","tag_id":"cldfonomv000o16vdqlhjv902","_id":"cldfonopr000z16vdqgeb0tdd"},{"post_id":"cldfonol2000b16vdp2mvhc7i","tag_id":"cldfonopv001016vdd4sbmanl","_id":"cldfonoqa001416vdtcbskmza"},{"post_id":"cldfonola000d16vdd44th76p","tag_id":"cldfonond000p16vd10ybfqt3","_id":"cldfonoqt001816vds0seovtr"},{"post_id":"cldfonola000d16vdd44th76p","tag_id":"cldfonomv000o16vdqlhjv902","_id":"cldfonoqt001916vdlzoxkzmv"},{"post_id":"cldfonola000d16vdd44th76p","tag_id":"cldfonoqr001616vdap14g8zr","_id":"cldfonoqu001b16vdpv92xaej"},{"post_id":"cldfonoll000e16vdvqcp5vmt","tag_id":"cldfonok9000516vdt952szzj","_id":"cldfonoqu001c16vdlg54ro4n"},{"post_id":"cldfonoll000e16vdvqcp5vmt","tag_id":"cldfonoqs001716vdm3evp9do","_id":"cldfonoqv001e16vdu6upo0es"},{"post_id":"cldfonols000g16vdrnw9xusi","tag_id":"cldfonoqs001716vdm3evp9do","_id":"cldfonoqx001g16vdujrg53oi"},{"post_id":"cldfonols000g16vdrnw9xusi","tag_id":"cldfonomv000o16vdqlhjv902","_id":"cldfonoqx001h16vd3exse8p2"},{"post_id":"cldfonoly000i16vdoy45as4e","tag_id":"cldfonoqs001716vdm3evp9do","_id":"cldfonor0001k16vdhgqe4yvp"},{"post_id":"cldfonoly000i16vdoy45as4e","tag_id":"cldfonomv000o16vdqlhjv902","_id":"cldfonor1001l16vdzs3x4r0x"},{"post_id":"cldfonoma000l16vdkg1vquml","tag_id":"cldfonond000p16vd10ybfqt3","_id":"cldfonor1001n16vdk675fitk"},{"post_id":"cldfonoma000l16vdkg1vquml","tag_id":"cldfonor1001m16vd6uo1cil6","_id":"cldfonor1001o16vdden0uxz0"},{"post_id":"cldfonoso001p16vdx2hmxdxp","tag_id":"cldfonoqs001716vdm3evp9do","_id":"cldfonot6001s16vd9cxds17v"},{"post_id":"cldfonoso001p16vdx2hmxdxp","tag_id":"cldfonomv000o16vdqlhjv902","_id":"cldfonotb001t16vd9nddp4m7"},{"post_id":"cldfonot1001r16vdfvxbn1bd","tag_id":"cldfonoqs001716vdm3evp9do","_id":"cldfonotk001u16vdvky1iu1t"},{"post_id":"cldfonot1001r16vdfvxbn1bd","tag_id":"cldfonomv000o16vdqlhjv902","_id":"cldfonotq001v16vd16l3vv73"},{"post_id":"cldfonoky000a16vd2mlvz048","tag_id":"cldfonok9000516vdt952szzj","_id":"cldfoxspr001y16vd8nav8k4y"},{"post_id":"cldfonoky000a16vd2mlvz048","tag_id":"cldfonop9000x16vdeeupddex","_id":"cldfoxsps001z16vdi3et0sdf"}],"Tag":[{"name":"Linux","_id":"cldfonok9000516vdt952szzj"},{"name":"coreos","_id":"cldfonokq000916vd8vn29wp5"},{"name":"OpenShift","_id":"cldfonol4000c16vdxhope1b2"},{"name":"Golang","_id":"cldfonolq000f16vdsugl6dn1"},{"name":"云原生","_id":"cldfonomv000o16vdqlhjv902"},{"name":"Kubernetes","_id":"cldfonond000p16vd10ybfqt3"},{"name":"进程","_id":"cldfonop9000x16vdeeupddex"},{"name":"HTTPS","_id":"cldfonopv001016vdd4sbmanl"},{"name":"Ansible","_id":"cldfonoqr001616vdap14g8zr"},{"name":"容器","_id":"cldfonoqs001716vdm3evp9do"},{"name":"数据库","_id":"cldfonor1001m16vd6uo1cil6"}]}}